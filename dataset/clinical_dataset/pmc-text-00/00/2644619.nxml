<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN" "archivearticle.dtd"><article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article" xml:lang="EN"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Integr Neurosci</journal-id><journal-id journal-id-type="publisher-id">Front. Integr. Neurosci.</journal-id><journal-title>Frontiers in Integrative Neuroscience</journal-title><issn pub-type="epub">1662-5145</issn><publisher><publisher-name>Frontiers Research Foundation</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">19225578</article-id><article-id pub-id-type="pmc">2644619</article-id><article-id pub-id-type="doi">10.3389/neuro.07.001.2009</article-id><article-categories><subj-group subj-group-type="heading"><subject>Neuroscience</subject><subj-group><subject>Original Research</subject></subj-group></subj-group></article-categories><title-group><article-title>Covert Expectation-of-Reward in Rat Ventral Striatum at Decision Points</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>van der Meer</surname><given-names>Matthijs A. A.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Redish</surname><given-names>A. David</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="author-notes" rid="fn001">*</xref></contrib></contrib-group><aff id="aff1"><sup>1</sup><institution>Department of Neuroscience, University of Minnesota</institution><country>Minneapolis, MN, USA</country></aff><author-notes><fn fn-type="edited-by"><p>Edited by: Rui M. Costa, National Institutes of Health, USA</p></fn><fn fn-type="edited-by"><p>Reviewed by: Geoffrey Schoenbaum, University of Maryland School of Medicine, USA; Henry H. Yin, Duke University, USA; Yael Niv, Princeton University, USA</p></fn><corresp id="fn001">*Correspondence: A. David Redish, Department of Neuroscience, University of Minnesota, 6-145 Jackson Hall, 321 Church Street SE, Minneapolis, MN 55455, USA. e-mail: <email>redish@umn.edu</email>; <email>mvdm@umn.edu</email></corresp></author-notes><pub-date pub-type="epreprint"><day>18</day><month>1</month><year>2009</year></pub-date><pub-date pub-type="epub"><day>05</day><month>2</month><year>2009</year></pub-date><pub-date pub-type="collection"><year>2009</year></pub-date><volume>3</volume><elocation-id>1</elocation-id><history><date date-type="received"><day>12</day><month>12</month><year>2008</year></date><date date-type="accepted"><day>22</day><month>1</month><year>2009</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2009 van der Meer and Redish.</copyright-statement><copyright-year>2009</copyright-year><license license-type="open-access" xlink:href="http://www.frontiersin.org/licenseagreement"><p>This is an open-access article subject to an exclusive license agreement between the authors and the Frontiers Research Foundation, which permits unrestricted use, distribution, and reproduction in any medium, provided the original authors and source are credited.</p></license></permissions><abstract><p>Flexible decision-making strategies (such as planning) are a key component of adaptive behavior, yet their neural mechanisms have remained resistant to experimental analysis. Theories of planning require prediction and evaluation of potential future rewards, suggesting that reward signals may covertly appear at decision points. To test this idea, we recorded ensembles of ventral striatal neurons on a spatial decision task, in which hippocampal ensembles are known to represent future possibilities at decision points. We found representations of reward which were not only activated at actual reward delivery sites, but also at a high-cost choice point and before error correction. This expectation-of-reward signal at decision points was apparent at both the single cell and the ensemble level, and vanished with behavioral automation. We conclude that ventral striatal representations of reward are more dynamic than suggested by previous reports of reward- and cue-responsive cells, and may provide the necessary signal for evaluation of internally generated possibilities considered during flexible decision-making.</p></abstract><kwd-group><kwd>ventral striatum</kwd><kwd>reward</kwd><kwd>decision-making</kwd><kwd>nucleus accumbens</kwd><kwd>ensemble decoding</kwd></kwd-group><counts><fig-count count="10"/><table-count count="0"/><equation-count count="0"/><ref-count count="79"/><page-count count="15"/><word-count count="11747"/></counts></article-meta></front><body><sec sec-type="introduction"><title>Introduction</title><p>Flexible decision-making strategies are thought to rely on the processing of information beyond current sensory input (Buckner and Carroll, <xref ref-type="bibr" rid="B10">2007</xref>; Hebb, <xref ref-type="bibr" rid="B27">1949</xref>; Tolman, <xref ref-type="bibr" rid="B73">1932</xref>). In particular, a process of generating and evaluating possible outcomes before they are actually experienced has been proposed to support complex behaviors such as sensitivity to reward devaluation and action-outcome contingencies in conditioning experiments (Adams and Dickinson, <xref ref-type="bibr" rid="B1">1981</xref>; Balleine and Dickinson, <xref ref-type="bibr" rid="B6">1998</xref>; Holman, <xref ref-type="bibr" rid="B29">1975</xref>), spatial (place) navigation in rats (Johnson and Redish, <xref ref-type="bibr" rid="B32">2007</xref>; O'Keefe and Nadel, <xref ref-type="bibr" rid="B52">1978</xref>; Tolman, <xref ref-type="bibr" rid="B74">1948</xref>), and problem solving in humans (Miller et al., <xref ref-type="bibr" rid="B41">1960</xref>; Newell and Simon, <xref ref-type="bibr" rid="B46">1972</xref>; Shallice, <xref ref-type="bibr" rid="B69">1982</xref>). Put simply, such theories propose that this flexible &#x0201c;planning&#x0201d; system selects a particular action because it (a) predicts the action's outcome, and (b) judges the outcome to be desirable (Balleine, <xref ref-type="bibr" rid="B5">2001</xref>; Cardinal et al., <xref ref-type="bibr" rid="B11">2002</xref>; Niv et al., <xref ref-type="bibr" rid="B49">2006</xref>; Redish and Johnson, <xref ref-type="bibr" rid="B58">2007</xref>; Toates, <xref ref-type="bibr" rid="B72">1986</xref>). Such a system derives adaptive power from the ability to evaluate the desirability of potential outcomes and choose accordingly, in contrast to rigid stimulus-response or cache-based processing to which it is thought to give way with repeated, stable experience (Daw et al., <xref ref-type="bibr" rid="B19">2005</xref>; Poldrack and Packard, <xref ref-type="bibr" rid="B56">2003</xref>; Redish et al., <xref ref-type="bibr" rid="B57">2008</xref>).</p><p>Prediction and evaluation of potential outcomes implies the existence of neural representations spatiotemporally dissociated from current stimuli (Hebb, <xref ref-type="bibr" rid="B27">1949</xref>; Johnson et al., <xref ref-type="bibr" rid="B33">2007</xref>, <xref ref-type="bibr" rid="B31">2009</xref>). That is, representations in planning systems are intrinsically dynamic, as opposed to a determinate response to any particular external stimulus. This has made such signals hard to detect. While circumstances such as novelty or uncertainty are thought to engage the planning system (Daw et al., <xref ref-type="bibr" rid="B19">2005</xref>), the representations within it can change from trial to trial and from moment to moment. Ensemble recording and decoding techniques allow examination of such dynamics: a recent recording study in the rodent hippocampus found that as rats pause at a choice point on a spatial task, hippocampal place representations transiently sweep forward of the animal (Johnson and Redish, <xref ref-type="bibr" rid="B32">2007</xref>). Such non-local representations could provide a prediction component of flexible decision-making; however, no suitable evaluative signal has yet been identified.</p><p>A candidate location for such a signal is the ventral striatum, which receives inputs from the hippocampal formation through the subiculum (Finch, <xref ref-type="bibr" rid="B22">1996</xref>; Groenewegen et al., <xref ref-type="bibr" rid="B25">1987</xref>; Voorn et al., <xref ref-type="bibr" rid="B76">2004</xref>), enabling fast-timescale firing patterns in hippocampus to affect ventral striatal activity (Martin, <xref ref-type="bibr" rid="B38">2001</xref>; Pennartz et al., <xref ref-type="bibr" rid="B55">2004</xref>). A current integrative view on ventral striatal function holds it mediates the influence of motivationally relevant stimuli on behavior (Cardinal et al., <xref ref-type="bibr" rid="B11">2002</xref>; Day and Carelli, <xref ref-type="bibr" rid="B20">2007</xref>; Kelley, <xref ref-type="bibr" rid="B34">2004</xref>). In support of this idea, ventral striatal lesions impair responding to cues predictive of reward (Corbit et al., <xref ref-type="bibr" rid="B16">2001</xref>; Parkinson et al., <xref ref-type="bibr" rid="B54">2002</xref>; Schoenbaum and Setlow, <xref ref-type="bibr" rid="B65">2003</xref>). Recording studies have found a prominent population responsive to reward receipt (Apicella et al., <xref ref-type="bibr" rid="B3">1991</xref>; Carelli, <xref ref-type="bibr" rid="B13">2002</xref>); in addition, some ventral striatal cells show anticipatory ramping responses (Lavoie and Mizumori, <xref ref-type="bibr" rid="B37">1994</xref>; Miyazaki et al., <xref ref-type="bibr" rid="B42">1998</xref>) or bind to cues predictive of reward (Roitman et al., <xref ref-type="bibr" rid="B59">2005</xref>; Setlow et al., <xref ref-type="bibr" rid="B68">2003</xref>; Wheeler et al., <xref ref-type="bibr" rid="B77">2008</xref>). Such cue-elicited responses are thought to underlie the motivational impact of reward-predictive cues on behavior.</p><p>In contrast to this established role of ventral striatal representations of reward in cue-driven (stimulus-response) settings, relatively little is known about the involvement of reward representations underlying instrumental (action-outcome) behavior. While lesion evidence for ventral striatal involvement in tasks demonstrably requiring outcome-dependent processing is conflicting (Corbit et al., <xref ref-type="bibr" rid="B16">2001</xref>; de Borchgrave et al., <xref ref-type="bibr" rid="B21">2002</xref>), several studies testing a range of spatial and instrumental behaviors have implicated ventral striatum (Atallah et al., <xref ref-type="bibr" rid="B4">2007</xref>; Cardinal et al., <xref ref-type="bibr" rid="B12">2001</xref>; Floresco et al., <xref ref-type="bibr" rid="B23">1997</xref>; Setlow, <xref ref-type="bibr" rid="B67">1997</xref>; Sutherland and Rodriguez, <xref ref-type="bibr" rid="B70">1989</xref>). However, it is not clear if these deficits can be fully accounted for by reward-predictive cue responses. More generally, it is not known if and how representations of reward might contribute to flexible decision-making, when different outcomes are under active consideration. Given non-local hippocampal representations of future possibilities during decision-making (Johnson and Redish, <xref ref-type="bibr" rid="B32">2007</xref>), functional projections from hippocampus to ventral striatum, and ventral striatal involvement in reward processing, we hypothesized that ventral striatum encoded non-local representations of reward at decision points. We sought to test this idea by recording ventral striatal neural ensembles on the same Multiple-T task where hippocampal representations of future possibilities were found.</p></sec><sec sec-type="materials|methods"><title>Materials and Methods</title><sec><title>Subjects</title><p>Five male Brown Norway-Fisher 344 hybrid rats (Harlan, IA, USA), aged 10&#x02013;12&#x02009;months at the start of behavioral training, were trained to run the Multiple-T task, described below. Rats were food deprived to no less than 85% of their free-feeding body weight during behavioral training; water was available ad libitum in the home cage at all times. All procedures were conducted in accordance with National Institutes of Health guidelines for animal care and approved by the IACUC at the University of Minnesota. Care was taken to minimize the number of animals used in these experiments and to minimize suffering.</p></sec><sec><title>Surgery</title><p>After pre-training on the task, rats were chronically implanted with an electrode array consisting of 12 tetrodes and 2 reference electrodes (&#x0201c;hyperdrive&#x0201d;, Kopf, Tujunga, CA, USA) targeting the ventral striatum (coordinates: AP + 1.2, ML &#x000b1; 2.3&#x02013;2.5 mm relative to bregma). Surgical and histological procedures were as described previously (Johnson and Redish, <xref ref-type="bibr" rid="B32">2007</xref>; Schmitzer-Torbert and Redish, <xref ref-type="bibr" rid="B62">2004</xref>).</p></sec><sec><title>Multiple-T task</title><p>As described before (Johnson and Redish, <xref ref-type="bibr" rid="B32">2007</xref>; Schmitzer-Torbert and Redish, <xref ref-type="bibr" rid="B62">2004</xref>), the Multiple-T task apparatus is a carpet-lined track elevated 15&#x02009;cm above the floor, consisting of a <italic>navigation sequence</italic> of 3&#x02013;5 T-choices, and two <italic>return rails</italic> leading back to the start of the sequence (Figure <xref ref-type="fig" rid="F1">1</xref>A). Both return rails are equipped with two feeder sites, set up to deliver two 45-mg food pellets each (Research Diets, New Brunswick, NJ, USA) through computer-controlled pellet dispensers (Med-Associates, St. Albans, VT, USA). Pellets are released when a ceiling-mounted camera and a position tracking system (Cheetah, Neuralynx, Bozeman, MT, USA, and custom software written in MATLAB, Natick, MA, USA) detected the rat crossing an active feeder trigger line (green lines in Figure <xref ref-type="fig" rid="F1">1</xref>A); these events (&#x0201c;feeder fires&#x0201d;, time 0 in the peri-stimulus time histograms in Figures <xref ref-type="fig" rid="F3">3</xref>, <xref ref-type="fig" rid="F4">4</xref>, <xref ref-type="fig" rid="F7">7</xref>, <xref ref-type="fig" rid="F8">8</xref> and <xref ref-type="fig" rid="F9">9</xref>) were time-stamped and recorded for later analysis. This system will deliver food pellets onto the track within a zone of about 15&#x02009;cm in length around the feeder; however, rats quickly learn to push their snout into the food delivery tube, often catching the pellets as they arrive before they fall onto the track. It was possible for a pellet to fall off the track with the rat unable to retrieve it, but such occurrences were rare. Because the pellet dispensers were mounted on the walls, away from the track, pellets take between 1 and 2&#x02009;s from release (feeder fire) to arrival on the track.</p><fig id="F1" position="float"><label>Figure 1</label><caption><p><bold>Behavior on the Multiple-T maze</bold>. <bold>(A)</bold> Diagram of a single Multiple-T configuration (&#x0201c;RRLL&#x0201d;). T1&#x02013;4 indicate turns, with T4 the final choice point (CP). Food reward is delivered at the feeder sites (F1, F2) when the rat crosses the active feeder trigger lines (in green). Tracking data for the entire session (grey dots) shows one error lap to the unrewarded (right)&#x02009;side, as well as smaller deviations at turn 3 (T3), the final CP, and the return rails. <bold>(B)</bold>&#x02009;Fraction of correct laps within a session, averaged over all sessions and rats. A correct lap was defined as crossing the first trigger line on the rewarded side [green line in panel <bold>(A)</bold>]; an error lap was defined as entering the equivalent region on the unrewarded side. <bold>(C)</bold> Time spent at the CP [red line, red box in panel <bold>(A)</bold>] normalized by lap time is increased during early, but not late laps, as compared to a control area [blue line, blue box in <bold>(A)</bold>]. Lap times <bold>(D)</bold>&#x02009;are computed as the time taken from entering the navigation sequence [light orange section in panel <bold>(A)</bold>] at the bottom of the maze to exiting it at the top. Shaded areas are S.E.M. over recording sessions.</p></caption><graphic xlink:href="fnint-03-001-g001"/></fig><p>In any given session, only one set of feeders (either on the left or the right return rail) is active, such that a rat navigating the maze is required to learn which is the active (rewarded) side for that session in order to obtain reward. The number and arrangement of T-choices in the navigation sequence could be varied between sessions. For training prior to surgery, rats were first allowed to run on 3-T mazes, with the incorrect final choice blocked, and the turn sequence changed every day, until they ran at least 50 laps for 2 consecutive days. Daily sessions lasted 40&#x02009;min. Next, the blocks were removed and 3-T training continued until the 2-day 50 laps criterion was reached again, and again using 5-T mazes. Once rats met the 2-day 50 laps criterion on 5-T, they were ready for surgery. Training took between 2 and 3&#x02009;weeks for all rats.</p><p>After surgery, rats were allowed to recover for 2&#x02013;3&#x02009;days on a free feeding schedule to return to a stable weight, before being returned to 3-T training. Once rats were back to running proficiently and accustomed to running with the recording headstage and cable, the main experimental protocol commenced (typically starting 10&#x02013;20&#x02009;days after surgery). Rats were run on 4-T mazes in a sequence of seven novel/seven unchanged/seven novel configurations, for a total of 21 sessions per rat. Novel sequences consisted of session-unique sequences of which choices were correct for that session, e.g. &#x0201c;RRLL&#x0201d; in Figure <xref ref-type="fig" rid="F1">1</xref>A, &#x0201c;LLLR,&#x0201d; &#x0201c;RLRL,&#x0201d; et cetera, such that 14 out of 16 possible configurations were used. For the seven familiar days, the (initially) novel configururation from the seventh novel day was repeated. Analyses did not distinguish between novel and familiar sessions.</p><fig id="F2" position="float"><label>Figure 2</label><caption><p><bold>Electrode locations were mostly confirmed to be in ventral striatum (nucleus accumbens core, shell, and ventral caudate-putamen)</bold>. Shown are final tetrode locations as identified by current-induced gliosis marks. As animals had a very uniform distribution of number of cells recorded from each tetrode, cells recorded from any one single tetrode would be expected to be a negligible influence on the results. While some tetrode locations from animal 129 were caudal and medial to the target, this animal only contributed a relatively small proportion of cells to the data set. Based on these considerations, we estimate that at least 90% of spike trains were recorded from ventral striatum.</p></caption><graphic xlink:href="fnint-03-001-g002"/></fig></sec><sec><title>Data collection</title><p>Following surgery, tetrodes were first rapidly advanced 2&#x02009;mm in 2&#x02009;days, followed by a slower regime of &#x0003c;320&#x02009;&#x003bc;m per day. Unit and local field activity was monitored for changes from cortex to corpus callosum to dorsal striatum (Schmitzer-Torbert and Redish, <xref ref-type="bibr" rid="B63">2008</xref>) as an early depth calibration, and subsequently for the appearance of strong, transient 50&#x02009;Hz oscillations (Masimore et al., <xref ref-type="bibr" rid="B40">2005</xref>). For our implant coordinates these appeared reliably at a depth of around 4&#x02013;5&#x02009;mm from the cortical surface; after reaching an estimated depth of 5.5&#x02013;6&#x02009;mm, tetrodes were only advanced in small amounts (&#x0003c;40&#x02009;&#x003bc;m per day) with the aim of assembling the largest possible ensemble.</p><p>Neural activity was recorded using a 64 channel Cheetah recording system (Neuralynx, Bozeman, MT, USA) as described previously (Johnson et al., <xref ref-type="bibr" rid="B33">2007</xref>; Schmitzer-Torbert and Redish, <xref ref-type="bibr" rid="B62">2004</xref>, <xref ref-type="bibr" rid="B63">2008</xref>). For the majority of the recording sessions, a positive voltage threshold was used and 1&#x02009;ms (32 samples) spike waveforms were recorded. For some sessions, the filtered electrical potentials were written continuously to disk, and spikes were identified in these recordings offline using both positive and negative voltage thresholds to trigger spikes and generate waveforms for cluster cutting.</p><p>Spikes were clustered off-line into putative cells on the basis of their waveform properties using MClust 3.4 (A.D. Redish, current software available at <uri xlink:type="simple" xlink:href="http://umn.edu/&#x0223c;redish/mclust">http://umn.edu/&#x0223c;redish/mclust</uri>), with automatic pre-clustering using KlustaKwik 1.5 (K. Harris, available at <uri xlink:type="simple" xlink:href="http://klustakwik.sourceforge.net">http://klustakwik.sourceforge.net</uri>) to create a set of spike trains, each of which was a list of the times at which action potentials occurred for one putative neuron. Because tetrodes with good recording quality were not moved between sessions, the number of distinct cells recorded is less than the number of spike trains.</p><p>During recording sessions, the position of the rat was tracked using LEDs on the recording headstage. During training, a LED &#x0201c;backpack&#x0201d; constructed in the laboratory was used. The position of the LEDs was observed by an overhead camera, and recorded and time-stamped by the Cheetah system.</p></sec><sec><title>Data analysis</title><sec><title>Cell categorization</title><p>Cells were assigned to one of three putative cell type categories: PFN, TFN, and HFN, based on their firing properties, as described in Schmitzer-Torbert and Redish (<xref ref-type="bibr" rid="B63">2008</xref>). Each cell was tested for reward- and maze-responsiveness. To test for a reward response, the cell's actual average spike count in the window from 1 to 5 s after both feeder trigger times was <italic>z</italic>-scored relative to the distribution of spike counts obtained from 100 sets of randomly shuffled feeder times. A cell was classified as reward-responsive if its reward <italic>z</italic>-score was larger than 2. To test for a maze response, the position data for that session was first linearized and warped to allow comparison across sessions (described below), and subsequently divided into seven segments that did not include the area around the feeders. If the one-factor ANOVA significance level of the cell's average firing rate with maze segment as a factor was below 0.05, the cell was classified as maze-responsive.</p></sec><sec><title>Path linearization and warping</title><p>In order to allow averaging of neural data across different paths taken on different maze configurations, the two-dimensional position of the rat on the maze was mapped to the closest point on an idealized path (the typical path taken through the maze by the rat, see Schmitzer-Torbert and Redish, <xref ref-type="bibr" rid="B62">2004</xref> for an example) to create a one-dimensional representation of the path rats took through the Multiple-T maze. This idealized path was drawn off-line by the experimenter, and the locations of seven landmarks (start of the navigation sequence, turns 1&#x02013;4, and the two feeder sites) identified. The position data between every pair of successive landmarks was then assigned to a fixed number of spatial bins. All data further than 10&#x02009;cm away from the idealized path was excluded from further analyses, except for the errors/turnaround analysis, discussed below.</p></sec><sec><title>Ensemble decoding</title><p>We applied a one-step Bayesian decoding method (Zhang et al., <xref ref-type="bibr" rid="B79">1998</xref>), using all cells that fired at least 25 spikes in a session, to the spatial (linearized, warped) tuning curves of all data sets with at least 10 simultaneously recorded cells (84/104 sessions) using 50&#x02009;ms time bins and a uniform spatial prior. For each time bin, this method takes the spike counts from each cell <italic>i</italic> and computes the posterior probability of the rat being at location <italic>x</italic> given spike counts <italic>s<sub>i</sub></italic>, <italic>p</italic>(<italic>x</italic>|<bold>s</bold>). The plot of actual vs. decoded location (Figure <xref ref-type="fig" rid="F3">3</xref>A) shows the average decoded probability distribution for each actual location, obtained by averaging the posterior distributions over all time bins corresponding to that actual location. Average decoded probability distributions for before, during, and after passes through the CP (Figure <xref ref-type="fig" rid="F3">3</xref>B) where obtained by first finding the entry and exit points of individual passes through the CP zone (red box in Figure <xref ref-type="fig" rid="F1">1</xref>A) and then averaging over all time bins within each pass. The decoding probability at the feeder locations <italic>p(Feeders)</italic> was defined, for each time bin, as the average decoding probability to the space bin of the feeder locations and their adjacent bins (6 bins out of 110 total). For the time decoding analysis, tuning curves in time, i.e. PETHs, were constructed from&#x02009;&#x02212;10 to 5&#x02009;s, in 150&#x02009;ms bins, relative to the time of pellet release (feeder fire) at the first reward location. If the rat left the reward location earlier than 5&#x02009;s after food delivery, the remaining time was not used in computing the tuning curve. As for spatial decoding, for each 50&#x02009;ms time bin as the rat runs, the spike counts from each cell <italic>i</italic> in that window were used to compute the posterior probability of the rat being at time <italic>t</italic> given spike counts <italic>s<sub>i</sub></italic>, <italic>p</italic>(<italic>t</italic>|<bold>s</bold>). We used a uniform prior in time. For both the space and time decoding analyses, we separated training and test data by decoding spiking data on even laps using only tuning curves obtained from odd laps and vice versa.</p><fig id="F3" position="float"><label>Figure 3</label><caption><p>(A) Spike trains (n&#x02009;=&#x02009;2402) were assigned to putative phasic-firing neurons (PFNs, n&#x02009;=&#x02009;2131), high-firing neurons (HFNs, n&#x02009;=&#x02009;249) and tonically-firing neurons (TFNs, n&#x02009;=&#x02009;22). PFNs exhibited spatial and reward firing correlates consistent with previous reports. <bold>(B)</bold> Representative example of an anticipatory ramp cell, which gradually increases in firing rate as the reward sites are approached and drops off rapidly once reached. The top panel shows tracking data (small grey dots, one dot for each 16.6&#x02009;ms position sample)&#x02009;and locations where a spike occurred (black dots, one dot for each spike) during one 40-min recording session. Inset shows this cell's average waveforms on the 4 tetrode channels. The lower panels show peri-event time histograms (blue bars), where time 0 is pellet release time (&#x0201c;feeder fire&#x0201d;) for feeder 1 (F1, top) and feeder 2 (F2, bottom), as well as the animal's speed (red line). Note how although time 0 is the time of pellet release (triggered when the animals crossed the green lines in Figure <xref ref-type="fig" rid="F1">1</xref>A), pellets only reached the track about 1.5&#x02013;2&#x02009;s after this time. <bold>(C)</bold> Typical example of a cell with spatial firing fields. Unlike primary neurons in hippocampus (&#x0201c;place cells&#x0201d;)&#x02009;ventral striatal cells rarely exhibited single, well defined firing fields.</p></caption><graphic xlink:href="fnint-03-001-g003"/></fig></sec><sec><title>Reversals</title><p>This analysis was designed to detect times when the rat abruptly changed movement direction while correcting an error. First, time intervals from when the rat strayed further than 7&#x02009;cm from the idealized path, but subsequently returned within that same range, were identified. Large deviations from the idealized path (&#x0003e;30&#x02009;cm), such as those generated by returns down the non-rewarded rail, were excluded. For each episode lasting longer than 100&#x02009;ms, the time course of three variables (movement speed, distance from the linearized path, and position) was examined for local extrema. If at least two of these had a clear extremum, their times were averaged to yield the estimated point of turnaround, and the episode was included in the analysis. The output of this algorithm was manually checked for correctness.</p></sec><sec><title>Arrivals and departures at the feeder sites</title><p>For each session, a 8-cm diameter circle was drawn around the feeder sites (as identified from the occupancy matrix) and the times of crossings into and out of this area counted as arrivals and departures respectively.</p></sec><sec><title>Errors</title><p>An error was scored when the rat crossed an imaginary vertical line through the first feeder trigger line on the non-rewarded side of the maze.</p></sec><sec><title>Lap times</title><p>Lap times were defined as the time elapsed between when the rat entered the navigation sequence at the bottom of the maze to when it crossed either reward trigger line at the top end of the maze (i.e. when the rat enters a return rail after having made a choice). For the first lap (when the rat was placed on the track by the experimenter) times and data from before the start of the first T (T1) were excluded.</p></sec></sec></sec><sec><title>Results</title><p>We recorded ventral striatal neural activity from rats (<italic>n</italic>&#x02009;=&#x02009;5) running laps on an elevated track (the Multiple-T task; Figure <xref ref-type="fig" rid="F1">1</xref>A) for food reward. The track contained three low-cost T-shaped choice points (or turns, T1, T2 and T3) as well as a final high-cost choice, T4. At the final choice point, choosing one return rail, but not the other, triggered reward delivery at two feeder sites F1 and F2. The sequence of turns, as well as which return rail was rewarded, could be varied on a daily basis, such that in each session rats started out uncertain about which choices lead to reward. Consistent with previous reports (Johnson and Redish, <xref ref-type="bibr" rid="B32">2007</xref>; Schmitzer-Torbert and Redish, <xref ref-type="bibr" rid="B62">2004</xref>), rats quickly learned to choose the correct return rail within each 40-min session (<italic>n</italic>&#x02009;=&#x02009;104 sessions; Figure <xref ref-type="fig" rid="F1">1</xref>B), coinciding with a period of increased pausing at the final choice point (Figure <xref ref-type="fig" rid="F1">1</xref>C). Lap times continued to decrease over the course of a session (Figure <xref ref-type="fig" rid="F1">1</xref>D). Rats ran an average of 75.2&#x02009;&#x000b1;&#x02009;8.8 (S.E.M.) laps per session. All analyses were restricted to the first 70 laps of each session to avoid sampling biases in later laps.</p><p>Cells were recorded and isolated using standard techniques, with a total of 2402 spike trains containing at least 100 spikes recorded from 104 sessions. Recording electrodes were confirmed to be in ventral striatum (nucleus accumbens core and ventral caudate-putamen; Figure <xref ref-type="fig" rid="F2">2</xref>). Following earlier reports (Barnes et al., <xref ref-type="bibr" rid="B7">2005</xref>; Berke et al., <xref ref-type="bibr" rid="B8">2004</xref>; Schmitzer-Torbert and Redish, <xref ref-type="bibr" rid="B62">2004</xref>, <xref ref-type="bibr" rid="B63">2008</xref>), spike trains were categorized as phasically-firing neurons (PFNs, putative medium spiny projection neurons), tonically firing interneurons (TFNs) or high-firing interneurons (HFNs) based on spike train firing statistics (post-spike suppression and proportion of interspike intervals larger than 2 s; see Schmitzer-Torbert and Redish, <xref ref-type="bibr" rid="B62">2004</xref> for details). Single cell analyses were restricted to PFNs only, for a total of 2131 spike trains. Consistent with previous reports (Carelli and Deadwyler, <xref ref-type="bibr" rid="B14">1994</xref>; Lavoie and Mizumori, <xref ref-type="bibr" rid="B37">1994</xref>; Martin and Ono, <xref ref-type="bibr" rid="B39">2000</xref>; Miyazaki et al., <xref ref-type="bibr" rid="B42">1998</xref>; Mulder et al., <xref ref-type="bibr" rid="B45">2005</xref>) PFNs showed both reward-related responses and maze (location)-related responses: 49.6% had a maze response, 34.6% a reward response, and 15.1% had both (Figure <xref ref-type="fig" rid="F3">3</xref>A). As reported in these previous studies, a subset of maze-responsive cells showed a smooth, clear ramping-up of activity when approaching the feeder locations, followed by an abrupt decrease in firing upon arrival. On visual inspection, 105/2131 (5%) of cells fit this description (Figure <xref ref-type="fig" rid="F3">3</xref>B). In general, maze-responsive cells tended to show a variety of large, diffuse, and/or multiple fields (e.g. Figure <xref ref-type="fig" rid="F3">3</xref>C). Reward responses were also varied, both in their timing relative to reward delivery and in the temporal profile of the response (Figure <xref ref-type="fig" rid="F4">4</xref>). Cells also differed in whether they responded to one of the reward locations or both, despite the rewards being identical (Figures <xref ref-type="fig" rid="F4">4</xref>C&#x02013;D).</p><fig id="F4" position="float"><label>Figure 4</label><caption><p><bold>Examples of reward-responsive cells; panel layout as in Figure <xref ref-type="fig" rid="F3">3</xref></bold>. Reward cells varied in the timing and broadness of the reward response, as well as in whether they responded at one or both of the reward sites. The majority of reward cells, including those shown here, also emitted a small number of spikes outside of the reward locations. Note in particular the activity at the final choice point and the spikes at reversal points (when the animal strays from its usual path).</p></caption><graphic xlink:href="fnint-03-001-g004"/></fig><p>In this same task, prospective hippocampal activity has been found at the final choice point (CP) (Johnson and Redish, <xref ref-type="bibr" rid="B32">2007</xref>). To confirm that our rats treated the final choice point (T4) differently from other turns, we compared the time spent at the final choice point to that spent at a control, low-cost choice point (T2). To account for gross variations in running speed, the time spent at in these two zones was normalized by lap time. The resulting plot (Figure <xref ref-type="fig" rid="F1">1</xref>C) shows that during early laps, rats spent more time at the final choice point (T4) than at the control choice point (T2), but this difference disappeared over the course of the session. Over the laps in which animals showed such pausing at the final choice point, behavioral performance (correct choices) increased sharply (Figure <xref ref-type="fig" rid="F1">1</xref>B). We interpret this as consistent with the idea that pausing behavior reflects processing beyond simple stimulus-response processes, indicating the engagement of flexible decision-making or &#x0201c;planning&#x0201d; systems (Dale, <xref ref-type="bibr" rid="B18">1986</xref>; Tolman, <xref ref-type="bibr" rid="B74">1948</xref>).</p><sec><title>Ventral striatal reward cells show increased firing at the final choice point</title><p>Given that upstream hippocampal activity can represent non-local information at the final choice point (Johnson and Redish, <xref ref-type="bibr" rid="B32">2007</xref>), we hypothesized that ventral striatal representations of reward might be transiently active during pauses at this point. To test this, we asked whether cells that responded to reward receipt showed additional activity at the final choice point. In general, reward cells tended to fire a small number of spikes at various locations distant from the reward site (Figure <xref ref-type="fig" rid="F4">4</xref>). An example of a cell with a clear reward response, but with a few such &#x0201c;extra-field&#x0201d; spikes specifically at the final choice point, is shown in Figure <xref ref-type="fig" rid="F4">4</xref>A. This neuron and others in the same figure are not well described as simply being active at low speeds: those in panels of Figure <xref ref-type="fig" rid="F4">4</xref>A,C respond only to one reward site, despite animals pausing at both. The cells in panels of Figure <xref ref-type="fig" rid="F4">4</xref>B,D show strong activation after reward delivery, but not when the animal pauses at the first reward site prior to arriving at the next (e.g. between 2 and 1 s before the second &#x0201c;feeder fire&#x0201d;, the time at which food pellets are released). Additionally, the position traces indicate the animals' tendency to pause at reversal points before returning to their usual path. While some neurons exhibited some activity at these points (e.g. the neuron in Figure <xref ref-type="fig" rid="F4">4</xref>D), there were also many cases where no such firing was seen (Figures <xref ref-type="fig" rid="F4">4</xref>A,B, but also in Figure <xref ref-type="fig" rid="F4">4</xref>D). Thus, inspection of individual ventral striatal reward neurons suggests that such cells also display activity in the absence of reward delivery.</p><p>To address the question of whether reward-responsive cells are also activated at the choice point more generally, we compared the spatial distribution of the firing rates of reward-responsive PFNs to those of non-reward responsive PFNs. A cell was classified as reward-responsive if its spike count in the window of 1&#x02013;5&#x02009;s after reward delivery at one or both of the reward sites had a <italic>z</italic>-score of at least 2 against the distribution of spike counts obtained by randomly shuffling the reward delivery times. (In other words, we compared the observed post-reward delivery spike counts against the distribution of randomly selected windows of the same length.) In order to be able to average data over different maze configurations, the rats' two-dimensional position tracking data was mapped onto a standardized, linear path (Schmitzer-Torbert and Redish, <xref ref-type="bibr" rid="B62">2004</xref>). We then compared reward-responsive cells and non-reward-responsive cells, as distinguished by their reward <italic>z</italic>-score. For reward cells (reward <italic>z</italic>-score &#x0003e;2; 682 cells), but not for cells with negative reward <italic>z</italic>-scores (931 cells), an increase in firing rate at the final choice point (T4) was apparent during early, but not late laps (Figures <xref ref-type="fig" rid="F5">5</xref>A,B). Because different cells have different firing rates, each cell's space-binned firing rate was normalized by computing the <italic>z</italic>-score of each spatial bin against that cell's distribution of firing rates over the navigation sequence (the start of the first T to one-third of the way between T4 and F1) in its overall spatial tuning curve. A two-way ANOVA with location on the maze (nine bins, from the start of the first T to one-third of the way between T4 and F1) and cell type (reward or non-reward) as factors showed a significant interaction for early laps (1&#x02013;10, <italic>F</italic>&#x02009;=&#x02009;2.56, <italic>p</italic>&#x02009;=&#x02009;0.0087), but not late laps (61&#x02013;70, <italic>F</italic>&#x02009;=&#x02009;0.88, <italic>p</italic>&#x02009;=&#x02009;0.53). For reward cells in early laps, the T4 location had the highest mean and was different from non-reward firing at T4 (<italic>F</italic>&#x02009;=&#x02009;13.07, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001).</p><fig id="F5" position="float"><label>Figure 5</label><caption><p><bold>Reward-responsive cells, but not non-reward cells, show increased firing at the final choice point (T4) during early laps</bold>. <bold>(A)</bold> Averaged over all cells, average <italic>z</italic>-scored firing rate is increased at the final choice point (T4) during early laps (1&#x02013;10) for reward-related (blue), but not non-reward-related cells (red). During late laps (61&#x02013;70), there was no such difference <bold>(B)</bold>. Note how during late laps, while there is no increase in reward cell firing at T4, the response to actual reward receipt (F1, F2) is undiminished. This pattern of results was preserved when only cells that had a significant reward response to one, but not the other, reward location, were used <bold>(C,D)</bold>, excluding cells with general movement correlates. When reward cells were further subdivided into cells responding to only the first, only the second, or both locations, each group showed higher activity at the final choice point compared to non-reward cells <bold>(E)</bold>.</p></caption><graphic xlink:href="fnint-03-001-g005"/></fig><p>Due to our criterion for reward-responsive cells, it is possible that cells firing selectively at low speeds or at movement initiations could be erroneously included in this analysis as reward cells, leading to alternative explanations for the extra &#x0201c;reward-cell&#x0201d; activity at T4. To control for this type of possibility, the same analysis was performed only on those cells that had a reward response to one, but not the other, reward site (495 cells; Figures <xref ref-type="fig" rid="F5">5</xref>C,D). Cells with a general movement-related response common to both sites would thus be excluded from analysis. Using only these cells, a similar pattern of results was observed. Firing at T4 was higher for reward than for non-reward cells during early, but not late, laps (early: cell type &#x000d7; space bin interaction, <italic>F</italic> = 2.62, <italic>p</italic> &#x0003c; 0.0072; difference at T4, <italic>F</italic> = 8.74, <italic>p</italic> = 0.0031; late: no interaction, <italic>F</italic> = 0.6, <italic>p</italic> = 0.77). Thus, reward-responsive cells show increased firing at the choice point during early, but not late, laps. When these cells were separated according to whether they responded to only the first, only the second, or both locations, each group showed higher activity at the final choice point compared to non-reward cells (Figure <xref ref-type="fig" rid="F5">5</xref>E).</p></sec><sec><title>Ensemble decoding shows increased reward site representation at the final choice point</title><p>The preceding analysis relies on assumptions about what is being coded for by individual cells. A more general approach to the question of what is represented in ventral striatum at the final choice point can be found through ensemble decoding methods. A one-step Bayesian decoding method (Zhang et al., <xref ref-type="bibr" rid="B79">1998</xref>) was applied, where, for each time bin, the posterior probability <italic>p</italic>(<italic>x</italic>|<bold>s</bold>) of the rat being at location <italic>x</italic> given spike counts <italic>s<sub>i</sub></italic> is computed. This method is agnostic about what variable is in fact represented; it merely shows to what extent different locations are related based on ensemble firing patterns. To visualize such relationships, the average posterior (decoded) probability distribution for each actual location was plotted (Figure <xref ref-type="fig" rid="F6">6</xref>A). The diagonal of increased decoding probability indicates that ventral striatal ensembles contain information about spatial location. Although both feeder locations have a high probability of being decoded correctly, there was significant confusion between the two feeder locations F1 and F2 (as indicated by the symmetric blobs offset from the diagonal), an effect that can result from a population of cells firing similarly at both locations, such as reward-responsive cells.</p><fig id="F6" position="float"><label>Figure 6</label><caption><p><bold>Decoding of ventral striatal ensembles reveals increased representation of rewarded locations as rats pause at the choice point</bold>. <bold>(A)</bold> Average posterior (decoded) spatial probability distribution as a function of actual location. Cold colors indicate low, hot colors high decoding probability. <bold>(B)</bold> Posterior probability distributions for short (left panel) and long (right panel) passes through the choice point (CP). The three columns in each panel correspond to the 0.5&#x02009;s immediately preceding each CP pass, the CP pass itself, and the 0.5&#x02009;s immediately following it, respectively. The progression of the red, high reconstruction probability zone tracks the rat moving through the CP, but note the increased probability at the feeders for the long pauses. The average probability of decoding to the feeder locations, normalized to pre-CP levels, is plotted in <bold>(C)</bold>, with the increase for the long pauses highly significant (see main text).</p></caption><graphic xlink:href="fnint-03-001-g006"/></fig><p>Having established that spatial information can be extracted in this manner, we next asked what locations were represented when the rat paused at the choice point. For each session, a rectangular region around the choice point was defined (red box in Figure <xref ref-type="fig" rid="F1">1</xref>A). Passes through this zone were categorized as short (&#x0003c;1&#x02009;s) or long (&#x0003e;2.5&#x02009;s). Average decoded probability distributions for each pass were identified and compared to the 0.5&#x02009;s preceding and following it (Figure <xref ref-type="fig" rid="F6">6</xref>B). In each case, high decoding probability tracked the rat as it moved through the choice point. During long pauses, however, the probability of decoding to the feeders <italic>p(Feeders)</italic> was strongly increased at the choice point compared to regions immediately before or after the choice point (Figure <xref ref-type="fig" rid="F6">6</xref>C; ANOVA <italic>F</italic>&#x02009;=&#x02009;14.52, <italic>p</italic>&#x02009;&#x0003c;&#x02009;10<sup>&#x02212;6</sup>).</p><p>Because increased pausing and reward cell firing occurs at the choice point during early, but not late laps, we asked how <italic>p(Feeders)</italic> changed with experience. For early laps, an ANOVA of <italic>p(Feeders)</italic> with spatial location as a factor (five blocks, one for each turn and one for after T4) showed significant variation (<italic>F</italic>&#x02009;=&#x02009;9.6, <italic>p</italic>&#x02009;&#x0003c;&#x02009;10<sup>&#x02212;7</sup>) with T4 having the highest mean. A two-way ANOVA showed a significant interaction between early/late laps and spatial location (<italic>F</italic>&#x02009;=&#x02009;3.15, <italic>p</italic>&#x02009;=&#x02009;0.013), with <italic>p(Feeders)</italic> higher at T4 in early laps compared to late (<italic>F</italic>&#x02009;=&#x02009;69.52, <italic>p</italic>&#x02009;&#x0003c;&#x02009;10<sup>&#x02212;10</sup>). Thus, increased feeder location representation is present at the choice point during early laps, but disappears with experience.</p><p>Could this increase in feeder location representation result from disorganized firing as the rat pauses? To test this, we compared the average posterior probability distribution for long pauses to a shuffled control where the interspike intervals of all cells were randomly rearranged. The interaction term in a two-way ANOVA with space and shuffled/non-shuffled as factors was highly significant (<italic>F</italic>&#x02009;=&#x02009;15.51, <italic>p</italic>&#x02009;&#x0003c;&#x02009;10<sup>&#x02212;10</sup>), implying that random spiking cannot fully account for increased feeder representation at the choice point. Alternatively, a linear combination of the decoded probability distribution obtained from random spiking and that obtained from before, after, or during (for short passes) the choice point might explain increased feeder representation. To address this, we compared the decoded probability distribution difference between either (a) before the choice point (long passes), (b) after the choice point (long passes), and (c) at the choice point (short passes) and that at the choice point for long pauses to the randomly shuffled distribution (two-way ANOVA). For each comparison, the interaction between space and random/non-random was significant (least significant <italic>F</italic>&#x02009;=&#x02009;4.88, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001). Therefore, the increase in <italic>p(Feeders)</italic> during pauses at the choice point cannot be accounted for by a linear combination of the pre- or post- decoded probability distribution and that obtained from random spiking.</p><p>As in the single cell-based analysis (Figure <xref ref-type="fig" rid="F5">5</xref>), increased probability of decoding to the feeder locations could be the result of a number of similarities between the feeder locations and the choice point other than representation of reward, such as lower speed or movement initiation. While <italic>p(Feeders)</italic> was negatively correlated with movement speed overall (<italic>r</italic>&#x02009;=&#x02009;&#x02212;0.35 over all sessions with &#x0003e;40 cell ensembles), Figure <xref ref-type="fig" rid="F7">7</xref>C shows that at the first feeder, <italic>p(Feeders)</italic> was in fact modulated independently from speed and was not related to movement initiation. Thus, like reward-responsive neurons, ensemble decoding of the reward locations is correlated with pausing, but can be dissociated from it.</p><fig id="F7" position="float"><label>Figure 7</label><caption><p>(A&#x02013;C) <italic>p(Feeders)</italic> is modulated independently of speed when the rats arrive at the first feeder. While speed is negatively correlated with <italic>p(Feeders)</italic> overall, as is apparent from comparing panels <bold>(A)</bold> [<italic>p(Feeders)</italic> relative to the time of feeder 1 fire] and <bold>(B)</bold> (speed), panel <bold>(C)</bold> shows that when speed is factored out, <italic>p(Feeders)</italic> still shows a clear increase. Panels <bold>(D,E</bold>) show the distribution of arrival and departure times at the feeder site, again relative to the time of pellet release.</p></caption><graphic xlink:href="fnint-03-001-g007"/></fig><p>To address in more detail the issue of what neural ensembles represent as rats paused at the final choice point, we applied the same ensemble decoding algorithm not to space but to time. In this analysis, instead of using spatial tuning curves to generate a decoded probability distribution over space (as in Figure <xref ref-type="fig" rid="F6">6</xref>), we compute tuning curves in time relative to reward delivery [i.e. peri-event time histograms (PETHs)] and obtain the decoded probability distribution over time given spiking activity. Thus, given ensemble spiking in each 50 ms time window, we construct the probability distribution over <italic>t</italic> where <italic>t</italic> is the time relative to reward delivery. This analysis essentially asks: compared to ensemble activity at various times relative to reward, how much like that activity is the current set of spikes that we observe (e.g. at pauses at the choice point)? The results of this time decoding analysis are shown in Figure <xref ref-type="fig" rid="F8">8</xref>.</p><fig id="F8" position="float"><label>Figure 8</label><caption><p><bold>Time at the choice point shows the specific time course of the increased feeder representation</bold>. <bold>(A)</bold> As in Figure <xref ref-type="fig" rid="F6">6</xref>, passes through the final choice point (CP) were divided into short (left), and long (right). As expected, as rats passed through the choice point, the red high reconstruction probability in time advanced towards time 0, when food delivery at the first feeder was triggered. (Note that on average, rats arrived at the first feeder 1.6&#x02009;s after this time; see Figure <xref ref-type="fig" rid="F7">7</xref>). For long passes, there was increased probability in the 2 to 4-s range <bold>(B)</bold>.</p></caption><graphic xlink:href="fnint-03-001-g008"/></fig><p>Consistent with the results from the space decoding analysis, there was an increase in reward representation for pauses at the final choice point (Figure <xref ref-type="fig" rid="F8">8</xref>A, right panel). Taking the average reconstruction probability over the 0 to 5-s post-feeder trigger time window of interest, there was an overall effect of time at the CP and pre/CP/post, as well as a significant interaction (two-way ANOVA, time at CP: <italic>F</italic> = 12.87, <italic>p</italic> &#x0003c; 10<sup>&#x02212;5</sup>; pre/CP/post: <italic>F</italic> = 26.68, <italic>p</italic> &#x0003c; 10<sup>&#x02212;10</sup>; interaction: <italic>F</italic> = 3.95, <italic>p</italic> = 0.0033). For long pauses at the CP, the actual time course of the posterior probability was differentially modulated depending on pre/CP/post (significant interaction, ANOVA <italic>F</italic> = 1.82, <italic>p</italic> &#x0003c; 0.0001). When averaged over the 2 to 4-s interval, there was increased reconstruction probability at the CP compared to before and after (ANOVA <italic>F</italic> = 5.6, <italic>p</italic> &#x0003c; 0.004; Figure <xref ref-type="fig" rid="F8">8</xref>B). As with the space decoding method, the long pause probability distribution was different from that obtained from shuffled interspike intervals and from linear combinations of this random distribution and pre, post, or short passes (least significant ANOVA: <italic>F</italic> = 2.09, <italic>p</italic> &#x0003c; 0.0026).</p><p>Importantly, the time course of this increase, peaking at about 3&#x02009;s after the time of food pellet release (corresponding to about 1.5&#x02009;s after arrival at the reward location), is inconsistent with the distribution of departures from the feeder and movement speed (Figures <xref ref-type="fig" rid="F7">7</xref>D,E). Over the time window of increased decoding probability at the choice point (2&#x02013;4&#x02009;s after feeder fire) there is no correlation between the reconstructed temporal profile and the animals' speed over the same time (<italic>r</italic>&#x02009;=&#x02009;0.06, <italic>p</italic>&#x02009;=&#x02009;0.53 for large ensembles). Furthermore, over the full 0 to 5-s profile there was a significant <italic>positive</italic> correlation with speed (<italic>r</italic>&#x02009;=&#x02009;0.21, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001). This is the opposite effect of what would be expected if increased reconstruction probability when pausing at the CP would be due to low speed. Interestingly, the peak in increased decoding at around 3&#x02009;s after reward delivery closely matched the time course of the overall reward response, particularly the late components (Figure <xref ref-type="fig" rid="F9">9</xref>).</p><fig id="F9" position="float"><label>Figure 9</label><caption><p><bold>Population reward response for all reward-responsive cells</bold>. At both reward locations a modulation in overall firing rate (black lines) was seen (left, feeder 1; right, feeder 2). The feeder 1 response appears to have two components to it: an early, sharp peak followed by a late, broader response. For feeder 2, the relative magnitude of these two responses was altered, such that the late, broad response dominates. Note how this late component does not appear to be related to instantaneous running speed (red line).</p></caption><graphic xlink:href="fnint-03-001-g009"/></fig></sec><sec><title>Decoding to reward locations is increased during error correction</title><p>Hippocampal prospective activity is known to occur not just at the final choice point, but also at other locations, notably during error correction (Johnson and Redish, <xref ref-type="bibr" rid="B32">2007</xref>), suggesting that ventral striatal representations may also be non-local at such points. A plot of the probability of decoding to the feeders <italic>p(Feeders)</italic> as a function of location on the horizontal section of the final choice point (Figure <xref ref-type="fig" rid="F10">10</xref>A) illustrates that while <italic>p(Feeders)</italic> is increased around the choice point during early laps, it also appears especially high on the non-rewarded side. Because rats were much more likely to reverse direction when moving to the non-rewarded side (i.e. after taking a wrong turn at the CP) than when moving to the correct side, we identified points in the rats' path where during errors, they reversed direction back towards the idealized path. For 413 such reversal points the average value of <italic>p(Feeders)</italic> was plotted centered around the reversal point in time. As Figures <xref ref-type="fig" rid="F10">10</xref>B,C show, <italic>p(Feeders)</italic> was increased around the turnaround point, and was significantly higher before turning around than after (ANOVA with before/after as factors, <italic>F</italic>&#x02009;=&#x02009;44.87, <italic>p</italic>&#x02009;&#x0003c;&#x02009;10<sup>&#x02212;10</sup>). Thus, ventral striatal representations of the feeder locations are increased during error correction, particularly before reversing.</p><fig id="F10" position="float"><label>Figure 10</label><caption><p><bold>Representations of reward sites are increased preferentially before error correction</bold>. <bold>(A)</bold> Average probability of decoding to the reward sites&#x02009;<italic>p(Feeders)</italic> as a function of lap and position on the final T (the area of the maze indicated by the red dashed box, below). Sessions are aligned so that the rewarded side (R) is always on the right. <italic>p(Feeders)</italic> is increased at the choice point (CP) during early laps, as well as on the non-rewarded side (R). Strong feeder representation on the non-rewarded side arises from a more general increase associated with reversals <bold>(B,C)</bold>. <bold>(B)</bold> Example of <italic>p(Feeders)</italic> over time around a reversal point (inset, green circle) indicated by the vertical red line. Averaged over all reversal points, <italic>p(Feeders)</italic> is increased around the reversal point, higher before than after [<italic>F</italic>&#x02009;=&#x02009;44.87, <italic>p</italic>&#x02009;&#x0003c;&#x02009;10<sup>&#x02212;6</sup>, <bold>(C)</bold>]. Errorbars are S.E.M.</p></caption><graphic xlink:href="fnint-03-001-g010"/></fig></sec></sec><sec sec-type="discussion"><title>Discussion</title><p>We recorded neuronal activity from ventral striatum on a spatial decision task, and observed that the activity of many neurons with a clear reward response was not restricted to the reward sites alone: such neurons also tended to be activated, albeit to a lesser degree, at other locations. Examination of the structure in such &#x0201c;extra-field&#x0201d; spikes revealed that on average, reward-responsive cells, but not non-reward-responsive cells, increased their firing at the final choice point during early laps. More generally, ensemble decoding analyses revealed increased decoding probability to the reward sites as rats paused at the choice point, as well as during error correction. The time course of the increased reward firing and feeder reconstruction matched that of the rats' pausing behavior and increase in performance, yet the two could be dissociated. As rats became more proficient at the task, increased reward activity at the choice point disappeared. These data suggest the presence of a reward-like signal in ventral striatum at points where decision-making processes occur, in the absence of reward in the environment.</p><p>Multiple-systems theories of decision-making posit the existence of a flexible &#x0201c;search&#x0201d; or &#x0201c;planning&#x0201d; system (Buckner and Carroll, <xref ref-type="bibr" rid="B10">2007</xref>; Daw et al., <xref ref-type="bibr" rid="B19">2005</xref>; Johnson et al., <xref ref-type="bibr" rid="B33">2007</xref>; Niv et al., <xref ref-type="bibr" rid="B49">2006</xref>; O'Keefe and Nadel, <xref ref-type="bibr" rid="B52">1978</xref>; Redish et al., <xref ref-type="bibr" rid="B57">2008</xref>; Schacter et al., <xref ref-type="bibr" rid="B61">2008</xref>) which relies on processing of situations or outcomes spatiotemporally distant from the present. While the scope and details of proposed implementations of this system depend on the specific behavior under consideration, common characteristics of such a planning system have emerged across different tasks and organisms. These include the use of information about outcomes, ranging from simple one-step associative links to complex model-based reasoning, integration of such outcome information with goals or motivational state (e.g. hunger or thirst), and engagement during early learning (Adams, <xref ref-type="bibr" rid="B2">1982</xref>; Daw et al., <xref ref-type="bibr" rid="B19">2005</xref>; Holland, <xref ref-type="bibr" rid="B28">2004</xref>; Niv et al., <xref ref-type="bibr" rid="B49">2006</xref>; Poldrack and Packard, <xref ref-type="bibr" rid="B56">2003</xref>). These properties contrast with those of &#x0201c;habit&#x0201d; or &#x0201c;cache&#x0201d; systems, thought to be gradually learned, inflexible, and based stimulus-response (S-R) associations. These two systems are supported by different mechanisms in the brain, a view supported by lesion and inactivation studies across different tasks (Packard and McGaugh, <xref ref-type="bibr" rid="B53">1996</xref>; Yin et al., <xref ref-type="bibr" rid="B78">2004</xref>). Non-local representations of reward in our data were most active during early learning and at the final choice point, This temporal and spatial specificity, as well as the observed pausing behavior, cannot be easily accomodated in a S-R framework. Instead, we suggest that our results reflect a component of the planning system. In order to be behaviorally useful, such flexible systems require both prediction of future states or outcomes, and evaluation of such states. Our finding of a covert reward signal activated during early learning is well situated in space and time to contribute to these predictions or their evaluation. While the magnitude of the observed non-local reward signal was small compared to responses to actual reward receipt, representations involved in the planning system are necessarily transient, self-initiated, and dynamic. Since our analyses averaged this putative signal over time and space, this difference in magnitude is not unexpected.</p><p>The fact that representations of reward at the final choice point disappear with stable performance may reflect a transfer of behavioral control to a different system. Such an interpretation is supported by the expression of pausing behavior at the choice point during early, but not late laps, previously described as vicarious trial-and-error (Hu and Amsel, <xref ref-type="bibr" rid="B30">1995</xref>; Johnson and Redish, <xref ref-type="bibr" rid="B32">2007</xref>; Muenzinger, <xref ref-type="bibr" rid="B44">1938</xref>), co-occurring with a rapid increase in performance. However, our task design did not permit us to directly assess, e.g. by a reward devaluation test, whether such a switch in control in fact occurred. The fact that reward representation at the final choice point was present during early laps might be interpreted as potentially inconsistent with learning mechanisms; however, it is important to note that when recording data was taken, rats were extensively trained on general structure of the task (even though specific maze configurations could be novel). Thus, even though the reward location could change on a session-to-session basis, the early presence of the choice point reward representation might reflect structural learning (Tenenbaum et al., <xref ref-type="bibr" rid="B71">2006</xref>; Tse et al., <xref ref-type="bibr" rid="B75">2007</xref>).</p><p>Previous recording studies have shown that ventral striatal neurons learn to respond to cues predictive of reward (Roitman et al., <xref ref-type="bibr" rid="B59">2005</xref>; Setlow et al., <xref ref-type="bibr" rid="B68">2003</xref>); however, the transient reward signal occurring at decision points reported here cannot be explained in this way. While the choice point itself might be considered a cue, there are other points presumably equally or more predictive of reward, such as the space between the choice point and the rewarded sites, where no increased reward signal was seen. Furthermore, instead of gradually developing a reward response to a predictive cue which then remains stable (Roitman et al., <xref ref-type="bibr" rid="B59">2005</xref>; Setlow et al., <xref ref-type="bibr" rid="B68">2003</xref>), the signal we observed showed the opposite pattern: it was prominent during early learning and faded with experience.</p><p>An alternative is that this signal could reflect something akin to a reward prediction error (Niv and Schoenbaum, <xref ref-type="bibr" rid="B50">2008</xref>; Schultz et al., <xref ref-type="bibr" rid="B66">1997</xref>), a suggestion in line with human imaging data (Knutson and Cooper, <xref ref-type="bibr" rid="B35">2005</xref>; O'Doherty et al., <xref ref-type="bibr" rid="B51">2004</xref>; but see Hare et al., <xref ref-type="bibr" rid="B26">2008</xref>). Such a signal would be expected to respond first to reward, and later to the first reward-predictive cue, without responding to cues closer to reward. We find this explanation unlikely, because the responses to actual reward delivery persisted with time, even after those at the choice point vanished. Additionally, while ventral striatum has access to such a signal through inputs from the ventral tegmental area, to our knowledge, prediction error signals in ventral striatum have not been documented electrophysiologically.</p><p>A different alternative explanation for the observed reward representation at decision points could rely on an interaction of reward activity evoked by reward-predictive cues and attentional processes modulated by some form of behavioral state, such as deliberation or uncertainty. In such a model, the animal would only attend to reward-predictive cues when engaged in deliberative decision-making, causing neurons that fire to those cues to become active. While it is difficult to discount this possibility as an explanation for the extra reward activity at the final choice point specifically, it is clear that typical reward neurons exhibit &#x0201c;extra-field&#x0201d; activity at many different points on the maze, when the animal is facing widely varying directions (such as in the examples in Figure <xref ref-type="fig" rid="F4">4</xref>). This observation is reinforced by the ensemble decoding data which shows an increase in feeder representation at turnaround points at various locations on the maze (Figure <xref ref-type="fig" rid="F10">10</xref>). In any case, even if this interpretation did turn out to be correct, our results document an interaction between reward-responsive cells and processes engaged during decision-making, showing that responses to reward-predictive cues are more dynamic than previously thought.</p><p>Recording studies on spatial tasks have found anticipatory firing in ventral striatum, such as activity before reaching a goal site (Martin and Ono, <xref ref-type="bibr" rid="B39">2000</xref>) or preceding specific goal-directed movements (German and Fields, <xref ref-type="bibr" rid="B24">2007</xref>). These studies are consistent with our data, but our data goes beyond these previous findings by establishing that (a) ventral striatal representations of <italic>reward</italic> can be non-local and distinct from specific predictive cues, and (b) this signal matches the spatial (specific to decision points) and temporal (disappearing with automation) profile expected of participation in planning processes. Interestingly, Lansink et al. (<xref ref-type="bibr" rid="B36">2008</xref>) found that reward-responsive cells in ventral striatum are preferentially re-activated during &#x0201c;off-line&#x0201d; processing; our results extend this apparently privileged position to processing during active decision-making.</p><p>While our analysis emphasizes reward-related activity at the final choice point, we do not claim that flexible decision-making processes are engaged at this point exclusively. The structure of our task may lend special relevance to the final choice point, but planning may occur at other points on the maze as well. In agreement with the hippocampal recording data from (Johnson and Redish, <xref ref-type="bibr" rid="B32">2007</xref>), we found increased reward representation during error correction, and it seems likely that a variety of circumstances can give rise to the deployment of flexible strategies. This might explain the observation that during long pauses at the choice point, representation of the reward locations appears to be higher than that on short passes even before the choice point is entered. On laps that contain those long pauses, the animal is likely to engage in planning at other points as well. A similar point relates to the question of whether the reward signal we report is selectively or differentially apparent on correct and incorrect trials. Because errors almost exclusively occurred during early learning, when animals exhibited pausing behavior and extra reward activity was observed, an overall correlation between reward representation and a behavioral error is likely. It would be a mistake, however, to conclude that increased representation of reward causes errors. Successful planning involves the integration of specific outcomes and their evaluations; in this light, valuable future experiments would involve dual-structure recordings addressing the relative timing and contents of reward signals and outcome representations.</p><p>A potential confound in our data is the correlation between reward cells being active and the animal being paused. As animals show an increased tendency to pause at the final choice point during early laps and during errors, simple &#x0201c;pausing cells&#x0201d; might explain our observations. The critical distinction to be made is whether the putative non-local signal <italic>represents</italic> pausing or low speed, or alternatively, is merely preferentially activated at low speeds, as would be expected from decision-making processes. Two main results argue in favor of the second possibility. First, many reward-related cells responded to only one, but not the other, reward location, thus excluding any motoric behavioral cause; yet these cells still showed extra activity at the choice point. Second, the temporal profile of the ensemble representation during pauses at the choice point was not compatible with the time course of speed and movement initiation at the feeders. Instead, ensembles during pauses at the choice point showed increased representation consistent with the late component of the reward response, which was particularly strong at the second reward location. This could also explain why the spatial decoding method showed the strongest increase in decoding to the second reward location. Similarly, while the observed representation of reward at the choice point during early laps is necessarily correlated with rats being uncertain about the location of reward, this signal is unlikely to code for uncertainty in any straightforward manner, as evidenced by their responses to actual reward receipt.</p><p>Anatomically, ventral striatum is well-positioned to influence action selection based on flexible representations from hippocampus and frontal cortical areas (Mogenson et al., <xref ref-type="bibr" rid="B43">1980</xref>). Ventral striatum receives inputs from the hippocampal formation through the subiculum (Finch, <xref ref-type="bibr" rid="B22">1996</xref>; Groenewegen et al., <xref ref-type="bibr" rid="B25">1987</xref>; Voorn et al., <xref ref-type="bibr" rid="B76">2004</xref>) and fast-timescale firing patterns in hippocampus affect ventral striatal activity (Martin, <xref ref-type="bibr" rid="B38">2001</xref>; Pennartz et al., <xref ref-type="bibr" rid="B55">2004</xref>). Thus, a possible source for the observed non-local signal in ventral striatum might be prospective coding in the hippocampus (Johnson and Redish, <xref ref-type="bibr" rid="B32">2007</xref>). While a lesion study could test this possibility, things may not be that simple, given that hippocampal lesions do not appear to impair sensitivity to devaluation (Chudasama et al., <xref ref-type="bibr" rid="B15">2008</xref>; Corbit et al., <xref ref-type="bibr" rid="B17">2002</xref>). This suggests that if ventral striatal non-local reward signals contribute to simple goal-directed instrumental responding (Cardinal et al., <xref ref-type="bibr" rid="B11">2002</xref>; Corbit et al., <xref ref-type="bibr" rid="B16">2001</xref>), they do not require hippocampal input. However, as a site of anatomical convergence, ventral striatum also has access to relevant representations in orbitofrontal cortex and the amygdala (Schoenbaum et al., <xref ref-type="bibr" rid="B64">2006</xref>); alternatively, flexible behavior on spatial and instrumental tasks may be supported by different mechanisms.</p><p>Functionally, extensive evidence links ventral striatum to a role in mediating the behavioral impact of motivationally relevant stimuli (Cardinal et al., <xref ref-type="bibr" rid="B11">2002</xref>; Day and Carelli, <xref ref-type="bibr" rid="B20">2007</xref>; Nicola, <xref ref-type="bibr" rid="B47">2007</xref>). Recording and lesion studies suggest that this role might be supported by general affective properties of cue-predicted outcomes (Nicola et al., <xref ref-type="bibr" rid="B48">2004</xref>; Roitman et al., <xref ref-type="bibr" rid="B59">2005</xref>; Setlow et al., <xref ref-type="bibr" rid="B68">2003</xref>; Wheeler et al., <xref ref-type="bibr" rid="B77">2008</xref>); future work could address whether the observed covert reward signal in our data relaties to general affective information, or contains outcome-specific information. As argued above, reward representation during pausing in early, but not late, learning suggests involvement in flexible &#x0201c;planning&#x0201d; processes. Lesion experiments on behaviors that can be shown to require such processes, such as sensitivity to reward devaluation in instrumental tasks, have yielded conflicting evidence for the role of ventral striatum (Corbit et al., <xref ref-type="bibr" rid="B16">2001</xref>; de Borchgrave et al., <xref ref-type="bibr" rid="B21">2002</xref>). Deficits after ventral striatum lesions have been found on a variety of other spatial and instrumental tasks (Atallah et al., <xref ref-type="bibr" rid="B4">2007</xref>; Block et al., <xref ref-type="bibr" rid="B9">2007</xref>; Floresco et al., <xref ref-type="bibr" rid="B23">1997</xref>; Salamone et al., <xref ref-type="bibr" rid="B60">2005</xref>; Sutherland and Rodriguez, <xref ref-type="bibr" rid="B70">1989</xref>). While these results are broadly consistent with a role for ventral striatum in rapid early learning and/or changing conditions, these studies did not focus on the representations that might support such a role. Further work could address how the observed representation of reward at decision points changes with task demands, how it relates to behavior, and how it is integrated with other aspects of decision-making.</p><p>In summary, we report ventral striatal representations of reward active at the final choice point and before error correction on a spatial decision task. This expectation-of-reward signal at decision points was apparent at both the single cell and the ensemble level, and vanished with behavioral automation. The signal we observed was prominent during early learning and faded with experience. Therefore, we conclude that the increased reward representations reported here are not simply reflecting learned cue-associations, unless internally generated possibilities constitute the cue, a position closer to cognition than stimulus-response (Hebb, <xref ref-type="bibr" rid="B27">1949</xref>; Johnson et al., <xref ref-type="bibr" rid="B31">2009</xref>). We suggest that the observed non-local reward signal may contribute to flexible decision-making or planning, a view consistent with the observed pausing behavior and non-local representations in hippocampus (Johnson and Redish, <xref ref-type="bibr" rid="B32">2007</xref>).</p></sec><sec><title>Conflict of Interest Statement</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></sec></body><back><ack><p>We are grateful to John Ferguson, Anoopum Gupta, Jadin Jackson, Adam Johnson, Neil Schmitzer-Torbert, and the members of the Center for Cognitive Sciences for discussion, and to Chris Boldt for technical assistance. We thank the referees for their constructive comments on an earlier version of the manuscript.</p></ack><ref-list><title>References</title><ref id="B1"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Adams</surname><given-names>C. D.</given-names></name><name><surname>Dickinson</surname><given-names>A.</given-names></name></person-group> (<year>1981</year>). <article-title>Instrumental responding following reinforcer devaluation</article-title>. <source>Q. J. Exp. Psychol. B</source><volume>2</volume>, <fpage>109</fpage>&#x02013;<lpage>121</lpage></citation></ref><ref id="B2"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Adams</surname><given-names>C. D.</given-names></name></person-group> (<year>1982</year>). <article-title>Variations in the sensitivity of instrumental responding to reinforcer devaluation</article-title>. <source>Q. J. Exp. Psychol. B</source><volume>34</volume>, <fpage>77</fpage>&#x02013;<lpage>98</lpage></citation></ref><ref id="B3"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Apicella</surname><given-names>P.</given-names></name><name><surname>Ljungberg</surname><given-names>T.</given-names></name><name><surname>Scarnati</surname><given-names>E.</given-names></name><name><surname>Schultz</surname><given-names>W.</given-names></name></person-group> (<year>1991</year>). <article-title>Responses to reward in monkey dorsal and ventral striatum</article-title>. <source>Exp. Brain Res.</source><volume>85</volume>, <fpage>491</fpage>&#x02013;<lpage>500</lpage><pub-id pub-id-type="doi">10.1007/BF00231732</pub-id><pub-id pub-id-type="pmid">1915708</pub-id></citation></ref><ref id="B4"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Atallah</surname><given-names>H. E.</given-names></name><name><surname>Lopez-Paniagua</surname><given-names>D.</given-names></name><name><surname>Rudy</surname><given-names>J. W.</given-names></name><name><surname>O'Reilly</surname><given-names>R. C.</given-names></name></person-group> (<year>2007</year>). <article-title>Separate neural substrates for skill learning and performance in the ventral and dorsal striatum</article-title>. <source>Nat. Neurosci.</source><volume>10</volume>, <fpage>126</fpage>&#x02013;<lpage>131</lpage><pub-id pub-id-type="doi">10.1038/nn1817</pub-id><pub-id pub-id-type="pmid">17187065</pub-id></citation></ref><ref id="B5"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Balleine</surname><given-names>B. W.</given-names></name></person-group> (<year>2001</year>). <article-title>Incentive processes in instrumental conditioning</article-title>. In <source>Handbook of Contemporary Learning Theories</source>, <person-group person-group-type="editor"><name><surname>Mowrer</surname><given-names>R. R.</given-names></name><name><surname>Klein</surname><given-names>S. B.</given-names></name></person-group>, eds (<publisher-loc>Philadelphia, PA</publisher-loc>, <publisher-name>Lawrence Erlbaum Associates</publisher-name>), pp. <fpage>307</fpage>&#x02013;<lpage>366</lpage></citation></ref><ref id="B6"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Balleine</surname><given-names>B. W.</given-names></name><name><surname>Dickinson</surname><given-names>A.</given-names></name></person-group> (<year>1998</year>). <article-title>Goal-directed instrumental action: contingency and incentive learning and their cortical substrates</article-title>. <source>Neuropharmacology</source><volume>37</volume>, <fpage>407</fpage>&#x02013;<lpage>419</lpage><pub-id pub-id-type="doi">10.1016/S0028-3908(98)00033-1</pub-id><pub-id pub-id-type="pmid">9704982</pub-id></citation></ref><ref id="B7"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Barnes</surname><given-names>T. D.</given-names></name><name><surname>Kubota</surname><given-names>Y.</given-names></name><name><surname>Hu</surname><given-names>D.</given-names></name><name><surname>Jin</surname><given-names>D. Z.</given-names></name><name><surname>Graybiel</surname><given-names>A. M.</given-names></name></person-group> (<year>2005</year>). <article-title>Activity of striatal neurons reflects dynamic encoding and recoding of procedural memories</article-title>. <source>Nature</source><volume>437</volume>, <fpage>1158</fpage>&#x02013;<lpage>1161</lpage><pub-id pub-id-type="doi">10.1038/nature04053</pub-id><pub-id pub-id-type="pmid">16237445</pub-id></citation></ref><ref id="B8"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Berke</surname><given-names>J. D.</given-names></name><name><surname>Okatan</surname><given-names>M.</given-names></name><name><surname>Skurski</surname><given-names>J.</given-names></name><name><surname>Eichenbaum</surname><given-names>H. B.</given-names></name></person-group> (<year>2004</year>). <article-title>Oscillatory entrainment of striatal neurons in freely moving rats</article-title>. <source>Neuron</source><volume>43</volume>, <fpage>883</fpage>&#x02013;<lpage>896</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2004.08.035</pub-id><pub-id pub-id-type="pmid">15363398</pub-id></citation></ref><ref id="B9"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Block</surname><given-names>A. E.</given-names></name><name><surname>Dhanji</surname><given-names>H.</given-names></name><name><surname>Thompson-Tardif</surname><given-names>S. F.</given-names></name><name><surname>Floresco</surname><given-names>S. B.</given-names></name></person-group> (<year>2007</year>). <article-title>Thalamic-prefrontal cortical-ventral striatal circuitry mediates dissociable components of strategy set shifting</article-title>. <source>Cereb. Cortex</source><volume>17</volume>, <fpage>1625</fpage>&#x02013;<lpage>1636</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhl073</pub-id><pub-id pub-id-type="pmid">16963518</pub-id></citation></ref><ref id="B10"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Buckner</surname><given-names>R. L.</given-names></name><name><surname>Carroll</surname><given-names>D. C.</given-names></name></person-group> (<year>2007</year>). <article-title>Self-projection and the brain</article-title>. <source>Trends Cogn. Sci.</source><volume>11</volume>, <fpage>49</fpage>&#x02013;<lpage>57</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2006.11.004</pub-id><pub-id pub-id-type="pmid">17188554</pub-id></citation></ref><ref id="B11"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Cardinal</surname><given-names>R. N.</given-names></name><name><surname>Parkinson</surname><given-names>J. A.</given-names></name><name><surname>Hall</surname><given-names>J.</given-names></name><name><surname>Everitt</surname><given-names>B. J.</given-names></name></person-group> (<year>2002</year>). <article-title>Emotion and motivation: the role of the amygdala, ventral striatum, and prefrontal cortex</article-title>. <source>Neurosci. Biobehav. Rev.</source><volume>26</volume>, <fpage>321</fpage>&#x02013;<lpage>352</lpage><pub-id pub-id-type="doi">10.1016/S0149-7634(02)00007-6</pub-id><pub-id pub-id-type="pmid">12034134</pub-id></citation></ref><ref id="B12"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Cardinal</surname><given-names>R. N.</given-names></name><name><surname>Pennicott</surname><given-names>D. R.</given-names></name><name><surname>Sugathapala</surname><given-names>C. L.</given-names></name><name><surname>Robbins</surname><given-names>T. W.</given-names></name><name><surname>Everitt</surname><given-names>B. J.</given-names></name></person-group> (<year>2001</year>). <article-title>Impulsive choice induced in rats by lesions of the nucleus accumbens core</article-title>. <source>Science</source><volume>292</volume>, <fpage>2499</fpage>&#x02013;<lpage>2501</lpage><pub-id pub-id-type="doi">10.1126/science.1060818</pub-id><pub-id pub-id-type="pmid">11375482</pub-id></citation></ref><ref id="B13"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Carelli</surname><given-names>R. M.</given-names></name></person-group> (<year>2002</year>). <article-title>Nucleus accumbens cell firing during goal-directed behaviors for cocaine vs. &#x0201c;natural&#x0201d; reinforcement</article-title>. <source>Physiol. Behav.</source><volume>76</volume>, <fpage>379</fpage>&#x02013;<lpage>387</lpage><pub-id pub-id-type="doi">10.1016/S0031-9384(02)00760-6</pub-id><pub-id pub-id-type="pmid">12117574</pub-id></citation></ref><ref id="B14"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Carelli</surname><given-names>R. M.</given-names></name><name><surname>Deadwyler</surname><given-names>S. A.</given-names></name></person-group> (<year>1994</year>). <article-title>A comparison of nucleus accumbens neuronal firing patterns during cocaine self-administration and water reinforcement in rats</article-title>. <source>J. Neurosci.</source><volume>14</volume>, <fpage>7735</fpage>&#x02013;<lpage>7746</lpage><pub-id pub-id-type="pmid">7996208</pub-id></citation></ref><ref id="B15"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Chudasama</surname><given-names>Y.</given-names></name><name><surname>Wright</surname><given-names>K. S.</given-names></name><name><surname>Murray</surname><given-names>E. A.</given-names></name></person-group> (<year>2008</year>). <article-title>Hippocampal lesions in rhesus monkeys disrupt emotional responses but not reinforcer devaluation effects</article-title>. <source>Biol. Psychiatry</source><volume>63</volume>, <fpage>1084</fpage>&#x02013;<lpage>1091</lpage><pub-id pub-id-type="doi">10.1016/j.biopsych.2007.11.012</pub-id><pub-id pub-id-type="pmid">18191111</pub-id></citation></ref><ref id="B16"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Corbit</surname><given-names>L. H.</given-names></name><name><surname>Muir</surname><given-names>J. L.</given-names></name><name><surname>Balleine</surname><given-names>B. W.</given-names></name></person-group> (<year>2001</year>). <article-title>The role of the nucleus accumbens in instrumental conditioning: evidence of a functional dissociation between accumbens core and shell</article-title>. <source>J. Neurosci.</source><volume>21</volume>, <fpage>3251</fpage>&#x02013;<lpage>3260</lpage><pub-id pub-id-type="pmid">11312310</pub-id></citation></ref><ref id="B17"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Corbit</surname><given-names>L. H.</given-names></name><name><surname>Ostlund</surname><given-names>S. B.</given-names></name><name><surname>Balleine</surname><given-names>B. W.</given-names></name></person-group> (<year>2002</year>). <article-title>Sensitivity to instrumental contingency degradation is mediated by the entorhinal cortex and its efferents via the dorsal hippocampus</article-title>. <source>J. Neurosci.</source><volume>22</volume>, <fpage>10976</fpage>&#x02013;<lpage>10984</lpage><pub-id pub-id-type="pmid">12486193</pub-id></citation></ref><ref id="B18"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Dale</surname><given-names>R. H.</given-names></name></person-group> (<year>1986</year>). <article-title>Spatial and temporal response patterns on the eight-arm radial maze</article-title>. <source>Physiol. Behav.</source><volume>36</volume>, <fpage>787</fpage>&#x02013;<lpage>790</lpage><pub-id pub-id-type="doi">10.1016/0031-9384(86)90370-7</pub-id><pub-id pub-id-type="pmid">3714854</pub-id></citation></ref><ref id="B19"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Daw</surname><given-names>N. D.</given-names></name><name><surname>Niv</surname><given-names>Y.</given-names></name><name><surname>Dayan</surname><given-names>P.</given-names></name></person-group> (<year>2005</year>). <article-title>Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control</article-title>. <source>Nat. Neurosci.</source><volume>8</volume>, <fpage>1704</fpage>&#x02013;<lpage>1711</lpage><pub-id pub-id-type="doi">10.1038/nn1560</pub-id><pub-id pub-id-type="pmid">16286932</pub-id></citation></ref><ref id="B20"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Day</surname><given-names>J. J.</given-names></name><name><surname>Carelli</surname><given-names>R. M.</given-names></name></person-group> (<year>2007</year>). <article-title>The nucleus accumbens and pavlovian reward learning</article-title>. <source>Neuroscientist</source><volume>13</volume>, <fpage>148</fpage>&#x02013;<lpage>159</lpage><pub-id pub-id-type="doi">10.1177/1073858406295854</pub-id><pub-id pub-id-type="pmid">17404375</pub-id></citation></ref><ref id="B21"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>de Borchgrave</surname><given-names>R.</given-names></name><name><surname>Rawlins</surname><given-names>J. N. P.</given-names></name><name><surname>Dickinson</surname><given-names>A.</given-names></name><name><surname>Balleine</surname><given-names>B. W.</given-names></name></person-group> (<year>2002</year>). <article-title>Effects of cytotoxic nucleus accumbens lesions on instrumental conditioning in rats</article-title>. <source>Exp. Brain Res.</source><volume>144</volume>, <fpage>50</fpage>&#x02013;<lpage>68</lpage><pub-id pub-id-type="doi">10.1007/s00221-002-1031-y</pub-id><pub-id pub-id-type="pmid">11976759</pub-id></citation></ref><ref id="B22"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Finch</surname><given-names>D. M.</given-names></name></person-group> (<year>1996</year>). <article-title>Neurophysiology of converging synaptic inputs from the rat prefrontal cortex, amygdala, midline thalamus, and hippocampal formation onto single neurons of the caudate/putamen and nucleus accumbens</article-title>. <source>Hippocampus</source><volume>6</volume>, <fpage>495</fpage>&#x02013;<lpage>512</lpage><pub-id pub-id-type="doi">10.1002/(SICI)1098-1063(1996)6:5&#x0003c;495::AID-HIPO3&#x0003e;3.0.CO;2-I</pub-id><pub-id pub-id-type="pmid">8953303</pub-id></citation></ref><ref id="B23"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Floresco</surname><given-names>S. B.</given-names></name><name><surname>Seamans</surname><given-names>J. K.</given-names></name><name><surname>Phillips</surname><given-names>A. G.</given-names></name></person-group> (<year>1997</year>). <article-title>Selective roles for hippocampal, prefrontal cortical, and ventral striatal circuits in radial-arm maze tasks with or without a delay</article-title>. <source>J. Neurosci.</source><volume>17</volume>, <fpage>1880</fpage>&#x02013;<lpage>1890</lpage><pub-id pub-id-type="pmid">9030646</pub-id></citation></ref><ref id="B24"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>German</surname><given-names>P. W.</given-names></name><name><surname>Fields</surname><given-names>H. L.</given-names></name></person-group> (<year>2007</year>). <article-title>Rat nucleus accumbens neurons persistently encode locations associated with morphine reward</article-title>. <source>J. Neurophysiol.</source><volume>97</volume>, <fpage>2094</fpage>&#x02013;<lpage>2106</lpage><pub-id pub-id-type="doi">10.1152/jn.00304.2006</pub-id><pub-id pub-id-type="pmid">17093128</pub-id></citation></ref><ref id="B25"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Groenewegen</surname><given-names>H. J.</given-names></name><name><surname>Vermeulen-Van der Zee</surname><given-names>E.</given-names></name><name><surname>te Kortschot</surname><given-names>A.</given-names></name><name><surname>Witter</surname><given-names>M. P.</given-names></name></person-group> (<year>1987</year>). <article-title>Organization of the projections from the subiculum to the ventral striatum in the rat. A study using anterograde transport of phaseolus vulgaris leucoagglutinin</article-title>. <source>Neuroscience</source><volume>23</volume>, <fpage>103</fpage>&#x02013;<lpage>120</lpage><pub-id pub-id-type="doi">10.1016/0306-4522(87)90275-2</pub-id><pub-id pub-id-type="pmid">3683859</pub-id></citation></ref><ref id="B26"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Hare</surname><given-names>T. A.</given-names></name><name><surname>O'Doherty</surname><given-names>J.</given-names></name><name><surname>Camerer</surname><given-names>C. F.</given-names></name><name><surname>Schultz</surname><given-names>W.</given-names></name><name><surname>Rangel</surname><given-names>A.</given-names></name></person-group> (<year>2008</year>). <article-title>Dissociating the role of the orbitofrontal cortex and the striatum in the computation of goal values and prediction errors</article-title>. <source>J. Neurosci.</source><volume>28</volume>, <fpage>5623</fpage>&#x02013;<lpage>5630</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1309-08.2008</pub-id><pub-id pub-id-type="pmid">18509023</pub-id></citation></ref><ref id="B27"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Hebb</surname><given-names>D. O.</given-names></name></person-group> (<year>1949</year>). <article-title>The Organization of Behavior</article-title>. <publisher-loc>New York</publisher-loc>, <publisher-name>Wiley</publisher-name></citation></ref><ref id="B28"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Holland</surname><given-names>P. C.</given-names></name></person-group> (<year>2004</year>). <article-title>Relations between pavlovian-instrumental transfer and reinforcer devaluation</article-title>. <source>J. Exp. Psychol. Anim. Behav. Process</source><volume>30</volume>, <fpage>104</fpage>&#x02013;<lpage>117</lpage><pub-id pub-id-type="doi">10.1037/0097-7403.30.2.104</pub-id><pub-id pub-id-type="pmid">15078120</pub-id></citation></ref><ref id="B29"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Holman</surname><given-names>E. W.</given-names></name></person-group> (<year>1975</year>). <article-title>Some conditions for the dissociation of consummatory and instrumental behavior in rats</article-title>. <source>Learn. Motiv.</source><volume>6</volume>, <fpage>358</fpage>&#x02013;<lpage>366</lpage><pub-id pub-id-type="doi">10.1016/0023-9690(75)90015-6</pub-id></citation></ref><ref id="B30"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Hu</surname><given-names>D.</given-names></name><name><surname>Amsel</surname><given-names>A.</given-names></name></person-group> (<year>1995</year>). <article-title>A simple test of the vicarious trial-and-error hypothesis of hippocampal function</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A.</source><volume>92</volume>, <fpage>5506</fpage>&#x02013;<lpage>5509</lpage><pub-id pub-id-type="doi">10.1073/pnas.92.12.5506</pub-id><pub-id pub-id-type="pmid">7777539</pub-id></citation></ref><ref id="B31"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>A.</given-names></name><name><surname>Fenton</surname><given-names>A. A.</given-names></name><name><surname>Kentros</surname><given-names>C.</given-names></name><name><surname>Redish</surname><given-names>A. D.</given-names></name></person-group> (<year>2009</year>). <article-title>Looking for cognition in the structure in the noise</article-title>. <source>Trends Cogn. Sci.</source> (in press).<pub-id pub-id-type="doi">10.1016/j.tics.2008.11.005</pub-id><pub-id pub-id-type="pmid">19135406</pub-id></citation></ref><ref id="B32"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>A.</given-names></name><name><surname>Redish</surname><given-names>A. D.</given-names></name></person-group> (<year>2007</year>). <article-title>Neural ensembles in CA3 transiently encode paths forward of the animal at a decision point</article-title>. <source>J. Neurosci.</source><volume>27</volume>, <fpage>12176</fpage>&#x02013;<lpage>12189</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3761-07.2007</pub-id><pub-id pub-id-type="pmid">17989284</pub-id></citation></ref><ref id="B33"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>A.</given-names></name><name><surname>van der Meer</surname><given-names>M. A. A.</given-names></name><name><surname>Redish</surname><given-names>A. D.</given-names></name></person-group> (<year>2007</year>). <article-title>Integrating hippocampus and striatum in decision-making</article-title>. <source>Curr. Opin. Neurobiol.</source><volume>17</volume>, <fpage>692</fpage>&#x02013;<lpage>697</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2008.01.003</pub-id><pub-id pub-id-type="pmid">18313289</pub-id></citation></ref><ref id="B34"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kelley</surname><given-names>A. E.</given-names></name></person-group> (<year>2004</year>). <article-title>Ventral striatal control of appetitive motivation: role in ingestive behavior and reward-related learning</article-title>. <source>Neurosci. Biobehav. Rev.</source><volume>27</volume>, <fpage>765</fpage>&#x02013;<lpage>776</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2003.11.015</pub-id><pub-id pub-id-type="pmid">15019426</pub-id></citation></ref><ref id="B35"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Knutson</surname><given-names>B.</given-names></name><name><surname>Cooper</surname><given-names>J. C.</given-names></name></person-group> (<year>2005</year>). <article-title>Functional magnetic resonance imaging of reward prediction</article-title>. <source>Curr. Opin. Neurol.</source><volume>18</volume>, <fpage>411</fpage>&#x02013;<lpage>417</lpage><pub-id pub-id-type="doi">10.1097/01.wco.0000173463.24758.f6</pub-id><pub-id pub-id-type="pmid">16003117</pub-id></citation></ref><ref id="B36"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Lansink</surname><given-names>C. S.</given-names></name><name><surname>Goltstein</surname><given-names>P. M.</given-names></name><name><surname>Lankelma</surname><given-names>J. V.</given-names></name><name><surname>Joosten</surname><given-names>R. N. J. M. A.</given-names></name><name><surname>McNaughton</surname><given-names>B. L.</given-names></name><name><surname>Pennartz</surname><given-names>C. M. A.</given-names></name></person-group> (<year>2008</year>). <article-title>Preferential reactivation of motivationally relevant information in the ventral striatum</article-title>. <source>J. Neurosci.</source><volume>28</volume>, <fpage>6372</fpage>&#x02013;<lpage>6382</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1054-08.2008</pub-id><pub-id pub-id-type="pmid">18562607</pub-id></citation></ref><ref id="B37"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Lavoie</surname><given-names>A. M.</given-names></name><name><surname>Mizumori</surname><given-names>S. J.</given-names></name></person-group> (<year>1994</year>). <article-title>Spatial, movement- and reward-sensitive discharge by medial ventral striatum neurons of rats</article-title>. <source>Brain Res.</source><volume>638</volume>, <fpage>157</fpage>&#x02013;<lpage>168</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(94)90645-9</pub-id><pub-id pub-id-type="pmid">8199856</pub-id></citation></ref><ref id="B38"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Martin</surname><given-names>P. D.</given-names></name></person-group> (<year>2001</year>). <article-title>Locomotion towards a goal alters the synchronous firing of neurons recorded simultaneously in the subiculum and nucleus accumbens of rats</article-title>. <source>Behav. Brain Res.</source><volume>124</volume>, <fpage>19</fpage>&#x02013;<lpage>28</lpage><pub-id pub-id-type="doi">10.1016/S0166-4328(01)00209-1</pub-id><pub-id pub-id-type="pmid">11423162</pub-id></citation></ref><ref id="B39"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Martin</surname><given-names>P. D.</given-names></name><name><surname>Ono</surname><given-names>T.</given-names></name></person-group> (<year>2000</year>). <article-title>Effects of reward anticipation, reward presentation, and spatial parameters on the firing of single neurons recorded in the subiculum and nucleus accumbens of freely moving rats</article-title>. <source>Behav. Brain Res.</source><volume>116</volume>, <fpage>23</fpage>&#x02013;<lpage>38</lpage><pub-id pub-id-type="doi">10.1016/S0166-4328(00)00249-7</pub-id><pub-id pub-id-type="pmid">11090883</pub-id></citation></ref><ref id="B40"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Masimore</surname><given-names>B.</given-names></name><name><surname>Schmitzer-Torbert</surname><given-names>N. C.</given-names></name><name><surname>Kakalios</surname><given-names>J.</given-names></name><name><surname>Redish</surname><given-names>A. D.</given-names></name></person-group> (<year>2005</year>). <article-title>Transient striatal gamma local field potentials signal movement initiation in rats</article-title>. <source>Neuroreport</source><volume>16</volume>, <fpage>2021</fpage>&#x02013;<lpage>2024</lpage><pub-id pub-id-type="doi">10.1097/00001756-200512190-00010</pub-id><pub-id pub-id-type="pmid">16317346</pub-id></citation></ref><ref id="B41"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>G.</given-names></name><name><surname>Galanter</surname><given-names>E.</given-names></name><name><surname>Pribram</surname><given-names>D.</given-names></name></person-group> (<year>1960</year>). <article-title>Plans and the Structure of Behavior</article-title>. <publisher-loc>New York</publisher-loc>, <publisher-name>Henry Holt &#x00026; Co</publisher-name></citation></ref><ref id="B42"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Miyazaki</surname><given-names>K.</given-names></name><name><surname>Mogi</surname><given-names>E.</given-names></name><name><surname>Araki</surname><given-names>N.</given-names></name><name><surname>Matsumoto</surname><given-names>G.</given-names></name></person-group> (<year>1998</year>). <article-title>Reward-quality dependent anticipation in rat nucleus accumbens</article-title>. <source>Neuroreport</source><volume>9</volume>, <fpage>3943</fpage>&#x02013;<lpage>3948</lpage><pub-id pub-id-type="doi">10.1097/00001756-199812010-00032</pub-id><pub-id pub-id-type="pmid">9875733</pub-id></citation></ref><ref id="B43"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Mogenson</surname><given-names>G. J.</given-names></name><name><surname>Jones</surname><given-names>D. L.</given-names></name><name><surname>Yim</surname><given-names>C. Y.</given-names></name></person-group> (<year>1980</year>). <article-title>From motivation to action: functional interface between the limbic system and the motor system</article-title>. <source>Prog. Neurobiol.</source><volume>14</volume>, <fpage>69</fpage>&#x02013;<lpage>97</lpage><pub-id pub-id-type="doi">10.1016/0301-0082(80)90018-0</pub-id><pub-id pub-id-type="pmid">6999537</pub-id></citation></ref><ref id="B44"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Muenzinger</surname><given-names>K. F.</given-names></name></person-group> (<year>1938</year>). <article-title>Vicarious trial and error at a point of choice. I. A general survey of its relation to learning efficiency</article-title>. <source>J. Genet. Psychol.</source><volume>53</volume>, <fpage>75</fpage>&#x02013;<lpage>86</lpage></citation></ref><ref id="B45"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Mulder</surname><given-names>A. B.</given-names></name><name><surname>Shibata</surname><given-names>R.</given-names></name><name><surname>Trullier</surname><given-names>O.</given-names></name><name><surname>Wiener</surname><given-names>S. I.</given-names></name></person-group> (<year>2005</year>). <article-title>Spatially selective reward site responses in tonically active neurons of the nucleus accumbens in behaving rats</article-title>. <source>Exp. Brain Res.</source><volume>163</volume>, <fpage>32</fpage>&#x02013;<lpage>43</lpage><pub-id pub-id-type="doi">10.1007/s00221-004-2135-3</pub-id><pub-id pub-id-type="pmid">15654593</pub-id></citation></ref><ref id="B46"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Newell</surname><given-names>A.</given-names></name><name><surname>Simon</surname><given-names>H. A.</given-names></name></person-group> (<year>1972</year>). <article-title>Human Problem Solving</article-title>. <publisher-loc>Englewood Cliffs, NJ</publisher-loc>, <publisher-name>Prentice-Hall</publisher-name></citation></ref><ref id="B47"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Nicola</surname><given-names>S. M.</given-names></name></person-group> (<year>2007</year>). <article-title>The nucleus accumbens as part of a basal ganglia action selection circuit</article-title>. <source>Psychopharmacology (Berl.)</source><volume>191</volume>, <fpage>521</fpage>&#x02013;<lpage>550</lpage><pub-id pub-id-type="doi">10.1007/s00213-006-0510-4</pub-id><pub-id pub-id-type="pmid">16983543</pub-id></citation></ref><ref id="B48"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Nicola</surname><given-names>S. M.</given-names></name><name><surname>Yun</surname><given-names>I. A.</given-names></name><name><surname>Wakabayashi</surname><given-names>K. T.</given-names></name><name><surname>Fields</surname><given-names>H. L.</given-names></name></person-group> (<year>2004</year>). <article-title>Cue-evoked firing of nucleus accumbens neurons encodes motivational significance during a discriminative stimulus task</article-title>. <source>J. Neurophysiol.</source><volume>91</volume>, <fpage>1840</fpage>&#x02013;<lpage>1865</lpage><pub-id pub-id-type="doi">10.1152/jn.00657.2003</pub-id><pub-id pub-id-type="pmid">14645377</pub-id></citation></ref><ref id="B49"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Niv</surname><given-names>Y.</given-names></name><name><surname>Joel</surname><given-names>D.</given-names></name><name><surname>Dayan</surname><given-names>P.</given-names></name></person-group> (<year>2006</year>). <article-title>A normative perspective on motivation</article-title>. <source>Trends Cogn. Sci.</source><volume>10</volume>, <fpage>375</fpage>&#x02013;<lpage>381</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2006.06.010</pub-id><pub-id pub-id-type="pmid">16843041</pub-id></citation></ref><ref id="B50"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Niv</surname><given-names>Y.</given-names></name><name><surname>Schoenbaum</surname><given-names>G.</given-names></name></person-group> (<year>2008</year>). <article-title>Dialogues on prediction errors</article-title>. <source>Trends Cogn. Sci.</source><volume>12</volume>, <fpage>265</fpage>&#x02013;<lpage>272</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2008.03.006</pub-id><pub-id pub-id-type="pmid">18567531</pub-id></citation></ref><ref id="B51"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>O'Doherty</surname><given-names>J.</given-names></name><name><surname>Dayan</surname><given-names>P.</given-names></name><name><surname>Schultz</surname><given-names>J.</given-names></name><name><surname>Deichmann</surname><given-names>R.</given-names></name><name><surname>Friston</surname><given-names>K.</given-names></name><name><surname>Dolan</surname><given-names>R. J.</given-names></name></person-group> (<year>2004</year>). <article-title>Dissociable roles of ventral and dorsal striatum in instrumental conditioning</article-title>. <source>Science</source><volume>304</volume>, <fpage>452</fpage>&#x02013;<lpage>454</lpage><pub-id pub-id-type="doi">10.1126/science.1094285</pub-id><pub-id pub-id-type="pmid">15087550</pub-id></citation></ref><ref id="B52"><citation citation-type="book"><person-group person-group-type="author"><name><surname>O'Keefe</surname><given-names>J.</given-names></name><name><surname>Nadel</surname><given-names>L.</given-names></name></person-group> (<year>1978</year>). <article-title>The Hippocampus as a Cognitive Map</article-title>. <publisher-loc>Oxford, UK</publisher-loc>, <publisher-name>Clarendon Press</publisher-name></citation></ref><ref id="B53"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Packard</surname><given-names>M. G.</given-names></name><name><surname>McGaugh</surname><given-names>J. L.</given-names></name></person-group> (<year>1996</year>). <article-title>Inactivation of hippocampus or caudate nucleus with lidocaine differentially affects expression of place and response learning</article-title>. <source>Neurobiol. Learn. Mem.</source><volume>65</volume>, <fpage>65</fpage>&#x02013;<lpage>72</lpage><pub-id pub-id-type="doi">10.1006/nlme.1996.0007</pub-id><pub-id pub-id-type="pmid">8673408</pub-id></citation></ref><ref id="B54"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Parkinson</surname><given-names>J. A.</given-names></name><name><surname>Dalley</surname><given-names>J. W.</given-names></name><name><surname>Cardinal</surname><given-names>R. N.</given-names></name><name><surname>Bamford</surname><given-names>A.</given-names></name><name><surname>Fehnert</surname><given-names>B.</given-names></name><name><surname>Lachenal</surname><given-names>G.</given-names></name><name><surname>Rudarakanchana</surname><given-names>N.</given-names></name><name><surname>Halkerston</surname><given-names>K. M.</given-names></name><name><surname>Robbins</surname><given-names>T. W.</given-names></name><name><surname>Everitt</surname><given-names>B. J.</given-names></name></person-group> (<year>2002</year>). <article-title>Nucleus accumbens dopamine depletion impairs both acquisition and performance of appetitive pavlovian approach behaviour: implications for mesoaccumbens dopamine function</article-title>. <source>Behav. Brain Res.</source><volume>137</volume>, <fpage>149</fpage>&#x02013;<lpage>163</lpage><pub-id pub-id-type="doi">10.1016/S0166-4328(02)00291-7</pub-id><pub-id pub-id-type="pmid">12445721</pub-id></citation></ref><ref id="B55"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Pennartz</surname><given-names>C. M. A.</given-names></name><name><surname>Lee</surname><given-names>E.</given-names></name><name><surname>Verheul</surname><given-names>J.</given-names></name><name><surname>Lipa</surname><given-names>P.</given-names></name><name><surname>Barnes</surname><given-names>C. A.</given-names></name><name><surname>McNaughton</surname><given-names>B. L.</given-names></name></person-group> (<year>2004</year>). <article-title>The ventral striatum in off-line processing: ensemble reactivation during sleep and modulation by hippocampal ripples</article-title>. <source>J. Neurosci.</source><volume>24</volume>, <fpage>6446</fpage>&#x02013;<lpage>6456</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0575-04.2004</pub-id><pub-id pub-id-type="pmid">15269254</pub-id></citation></ref><ref id="B56"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Poldrack</surname><given-names>R. A.</given-names></name><name><surname>Packard</surname><given-names>M. G.</given-names></name></person-group> (<year>2003</year>). <article-title>Competition among multiple memory systems: converging evidence from animal and human brain studies</article-title>. <source>Neuropsychologia</source><volume>41</volume>, <fpage>245</fpage>&#x02013;<lpage>251</lpage><pub-id pub-id-type="doi">10.1016/S0028-3932(02)00157-4</pub-id><pub-id pub-id-type="pmid">12457750</pub-id></citation></ref><ref id="B57"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Redish</surname><given-names>A. D.</given-names></name><name><surname>Jensen</surname><given-names>S.</given-names></name><name><surname>Johnson</surname><given-names>A.</given-names></name></person-group> (<year>2008</year>). <article-title>A unified framework for addiction: vulnerabilities in the decision process</article-title>. <source>Behav. Brain Sci.</source><volume>31</volume>, <fpage>415</fpage>&#x02013;<lpage>437</lpage>; Discussion <fpage>437</fpage>&#x02013;<lpage>487</lpage><pub-id pub-id-type="doi">10.1017/S0140525X0800472X</pub-id><pub-id pub-id-type="pmid">18662461</pub-id></citation></ref><ref id="B58"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Redish</surname><given-names>A. D.</given-names></name><name><surname>Johnson</surname><given-names>A.</given-names></name></person-group> (<year>2007</year>). <article-title>A computational model of craving and obsession</article-title>. <source>Ann. N. Y. Acad. Sci.</source><volume>1104</volume>, <fpage>324</fpage>&#x02013;<lpage>339</lpage><pub-id pub-id-type="doi">10.1196/annals.1390.014</pub-id><pub-id pub-id-type="pmid">17595292</pub-id></citation></ref><ref id="B59"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Roitman</surname><given-names>M. F.</given-names></name><name><surname>Wheeler</surname><given-names>R. A.</given-names></name><name><surname>Carelli</surname><given-names>R. M.</given-names></name></person-group> (<year>2005</year>). <article-title>Nucleus accumbens neurons are innately tuned for rewarding and aversive taste stimuli, encode their predictors, and are linked to motor output</article-title>. <source>Neuron</source><volume>45</volume>, <fpage>587</fpage>&#x02013;<lpage>597</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2004.12.055</pub-id><pub-id pub-id-type="pmid">15721244</pub-id></citation></ref><ref id="B60"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Salamone</surname><given-names>J. D.</given-names></name><name><surname>Correa</surname><given-names>M.</given-names></name><name><surname>Mingote</surname><given-names>S. M.</given-names></name><name><surname>Weber</surname><given-names>S. M.</given-names></name></person-group> (<year>2005</year>). <article-title>Beyond the reward hypothesis: alternative functions of nucleus accumbens dopamine</article-title>. <source>Curr. Opin. Pharmacol.</source><volume>5</volume>, <fpage>34</fpage>&#x02013;<lpage>41</lpage><pub-id pub-id-type="doi">10.1016/j.coph.2004.09.004</pub-id><pub-id pub-id-type="pmid">15661623</pub-id></citation></ref><ref id="B61"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Schacter</surname><given-names>D. L.</given-names></name><name><surname>Addis</surname><given-names>D. R.</given-names></name><name><surname>Buckner</surname><given-names>R. L.</given-names></name></person-group> (<year>2008</year>). <article-title>Episodic simulation of future events: concepts, data, and applications</article-title>. <source>Ann. N. Y. Acad. Sci.</source><volume>1124</volume>, <fpage>39</fpage>&#x02013;<lpage>60</lpage><pub-id pub-id-type="doi">10.1196/annals.1440.001</pub-id><pub-id pub-id-type="pmid">18400923</pub-id></citation></ref><ref id="B62"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Schmitzer-Torbert</surname><given-names>N. C.</given-names></name><name><surname>Redish</surname><given-names>A. D.</given-names></name></person-group> (<year>2004</year>). <article-title>Neuronal activity in the rodent dorsal striatum in sequential navigation: separation of spatial and reward responses on the multiple T task</article-title>. <source>J. Neurophysiol.</source><volume>91</volume>, <fpage>2259</fpage>&#x02013;<lpage>2272</lpage><pub-id pub-id-type="doi">10.1152/jn.00687.2003</pub-id><pub-id pub-id-type="pmid">14736863</pub-id></citation></ref><ref id="B63"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Schmitzer-Torbert</surname><given-names>N. C.</given-names></name><name><surname>Redish</surname><given-names>A. D.</given-names></name></person-group> (<year>2008</year>). <article-title>Task-dependent encoding of space and events by striatal neurons is dependent on neural subtype</article-title>. <source>Neuroscience</source><volume>153</volume>, <fpage>349</fpage>&#x02013;<lpage>360</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2008.01.081</pub-id><pub-id pub-id-type="pmid">18406064</pub-id></citation></ref><ref id="B64"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Schoenbaum</surname><given-names>G.</given-names></name><name><surname>Roesch</surname><given-names>M. R.</given-names></name><name><surname>Stalnaker</surname><given-names>T. A.</given-names></name></person-group> (<year>2006</year>). <article-title>Orbitofrontal cortex, decision-making and drug addiction</article-title>. <source>Trends Neurosci.</source><volume>29</volume>, <fpage>116</fpage>&#x02013;<lpage>124</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2005.12.006</pub-id><pub-id pub-id-type="pmid">16406092</pub-id></citation></ref><ref id="B65"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Schoenbaum</surname><given-names>G.</given-names></name><name><surname>Setlow</surname><given-names>B.</given-names></name></person-group> (<year>2003</year>). <article-title>Lesions of nucleus accumbens disrupt learning about aversive outcomes</article-title>. <source>J. Neurosci.</source><volume>23</volume>, <fpage>9833</fpage>&#x02013;<lpage>9841</lpage><pub-id pub-id-type="pmid">14586012</pub-id></citation></ref><ref id="B66"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Schultz</surname><given-names>W.</given-names></name><name><surname>Dayan</surname><given-names>P.</given-names></name><name><surname>Montague</surname><given-names>P. R.</given-names></name></person-group> (<year>1997</year>). <article-title>A neural substrate of prediction and reward</article-title>. <source>Science</source><volume>275</volume>, <fpage>1593</fpage>&#x02013;<lpage>1599</lpage><pub-id pub-id-type="doi">10.1126/science.275.5306.1593</pub-id><pub-id pub-id-type="pmid">9054347</pub-id></citation></ref><ref id="B67"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Setlow</surname><given-names>B.</given-names></name></person-group> (<year>1997</year>). <article-title>The nucleus accumbens and learning and memory</article-title>. <source>J. Neurosci. Res.</source><volume>49</volume>, <fpage>515</fpage>&#x02013;<lpage>521</lpage><pub-id pub-id-type="doi">10.1002/(SICI)1097-4547(19970901)49:5&#x0003c;515::AID-JNR1&#x0003e;3.0.CO;2-E</pub-id><pub-id pub-id-type="pmid">9302072</pub-id></citation></ref><ref id="B68"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Setlow</surname><given-names>B.</given-names></name><name><surname>Schoenbaum</surname><given-names>G.</given-names></name><name><surname>Gallagher</surname><given-names>M.</given-names></name></person-group> (<year>2003</year>). <article-title>Neural encoding in ventral striatum during olfactory discrimination learning</article-title>. <source>Neuron</source><volume>38</volume>, <fpage>625</fpage>&#x02013;<lpage>636</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(03)00264-2</pub-id><pub-id pub-id-type="pmid">12765613</pub-id></citation></ref><ref id="B69"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Shallice</surname><given-names>T.</given-names></name></person-group> (<year>1982</year>). <article-title>Specific impairments of planning</article-title>. <source>Philos. Trans. R. Soc. Lond. B Biol. Sci.</source><volume>298</volume>, <fpage>199</fpage>&#x02013;<lpage>209</lpage><pub-id pub-id-type="doi">10.1098/rstb.1982.0082</pub-id><pub-id pub-id-type="pmid">6125971</pub-id></citation></ref><ref id="B70"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Sutherland</surname><given-names>R. J.</given-names></name><name><surname>Rodriguez</surname><given-names>A. J.</given-names></name></person-group> (<year>1989</year>). <article-title>The role of the fornix/fimbria and some related subcortical structures in place learning and memory</article-title>. <source>Behav. Brain Res.</source><volume>32</volume>, <fpage>265</fpage>&#x02013;<lpage>277</lpage><pub-id pub-id-type="doi">10.1016/S0166-4328(89)80059-2</pub-id><pub-id pub-id-type="pmid">2496702</pub-id></citation></ref><ref id="B71"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Tenenbaum</surname><given-names>J. B.</given-names></name><name><surname>Griffiths</surname><given-names>T. L.</given-names></name><name><surname>Kemp</surname><given-names>C.</given-names></name></person-group> (<year>2006</year>). <article-title>Theory-based bayesian models of inductive learning and reasoning</article-title>. <source>Trends Cogn. Sci.</source><volume>10</volume>, <fpage>309</fpage>&#x02013;<lpage>318</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2006.05.009</pub-id><pub-id pub-id-type="pmid">16797219</pub-id></citation></ref><ref id="B72"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Toates</surname><given-names>F.</given-names></name></person-group> (<year>1986</year>). <article-title>Motivational Systems</article-title>. <publisher-loc>Cambridge, UK</publisher-loc>, <publisher-name>Cambridge University Press</publisher-name><pub-id pub-id-type="pmid">3099697</pub-id></citation></ref><ref id="B73"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Tolman</surname><given-names>E. C.</given-names></name></person-group> (<year>1932</year>). <article-title>Purposive Behavior in Animals and Men</article-title>. <publisher-loc>New York</publisher-loc>, <publisher-name>Appleton&#x02013;Century&#x02013;Crofts</publisher-name></citation></ref><ref id="B74"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Tolman</surname><given-names>E. C.</given-names></name></person-group> (<year>1948</year>). <article-title>Cognitive maps in rats and men</article-title>. <source>Psychol. Rev.</source><volume>55</volume>, <fpage>189</fpage>&#x02013;<lpage>208</lpage><pub-id pub-id-type="doi">10.1037/h0061626</pub-id><pub-id pub-id-type="pmid">18870876</pub-id></citation></ref><ref id="B75"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Tse</surname><given-names>D.</given-names></name><name><surname>Langston</surname><given-names>R. F.</given-names></name><name><surname>Kakeyama</surname><given-names>M.</given-names></name><name><surname>Bethus</surname><given-names>I.</given-names></name><name><surname>Spooner</surname><given-names>P. A.</given-names></name><name><surname>Wood</surname><given-names>E. R.</given-names></name><name><surname>Witter</surname><given-names>M. P.</given-names></name><name><surname>Morris</surname><given-names>R. G. M.</given-names></name></person-group> (<year>2007</year>). <article-title>Schemas and memory consolidation</article-title>. <source>Science</source><volume>316</volume>, <fpage>76</fpage>&#x02013;<lpage>82</lpage><pub-id pub-id-type="doi">10.1126/science.1135935</pub-id><pub-id pub-id-type="pmid">17412951</pub-id></citation></ref><ref id="B76"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Voorn</surname><given-names>P.</given-names></name><name><surname>Vanderschuren</surname><given-names>L. J. M. J.</given-names></name><name><surname>Groenewegen</surname><given-names>H. J.</given-names></name><name><surname>Robbins</surname><given-names>T. W.</given-names></name><name><surname>Pennartz</surname><given-names>C. M. A.</given-names></name></person-group> (<year>2004</year>). <article-title>Putting a spin on the dorsal&#x02013;ventral divide of the striatum</article-title>. <source>Trends Neurosci.</source><volume>27</volume>, <fpage>468</fpage>&#x02013;<lpage>474</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2004.06.006</pub-id><pub-id pub-id-type="pmid">15271494</pub-id></citation></ref><ref id="B77"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Wheeler</surname><given-names>R. A.</given-names></name><name><surname>Twining</surname><given-names>R. C.</given-names></name><name><surname>Jones</surname><given-names>J. L.</given-names></name><name><surname>Slater</surname><given-names>J. M.</given-names></name><name><surname>Grigson</surname><given-names>P. S.</given-names></name><name><surname>Carelli</surname><given-names>R. M.</given-names></name></person-group> (<year>2008</year>). <article-title>Behavioral and electrophysiological indices of negative affect predict cocaine self-administration</article-title>. <source>Neuron</source><volume>57</volume>, <fpage>774</fpage>&#x02013;<lpage>785</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.01.024</pub-id><pub-id pub-id-type="pmid">18341996</pub-id></citation></ref><ref id="B78"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Yin</surname><given-names>H. H.</given-names></name><name><surname>Knowlton</surname><given-names>B. J.</given-names></name><name><surname>Balleine</surname><given-names>B. W.</given-names></name></person-group> (<year>2004</year>). <article-title>Lesions of dorsolateral striatum preserve outcome expectancy but disrupt habit formation in instrumental learning</article-title>. <source>Eur. J. Neurosci.</source><volume>19</volume>, <fpage>181</fpage>&#x02013;<lpage>189</lpage><pub-id pub-id-type="doi">10.1111/j.1460-9568.2004.03095.x</pub-id><pub-id pub-id-type="pmid">14750976</pub-id></citation></ref><ref id="B79"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>K.</given-names></name><name><surname>Ginzburg</surname><given-names>I.</given-names></name><name><surname>McNaughton</surname><given-names>B. L.</given-names></name><name><surname>Sejnowski</surname><given-names>T. J.</given-names></name></person-group> (<year>1998</year>). <article-title>Interpreting neuronal population activity by reconstruction: unified framework with application to hippocampal place cells</article-title>. <source>J. Neurophysiol.</source><volume>79</volume>, <fpage>1017</fpage>&#x02013;<lpage>1044</lpage><pub-id pub-id-type="pmid">9463459</pub-id></citation></ref></ref-list></back></article>