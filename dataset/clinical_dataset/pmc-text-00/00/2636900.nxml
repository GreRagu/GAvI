<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN" "archivearticle.dtd"><article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article" xml:lang="EN"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Neuroinformatics</journal-id><journal-id journal-id-type="publisher-id">Front. Neuroinform.</journal-id><journal-title>Frontiers in Neuroinformatics</journal-title><issn pub-type="epub">1662-5196</issn><publisher><publisher-name>Frontiers Research Foundation</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">19198667</article-id><article-id pub-id-type="pmc">2636900</article-id><article-id pub-id-type="doi">10.3389/neuro.11.012.2008</article-id><article-categories><subj-group subj-group-type="heading"><subject>Neuroscience</subject><subj-group><subject>Original Research</subject></subj-group></subj-group></article-categories><title-group><article-title>PyNEST: A Convenient Interface to the NEST Simulator</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Eppler</surname><given-names>Jochen Martin</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="author-notes" rid="fn001">*</xref><xref ref-type="author-notes" rid="fn002"><sup>&#x02020;</sup></xref></contrib><contrib contrib-type="author"><name><surname>Helias</surname><given-names>Moritz</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="author-notes" rid="fn002"><sup>&#x02020;</sup></xref></contrib><contrib contrib-type="author"><name><surname>Muller</surname><given-names>Eilif</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref></contrib><contrib contrib-type="author"><name><surname>Diesmann</surname><given-names>Markus</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff4"><sup>4</sup></xref><xref ref-type="aff" rid="aff5"><sup>5</sup></xref></contrib><contrib contrib-type="author"><name><surname>Gewaltig</surname><given-names>Marc-Oliver</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib></contrib-group><aff id="aff1"><sup>1</sup><institution>Honda Research Institute Europe GmbH, Offenbach</institution><country>Germany</country></aff><aff id="aff2"><sup>2</sup><institution>Bernstein Center for Computational Neuroscience, Albert-Ludwig University</institution><country>Freiburg, Germany</country></aff><aff id="aff3"><sup>3</sup><institution>Laboratory for Computational Neuroscience, Swiss Federal Institute of Technology, EPFL</institution><country>Lausanne, Switzerland</country></aff><aff id="aff4"><sup>4</sup><institution>Theoretical Neuroscience Group, RIKEN Brain Science Institute</institution><country>Wako City, Japan</country></aff><aff id="aff5"><sup>5</sup><institution>Brain and Neural Systems Team, Computational Science Research Program, RIKEN</institution><country>Wako City, Japan</country></aff><author-notes><fn fn-type="edited-by"><p>Edited by: Rolf K&#x000f6;tter, Radboud University Nijmegen, The Netherlands</p></fn><fn fn-type="edited-by"><p>Reviewed by: Upinder S. Bhalla, National Center for Biological Sciences, India; Terrence C. Stewart, Carleton University, Canada</p></fn><corresp id="fn001">*Correspondence: Jochen Martin Eppler, Honda Research Institute Europe GmbH, Carl-Legien-Str. 30, 63073 Offenbach am Main, Germany. e-mail: <email>eppler@biologie.uni-freiburg.de</email></corresp><fn fn-type="other" id="fn002"><p><sup>&#x02020;</sup>Eppler and Helias contributed equally to this work.</p></fn></author-notes><pub-date pub-type="epreprint"><day>29</day><month>9</month><year>2008</year></pub-date><pub-date pub-type="epub"><day>29</day><month>1</month><year>2009</year></pub-date><pub-date pub-type="collection"><year>2008</year></pub-date><volume>2</volume><elocation-id>12</elocation-id><history><date date-type="received"><day>14</day><month>9</month><year>2008</year></date><date date-type="accepted"><day>30</day><month>12</month><year>2008</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2009 Eppler, Helias, Muller, Diesmann and Gewaltig.</copyright-statement><copyright-year>2009</copyright-year><license license-type="open-access" xlink:href="http://www.frontiersin.org/licenseagreement"><p>This is an open-access article subject to an exclusive license agreement between the authors and the Frontiers Research Foundation, which permits unrestricted use, distribution, and reproduction in any medium, provided the original authors and source are credited.</p></license></permissions><abstract><p>The neural simulation tool NEST (<monospace><uri xlink:type="simple" xlink:href="http://www.nest-initiative.org">http://www.nest-initiative.org</uri></monospace>) is a simulator for heterogeneous networks of point neurons or neurons with a small number of compartments. It aims at simulations of large neural systems with more than 10<sup>4</sup> neurons and 10<sup>7</sup> to 10<sup>9</sup> synapses. NEST is implemented in C++ and can be used on a large range of architectures from single-core laptops over multi-core desktop computers to super-computers with thousands of processor cores. Python (<monospace><uri xlink:type="simple" xlink:href="http://www.python.org">http://www.python.org</uri></monospace>) is a modern programming language that has recently received considerable attention in Computational Neuroscience. Python is easy to learn and has many extension modules for scientific computing (e.g. <monospace><uri xlink:type="simple" xlink:href="http://www.scipy.org">http://www.scipy.org</uri></monospace>). In this contribution we describe PyNEST, the new user interface to NEST. PyNEST combines NEST's efficient simulation kernel with the simplicity and flexibility of Python. Compared to NEST's native simulation language SLI, PyNEST makes it easier to set up simulations, generate stimuli, and analyze simulation results. We describe how PyNEST connects NEST and Python and how it is implemented. With a number of examples, we illustrate how it is used.</p></abstract><kwd-group><kwd>Python</kwd><kwd>modeling</kwd><kwd>integrate-and-fire neuron</kwd><kwd>large-scale simulation</kwd><kwd>scientific computing</kwd><kwd>networks</kwd><kwd>programming</kwd></kwd-group><counts><fig-count count="5"/><table-count count="0"/><equation-count count="0"/><ref-count count="27"/><page-count count="12"/><word-count count="8784"/></counts></article-meta></front><body><sec sec-type="introduction"><title>Introduction</title><p>The first user interface for NEST (Gewaltig and Diesmann, <xref ref-type="bibr" rid="B10">2007</xref>; Plesser et al., <xref ref-type="bibr" rid="B24">2007</xref>) was the simulation language SLI, a stack-based language derived from PostScript (Adobe Systems Inc., <xref ref-type="bibr" rid="B1">1999</xref>). However, programming in SLI turned out to be difficult to learn and users asked for a more convenient programming language for NEST.</p><p>When we decided to use Python as the new simulation language, it was almost unknown in Computational Neuroscience. In fact, Matlab (MathWorks, <xref ref-type="bibr" rid="B16">2002</xref>) was far more common, both for simulations and for analysis. Other simulators, like e.g. CSIM (Natschl&#x000e4;ger, <xref ref-type="bibr" rid="B21">2003</xref>), already used Matlab as their interface language. Thus, Matlab would have been a natural choice for NEST as well.</p><p>Python has a number of advantages over commercial software like Matlab and other free scripting languages like Tcl/Tk (Ousterhout, <xref ref-type="bibr" rid="B23">1994</xref>). First, Python is installed by default on all Linux and Mac-OS based computers. Second, Python is stable, portable, and supported by a large and active developer community, and has a long history in scientific fields outside the neurosciences (Dubois, <xref ref-type="bibr" rid="B8">2007</xref>). Third, Python is a powerful interactive programming language with a surprisingly concise and readable syntax. It supports many programming paradigms such as object-oriented and functional programming. Through packages like NumPy <monospace>(<uri xlink:type="simple" xlink:href="http://www.numpy.org">http://www.numpy.org</uri></monospace>) and SciPy (<monospace><uri xlink:type="simple" xlink:href="http://www.scipy.org">http://www.scipy.org</uri></monospace>), Python supports scientific computing and visualization &#x000e0; la Matlab. Finally, a number of neuroscience laboratories meanwhile use Python for simulation and analysis, which further supports our choice.</p><p>Python is powerful at steering other applications and provides a well documented interface (API) to link applications to Python (van Rossum, <xref ref-type="bibr" rid="B27">2008</xref>). To do so, it is common to map the application's functions and data structures to Python classes and functions. This approach has the advantage that the coupling between the application and Python is as tight as possible. But there is also a drawback: Whenever a new feature is implemented in the application, the interface to Python must be changed as well.</p><p>On many high-performance computers Python is not available and we have to preserve NEST's native simulation language SLI. In order to avoid two different interfaces, one to Python and one to SLI, we decided to deviate from the standard way of coupling applications to Python. Rather than using NEST's classes, we use NEST's simulation language as the interface: Python sends data and SLI commands to NEST and NEST responds with Python data structures.</p><p>Exchanging data between Python and NEST is easy since all important data types in NEST have equivalents in Python. Executing NEST commands from Python is also straightforward: Python only needs to send a string with commands to NEST, and NEST will execute them. With this approach, we only need to maintain one binary interface to the simulation kernel instead of two: Each new feature of the simulation kernel only needs to be mapped to SLI and immediately becomes accessible in PyNEST without changing its binary interface. This generic interpreter interface allows us to program PyNEST's high-level API in Python. This is an advantage, because programming in Python is more productive than programming in C++ (Prechelt, <xref ref-type="bibr" rid="B25">2000</xref>). Python is also more expressive: A given number of lines of Python code achieve much more than the same number of lines in C++ (McConnell, <xref ref-type="bibr" rid="B17">2004</xref>).</p><p>NEST users benefit from the increased productivity. They can now take advantage of the large number of extension modules for Python. NumPy is the Python interface to the BLAS libraries, the same libraries which power Matlab. Matplotlib (<monospace><uri xlink:type="simple" xlink:href="http://matplotlib.sourceforge.net">http://matplotlib.sourceforge.net</uri></monospace>) provides many routines to plot scientific data in publication quality. Many other packages exist to analyze and visualize data. Thus, PyNEST allows users to combine simulation, data analysis, and visualization in a single programming language.</p><p>In the Section <xref ref-type="sec" rid="s1">&#x0201c;Using PyNEST&#x0201d;</xref>, we introduce the basic modeling concepts of NEST. With a number of PyNEST code examples, we illustrate how simulations are defined and how the results are analyzed and plotted. In the Section <xref ref-type="sec" rid="s2">&#x0201c;The Interface Between Python and NEST&#x0201d;</xref>, we describe in detail how we bind NEST to the Python interpreter. In the Section <xref ref-type="sec" rid="s4">&#x0201c;Discussion&#x0201d;</xref>, we discuss our implementation and analyze its performance. The complete API reference for PyNEST is contained in <xref ref-type="sec" rid="s7">Appendix A</xref>. In <xref ref-type="sec" rid="s8">Appendix B</xref> we illustrate advanced PyNEST features, using a large scale model.</p></sec><sec id="s1"><title>Using PyNEST</title><p>A neural network in NEST consists of two basic element types: Nodes and connections. Nodes are either neurons, devices or subnetworks. Devices are used to stimulate neurons or to record from them. Nodes can be arranged in subnetworks to build hierarchical networks like layers, columns, and areas. After starting NEST, there is one empty subnetwork, the so-called <italic>root node</italic>. New nodes are created with the command <monospace>Create()</monospace>, which takes the model name and optionally the number of nodes as arguments and returns a list of handles to the new nodes. These handles are integer numbers, called <italic>id</italic>s. Most PyNEST functions expect or return a list of ids (see <xref ref-type="sec" rid="s7">Appendix A</xref>). Thus it is easy to apply functions to large sets of nodes with a single function call.</p><p>Nodes are connected using <monospace>Connect()</monospace>. Connections have a configurable delay and weight. The weight can be static or dynamic, as for example in the case of spike timing dependent plasticity (STDP; Morrison et al., <xref ref-type="bibr" rid="B19">2008</xref>). Different types of nodes and connections have different parameters and state variables. To avoid the problem of <italic>fat interfaces</italic> (Stroustrup, <xref ref-type="bibr" rid="B26">1997</xref>), we use <italic>dictionaries</italic> with the functions <monospace>GetStatus()</monospace> and <monospace>SetStatus()</monospace> for the inspection and manipulation of an element's configuration. The properties of the simulation kernel are controlled through the commands <monospace>GetKernelStatus()</monospace> and <monospace>SetKernelStatus()</monospace>. PyNEST contains the submodules <italic>raster_plot</italic> and <italic>voltage_trace</italic> to visualize spike activity and membrane potential traces. They use Matplotlib internally and are good templates for new visualization functions. However, it is not our intention to develop PyNEST into a toolbox for the analysis of neuroscience data; we follow the modularity concept of Python and leave this task to others (e.g. NeuroTools, <monospace><uri xlink:type="simple" xlink:href="http://www.neuralensemble.org/NeuroTools">http://www.neuralensemble.org/NeuroTools</uri>)</monospace>.</p><sec><title>Example</title><p>We illustrate the key features of PyNEST with a simulation of a neuron receiving input from an excitatory and an inhibitory population of neurons (modified from Gewaltig and Diesmann, <xref ref-type="bibr" rid="B10">2007</xref>). Each presynaptic population is modeled by a Poisson generator, which generates a unique Poisson spike train for each target. The simulation adjusts the firing rate of the inhibitory input population such that the neurons of the excitatory population and the target neuron fire at the same rate.</p><p>First, we import all necessary modules for simulation, analysis and plotting.</p><preformat position="float" xml:space="preserve"><monospace> 1 <bold>from</bold> nest <bold>import</bold> * 2 <bold>from</bold> scipy.optimize <bold>import</bold> bisect 3 <bold>import</bold> nest.voltage_trace as plot</monospace></preformat><p>Second, the parameters for the simulation are set.</p><preformat position="float" xml:space="preserve"><monospace> 4 t_sim = 100000.0  #[ms] simulation time 5 n_ex  =  16000    #size of exc. population 6 n_in  =   4000    #size of inh. population 7 r_ex  =      5.0  #[Hz] rate of exc. neurons 8 epsc  =     45.0  #[pA] amplitude of exc. 9                   #synaptic currents10 ipsc  =    &#x02212;45.0  #[pA] amplitude of inh.11                   #synaptic currents12 d     =      1.0  #[ms] synaptic delay13 lower =      5.0  #[Hz] lower bound of the14                   #search interval15 upper =     25.0  #[Hz] upper bound of the16                   #search interval17 prec  =      0.05 #accuracy goal (in percent 18                   #of inhibitory rate)</monospace></preformat><p>Third, the nodes are created using <monospace>Create()</monospace>. Its arguments are the name of the neuron or device model and optionally the number of nodes to create. If the number is not specified, a single node is created. <monospace>Create()</monospace> returns a list of ids for the new nodes, which we store in variables for later reference.</p><preformat position="float" xml:space="preserve"><monospace>19 neuron        = Create("iaf_neuron")20 noise         = Create("poisson_generator", 2)21 voltmeter     = Create("voltmeter")22 spikedetector = Create("spike_detector")</monospace></preformat><p>Fourth, the excitatory Poisson generator (<monospace>noise[0]</monospace>) and the voltmeter are configured using <monospace>SetStatus()</monospace>, which expects a list of node handles and a list of parameter dictionaries. The rate of the inhibitory Poisson generator is set in line 32. For the neuron and the spike detector we use the default parameters.</p><preformat position="float" xml:space="preserve"><monospace>23 SetStatus([&#x02005;noise&#x02005;[0]], [{&#x02005;"rate"&#x02005;: n_ex*r_ex&#x02005;}])24 SetStatus(voltmeter, [{&#x02005;"interval"&#x02005;: 1000.0,25                        &#x02005;"withgid"&#x02005;: True}])</monospace></preformat><p>Fifth, the neuron is connected to the spike detector and the voltmeter, as are the two Poisson generators to the neuron:</p><preformat position="float" xml:space="preserve"><monospace>26 Connect(neuron, spikedetector)27 Connect(voltmeter, neuron)28 ConvergentConnect(noise, neuron, 29                   [epsc, ipsc], [d, d])</monospace></preformat><p>The command <monospace>Connect()</monospace> has different variants. Plain <monospace>Connect()</monospace> (line 26 and 27) just takes the handles of pre- and postsynaptic nodes and uses the default values for weight and delay. <monospace>ConvergentConnect()</monospace> (line 28) takes four arguments: A list of presynaptic nodes, a list of postsynaptic nodes, and lists of weights and delays. It connects all presynaptic nodes to each postsynaptic node. All variants of the <monospace>Connect()</monospace> command reflect the direction of signal flow in the simulation kernel rather than the physical process of inserting an electrode into a neuron. For example, neurons send their spikes to a spike detector, thus the neuron is the first argument to <monospace>Connect()</monospace> in line 26. By contrast, a voltmeter polls the membrane potential of a neuron in regular intervals, thus the voltmeter is the first argument of <monospace>Connect()</monospace> in line 27. The documentation of each model explains the types of events it can send and receive.</p><p>To determine the optimal rate of the neurons in the inhibitory population, the network is simulated several times for different values of the inhibitory rate while measuring the rate of the target neuron. This is done until the rate of the inhibitory neurons is determined up to a given relative precision (<monospace>prec</monospace>), such that the target neuron fires at the same rate as the neurons in the excitatory population. The algorithm is implemented in two steps:</p><p>First, the function <monospace>output_rate()</monospace> is defined to measure the firing rate of the target neuron for a given rate of the inhibitory neurons.</p><preformat position="float" xml:space="preserve"><monospace>30 <bold>def</bold> output_rate(guess):31     rate = float(abs(n_in*guess))32     SetStatus([&#x02005;noise&#x02005;[1]], [{"rate": rate}])33     SetStatus(spikedetector, [{"n_events": 0}])34     Simulate(t_sim)35     n_events = GetStatus(spikedetector, 36                          "n_events")[0]37     r_target = n_events*1000.0/t_sim38     <bold>print</bold> "r_in&#x02005;=&#x02005;%.4f Hz," % guess, 39     <bold>print</bold> "r_target&#x02005;=&#x02005;%.3f Hz" % r_target40     <bold>return</bold> r_target</monospace></preformat><p>The function takes the firing rate of the inhibitory neurons as an argument. It scales the rate with the size of the inhibitory population (line 31) and configures the inhibitory Poisson generator (<monospace>noise[1]</monospace>) accordingly (line 32). In line 33, the spike-counter of the spike detector is reset to zero. Line 34 simulates the network using <monospace>Simulate()</monospace>, which takes the desired simulation time in milliseconds and advances the network state by this amount of time. During the simulation, the spike detector counts the spikes of the target neuron and the total number is read out at the end of the simulation period (line 35). The return value of <monospace>output_rate()</monospace> is an estimate of the firing rate of the target neuron in Hz.</p><p>Second, we determine the optimal firing rate of the neurons of the inhibitory population using the bisection method.</p><preformat position="float" xml:space="preserve"><monospace>41 <bold>print</bold> "Desired target rate: %.2f Hz" % r_ex42 r = bisect(<bold>lambda</bold> x: output_rate(x)-r_ex, 43            lower, upper, rtol=prec)44 <bold>print</bold> "Resulting inhibitory rate: %.4f" % r</monospace></preformat><p>The SciPy function <monospace>bisect()</monospace> takes four arguments: First a function whose zero crossing is to be determined. Here, the firing rate of the target neuron should equal the firing rate of the neurons of the excitatory population. Thus we define an anonymous function (using <monospace>lambda</monospace>) that returns the difference between the actual rate of the target neuron and the rate of the excitatory Poisson generator, given a rate for the inhibitory neurons. The next two arguments are the lower and upper bound of the interval in which to search for the zero crossing. The fourth argument of <monospace>bisect()</monospace> is the desired relative precision of the zero crossing.</p><p>Finally, we plot the target neuron's membrane potential as a function of time.</p><preformat position="float" xml:space="preserve"><monospace>45 plot.from_device(voltmeter, timeunit="s")</monospace></preformat><p>A transcript of the simulation session and the resulting plot are shown in Figure <xref ref-type="fig" rid="F1">1</xref>.</p><fig id="F1" position="float"><label>Figure 1</label><caption><p><bold>Results of the example simulation</bold>. <bold>(A)</bold> The transcript of the simulation session shows the intermediate results of <monospace>r_target</monospace> as <monospace>bisect()</monospace> searches for the optimal rate. <bold>(B)</bold> The membrane potential of the target neuron as a function of time. Repeated adjustment of the spike rate of the inhibitory population by <monospace>bisect()</monospace> results in a convergence of the mean membrane potential to &#x02212;112&#x02009;mV, corresponding to an output spike rate of 5.0&#x02009;Hz.</p></caption><graphic xlink:href="fninf-02-012-g001"/></fig></sec><sec><title>PyNEST on multi-core processors and clusters</title><p>NEST has built-in support for parallel and distributed computing (Morrison et al., <xref ref-type="bibr" rid="B20">2005</xref>; Plesser et al., <xref ref-type="bibr" rid="B24">2007</xref>): On multi-core processors, NEST uses POSIX threads (Lewis and Berg, <xref ref-type="bibr" rid="B14">1997</xref>), on computer clusters, NEST uses the Message Passing Interface (MPI; Message Passing Interface Forum, <xref ref-type="bibr" rid="B18">1994</xref>). Nodes and connections are assigned automatically to threads and processes, i.e. the same script can be executed single-threaded, multi-threaded, distributed over multiple processes, or using a combination of both methods. This naturally carries over to PyNEST: To use multiple threads for the simulation, the desired number has to be set prior to the creation of nodes and connections. Note that the network setup is carried out by a single thread, as only a single instance of the Python interpreter exists in each process. Only the simulation takes advantage of multiple threads. Distributed simulations can be run via the <monospace>mpirun</monospace> command of the respective MPI implementation. Where, for SLI, one would execute <monospace>mpirun -np n nest simulation.sli</monospace> to distribute a simulation onto <monospace>n</monospace> processes, one has to call <monospace>mpirun -np n python simulation.py</monospace> to get the same result with PyNEST. In the distributed case, <monospace>n</monospace> Python interpreters run in parallel and execute the same simulation script. This means that both network setup and simulation are parallelized. With third-party tools like IPython (<monospace><uri xlink:type="simple" xlink:href="http://ipython.scipy.org">http://ipython.scipy.org</uri></monospace>) or MPI for Python (<monospace><uri xlink:type="simple" xlink:href="http://mpi4py.scipy.org">http://mpi4py.scipy.org</uri></monospace>), it is possible to use PyNEST interactively even in distributed scenarios. For a more elaborate documentation of parallel and distributed simulations with NEST, see the NEST user manual (<monospace><uri xlink:type="simple" xlink:href="http://www.nest-initiative.org">http://www.nest-initiative.org</uri></monospace>).</p></sec></sec><sec id="s2"><title>The Interface Between Python and NEST</title><p>NEST's built-in simulation language (SLI) is a stack-based language in which functions expect their arguments on an operand stack to which they also return their results. This means that in every expression, the arguments must be entered before the command that uses them (<italic>reverse polish notation</italic>). For many new users, SLI is difficult to learn and hard to read. This is especially true for math: The simple expression &#x003b1; = <italic>t</italic> &#x000b7; <italic>e</italic><sup>&#x02212;<italic>t</italic>/&#x003c4;</sup> has to be written as <monospace>/alpha t t neg tau div exp mul def</monospace> in SLI. But SLI is also a high-level language where functions can be assembled at run time, stored in variables and passed as arguments to other functions (functional programming; Finkel, <xref ref-type="bibr" rid="B9">1996</xref>). Powerful indexing operators like <monospace>Part</monospace> and functional operators like <monospace>Map</monospace>, together with data types like heterogeneous arrays and dictionaries, allow a compact and expressive formulation of algorithms.</p><p>Stack-based languages are often used as intermediate languages in compilers and interpreters (Aho et al., <xref ref-type="bibr" rid="B2">1988</xref>). This inspired us to couple NEST and Python using SLI as an intermediate language.</p><sec><title>The PyNEST low-level interface</title><p>The low-level API of PyNEST is implemented in C/C++ using the Python C-API (van Rossum, <xref ref-type="bibr" rid="B27">2008</xref>). It exposes only three functions to Python, and has private routines for converting between SLI data types and their Python equivalents. The exposed functions are:<list list-type="order"><list-item><p><monospace>sli_push(py_object)</monospace>, which converts the Python object <monospace>py_object</monospace> to the corresponding SLI data type and pushes it onto SLI's operand stack.</p></list-item><list-item><p><monospace>sli_pop()</monospace>, which removes the top element from SLI's operand stack and returns it as a Python object.</p></list-item><list-item><p><monospace>sli_run(slicommand)</monospace>, which uses NEST's simulation language interpreter to execute the string <monospace>slicommand</monospace>. If the command requires arguments, they have to be present on SLI's operand stack or must be part of <monospace>slicommand</monospace>. After the command is executed, its return values will be on the interpreter's operand stack.</p></list-item></list></p><p>Since these functions provide full access to the simulation language interpreter, we can now control NEST's simulation kernel without explicit Python bindings for all NEST functions. This interface also provides a natural way to execute legacy SLI code from within a PyNEST script by just using the command <monospace>sli_run("(legacy.sli) run")</monospace>. However, it does not provide any benefits over plain SLI from a syntactic point of view: All simulation specific code still has to be written in SLI. This problem is solved by a set of high-level functions.</p></sec><sec id="s3"><title>The PyNEST high-level interface</title><p>To allow the researcher to define, run and evaluate NEST simulations using only Python, PyNEST offers convenient wrappers for the most important functions of NEST. These wrappers are implemented on top of the low-level API and execute appropriate SLI expressions. Thus, at the level of PyNEST, SLI is invisible to the user. Each high-level function consists essentially of three parts:<list list-type="order"><list-item><p>The arguments of the function are put on SLI's operand stack.</p></list-item><list-item><p>One or more SLI commands are executed to perform the desired action in NEST.</p></list-item><list-item><p>The results (if any) are fetched from the operand stack and returned as Python objects.</p></list-item></list></p><p>A concrete example of the procedure is given in the following listing, which shows the implementation of <monospace>Create()</monospace>:</p><preformat position="float" xml:space="preserve"><monospace>1 <bold>def</bold> Create(model, n=1):2     sli_run("/%s" % model)3     sli_push(n)4     sli_run("CreateMany")5     lastid = sli_pop()6     <bold>return</bold> range(lastid - n + 1, lastid + 1)</monospace></preformat><p>In line 2, we first transfer the model name to NEST. Model names in NEST have to be of type <italic>literal</italic>, a special symbol type that is not available in Python. Because of this, we cannot use <monospace>sli_push()</monospace> for the data transfer, but have to use <monospace>sli_run()</monospace>, which executes a given command string instead of just pushing it onto SLI's stack. The command string consists of a slash followed by the model name, which is interpreded as a literal by SLI. Line 3 uses <monospace>sli_push()</monospace> to transmit the number of nodes&#x02009;<monospace>(n)</monospace> to SLI. The nodes are then created by <monospace>CreateMany</monospace> in line 4, which expects the model name and number of nodes on SLI's operand stack and puts the id of the last created node back onto the stack. The id is retrieved in line 5 via <monospace>sli_pop()</monospace>. To be consistent with the convention that all PyNEST functions work with lists of nodes, we build a list of all created nodes' ids, which is returned in line 6.</p><p>A sequence diagram of the interaction between the different software layers of PyNEST is shown in Figure <xref ref-type="fig" rid="F2">2</xref> for a call to the <monospace>Create()</monospace> function.</p><fig id="F2" position="float"><label>Figure 2</label><caption><p><bold>Sequence diagram showing the interaction between Python and SLI</bold>. A call to the PyNEST high-level function <monospace>Create()</monospace> first transmits the model name to SLI using <monospace>sli_run()</monospace>. It is converted to the SLI type <italic>literal</italic> by the interpreter (<inline-graphic xlink:href="fninf-02-012-i001.jpg"/>). Next, it pushes the number of nodes (10) to SLI using <monospace>sli_push()</monospace>. The PyNEST low-level API converts the argument to a&#x02009;SLI datum (<inline-graphic xlink:href="fninf-02-012-i002.jpg"/>) and pushes it onto SLI's operand stack. Next, it executes appropriate SLI code to create the nodes of type <monospace>iaf_neuron</monospace> in the simulation kernel. Finally it retrieves the results of the NEST operations using&#x02009;<monospace>sli_pop()</monospace>, which converts the data back to a Python object&#x02009;(<inline-graphic xlink:href="fninf-02-012-i003.jpg"/>). The result of the operation in SLI (the id of the last node created) is used to create a&#x02009;list with the ids of all new nodes, which is returned to Python.</p></caption><graphic xlink:href="fninf-02-012-g002"/></fig></sec><sec><title>Data conversion</title><sec><title>From Python to SLI</title><p>The data conversion between Python and SLI exploits the fact that most data types in SLI have an equivalent type in Python. The function <monospace>sli_push()</monospace> calls <monospace>PyObjectToDatum()</monospace> to convert a Python object <monospace>py_object</monospace> to the corresponding SLI data type (see <inline-graphic xlink:href="fninf-02-012-i002.jpg"/> in Figure <xref ref-type="fig" rid="F2">2</xref>). <monospace>PyObjectToDatum()</monospace> determines the type of <monospace>py_object</monospace> in a cascade of type checks (e.g. <monospace>PyInt_Check()</monospace>, <monospace>PyString_Check()</monospace>, <monospace>PyFloatCheck()</monospace>) as described by van Rossum (<xref ref-type="bibr" rid="B27">2008</xref>). If a type check succeeds, the Python object is used to create a new SLI <monospace>Datum</monospace> of the respective type. <monospace>PyObjectToDatum()</monospace> is called recursively on the elements of lists and dictionaries. The listing below shows how this technique is used for the conversion of the Python type <monospace>float</monospace> and for <monospace>NumPy array</monospace>s of <monospace>double</monospace>s:</p><preformat position="float" xml:space="preserve"><monospace> 1 Datum* PyObjectToDatum(PyObject *py_object) 2 { 3    <bold>if</bold> (PyFloat_Check(py_object)) //float? 4    { 5     <bold>return new</bold> DoubleDatum(PyFloat_AsDouble( 6                                 py_object)); 7    } 8 9    <bold>if</bold> (PyArray_Check(py_object)) //NumPy array?10    {11     <bold>int</bold> size = PyArray_Size(py_object);12     PyArrayObject *array;13     array = (PyArrayObject*) py_object;14     assert(array != 0);15     <bold>switch</bold> (array-&#x0003e;descr-&#x0003e;type_num)16     {17      <bold>case</bold> PyArray_DOUBLE:18      {19        <bold>double</bold> *begin = (<bold>double</bold>*) array-&#x0003e;data;20        <bold>return new</bold> DoubleVectorDatum(21            <bold>new</bold> std::vector&#x0003c;<bold>double</bold>&#x0003e;(22                  begin, begin+size));23       }24      //cases for NumPy arrays of other types25     }26    }27    //checks for other supported Python types28 }</monospace></preformat></sec><sec><title>From SLI to Python</title><p>To convert a SLI data type to the corresponding Python type, we can avoid the cascade of type checks, since all SLI data types are derived from a common base class, called <monospace>Datum</monospace>. The C++ textbook solution would add a pure virtual conversion function <monospace>convert()</monospace> to the class <monospace>Datum</monospace>. Each derived class (e.g. <monospace>DoubleDatum</monospace>, <monospace>DoubleVectorDatum</monospace>) then overloads this function to implement its own conversion to the corresponding Python type. This approach is shown for the SLI type <monospace>DoubleDatum</monospace> in the following listing. The function <monospace>get()</monospace> is implemented in each <monospace>Datum</monospace> and returns its data member.</p><preformat position="float" xml:space="preserve"><monospace>1 PyObject*2 DoubleDatum::convert()3 {4   return PyFloat_FromDouble(get());5 }</monospace></preformat><p>However, this solution would make SLI's type hierarchy (and thus NEST) depend on Python. To keep NEST independent of Python, we split the implementation in two parts: The first is Python-unspecific and resides in the NEST source code (Figure <xref ref-type="fig" rid="F3">3</xref>, left rectangle), the second is Python-specific and defined in the PyNEST source code (Figure <xref ref-type="fig" rid="F3">3</xref>, right rectangle).</p><fig id="F3" position="float"><label>Figure 3</label><caption><p><bold>Class diagram for the acyclic visitor pattern used to convert SLI types to Python types</bold>. The left rectangle contains classes belonging to NEST, the right rectangle contains classes that are part of PyNEST. All SLI data types are derived from the base class <monospace>Datum</monospace> and inherit its function <monospace>use_converter()</monospace>. The class <monospace>DatumConverter</monospace> is the base class of <monospace>DatumToPythonConverter</monospace>. The actual data conversion is carried out in one of&#x02009;<monospace>DatumToPythonConverter</monospace>'s <monospace>convert_me()</monospace> functions. Virtual functions are typeset in italics.</p></caption><graphic xlink:href="fninf-02-012-g003"/></fig><p>We move the Python-specific conversion code from <monospace>convert()</monospace> to a new function <monospace>convert_me()</monospace>, which is then called by the interface function <monospace>use_converter()</monospace>. This function is now independent of Python:</p><preformat position="float" xml:space="preserve"><monospace>1 <bold>void</bold>2 Datum::use_converter(DatumConverter&#x00026; converter)3 {4   converter.convert_me(*&#x02005;<bold>this</bold>);5 }</monospace></preformat><p>The function <monospace>use_converter()</monospace> is defined in the base class <monospace>Datum</monospace> and inherited by all derived classes. It calls the <monospace>convert_me()</monospace> function of <monospace>converter</monospace> that matches the type of the derived <monospace>Datum</monospace>. NEST's class <monospace>DatumConverter</monospace> is an abstract class that defines a pure virtual function <monospace>convert_me(T&#x00026;)</monospace> for each SLI type <monospace>T</monospace>:</p><preformat position="float" xml:space="preserve"><monospace>1 <bold>class</bold> DatumConverter2 {3  <bold>public</bold>:4   <bold>virtual void</bold> convert_me(Datum&#x00026;);5   <bold>virtual void</bold> convert_me(DoubleDatum&#x00026;)=0;6   <bold>virtual void</bold> convert_me(DoubleVectorDatum&#x00026;)=0;7   //convert_me() function for other Datums8 };</monospace></preformat><p>The Python-specific part of the conversion is encapsulated in the class <monospace>DatumToPythonConverter</monospace>, which derives from <monospace>DatumConverter</monospace> and implements the <monospace>convert_me()</monospace> functions to actually convert the SLI types to Python objects. <monospace>DatumToPythonConverter::convert_me()</monospace> takes a reference to the <monospace>Datum</monospace> as an argument and is overloaded for each SLI type. It stores the result of the conversion in the class variable <monospace>py_object</monospace>. An example for the conversion of <monospace>DoubleDatum</monospace> is given in the following listing:</p><preformat position="float" xml:space="preserve"><monospace>1 <bold>void</bold>2 DatumToPythonConverter::convert_me(3     DoubleDatum&#x00026; dd)4 {5   py_object = PyFloat_FromDouble(dd.get());6 }</monospace></preformat><p><monospace>DatumToPythonConverter</monospace> also provides the function <monospace>convert()</monospace>, which converts a given <monospace>Datum d</monospace> to a Python object by calling <monospace>d.use_converter()</monospace> with itself as an argument. It is used in the implementation of <monospace>sli_pop()</monospace> (see <inline-graphic xlink:href="fninf-02-012-i003.jpg"/> in Figure <xref ref-type="fig" rid="F2">2</xref>). After the call to <monospace>use_converter()</monospace>, the result of the conversion is available in the member variable <monospace>py_object</monospace>, and is returned to the caller:</p><preformat position="float" xml:space="preserve"><monospace>1 PyObject*2 DatumToPythonConverter::convert(Datum&#x00026; d)3 {4   d.use_converter(*<bold>this</bold>);5   <bold>return</bold> py_object;6 }</monospace></preformat><p>In the Computer Science literature, this method of decoupling different parts of program code is called the <italic>acyclic visitor pattern</italic> (Martin et al., <xref ref-type="bibr" rid="B15">1998</xref>). Our implementation is based on Alexandrescu (<xref ref-type="bibr" rid="B3">2001</xref>).</p><p>As an example, the diagram in Figure <xref ref-type="fig" rid="F4">4</xref> illustrates the sequence of events in <monospace>sli_pop()</monospace>: First, <monospace>sli_pop()</monospace> retrieves a SLI <monospace>Datum d</monospace> from the operand stack (not shown). Second, it creates an instance of <monospace>DatumToPythonConverter</monospace> and calls its <monospace>convert()</monospace> function, which then passes itself as visitor to the <monospace>use_converter()</monospace> function of <monospace>d. Datum::use_converter()</monospace> calls the <monospace>DatumToPythonConverter</monospace>'s <monospace>convert_me()</monospace> function that matches the type of <monospace>d</monospace>. The function <monospace>convert_me()</monospace> then creates a new Python object from the data in <monospace>d</monospace> and stores it in the <monospace>DatumToPythonConverter</monospace>'s member variable <monospace>py_object</monospace>, which is returned to <monospace>sli_pop()</monospace>.</p><fig id="F4" position="float"><label>Figure 4</label><caption><p><bold>Sequence diagram of the acyclic visitor pattern for data conversion from SLI to Python</bold>. For the conversion of a SLI datum <monospace>d</monospace>, <monospace>sli_pop()</monospace> creates an instance of <monospace>DatumToPythonConverter</monospace>. It then calls the <monospace>DatumToPythonConverter</monospace>'s <monospace>convert()</monospace> function, which passes itself as a visitor to the <monospace>use_converter()</monospace> function of <monospace>d</monospace>. <monospace>Datum::use_converter()</monospace> calls the <monospace>DatumToPythonConverter</monospace>'s <monospace>convert_me()</monospace> function that matches <monospace>d</monospace>'s type. <monospace>convert_me()</monospace> creates a new Python object from the data contained in <monospace>d</monospace>. The new Python object is returned to <monospace>sli_pop()</monospace>.</p></caption><graphic xlink:href="fninf-02-012-g004"/></fig></sec><sec><title>NumPy support</title><p>To make PyNEST depend on NumPy only if it is available, we use conditional compilation based on the preprocessor macro <monospace>HAVE_NUMPY</monospace>, which is determined during the configuration of PyNEST prior to compilation. For example, the following listing shows the implementation of the <monospace>DatumToPythonConverter::convert_me()</monospace> function to convert homogeneous arrays of doubles from SLI to Python. If NumPy is available during compilation, its homogeneous array type is used to store the data. Without NumPy, a Python list is used instead.</p><preformat position="float" xml:space="preserve"><monospace> 1 <bold>void</bold> 2 DatumToPythonConverter::convert_me( 3     DoubleVectorDatum&#x00026; d) 4 { 5   <bold>int</bold> dims = d-&#x0003e;size(); 6 #<bold>ifdef</bold> HAVE_NUMPY 7  &#x02005;&#x02005;&#x02005;PyArrayObject* array; 8  &#x02005;&#x02005;&#x02005;array = (PyArrayObject*) 9       PyArray_FromDims(1, &#x00026;dims, PyArray_DOUBLE);10  &#x02005;&#x02005;&#x02005;std::copy(d-&#x0003e;begin(), d-&#x0003e;end(),11             (<bold>double</bold>*) array-&#x0003e;data);12  &#x02005;&#x02005;&#x02005;py_object = (PyObject*) array;13 #<bold>else</bold>14  &#x02005;&#x02005;&#x02005;py_object = PyList_New(dims);15  &#x02005;&#x02005;&#x02005;<bold>for</bold>(<bold>int</bold> i=0; i&#x0003c;dims; i++)16     PyList_SetItem(py_object, i, 17                    PyFloat_FromDouble((*d)[i]));18 #<bold>endif</bold>19 }</monospace></preformat></sec></sec><sec><title>Error handling</title><p>Error handling in NEST is implemented using C++ exceptions that are propagated up the calling hierarchy until a suitable error handler catches them. In this section, we describe how we extend this strategy to PyNEST.</p><p>PyNEST executes SLI code using <monospace>sli_run()</monospace> as described in the Section <xref ref-type="sec" rid="s3">&#x0201c;The PyNEST High-Level Interface&#x0201d;</xref>. However, the high-level API does not call <monospace>sli_run()</monospace> directly, but rather through the wrapper function <monospace>catching_sr()</monospace>:</p><preformat position="float" xml:space="preserve"><monospace>1 <bold>def</bold> catching_sr(cmd):2     sli_run("{" + cmd + "} runprotected")3     <bold>if not</bold> sli_pop():   #cmd caused an error4        errorname = sli_pop()5        commandname = sli_pop()6        <bold>raise</bold> NESTError("NEST error: " + 7                        errorname + " in " + 8                        commandname)</monospace></preformat><p>In line 2, <monospace>catching_sr()</monospace> converts the command string <monospace>cmd</monospace> to a SLI procedure by adding braces. It then calls the SLI command <monospace>runprotected</monospace> (see listing below), which executes the procedure in a <monospace>stopped</monospace> context (PostScript; Adobe Systems Inc., <xref ref-type="bibr" rid="B1">1999</xref>). If an error occurs, <monospace>stopped</monospace> leaves the name of the failed command on the stack and returns <monospace>true</monospace>. In this case, <monospace>runprotected</monospace> extracts the name of the error from SLI's error dictionary, converts it to a string, and puts it back on the operand stack, followed by <monospace>false</monospace> to indicate the error condition to the caller. Otherwise, <monospace>true</monospace> is put on the stack. In case of an error, <monospace>catching_sr()</monospace> uses both the name of the command and the error to raise a Python exception <monospace>(NESTError)</monospace>, which can be handled by the user's simulation code. The following listing shows the implementation of <monospace>runprotected</monospace>:</p><preformat position="float" xml:space="preserve"><monospace> 1 /runprotected 2 { 3   <bold>stopped dup</bold> 4   { 5     errordict /commandname <bold>get cvs</bold> 6     % tell NEST that the error was handled 7     errordict /newerror <bold>false put</bold> 8   } <bold>if</bold> 9   <bold>not</bold>10 } <bold>def</bold></monospace></preformat><p>Forwarding the original NEST errors to Python has the advantage that PyNEST functions do not have to check their arguments, because the underlying NEST functions already do. This makes the code of the high-level API more readable, while at the same time, errors are raised as Python exceptions without requiring additional code. Moreover, this results in consistent error messages in NEST and PyNEST.</p></sec></sec><sec sec-type="discussion" id="s4"><title>Discussion</title><p>The previous sections describe the usage and implementation of PyNEST. Here we discuss consequences and limitations of the PyNEST implementation.</p><sec><title>Performance</title><p>The use of PyNEST entails a certain computational overhead over pure SLI-operated NEST. This overhead can be split into two main components:<list list-type="order"><list-item><p>Call overhead because of using SLI over direct access to the NEST kernel.</p></list-item><list-item><p>Data exchange between Python and NEST.</p></list-item></list></p><p>For most real-world simulations, the first is negligible, since the number of additional function calls is small. In practice, most overhead is caused by the second component, which we can reduce by minimizing the number of data conversions. For an illustration of the technique, see the following two listings that both add up a sequence of numbers in SLI. The first creates the sequence of numbers in Python, pushes them to SLI one after the other and lets SLI add them. Executing it takes approx. 15&#x02009;s on a laptop with an Intel Core Duo processor at 1.83&#x02009;GHz.</p><preformat position="float" xml:space="preserve"><monospace>1 sli_push(0)2 <bold>for</bold> i <bold>in</bold> range(1, 100001):3     sli_push(i)4     sli_run("add")</monospace></preformat><p>The second version computes the same result, but instead of creating the sequence in Python, it is created in SLI:</p><preformat position="float" xml:space="preserve"><monospace>1 sli_run("0 1 1 100000 { add } for")</monospace></preformat><p>Although Python loops are about twice as fast as SLI loops, this version takes only 0.6&#x02009;s, because of the reduced number of data conversions and, to a minor extent, the repeated parsing of the command string and the larger number of function calls in the first version.</p><p>The above technique is used in the implementation of the PyNEST high-level API wherever possible. The same technique is also applied for other loop-like commands (e.g. <monospace>Map</monospace>) that exist in both interpreters. However, it is important to note that the total run time of the simulation is often dominated by the actual creation and update of nodes and synapses, and by event delivery. These tasks take place inside of the optimized C++ code of NEST's simulation kernel, hence the choice between SLI or Python has no impact on performance.</p></sec><sec id="s5"><title>Independence</title><p>One of the design decisions for PyNEST was to keep NEST independent of third-party software. This is important because NEST is used on architectures, where Python is not available or only available as a minimal installation. Moreover, since NEST is a long term project that has already seen several scripting languages and graphics libraries coming and going, we do not want to introduce a hard dependency on one or the other. The stand-alone version of NEST can be compiled without any third-party libraries. Likewise, the implementation of PyNEST does not depend on anything except Python itself. The use of NumPy is recommended, but optional. The binary part of the interface is written by hand and does not depend on interface generators like SWIG (<monospace><uri xlink:type="simple" xlink:href="http://www.swig.org">http://www.swig.org</uri></monospace>) or third-party libraries like Boost.Python (<monospace><uri xlink:type="simple" xlink:href="http://www.boost.org">http://www.boost.org</uri></monospace>). In our opinion, this strategy is important for the long-term sustainability of our scientific software.</p></sec><sec><title>Extensibility</title><p>NEST can never provide all models and functions needed by every researcher. Extensibility is hence important.</p><p>Due to the asymmetry of the PyNEST interface (see <xref ref-type="sec" rid="s6">&#x0201c;Assymmetry of the Interface&#x0201d;</xref>), neuron models, devices and synapse models have to be implemented in C++, the language of the simulation kernel. However, new analysis functions and connection routines can be implemented in either Python, SLI or C++, depending on the performance required and the skills of the user. The implementation in Python is easy, but performance may be limited. However, this approach is safe, as the real functionality is performed by SLI code, which is often well tested. To improve the performance, the implementation can be translated to SLI. This requires knowledge of SLI in addition to Python. Migrating the function down to the C++ level yields the highest performance gain, but requires knowledge of C++ and the internals of the simulation kernel.</p><p>Since the user can choose between three languages, it is easy to extend PyNEST, while at the same time, it is possible to achieve high performance if necessary. The hierarchy of languages also provides abstraction layers, which make it possible to migrate the implementation of a function between the different languages, without affecting user code. The intermediate layer of SLI allows the decoupling of the development of the simulation kernel from the development of the PyNEST API. This is also helpful for developers of abstraction libraries like PyNN (Davison et al., <xref ref-type="bibr" rid="B5">2008</xref>), who only need limited knowledge of the simulation kernel.</p></sec><sec id="s6"><title>Assymmetry of the interface</title><p>Our implementation of PyNEST is asymmetric in that SLI code can be executed from Python, but NEST cannot respond, except for error handling and data exchange. Although this is sufficient to run NEST simulations from within a Python session, it could be beneficial to allow NEST to execute Python code: The user of PyNEST already knows the Python programming language, hence it might be easier to extend NEST in Python rather than to modify the C++ code of the simulation kernel. SciPy, NumPy and other packages provide well tested implementations of mathematical functions and numerical algorithms. Together with callback functions, these libraries would allow rapid prototyping of neuron and synapse models or to initialize parameters of neuron models or synapses according to complicated probability distributions: Python could be the middleware between NEST's simulation kernel and the numerical package. Using online feedback from the simulation, callback functions could also control simulations. Moreover, with a symmetric interface and appropriate Python modules it would be easier to add graphical user interfaces to NEST, along with online display of observables, and experiment management.</p><p>Different implementations of the symmetric interface are possible: One option is to pass callback functions from Python to NEST. Another option is to further exploit the idea that the &#x0201c;language is the protocol&#x0201d;. In the same way as PyNEST generates SLI code, NEST would emit code for Python. Already Harrison and McLennan (<xref ref-type="bibr" rid="B12">1998</xref>) mention this technique, and in experimental implementations it was used successfully to symmetrically couple NEST with Tcl/Tk (Diesmann and Gewaltig, <xref ref-type="bibr" rid="B6">2002</xref>), Mathematica, Matlab and IDL. The fact that none of these interfaces is still maintained confirms the conclusions of the Section <xref ref-type="sec" rid="s5">&#x0201c;Independence&#x0201d;</xref>.</p></sec><sec><title>Language considerations</title><p>At present, PyNEST maps NEST's capabilities to Python. Further advances in the expressiveness of the language may be easier to achieve at the level of Python or above (e.g. PyNN; Davison et al., <xref ref-type="bibr" rid="B5">2008</xref>) without a counterpart in SLI. An example for this is the support of units for physical quantities as available in SBML (Hucka et al., <xref ref-type="bibr" rid="B13">2002</xref>) or Brian (Goodman and Brette, <xref ref-type="bibr" rid="B11">2008</xref>).</p><p>More generally, the development of simulation tools has not kept up with the increasing complexity of network models. As a consequence the reliable documentation of simulation studies is challenging and laboratories notoriously have difficulties in reproducing published results (Djurfeldt and Lansner, <xref ref-type="bibr" rid="B7">2007</xref>). One component of a solution is the ability to concisely formulate simulations in terms of the neuroscientific problem domain like connection topologies and probability distributions. At present little research has been carried out on the particular design of such a language (Davison et al., <xref ref-type="bibr" rid="B5">2008</xref>; Nordlie et al., <xref ref-type="bibr" rid="B22">2008</xref>), but a general purpose high-level language interface to the simulation engine is a first step towards this goal.</p></sec></sec><sec><title>Conflict of Interest Statement</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></sec></body><back><app-group><app><title>Appendix</title><sec id="s7"><title>A. PyNEST API reference</title><sec><title>Models</title><p><monospace>Models(mtype="all", sel=None)</monospace>: Return a list of all available models (nodes and synapses). Use <monospace>mtype="nodes"</monospace> to only see node models, <monospace>mtype="synapses"</monospace> to only see synapse models. <monospace>sel</monospace> can be a string, used to filter the result list and only return models containing it.</p><p><monospace>GetDefaults(model)</monospace>: Return a dictionary with the default parameters of the given <monospace>model</monospace>, specified by a string.</p><p><monospace>SetDefaults(model, params)</monospace>: Set the default parameters of the given <monospace>model</monospace> to the values specified in the <monospace>params</monospace> dictionary.</p><p><monospace>GetStatus(model, keys=None)</monospace>: Return a dictionary with status information for the given <monospace>model</monospace>. If <monospace>keys</monospace> is given, a value is returned instead. <monospace>keys</monospace> may also be a list, in which case a list of values is returned.</p><p><monospace>CopyModel(existing, new, params=None)</monospace>: Create a <monospace>new</monospace> model by copying an <monospace>existing</monospace> one. Default parameters can be given as <monospace>params</monospace>, or else are taken from <monospace>existing</monospace>.</p></sec><sec><title>Nodes</title><p><monospace>Create(model, n=1, params=None)</monospace>: Create <monospace>n</monospace> instances of type <monospace>model</monospace> in the current subnetwork. Parameters for the new nodes can be given as <monospace>params</monospace> (a single dictionary, or a list of dictionaries with size <monospace>n</monospace>). If omitted, the <monospace>model</monospace>'s defaults are used.</p><p><monospace>GetStatus(nodes, keys=None)</monospace>: Return a list of parameter dictionaries for the given list of <monospace>nodes</monospace>. If <monospace>keys</monospace> is given, a list of values is returned instead. <monospace>keys</monospace> may also be a list, in which case the returned list contains lists of values.</p><p><monospace>SetStatus(nodes, params, val=None)</monospace>: Set the parameters of the given <monospace>nodes</monospace> to <monospace>params</monospace>, which may be a single dictionary, or a list of dictionaries of the same size as <monospace>nodes</monospace>. If <monospace>val</monospace> is given, <monospace>params</monospace> has to be the name of a property, which is set to <monospace>val</monospace> on the <monospace>nodes</monospace>. <monospace>val</monospace> can be a single value, or a list of the same size as <monospace>nodes</monospace>.</p></sec><sec><title>Connections</title><p><monospace>Connect(pre, post, params=None, delay=None, model="static_synapse")</monospace>: Make one-to-one connections of type <monospace>model</monospace> between the nodes in <monospace>pre</monospace> and the nodes in <monospace>post</monospace>. <monospace>pre</monospace> and <monospace>post</monospace> have to be lists of the same length. If <monospace>params</monospace> is given (as a dictionary or as a list of dictionaries with the same size as <monospace>pre</monospace> and <monospace>post</monospace>), they are used as parameters for the connections. If <monospace>params</monospace> is given as a single float, or as a list of floats of the same size as <monospace>pre</monospace> and <monospace>post</monospace>, it is interpreted as weight. In this case, <monospace>delay</monospace> also has to be given (as a float, or as a list of floats with the same size as <monospace>pre</monospace> and <monospace>post</monospace>).</p><p><monospace>ConvergentConnect(pre, post, weight=None, delay=None, model="static_synapse")</monospace>: Connect all nodes in <monospace>pre</monospace> to each node in <monospace>post</monospace> with connections of type <monospace>model</monospace>. If <monospace>weight</monospace> is given, <monospace>delay</monospace> also has to be given. Both can be specified as a float, or as a list of floats with the same size as <monospace>pre</monospace>.</p><p><monospace>RandomConvergentConnect(pre, post, n, weight=None, delay=None, model="static_synapse")</monospace>: Connect <monospace>n</monospace> randomly selected nodes from <monospace>pre</monospace> to each node in <monospace>post</monospace> with connections of type <monospace>model</monospace>. Presynaptic nodes are drawn independently for each postsynaptic node. If <monospace>weight</monospace> is given, <monospace>delay</monospace> also has to be given. Both can be specified as a float, or as a list of floats of size <monospace>n</monospace>.</p><p><monospace>DivergentConnect(pre, post, weight=None, delay=None, model="static_synapse")</monospace>: Connect each node in <monospace>pre</monospace> to all nodes in <monospace>post</monospace> with connections of type <monospace>model</monospace>. If <monospace>weight</monospace> is given, <monospace>delay</monospace> also has to be given. Both can be specified as a float, or as a list of floats with the same size as <monospace>post</monospace>.</p><p><monospace>RandomDivergentConnect(pre, post, n, weight=None, delay=None, model="static_synapse")</monospace>: Connect each node in <monospace>pre</monospace> to <monospace>n</monospace> randomly selected nodes from <monospace>post</monospace> with connections of type <monospace>model</monospace>. If <monospace>weight</monospace> is given, <monospace>delay</monospace> also has to be given. Both can be specified as a float, or as a list of floats of size <monospace>n</monospace>.</p></sec><sec><title>Structured networks</title><p><monospace>CurrentSubnet()</monospace>: Return the id of the current subnetwork.</p><p><monospace>ChangeSubnet(subnet)</monospace>: Make <monospace>subnet</monospace> the current subnetwork.</p><p><monospace>GetLeaves(subnet)</monospace>: Return the ids of all nodes under <monospace>subnet</monospace> that are not subnetworks.</p><p><monospace>GetNodes(subnet)</monospace>: Return the complete list of <monospace>subnet</monospace>'s children (including subnetworks).</p><p><monospace>GetNetwork(subnet, depth)</monospace>: Return a nested list of <monospace>subnet</monospace>'s children up to <monospace>depth</monospace> (including subnetworks).</p><p><monospace>LayoutNetwork(model, shape, label=None, customdict=None)</monospace>: Create a subnetwork of shape <monospace>shape</monospace> that contains nodes of type <monospace>model</monospace>. <monospace>label</monospace> is an optional name for the subnetwork. If present, <monospace>customdict</monospace> is set as custom dictionary of the subnetwork, which can be used by the user to store custom information.</p><p><monospace>BeginSubnet(label=None, customdict=None)</monospace>: Create a new subnetwork and change into it. <monospace>label</monospace> is an optional name for the subnetwork. If present, <monospace>customdict</monospace> is set as custom dictionary of the subnetwork, which can be used by the user to store custom information.</p><p><monospace>EndSubnet()</monospace>: Change to the parent subnetwork and return the id of the subnetwork just left.</p></sec><sec><title>Simulation control</title><p><monospace>Simulate(t)</monospace>: Simulate the network for <monospace>t</monospace> milliseconds.</p><p><monospace>ResetKernel()</monospace>: Reset the simulation kernel. This will destroy the network as well as all custom models created with <monospace>CopyModel()</monospace>. The parameters of built-in models are reset to their defaults. Calling this function is equivalent to restarting NEST.</p><p><monospace>ResetNetwork()</monospace>: Reset all nodes and connections to the defaults of their respective model.</p><p><monospace>SetKernelStatus(params)</monospace>: Set the parameters of the simulation kernel to the ones given in <monospace>params</monospace>.</p><p><monospace>GetKernelStatus()</monospace>: Return a dictionary with the parameters of the simulation kernel.</p><p><monospace>PrintNetwork(depth=1, subnet=None)</monospace>: Print the network tree up to <monospace>depth</monospace>, starting at <monospace>subnet</monospace>. If <monospace>subnet</monospace> is omitted, the current subnetwork is used instead.</p></sec></sec><sec id="s8"><title>B. Advanced example</title><p>In the Section <xref ref-type="sec" rid="s1">&#x0201c;Using PyNEST&#x0201d;</xref>, we introduced the main features of PyNEST with a short example. This section contains a simulation of a balanced random network of 10,000 excitatory and 2,500 inhibitory integrate-and-fire neurons as described in Brunel (<xref ref-type="bibr" rid="B4">2000</xref>). We start with importing the required modules.</p><preformat position="float" xml:space="preserve"><monospace>1 <bold>from</bold> nest <bold>import</bold> *2 <bold>import</bold> nest.raster_plot as plot3 <bold>import</bold> time</monospace></preformat><p>We store the current time at the start of the simulation.</p><preformat position="float" xml:space="preserve"><monospace>4 startbuild = time.time()</monospace></preformat><p>Next, we use <monospace>SetKernelStatus()</monospace> to set the temporal resolution for the simulation to 0.1&#x02009;ms.</p><preformat position="float" xml:space="preserve"><monospace>5 SetKernelStatus({"resolution": 0.1})</monospace></preformat><p>We define variables for the simulation duration, the network size and the number of neurons to be recorded.</p><preformat position="float" xml:space="preserve"><monospace>6 simtime =   500.0 #[ms] Simulation time7 NE      = 10000   #number of exc. neurons8 NI      =  2500   #number of inh. neurons9 N_rec   =    50   #record from 50 neurons</monospace></preformat><p>The following are the parameters of the integrate-and-fire neuron that deviate from the defaults.</p><preformat position="float" xml:space="preserve"><monospace>10 tauMem = 20.0 #[ms] membrane time constant11 theta  = 20.0 #[mV] threshold for firing12 t_ref  =  2.0 #[ms] refractory period13 E_L    =  0.0 #[mV] resting potential</monospace></preformat><p>The synaptic delay and weights and the number of afferent synapses per neuron are assigned to variables. By choosing the relative strength of inhibitory connections to be |&#x02005;<italic>J<sub>in</sub>&#x02005;</italic>| / |&#x02005;<italic>J<sub>ex</sub>&#x02005;</italic>| = <italic>g</italic> = 5.0, the network is in the inhibition-dominated regime.</p><preformat position="float" xml:space="preserve"><monospace>14 delay   = 1.5             #[ms] synaptic delay15 J_ex    = 0.1             #[mV] exc. synaptic strength16 g       = 5.0             #ratio between inh. and exc.17 J_in    = &#x02212;g*J_ex         #[mV] inh. synaptic strength18 epsilon = 0.1             #connection probability19 CE      = int(epsilon*NE) #exc. synapses/neuron20 CI      = int(epsilon*NI) #inh. synapses/neuron</monospace></preformat><p>To reproduce Figure 8C from Brunel (<xref ref-type="bibr" rid="B4">2000</xref>), we choose parameters for asynchronous, irregular firing: &#x003bd;<sub>&#x003b8;</sub> denotes the external Poisson rate which results in a mean free membrane potential equal to the threshold. We set the rate of the external Poisson input to &#x003bd;<sub>ext</sub> = &#x003b7;&#x003bd;<sub>&#x003b8;</sub> = 2&#x003bd;<sub>&#x003b8;</sub>.</p><preformat position="float" xml:space="preserve"><monospace>21 eta    = 2.0                 #fraction of ext. input22 nu_th  = theta/(J_ex*tauMem) #[kHz] ext. rate23 nu_ext = eta*nu_th           #[kHz] exc. ext. rate24 p_rate = 1000.0*nu_ext       #[Hz] ext. Poisson rate</monospace></preformat><p>In the next step we set up the populations of excitatory (<monospace>nodes_ex</monospace>) and inhibitory (<monospace>nodes_in</monospace>) neurons. The neurons of both pools have identical parameters, which are configured for the model with <monospace>SetDefaults()</monospace>, before creating instances with <monospace>Create()</monospace>.</p><preformat position="float" xml:space="preserve"><monospace>25 <bold>print</bold> "Creating network nodes &#x02026;"26 SetDefaults("iaf_psc_delta", {"C_m"  : tauMem,27                               "tau_m": tauMem,28                               "t_ref": t_ref,29                               "E_L"  : E_L,30                               "V_th" : theta})31 nodes_ex = Create("iaf_psc_delta", NE)32 nodes_in = Create("iaf_psc_delta", NI)33 nodes = nodes_ex+nodes_in</monospace></preformat><p>Next, a Poisson spike generator (<monospace>noise</monospace>) is created and its rate is set. We use it to provide external excitatory input to the network.</p><preformat position="float" xml:space="preserve"><monospace>34 noise = Create("poisson_generator"<bold/>, 35                 params={"rate": p_rate})</monospace></preformat><p>The next paragraph creates the devices for recording spikes from the excitatory and inhibitory population. The spike detectors are configured to record the spike times and the id of the sending neuron to a file.</p><preformat position="float" xml:space="preserve"><monospace>36 SetDefaults("spike_detector", {"withtime": True,37                                "withgid" : True,38                                "to_file" : True})39 espikes = Create("spike_detector")40 ispikes = Create("spike_detector")</monospace></preformat><p>Next, we use <monospace>CopyModel()</monospace> to create copies of the synapse model <monospace>"static_synapse"</monospace>, which are used for the excitatory and inhibitory connections.</p><preformat position="float" xml:space="preserve"><monospace>41 SetDefaults("static_synapse", {"delay": delay})42 CopyModel("static_synapse", "excitatory",43           {"weight": J_ex})44 CopyModel("static_synapse", "inhibitory", 45           {"weight": J_in})</monospace></preformat><p>The following code connects neurons and devices. <monospace>DivergentConnect()</monospace> connects one source node with each of the given target nodes and is used to connect the Poisson generator (<monospace>noise</monospace>) to the excitatory and the inhibitory neurons (<monospace>nodes</monospace>). <monospace>ConvergentConnect()</monospace> is used to connect the first <monospace>N_rec</monospace> excitatory and inhibitory neurons to the corresponding spike detectors.</p><preformat position="float" xml:space="preserve"><monospace>46 <bold>print</bold> "Connecting network &#x02026;"47 DivergentConnect(noise, nodes, 48                  model="excitatory")49 ConvergentConnect(nodes_ex[:N_rec], espikes, 50                   model="excitatory")51 ConvergentConnect(nodes_in[:N_rec], ispikes, 52                   model="excitatory")</monospace></preformat><p>The following lines connect the neurons with each other. The function <monospace>RandomConvergentConnect()</monospace> draws <monospace>CE</monospace> presynaptic neurons randomly from the given list (first argument) and connects them to each postsynaptic neuron (second argument). The presynaptic neurons are drawn repeatedly and independent for each postsynaptic neuron.</p><preformat position="float" xml:space="preserve"><monospace>53 RandomConvergentConnect(nodes_ex, nodes, CE, 54                         model="excitatory")55 RandomConvergentConnect(nodes_in, nodes, CI, 56                         model="inhibitory")</monospace></preformat><p>To calculate the duration of the network setup later, we again store the current time.</p><preformat position="float" xml:space="preserve"><monospace>57 endbuild = time.time()</monospace></preformat><p>We use <monospace>Simulate()</monospace> to run the simulation.</p><preformat position="float" xml:space="preserve"><monospace>58 <bold>print</bold> "Simulating", simtime, "ms &#x02026;"59 Simulate(simtime)</monospace></preformat><p>Again, we store the time to calculate the runtime of the simulation later.</p><preformat position="float" xml:space="preserve"><monospace>60 endsimulate = time.time()</monospace></preformat><p>The following code calculates the mean firing rate of the excitatory and the inhibitory neurons, determines the total number of synapses, and the time needed to set up the network and to simulate it. The firing rates are calculated from the total number of events received by the spike detectors. The total number of synapses is available from the status dictionary of the respective synapse models.</p><preformat position="float" xml:space="preserve"><monospace>61 events_ex   = GetStatus(espikes, "n_events")[0]62 rate_ex     = event_ex/simtime*1000.0/N_rec63 events_in   = GetStatus(ispikes, "n_events")[0]64 rate_in     = events_in/simtime*1000.0/N_rec65 synapses_ex = GetStatus("excitatory", 66                         "num_connections")67 synapses_in = GetStatus("inhibitory", 68                         "num_connections")69 synapses    = synapses_ex+synapses_in70 build_time  = endbuild&#x02212;startbuild71 sim_time    = endsimulate&#x02212;endbuild</monospace></preformat><p>The next lines print a summary with network and runtime statistics.</p><preformat position="float" xml:space="preserve"><monospace>72 <bold>print</bold> "Brunel network simulation using PyNEST:"73 <bold>print</bold> "Number of neurons :", len(nodes)74 <bold>print</bold> "Number of synapses:", synapses75 <bold>print</bold> "       Exitatory  :", synapses_ex76 <bold>print</bold> "       Inhibitory :", synapses_in77 <bold>print</bold> "Excitatory rate   : %.2f Hz" % rate_ex78 <bold>print</bold> "Inhibitory rate   : %.2f Hz" % rate_in79 <bold>print</bold> "Building time     : %.2f s" % build_time80 <bold>print</bold> "Simulation time   : %.2f s" % sim_time</monospace></preformat><p>Finally, <monospace>nest.raster_plot</monospace> is used to visualize the spikes of the <monospace>N_rec</monospace> selected excitatory neurons, similar to Figure 8C of Brunel (<xref ref-type="bibr" rid="B4">2000</xref>).</p><preformat position="float" xml:space="preserve"><monospace>81 plot.from_device(espikes, hist=True)</monospace></preformat><p>The resulting plot is shown in Figure <xref ref-type="fig" rid="F5">5</xref> together with a transcript of the simulation session. The simulation was run on a laptop with an Intel Core Duo processor at 1.83&#x02009;GHz and 1.5&#x02009;GB of RAM.</p><fig id="F5" position="anchor"><label>Figure 5</label><caption><p><bold>Results of the balanced random network simulation</bold>. <bold>(A)</bold> The transcript of the simulation session shows the output during network setup and the summary printed at the end of the simulation. <bold>(B)</bold> Spike raster (top) and spike time histogram (bottom) of the <monospace>N_rec</monospace> recorded excitatory neurons.</p></caption><graphic xlink:href="fninf-02-012-g005"/></fig></sec></app></app-group><ack><p>We are grateful to our colleagues in the NEST Initiative and the FACETS project for stimulating discussions, in particular to Hans Ekkehard Plesser for drawing our attention to the visitor pattern. Partially funded by DIP F1.2, BMBF Grant 01GQ0420 to the Bernstein Center for Computational Neuroscience Freiburg, EU Grant 15879 (FACETS), and &#x0201c;The Next-Generation Integrated Simulation of Living Matter&#x0201d; project, part of the Development and Use of the Next-Generation Supercomputer Project of the Ministry of Education, Culture, Sports, Science and Technology (MEXT) of Japan.</p></ack><ref-list><title>References</title><ref id="B1"><citation citation-type="book"><person-group person-group-type="author"><collab>Adobe Systems Inc.</collab></person-group> (<year>1999</year>). <article-title>Postscript Language Reference Manual</article-title>, <edition>third edn.</edition><publisher-loc>Reading, MA</publisher-loc>, <publisher-name>Addison-Wesley</publisher-name></citation></ref><ref id="B2"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Aho</surname><given-names>A. V.</given-names></name><name><surname>Sethi</surname><given-names>R.</given-names></name><name><surname>Ullman</surname><given-names>J. D.</given-names></name></person-group> (<year>1988</year>). <article-title>Compilers, Principles, Techniques, and Tools</article-title>. <publisher-loc>Reading, MA</publisher-loc>, <publisher-name>Addison-Wesley</publisher-name></citation></ref><ref id="B3"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Alexandrescu</surname><given-names>A.</given-names></name></person-group> (<year>2001</year>). <article-title>Modern C++ Design</article-title>. <publisher-loc>Boston</publisher-loc>, <publisher-name>Addison-Wesley</publisher-name></citation></ref><ref id="B4"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Brunel</surname><given-names>N.</given-names></name></person-group> (<year>2000</year>). <article-title>Dynamics of sparsely connected networks of excitatory and inhibitory spiking neurons</article-title>. <source>J. Comput. Neurosci.</source><volume>8</volume>, <fpage>183</fpage>&#x02013;<lpage>208</lpage><pub-id pub-id-type="doi">10.1023/A:1008925309027</pub-id><pub-id pub-id-type="pmid">10809012</pub-id></citation></ref><ref id="B5"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Davison</surname><given-names>A.</given-names></name><name><surname>Br&#x000fc;derle</surname><given-names>D.</given-names></name><name><surname>Eppler</surname><given-names>J. M.</given-names></name><name><surname>Kremkow</surname><given-names>J.</given-names></name><name><surname>Muller</surname><given-names>E.</given-names></name><name><surname>Pecevski</surname><given-names>D.</given-names></name><name><surname>Perrinet</surname><given-names>L.</given-names></name><name><surname>Yger</surname><given-names>P.</given-names></name></person-group> (<year>2008</year>). <article-title>PyNN: a common interface for neuronal network simulators</article-title>. <source>Front. Neuroinformatics</source><volume>2</volume><pub-id pub-id-type="doi">10.3389/neuro.11.011.2008</pub-id></citation></ref><ref id="B6"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Diesmann</surname><given-names>M.</given-names></name><name><surname>Gewaltig</surname><given-names>M.-O.</given-names></name></person-group> (<year>2002</year>). <article-title>NEST: an environment for neural systems simulations</article-title>. In <source>Forschung und wisschenschaftliches Rechnen, Beitrage zum Heinz-Billing-Preis 2001, Vol. 58 of GWDG-Bericht</source>, <person-group person-group-type="editor"><name><surname>Plesser</surname><given-names>T.</given-names></name><name><surname>Macho</surname><given-names>V.</given-names></name></person-group>, eds (<publisher-loc>Gottingen</publisher-loc>, <publisher-name>Ges. f&#x000fc;r Wiss. Datenverarbeitung</publisher-name>), pp. <fpage>43</fpage>&#x02013;<lpage>70</lpage></citation></ref><ref id="B7"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Djurfeldt</surname><given-names>M.</given-names></name><name><surname>Lansner</surname><given-names>A.</given-names></name></person-group> (<year>2007</year>). <article-title>Workshop report: 1st INCF workshop on large-scale modeling of the nervous system</article-title>. <source>Nature Precedings</source><pub-id pub-id-type="doi">10.1038/npre.2007.262.1</pub-id></citation></ref><ref id="B8"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Dubois</surname><given-names>P. F.</given-names></name></person-group> (<year>2007</year>). <article-title>Guest editor's introduction: Python: batteries included</article-title>. <source>Comput. Sci. Eng.</source><volume>9</volume>, <fpage>7</fpage>&#x02013;<lpage>9</lpage><pub-id pub-id-type="doi">10.1109/MCSE.2007.51</pub-id></citation></ref><ref id="B9"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Finkel</surname><given-names>R. A.</given-names></name></person-group> (<year>1996</year>). <article-title>Advanced Programming Languages</article-title>. <publisher-loc>Menlo Park, CA</publisher-loc>, <publisher-name>Addison-Wesley</publisher-name></citation></ref><ref id="B10"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Gewaltig</surname><given-names>M.-O.</given-names></name><name><surname>Diesmann</surname><given-names>M.</given-names></name></person-group> (<year>2007</year>). <article-title>NEST (Neural Simulation Tool)</article-title>. <source>Scholarpedia</source><volume>2</volume>, <fpage>1430</fpage></citation></ref><ref id="B11"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Goodman</surname><given-names>D.</given-names></name><name><surname>Brette</surname><given-names>R.</given-names></name></person-group> (<year>2008</year>). <article-title>Brian: a simulator for spiking neural networks in Python</article-title>. <source>Front. Neuroinformatics</source><volume>2</volume><pub-id pub-id-type="doi">10.1007/978-1-59745-520-6_8</pub-id><pub-id pub-id-type="pmid">19115011</pub-id></citation></ref><ref id="B12"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Harrison</surname><given-names>M.</given-names></name><name><surname>McLennan</surname><given-names>M.</given-names></name></person-group> (<year>1998</year>). <article-title>Effective Tcl/Tk Programming: Writing Better Programs with Tcl and Tk</article-title>. <publisher-loc>Reading, MA</publisher-loc>, <publisher-name>Addison-Wesley</publisher-name></citation></ref><ref id="B13"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Hucka</surname><given-names>M.</given-names></name><name><surname>Finney</surname><given-names>A.</given-names></name><name><surname>Sauro</surname><given-names>H. M.</given-names></name><name><surname>Bolouri</surname><given-names>H.</given-names></name><name><surname>Doyle</surname><given-names>J. C.</given-names></name><name><surname>Kitano</surname><given-names>H.</given-names></name><name><surname>Arkin</surname><given-names>A. P.</given-names></name><name><surname>Bornstein</surname><given-names>B. J.</given-names></name><name><surname>Bray</surname><given-names>D.</given-names></name><name><surname>Cornish-Bowden</surname><given-names>A.</given-names></name><etal/></person-group> (<year>2002</year>). <article-title>The systems biology markup language (SBML): a medium for representation and exchange of biochemical network models</article-title>. <source>Bioinformatics</source><volume>19</volume>, <fpage>524</fpage>&#x02013;<lpage>531</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btg015</pub-id><pub-id pub-id-type="pmid">12611808</pub-id></citation></ref><ref id="B14"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Lewis</surname><given-names>B.</given-names></name><name><surname>Berg</surname><given-names>D. J.</given-names></name></person-group> (<year>1997</year>). <article-title>Multithreaded Programming With PThreads</article-title>. <publisher-loc>Upper Saddle River</publisher-loc>: <publisher-name>Sun Microsystems Press</publisher-name></citation></ref><ref id="B15"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Martin</surname><given-names>R. C.</given-names></name><name><surname>Riehle</surname><given-names>D.</given-names></name><name><surname>Buschmann</surname><given-names>F.</given-names></name></person-group> (eds) (<year>1998</year>). <article-title>Pattern Languages of Program Design 3</article-title>. <publisher-loc>Reading, MA</publisher-loc>, <publisher-name>Addison-Wesley</publisher-name></citation></ref><ref id="B16"><citation citation-type="book"><person-group person-group-type="author"><collab>MathWorks</collab></person-group> (<year>2002</year>). <article-title>MATLAB The Language of Technical Computing: Using MATLAB</article-title>. <publisher-loc>Natick, MA</publisher-loc>, <publisher-name>3 Apple Hill Drive</publisher-name></citation></ref><ref id="B17"><citation citation-type="book"><person-group person-group-type="author"><name><surname>McConnell</surname><given-names>S.</given-names></name></person-group> (<year>2004</year>). <article-title>Code Complete:A practical Handbook of Software Construction</article-title>. <edition>2nd edn.</edition><publisher-loc>Redmond, WA</publisher-loc>, <publisher-name>Microsoft Press</publisher-name></citation></ref><ref id="B18"><citation citation-type="other"><person-group person-group-type="author"><collab>Message Passing Interface Forum</collab></person-group> (<year>1994</year>). <article-title>MPI: A Message-Passing Interface Standard</article-title>. Technical Report UT-CS-94-230.</citation></ref><ref id="B19"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Morrison</surname><given-names>A.</given-names></name><name><surname>Diesmann</surname><given-names>M.</given-names></name><name><surname>Gerstner</surname><given-names>W.</given-names></name></person-group> (<year>2008</year>). <article-title>Phenomenological models of synaptic plasticity based on spike-timing</article-title>. <source>Biol. Cybern.</source><volume>98</volume>, <fpage>459</fpage>&#x02013;<lpage>478</lpage><pub-id pub-id-type="doi">10.1162/0899766054026648</pub-id><pub-id pub-id-type="pmid">18491160</pub-id></citation></ref><ref id="B20"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Morrison</surname><given-names>A.</given-names></name><name><surname>Mehring</surname><given-names>C.</given-names></name><name><surname>Geisel</surname><given-names>T.</given-names></name><name><surname>Aertsen</surname><given-names>A.</given-names></name><name><surname>Diesmann</surname><given-names>M.</given-names></name></person-group> (<year>2005</year>). <article-title>Advancing the boundaries of high connectivity network simulation with distributed computing</article-title>. <source>Neural Comput.</source><volume>17</volume>, <fpage>1776</fpage>&#x02013;<lpage>1801</lpage><pub-id pub-id-type="doi">10.1162/0899766054026648</pub-id><pub-id pub-id-type="pmid">15969917</pub-id></citation></ref><ref id="B21"><citation citation-type="other"><person-group person-group-type="author"><name><surname>Natschl&#x000e4;ger</surname><given-names>T.</given-names></name></person-group> (<year>2003</year>). <article-title>CSIM: A Neural Circuit SIMulator</article-title>. Technical report.</citation></ref><ref id="B22"><citation citation-type="other"><person-group person-group-type="author"><name><surname>Nordlie</surname><given-names>E.</given-names></name><name><surname>Plesser</surname><given-names>H. E.</given-names></name><name><surname>Gewaltig</surname><given-names>M.-O.</given-names></name></person-group> (<year>2008</year>). <article-title>Towards reproducible descriptions of neuronal network models</article-title>. Volume Conference Abstract: Neuroinformatics 2008.<pub-id pub-id-type="doi">10.3389/conf.neuro.11.2008.01.086</pub-id></citation></ref><ref id="B23"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Ousterhout</surname><given-names>J. K.</given-names></name></person-group> (<year>1994</year>). <article-title>Tcl and the Tk Toolkit</article-title>. <source>Professional Computing</source> <publisher-loc>Reading Massachusetts</publisher-loc>:<publisher-name>Addison-Wesley</publisher-name></citation></ref><ref id="B24"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Plesser</surname><given-names>H. E.</given-names></name><name><surname>Eppler</surname><given-names>J. M.</given-names></name><name><surname>Morrison</surname><given-names>A.</given-names></name><name><surname>Diesmann</surname><given-names>M.</given-names></name><name><surname>Gewaltig</surname><given-names>M.-O.</given-names></name></person-group> (<year>2007</year>). <article-title>Efficient parallel simulation of large-scale neuronal networks on clusters of multiprocessor computers</article-title>. In <source>Euro-Par 2007: Parallel Processing, Volume 4641 of Lecture Notes in Computer Science</source>, <person-group person-group-type="editor"><name><surname>Kermarrec</surname><given-names>A.-M.</given-names></name><name><surname>Bouge</surname><given-names>L.</given-names></name><name><surname>Priol</surname><given-names>T.</given-names></name></person-group>, eds (<publisher-loc>Berlin</publisher-loc>, <publisher-name>Springer-Verlag</publisher-name>), pp. <fpage>672</fpage>&#x02013;<lpage>681</lpage></citation></ref><ref id="B25"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Prechelt</surname><given-names>L.</given-names></name></person-group> (<year>2000</year>). <article-title>An empirical comparison of seven programming languages</article-title>. <source>COMPUTER</source><volume>33</volume>, <fpage>23</fpage>&#x02013;<lpage>29</lpage><pub-id pub-id-type="doi">10.1109/2.876288</pub-id></citation></ref><ref id="B26"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Stroustrup</surname><given-names>B.</given-names></name></person-group> (<year>1997</year>). <article-title>The C++ Programming Language</article-title>, <edition>3rd edn.</edition><publisher-loc>New York</publisher-loc>, <publisher-name>Addison-Wesely</publisher-name></citation></ref><ref id="B27"><citation citation-type="web"><person-group person-group-type="author"><name><surname>van Rossum</surname><given-names>G.</given-names></name></person-group> (<year>2008</year>). <article-title>Python/C API Reference Manual</article-title>. Available at: <uri xlink:type="simple" xlink:href="http://docs.python.org/api/api.html">http://docs.python.org/api/api.html</uri></citation></ref></ref-list></back></article>