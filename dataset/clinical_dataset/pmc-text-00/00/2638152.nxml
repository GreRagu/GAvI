<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN" "archivearticle.dtd"><article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id><journal-title>BMC Bioinformatics</journal-title><issn pub-type="epub">1471-2105</issn><publisher><publisher-name>BioMed Central</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">19091011</article-id><article-id pub-id-type="pmc">2638152</article-id><article-id pub-id-type="publisher-id">1471-2105-9-S12-S12</article-id><article-id pub-id-type="doi">10.1186/1471-2105-9-S12-S12</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research</subject></subj-group></article-categories><title-group><article-title>Real value prediction of protein solvent accessibility using enhanced PSSM features</article-title></title-group><contrib-group><contrib id="A1" corresp="yes" contrib-type="author"><name><surname>Chang</surname><given-names>Darby Tien-Hao</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>darby@ee.ncku.edu.tw</email></contrib><contrib id="A2" contrib-type="author"><name><surname>Huang</surname><given-names>Hsuan-Yu</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>n2695194@mail.ncku.edu.tw</email></contrib><contrib id="A3" contrib-type="author"><name><surname>Syu</surname><given-names>Yu-Tang</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>n2696195@mail.ncku.edu.tw</email></contrib><contrib id="A4" contrib-type="author"><name><surname>Wu</surname><given-names>Chih-Peng</given-names></name><xref ref-type="aff" rid="I2">2</xref><email>chinuy@gmail.com</email></contrib></contrib-group><aff id="I1"><label>1</label>Department of Electrical Engineering, National Cheng Kung University, Tainan, 70101, Taiwan, R.O.C</aff><aff id="I2"><label>2</label>Department of Computer Science and Information Engineering, National Taiwan University, Taipei, 10617, Taiwan, R.O.C</aff><pub-date pub-type="collection"><year>2008</year></pub-date><pub-date pub-type="epub"><day>12</day><month>12</month><year>2008</year></pub-date><volume>9</volume><issue>Suppl 12</issue><supplement><named-content content-type="supplement-title">Seventh International Conference on Bioinformatics (InCoB2008)</named-content><named-content content-type="supplement-editor">Shoba Ranganathan, Wen-Lian Hsu, Ueng-Cheng Yang and Tin Wee Tan</named-content></supplement><fpage>S12</fpage><lpage>S12</lpage><ext-link ext-link-type="uri" xlink:href="http://www.biomedcentral.com/1471-2105/9/S12/S12"/><permissions><copyright-statement>Copyright &#x000a9; 2008 Chang et al; licensee BioMed Central Ltd.</copyright-statement><copyright-year>2008</copyright-year><copyright-holder>Chang et al; licensee BioMed Central Ltd.</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.0"><p>This is an open access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/2.0"/>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</p><!--<rdf xmlns="http://web.resource.org/cc/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:dc="http://purl.org/dc/elements/1.1" xmlns:dcterms="http://purl.org/dc/terms"><Work xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:dcterms="http://purl.org/dc/terms/" rdf:about=""><license rdf:resource="http://creativecommons.org/licenses/by/2.0"/><dc:type rdf:resource="http://purl.org/dc/dcmitype/Text"/><dc:author>               Chang               Tien-Hao               Darby                              darby@ee.ncku.edu.tw            </dc:author><dc:title>            Real value prediction of protein solvent accessibility using enhanced PSSM features         </dc:title><dc:date>2008</dc:date><dcterms:bibliographicCitation>BMC Bioinformatics 9(Suppl 12): S12-. (2008)</dcterms:bibliographicCitation><dc:identifier type="sici">1471-2105(2008)9:Suppl 12&#x0003c;S12&#x0003e;</dc:identifier><dcterms:isPartOf>urn:ISSN:1471-2105</dcterms:isPartOf><License rdf:about="http://creativecommons.org/licenses/by/2.0"><permits rdf:resource="http://web.resource.org/cc/Reproduction" xmlns=""/><permits rdf:resource="http://web.resource.org/cc/Distribution" xmlns=""/><requires rdf:resource="http://web.resource.org/cc/Notice" xmlns=""/><requires rdf:resource="http://web.resource.org/cc/Attribution" xmlns=""/><permits rdf:resource="http://web.resource.org/cc/DerivativeWorks" xmlns=""/></License></Work></rdf>--></license></permissions><abstract><sec><title>Background</title><p>Prediction of protein solvent accessibility, also called accessible surface area (ASA) prediction, is an important step for tertiary structure prediction directly from one-dimensional sequences. Traditionally, predicting solvent accessibility is regarded as either a two- (exposed or buried) or three-state (exposed, intermediate or buried) classification problem. However, the states of solvent accessibility are not well-defined in real protein structures. Thus, a number of methods have been developed to directly predict the real value ASA based on evolutionary information such as position specific scoring matrix (PSSM).</p></sec><sec><title>Results</title><p>This study enhances the PSSM-based features for real value ASA prediction by considering the physicochemical properties and solvent propensities of amino acid types. We propose a systematic method for identifying residue groups with respect to protein solvent accessibility. The amino acid columns in the PSSM profile that belong to a certain residue group are merged to generate novel features. Finally, support vector regression (SVR) is adopted to construct a real value ASA predictor. Experimental results demonstrate that the features produced by the proposed selection process are informative for ASA prediction.</p></sec><sec><title>Conclusion</title><p>Experimental results based on a widely used benchmark reveal that the proposed method performs best among several of existing packages for performing ASA prediction. Furthermore, the feature selection mechanism incorporated in this study can be applied to other regression problems using the PSSM. The program and data are available from the authors upon request.</p></sec></abstract><conference><conf-date>20&#x02013;23 October 2008</conf-date><conf-name>Asia Pacific Bioinformatics Network (APBioNet) Seventh International Conference on Bioinformatics (InCoB2008)</conf-name><conf-loc>Taipei, Taiwan</conf-loc></conference></article-meta></front><body><sec><title>Background</title><p>Predicting protein tertiary structures directly from one-dimensional sequences remains a challenging problem [<xref ref-type="bibr" rid="B1">1</xref>]. The studies of solvent accessibility have shown that the process of protein folding is driven to maximal compactness by solvent aversion of some residues [<xref ref-type="bibr" rid="B2">2</xref>]. Therefore, solvent accessibility is considered as a crucial factor in protein folding and prediction of protein solvent accessibility, also called accessible surface area (ASA) prediction, is an important step in tertiary structure prediction [<xref ref-type="bibr" rid="B3">3</xref>].</p><p>Traditionally, predicting solvent accessibility is regarded as either a two- (exposed or buried) or three-state (exposed, intermediate or buried) classification problem. Various machine learning methods have been adopted, including neural networks [<xref ref-type="bibr" rid="B4">4</xref>-<xref ref-type="bibr" rid="B11">11</xref>], Bayesian statistics [<xref ref-type="bibr" rid="B12">12</xref>], logistic functions [<xref ref-type="bibr" rid="B13">13</xref>], information theory [<xref ref-type="bibr" rid="B14">14</xref>-<xref ref-type="bibr" rid="B16">16</xref>] and support vector machines (SVMs) [<xref ref-type="bibr" rid="B17">17</xref>-<xref ref-type="bibr" rid="B19">19</xref>]. Among these machine learning methods, neural networks were the first technique used in predicting protein solvent accessibility and are still extensively adopted in recent works. In addition, SVMs were also effective for ASA prediction. Several features were used to train these machine learning methods, such as local residue composition [<xref ref-type="bibr" rid="B4">4</xref>,<xref ref-type="bibr" rid="B5">5</xref>], probability profiles [<xref ref-type="bibr" rid="B20">20</xref>] and position specific scoring matrix (PSSM) [<xref ref-type="bibr" rid="B21">21</xref>].</p><p>However, subdividing residues into states requires selection of specific ASA values as thresholds, which are not well-defined in real protein structures. The applicability of state ASA predictors is thus limited as their performance is highly dependent on arbitrarily defined thresholds [<xref ref-type="bibr" rid="B22">22</xref>,<xref ref-type="bibr" rid="B23">23</xref>]. Ahmad <italic>et al</italic>. addressed this problem and developed a method, RVP-net, to predict the real values of relative solvent accessibility (RSA) [<xref ref-type="bibr" rid="B22">22</xref>]. The RVP-net used the local amino acid composition to train a neural network and yielded a mean absolute error (MAE) of 18.0&#x02013;19.5%. Yuan and Huang [<xref ref-type="bibr" rid="B23">23</xref>] also used the local amino acid composition and adopted support vector regression (SVR) (the regression version of SVM) to achieve an MAE of 17.0&#x02013;18.5%. Adamczak <italic>et al</italic>. [<xref ref-type="bibr" rid="B24">24</xref>] used the PSSM to train neural networks, which yielded an MAE of 15.3&#x02013;15.8%. After Adamczak's work, the PSSM was widely used for real value ASA prediction with some success. Wang <italic>et al</italic>. [<xref ref-type="bibr" rid="B25">25</xref>] proposed a real value ASA predictor with an MAE of 16.2&#x02013;16.4% by combining the PSSM with multiple linear regression. Garg <italic>et al</italic>. [<xref ref-type="bibr" rid="B26">26</xref>] combined the PSSM and secondary structure information with neural networks to predict RSA with an MAE of 15.2&#x02013;15.9%. Nguyen and Rajapakse [<xref ref-type="bibr" rid="B27">27</xref>] used the PSSM to construct a two-stage SVR, which further improved the MAE to 14.9&#x02013;15.7%.</p><p>Table <xref ref-type="table" rid="T1">1</xref> summarizes the recent developments in predicting real value ASA. Neural networks and SVRs were extensively adopted and outperformed other machine learning methods. However, the difference among alternative regression tools is relatively small in comparison with the introduction of the PSSM (Table <xref ref-type="table" rid="T1">1</xref>). This reveals the importance of the feature set in real value ASA prediction. This study focuses on the feature set and proposes a systematic process to enhance PSSM-based features.</p><table-wrap position="float" id="T1"><label>Table 1</label><caption><p>The recent developments, in chronological order, for real value ASA prediction</p></caption><table frame="hsides" rules="groups"><thead><tr><td align="left">Work</td><td align="left">Regression tool</td><td align="left">Description of features</td><td align="left">MAE (%)<sup>1</sup></td></tr></thead><tbody><tr><td align="left">Ahmad <italic>et al</italic>., 2003</td><td align="left">NN<sup>2</sup></td><td align="left">Amino acid composition</td><td align="left">18.8</td></tr><tr><td align="left">Yuan and Huang, 2004</td><td align="left">SVR<sup>3</sup></td><td align="left">Amino acid composition</td><td align="left">18.5</td></tr><tr><td align="left">Adamczak <italic>et al</italic>., 2004</td><td align="left">NN</td><td align="left">PSSM<sup>4</sup></td><td align="left">15.3&#x02013;15.8<sup>5</sup></td></tr><tr><td align="left">Wang <italic>et al</italic>., 2005</td><td align="left">MLR<sup>6</sup></td><td align="left">Amino acid composition, PSSM and sequence length</td><td align="left">16.2</td></tr><tr><td align="left">Garg <italic>et al</italic>., 2005</td><td align="left">NN</td><td align="left">PSSM and secondary structure information</td><td align="left">15.9</td></tr><tr><td align="left">Nguyen and Rajapakse, 2006</td><td align="left">Two-stage SVR</td><td align="left">PSSM</td><td align="left">15.7</td></tr></tbody></table><table-wrap-foot><p><sup>1</sup>Mean absolute error of real RSA values. All the methods were evaluated with a three-fold cross-validation on the Barton dataset, except Adamczak <italic>et al</italic>. used their own dataset. <sup>2</sup>Neural network. <sup>3</sup>Support vector regression. <sup>4</sup>Position specific scoring matrix. <sup>5</sup>The MAEs reported in this work were evaluated on a different dataset to other works. <sup>6</sup>Multiple linear regression.</p></table-wrap-foot></table-wrap><p>For a protein sequence, the PSSM describes the likelihood of a particular residue substitution at a specific position based on evolutionary information [<xref ref-type="bibr" rid="B21">21</xref>]. The basic idea of the enhanced PSSM is to merge similar residues into groups and use group likelihood to generate novel features [<xref ref-type="bibr" rid="B28">28</xref>,<xref ref-type="bibr" rid="B29">29</xref>]. The likelihood of a residue group is obtained by accumulating the PSSM columns of member residues into a single column. A feature selection mechanism is proposed to identify the residue groups appropriate for real value ASA prediction. Based on the proposed selection mechanism, grouped residues are guaranteed to have similar physicochemical properties and solvent propensities. Finally, the features produced by selected residue groups are combined with a two-stage SVR to construct a real value ASA predictor.</p><p>The present method is compared with five real value ASA predictors using a widely used benchmark. In addition, the predicted ASA values are transformed to ASA states for comparison with seven state ASA predictors. Experimental results demonstrate that the features produced by the proposed selection process are informative for ASA prediction. Moreover, the feature selection mechanism incorporated in this study can be applied to other regression problems using the PSSM.</p></sec><sec><title>Results and discussion</title><sec><title>Datasets</title><p>This study collects three independent datasets, Barton, Carugo and Manesh, from previous works for evaluating alternative ASA predictors. Additionally, two small datasets, SMA1 and SMA2, are created for the feature selection mechanism by sampling the Barton dataset. Table <xref ref-type="table" rid="T2">2</xref> lists the detailed statistics for these datasets.</p><table-wrap position="float" id="T2"><label>Table 2</label><caption><p>Summary of the datasets employed in this study</p></caption><table frame="hsides" rules="groups"><thead><tr><td align="left">Dataset</td><td align="left"># of chains</td><td align="left"># of residues</td><td align="left">Mean of RSA (%)</td><td align="left">Standard deviation of RSA (%)</td></tr></thead><tbody><tr><td align="left">Barton</td><td align="left">500</td><td align="left">83448</td><td align="left">28.9</td><td align="left">28.1</td></tr><tr><td align="left">&#x02003;set1</td><td align="left">166</td><td align="left">26274</td><td align="left">28.4</td><td align="left">27.8</td></tr><tr><td align="left">&#x02003;set2</td><td align="left">167</td><td align="left">26720</td><td align="left">28.7</td><td align="left">28.1</td></tr><tr><td align="left">&#x02003;set3</td><td align="left">167</td><td align="left">30454</td><td align="left">29.6</td><td align="left">28.3</td></tr><tr><td colspan="5"><hr></hr></td></tr><tr><td align="left">Carugo</td><td align="left">338</td><td align="left">82178</td><td align="left">29.9</td><td align="left">28.4</td></tr><tr><td align="left">&#x02003;set1</td><td align="left">113</td><td align="left">28871</td><td align="left">29.3</td><td align="left">28.4</td></tr><tr><td align="left">&#x02003;set2</td><td align="left">113</td><td align="left">27354</td><td align="left">29.9</td><td align="left">28.4</td></tr><tr><td align="left">&#x02003;set3</td><td align="left">112</td><td align="left">25953</td><td align="left">30.5</td><td align="left">28.3</td></tr><tr><td colspan="5"><hr></hr></td></tr><tr><td align="left">Manesh</td><td align="left">215</td><td align="left">50682</td><td align="left">28.5</td><td align="left">27.3</td></tr><tr><td align="left">&#x02003;set1</td><td align="left">72</td><td align="left">18770</td><td align="left">27.5</td><td align="left">26.9</td></tr><tr><td align="left">&#x02003;set2</td><td align="left">72</td><td align="left">15264</td><td align="left">29.2</td><td align="left">27.4</td></tr><tr><td align="left">&#x02003;set3</td><td align="left">71</td><td align="left">16648</td><td align="left">28.9</td><td align="left">27.6</td></tr><tr><td colspan="5"><hr></hr></td></tr><tr><td align="left">SMA1<sup>1</sup></td><td align="left">42</td><td align="left">6632</td><td align="left">27.6</td><td align="left">27.5</td></tr><tr><td align="left">SMA2<sup>2</sup></td><td align="left">42</td><td align="left">7680</td><td align="left">30.9</td><td align="left">28.3</td></tr></tbody></table><table-wrap-foot><p><sup>1</sup>This is a subset of the Barton set1. <sup>2</sup>This is a subset of the Barton set3.</p></table-wrap-foot></table-wrap><p>The Barton dataset, prepared by Cuff and Barton in 2000 [<xref ref-type="bibr" rid="B7">7</xref>], includes 502 non-homologous protein chains with &#x0003c;25% pairwise-sequence identity. According to previous work [<xref ref-type="bibr" rid="B22">22</xref>,<xref ref-type="bibr" rid="B23">23</xref>,<xref ref-type="bibr" rid="B27">27</xref>], this dataset was divided into three subsets with equal protein chains for cross-validation. These three subsets were used for training, testing, and validation data, which resulted in six evaluation combinations. The performances of the six combinations were averaged as overall performance. The second dataset, Carugo, was prepared by Carugo in 2000 [<xref ref-type="bibr" rid="B15">15</xref>], and includes 338 non-homologous monomeric proteins with &#x0003c;25% pairwise-sequence identity. The third dataset, Manesh, was prepared by Manesh <italic>et al</italic>. in 2001 [<xref ref-type="bibr" rid="B16">16</xref>], and has 215 non-homologous protein chains with &#x0003c;25% pairwise-sequence identity. These two datasets, Carugo and Manesh, were also divided into three subsets of equal size for cross-validation.</p><p>The three evaluation datasets &#x02013; Barton, Carugo and Manesh &#x02013; are used to evaluate the present method and to compare alternative ASA predictors. Moreover, the proposed feature selection mechanism requires two datasets. To prevent overfitting, this work uses only a small number of samples from the evaluation subsets with the worst prediction performance in previous work. The worst prediction performance implies that the selected subsets are more distinct than other subset combinations. Consequently, two small datasets, SMA1 and SMA2, are constructed by randomly selecting 42 protein chains from set1 and set3 of the Barton dataset, respectively. Both small datasets account for ~1/4 of the original set from which they are extracted.</p><p>The real values of ASA in Barton and Carugo were determined by the Dictionary of Protein Secondary Structure (DSSP) program [<xref ref-type="bibr" rid="B30">30</xref>], whereas the values in Manesh were determined by the Analytical Surface Calculation (ASC) program [<xref ref-type="bibr" rid="B31">31</xref>] based on the suggested van der Waals radii by Ooi <italic>et al</italic>. [<xref ref-type="bibr" rid="B32">32</xref>]. The RSA value of a residue was then computed by dividing the real ASA value by that observed in the extended Ala-X-Ala conformation of the residue. In this study, RSA is used as the main measure for evaluating real value ASA predictors.</p></sec><sec><title>Evaluation measures</title><p>Two widely used measures for real value ASA prediction are adopted in this study to evaluate existing ASA predictors. The first measure, mean absolute error (MAE), is defined as follows:</p><p><disp-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M1" name="1471-2105-9-S12-S12-i1" overflow="scroll">                     <mml:semantics>                        <mml:mrow>                           <mml:mtext>MAE</mml:mtext>                           <mml:mo>=</mml:mo>                           <mml:mfrac>                              <mml:mrow>                                 <mml:mstyle displaystyle="true">                                    <mml:munder>                                       <mml:mo>&#x02211;</mml:mo>                                       <mml:mrow>                                          <mml:mtext>for&#x000a0;each&#x000a0;residue</mml:mtext>                                       </mml:mrow>                                    </mml:munder>                                    <mml:mrow>                                       <mml:mrow>                                          <mml:mo>|</mml:mo>                                          <mml:mrow>                                             <mml:mi>R</mml:mi>                                             <mml:mi>S</mml:mi>                                             <mml:msub>                                                <mml:mi>A</mml:mi>                                                <mml:mrow>                                                   <mml:mi>p</mml:mi>                                                   <mml:mi>r</mml:mi>                                                   <mml:mi>e</mml:mi>                                                   <mml:mi>d</mml:mi>                                                   <mml:mi>i</mml:mi>                                                   <mml:mi>c</mml:mi>                                                   <mml:mi>t</mml:mi>                                                   <mml:mi>e</mml:mi>                                                   <mml:mi>d</mml:mi>                                                </mml:mrow>                                             </mml:msub>                                             <mml:mo>&#x02212;</mml:mo>                                             <mml:mi>R</mml:mi>                                             <mml:mi>S</mml:mi>                                             <mml:msub>                                                <mml:mi>A</mml:mi>                                                <mml:mrow>                                                   <mml:mi>o</mml:mi>                                                   <mml:mi>b</mml:mi>                                                   <mml:mi>s</mml:mi>                                                   <mml:mi>e</mml:mi>                                                   <mml:mi>r</mml:mi>                                                   <mml:mi>v</mml:mi>                                                   <mml:mi>e</mml:mi>                                                   <mml:mi>d</mml:mi>                                                </mml:mrow>                                             </mml:msub>                                          </mml:mrow>                                          <mml:mo>|</mml:mo>                                       </mml:mrow>                                    </mml:mrow>                                 </mml:mstyle>                              </mml:mrow>                              <mml:mi>n</mml:mi>                           </mml:mfrac>                           <mml:mo>,</mml:mo>                        </mml:mrow>                                             </mml:semantics>                  </mml:math></disp-formula></p><p>where <italic>n </italic>is the total number of residues to be predicted, and MAE is the absolute difference between predicted and observed (from experiments) RSA values. The second measure is Pearson's correlation coefficient (CC), which is defined as follows:</p><p><disp-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M2" name="1471-2105-9-S12-S12-i2" overflow="scroll">                     <mml:semantics>                        <mml:mrow>                           <mml:mtext>CC</mml:mtext>                           <mml:mo>=</mml:mo>                           <mml:mfrac>                              <mml:mn>1</mml:mn>                              <mml:mrow>                                 <mml:mi>n</mml:mi>                                 <mml:mo>&#x02212;</mml:mo>                                 <mml:mn>1</mml:mn>                              </mml:mrow>                           </mml:mfrac>                           <mml:mo>&#x022c5;</mml:mo>                           <mml:mstyle displaystyle="true">                              <mml:munder>                                 <mml:mo>&#x02211;</mml:mo>                                 <mml:mrow>                                    <mml:mtext>for&#x000a0;each&#x000a0;residue</mml:mtext>                                 </mml:mrow>                              </mml:munder>                              <mml:mrow>                                 <mml:mrow>                                    <mml:mo>(</mml:mo>                                    <mml:mrow>                                       <mml:mfrac>                                          <mml:mrow>                                             <mml:mi>X</mml:mi>                                             <mml:mo>&#x02212;</mml:mo>                                             <mml:mover accent="true">                                                <mml:mi>X</mml:mi>                                                <mml:mo>&#x000af;</mml:mo>                                             </mml:mover>                                          </mml:mrow>                                          <mml:mrow>                                             <mml:msub>                                                <mml:mi>s</mml:mi>                                                <mml:mi>X</mml:mi>                                             </mml:msub>                                          </mml:mrow>                                       </mml:mfrac>                                    </mml:mrow>                                    <mml:mo>)</mml:mo>                                 </mml:mrow>                              </mml:mrow>                           </mml:mstyle>                           <mml:mrow>                              <mml:mo>(</mml:mo>                              <mml:mrow>                                 <mml:mfrac>                                    <mml:mrow>                                       <mml:mi>Y</mml:mi>                                       <mml:mo>&#x02212;</mml:mo>                                       <mml:mover accent="true">                                          <mml:mi>Y</mml:mi>                                          <mml:mo>&#x000af;</mml:mo>                                       </mml:mover>                                    </mml:mrow>                                    <mml:mrow>                                       <mml:msub>                                          <mml:mi>s</mml:mi>                                          <mml:mi>Y</mml:mi>                                       </mml:msub>                                    </mml:mrow>                                 </mml:mfrac>                              </mml:mrow>                              <mml:mo>)</mml:mo>                           </mml:mrow>                           <mml:mo>,</mml:mo>                        </mml:mrow>                                             </mml:semantics>                  </mml:math></disp-formula></p><p>where <italic>n </italic>is the total number of residues to predict; <italic>X </italic>and <italic>Y </italic>are the predicted and observed RSA value of each residue, respectively; <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M3" name="1471-2105-9-S12-S12-i3" overflow="scroll"><mml:semantics><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover></mml:semantics></mml:math></inline-formula> and <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M4" name="1471-2105-9-S12-S12-i4" overflow="scroll"><mml:semantics><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover></mml:semantics></mml:math></inline-formula> are the average of predicted and observed RSA values of all residues, respectively; <italic>S</italic><sub><italic>X </italic></sub>and <italic>S</italic><sub><italic>Y </italic></sub>are the standard deviation (calculated using <italic>n</italic>-1 in the denominator) of predicted and observed RSA values of all residues, respectively; CC is the ratio of the covariance between the predicted and observed RSA values to the product of the standard deviations of the predicted and observed RSA values.</p></sec><sec><title>Feature selection</title><p>This study enhances PSSM-based features by considering the physicochemical properties and solvent propensities of amino acid types. The concepts of using the property- and propensity-based PSSM (called PSSMP) have been used in some classification problems. Shimizu <italic>et al</italic>. [<xref ref-type="bibr" rid="B28">28</xref>] first introduced the concept of the property-based PSSM by grouping residues belonging to a certain physicochemical property. Such residue groups exploit evolutionary information of a particular property at a specific position. The construction details of PSSM and PSSMP features can be found in the Methods section.</p><p>However, considering only the physicochemical property to identify residue groups generates an important question: Do all amino acids in a property group contribute consistently in various bioinformatics problems? Hence, Su <italic>et al</italic>. [<xref ref-type="bibr" rid="B29">29</xref>] proposed that physicochemical groups can be further divided into sub-groups according to residue propensities for order/disorder to predict protein disorder regions. For example, the property <italic>Small </italic>(V, C, A, G, D, N, S, T and P) was divided into <italic>Small </italic>with order propensity (V, C, N and T) and <italic>Small </italic>with disorder propensity (A, G, D, S and P). Such residue groups consider class propensities and can generate novel PSSM-based features for different problems.</p><p>Real ASA prediction, unlike order/disorder classification, lacks a well-defined threshold for measuring solvent propensities of amino acids. Thus, this study develops a novel iterative selection process that identifies the residue groups appropriate for real value ASA prediction without defining a propensity threshold. This process uses a physicochemical property (Table <xref ref-type="table" rid="T3">3</xref>) as the initial residue group and removes a member residue with the smallest or largest solvent propensity in each round, until prediction performance cannot be improved (see the Methods section for details). Starting from these properties ensures that grouped residues have similar physicochemical properties. Moreover, removing residues from those with extreme propensities indicates that the remaining residues have similar propensities.</p><table-wrap position="float" id="T3"><label>Table 3</label><caption><p>Conventional physicochemical properties</p></caption><table frame="hsides" rules="groups"><thead><tr><td align="left">Property</td><td align="left">I</td><td align="left">L</td><td align="left">V</td><td align="left">C</td><td align="left">A</td><td align="left">G</td><td align="left">M</td><td align="left">F</td><td align="right">Y</td><td align="right">W</td><td align="right">H</td><td align="right">K</td><td align="right">R</td><td align="right">E</td><td align="right">Q</td><td align="right">D</td><td align="right">N</td><td align="right">S</td><td align="right">T</td><td align="right">P</td></tr></thead><tbody><tr><td align="left"><italic>Hydrophobic</italic></td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="right">Y</td><td align="right">Y</td><td align="right">Y</td><td align="right">Y</td><td></td><td></td><td></td><td></td><td></td><td></td><td align="right">Y</td><td></td></tr><tr><td align="left"><italic>Polar</italic></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td align="right">Y</td><td align="right">Y</td><td align="right">Y</td><td align="right">Y</td><td align="right">Y</td><td align="right">Y</td><td align="right">Y</td><td align="right">Y</td><td align="right">Y</td><td align="right">Y</td><td align="right">Y</td><td></td></tr><tr><td align="left"><italic>Small</italic></td><td></td><td></td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td align="right">Y</td><td align="right">Y</td><td align="right">Y</td><td align="right">Y</td><td align="right">Y</td></tr><tr><td align="left"><italic>Aliphatic</italic></td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td align="left"><italic>Aromatic</italic></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td align="left">Y</td><td align="right">Y</td><td align="right">Y</td><td align="right">Y</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td align="left"><italic>Positive</italic></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td align="right">Y</td><td align="right">Y</td><td align="right">Y</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td align="left"><italic>Negative</italic></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td align="right">Y</td><td></td><td align="right">Y</td><td></td><td></td><td></td><td></td></tr><tr><td align="left"><italic>Proline</italic></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td align="right">Y</td></tr><tr><td align="left"><italic>Charged</italic></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td align="right">Y</td><td align="right">Y</td><td align="right">Y</td><td align="right">Y</td><td></td><td align="right">Y</td><td></td><td></td><td></td><td></td></tr><tr><td align="left"><italic>Tiny</italic></td><td></td><td></td><td></td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td align="right">Y</td><td></td><td></td></tr></tbody></table></table-wrap><p>This study compares prediction performance to that of the original PSSM and identifies five residue groups with improved performance (Table <xref ref-type="table" rid="T4">4</xref>). Finally, all possible combinations of the five groups are evaluated. Care has been taken to prevent the inclusion of <italic>Polar</italic><sub><italic>sel </italic></sub>and <italic>Charged</italic><sub><italic>sel </italic></sub>in a group combination &#x02013; <italic>Charged</italic><sub><italic>sel </italic></sub>is a subset of <italic>Polar</italic><sub><italic>sel</italic></sub>. The combination with the best prediction performance is the pair composed of <italic>Charged</italic><sub><italic>sel </italic></sub>and <italic>Tiny</italic><sub><italic>sel</italic></sub>. The final feature set with two selected properties is named PSSM-2SP, and is used as the feature set in the present method. The whole feature selection process is based on the two small datasets; that is, the prediction performances of all residue groups and group combinations are obtained using SMA1 to predict SMA2.</p><table-wrap position="float" id="T4"><label>Table 4</label><caption><p>The selected properties with improved performance than the original PSSM</p></caption><table frame="hsides" rules="groups"><thead><tr><td align="left">Property</td><td align="left">Residue group</td><td align="left">Removed residues</td></tr></thead><tbody><tr><td align="left"><italic>Polar</italic><sub>                              <italic>sel</italic>                           </sub></td><td align="left">KRQDN</td><td align="left">YWHEST</td></tr><tr><td align="left"><italic>Small</italic><sub>                              <italic>sel</italic>                           </sub></td><td align="left">GDNSTP</td><td align="left">VCA</td></tr><tr><td align="left"><italic>Negative</italic><sup>1</sup></td><td align="left">ED</td><td align="left">--</td></tr><tr><td align="left"><italic>Charged</italic><sub>                              <italic>sel</italic>                           </sub></td><td align="left">KD</td><td align="left">HRE</td></tr><tr><td align="left"><italic>Tiny</italic><sub>                              <italic>sel</italic>                           </sub></td><td align="left">AG</td><td align="left">CS</td></tr></tbody></table><table-wrap-foot><p><sup>1</sup>No amino acid type is removed from the property <italic>Negative </italic>in the iterative selection process.</p></table-wrap-foot></table-wrap></sec><sec><title>Two-stage regression</title><p>Following the design by Nguyen and Rajapakse [<xref ref-type="bibr" rid="B27">27</xref>], this study adopts two cascading regressions to predict real ASA values. In the first stage, this study uses PSSM-2SP as the feature set, which encodes the level of conservation at a position and the properties of substituted residues. A drawback of this feature set is that it lacks ASA information of neighbor residues. Thus, a second regression is included to account for the contextual information of neighboring solvent accessibility.</p><p>The second regression uses the output of the first regression as an estimation of neighboring solvent accessibility. The <italic>i</italic>-th residue in a protein sequence is represented as a 2<italic>w</italic>+1 dimensional vector <bold>v </bold>= (<italic>a</italic><sub><italic>i</italic>-<italic>h</italic></sub>, <italic>t</italic><sub><italic>i</italic>-<italic>h</italic></sub>, <italic>a</italic><sub><italic>i</italic>-<italic>h</italic>+1</sub>, <italic>t</italic><sub><italic>i</italic>-<italic>h</italic>+1</sub>,..., <italic>a</italic><sub><italic>i</italic></sub>, <italic>t</italic><sub><italic>i</italic></sub>,..., <italic>a</italic><sub><italic>i</italic>+<italic>h</italic></sub>, <italic>t</italic><sub><italic>i</italic>+<italic>h</italic></sub>, <italic>l</italic>), where <italic>a</italic><sub><italic>i </italic></sub>is the predicted RSA value of the <italic>i</italic>-th residue in the first regression, <italic>t</italic><sub><italic>i </italic></sub>is the terminal flag as either 1 (a null/terminal residue) or 0 (otherwise), <italic>l </italic>is the sequence length and <italic>w </italic>= 2<italic>h</italic>+1 is window size.</p><p>The SVR (see the Methods section for details) is used as the regression tool for both stages in the present method. For a test protein sequence, this study encodes the residues with PSSM-2SP and invokes the first SVR to obtain the first-stage RSA values. These RSA values are then used to encode residues for the second SVR. The RSA values predicted by the second SVR are the final output of the proposed ASA predictor. This study adopts the widely used LIBSVM package (version 2.86) for SVR implementation [<xref ref-type="bibr" rid="B33">33</xref>]. All required parameters are determined using SMA1 to predict SMA2. These parameters are constant in all 18 evaluation combinations of the three evaluation datasets. Table <xref ref-type="table" rid="T5">5</xref> shows these parameters.</p><table-wrap position="float" id="T5"><label>Table 5</label><caption><p>Parameters used in this study</p></caption><table frame="hsides" rules="groups"><thead><tr><td align="left">Parameter</td><td align="left">Value</td></tr></thead><tbody><tr><td align="left">In the first regression</td><td></td></tr><tr><td align="left">&#x02003;SVR kernel</td><td align="left">Gaussian</td></tr><tr><td align="left">&#x02003;C</td><td align="left">2<sup>-1</sup></td></tr><tr><td align="left">&#x02003;&#x003b3;</td><td align="left">2<sup>-7</sup></td></tr><tr><td align="left">&#x02003;&#x003b5;</td><td align="left">2<sup>-6</sup></td></tr><tr><td align="left">&#x02003;Window size</td><td align="left">11</td></tr><tr><td colspan="2"><hr></hr></td></tr><tr><td align="left">In the second regression</td><td></td></tr><tr><td align="left">&#x02003;SVR kernel</td><td align="left">Gaussian</td></tr><tr><td align="left">&#x02003;C</td><td align="left">2<sup>3</sup></td></tr><tr><td align="left">&#x02003;&#x003b3;</td><td align="left">2<sup>0</sup></td></tr><tr><td align="left">&#x02003;&#x003b5;</td><td align="left">2<sup>-8</sup></td></tr><tr><td align="left">&#x02003;Window size</td><td align="left">3</td></tr></tbody></table></table-wrap></sec><sec><title>Performance on evaluation datasets</title><p>The performance of the proposed method is compared to five real value ASA predictors (Table <xref ref-type="table" rid="T6">6</xref>). The predictors for comparison are the neural network method developed by Ahmad <italic>et al</italic>. [<xref ref-type="bibr" rid="B22">22</xref>], the single-stage SVR developed by Yuan and Huang [<xref ref-type="bibr" rid="B23">23</xref>], multiple linear regression developed by Wang <italic>et al</italic>. [<xref ref-type="bibr" rid="B25">25</xref>], multiple neural networks developed by Garg <italic>et al</italic>. [<xref ref-type="bibr" rid="B26">26</xref>] and the two-stage SVR developed by Nguyen and Rajapakse [<xref ref-type="bibr" rid="B27">27</xref>]. All predictors included the Barton dataset as one of the evaluation datasets (Table <xref ref-type="table" rid="T6">6</xref>). Although some variants exist in the prediction pipeline (e.g., Wang <italic>et al</italic>. used five-fold cross-validation, Garg <italic>et al</italic>. used seven-fold cross-validation and all other predictors used three-fold cross-validation), the performance on the Barton dataset is still a good benchmark for measuring the effectiveness of these predictors. For the Barton dataset, the MAE and CC of the proposed method are 14.8% and 0.68, respectively, both of which are better than those of the compared predictors.</p><table-wrap position="float" id="T6"><label>Table 6</label><caption><p>Comparison of the present method and five real value ASA predictors on the Barton, Carugo, and Manesh datasets</p></caption><table frame="hsides" rules="groups"><thead><tr><td></td><td align="left" colspan="2">Barton</td><td align="left" colspan="2">Carugo</td><td align="left" colspan="2">Manesh</td></tr><tr><td></td><td colspan="2"><hr></hr></td><td colspan="2"><hr></hr></td><td colspan="2"><hr></hr></td></tr><tr><td align="left">Method</td><td align="left">MAE (%)<sup>1</sup></td><td align="left">CC<sup>2</sup></td><td align="left">MAE (%)</td><td align="left">CC</td><td align="left">MAE (%)</td><td align="left">CC</td></tr></thead><tbody><tr><td align="left">Ahmad <italic>et al</italic>.</td><td align="left">18.8</td><td align="left">0.48</td><td align="left">19.0</td><td align="left">0.48</td><td align="left">18.0</td><td align="left">0.50</td></tr><tr><td align="left">Yuan and Huang</td><td align="left">18.5</td><td align="left">0.52</td><td align="left">--<sup>3</sup></td><td align="left">--</td><td align="left">--</td><td align="left">--</td></tr><tr><td align="left">Wang <italic>et al</italic>.</td><td align="left">16.2</td><td align="left">0.64</td><td align="left">--</td><td align="left">--</td><td align="left">--</td><td align="left">--</td></tr><tr><td align="left">Garg <italic>et al</italic>.</td><td align="left">15.9</td><td align="left">0.65</td><td align="left">--</td><td align="left">--</td><td align="left">15.2</td><td align="left">0.67</td></tr><tr><td align="left">Nguyen and Rajapakse</td><td align="left">15.7</td><td align="left">0.66</td><td align="left">15.7</td><td align="left">0.67</td><td align="left">14.9</td><td align="left">0.68</td></tr><tr><td align="left"><bold>Our method</bold></td><td align="left"><bold>14.8</bold></td><td align="left"><bold>0.68</bold></td><td align="left"><bold>14.8</bold></td><td align="left"><bold>0.69</bold></td><td align="left"><bold>14.2</bold></td><td align="left"><bold>0.69</bold></td></tr></tbody></table><table-wrap-foot><p>Wang <italic>et al</italic>. applied five-fold cross-validation on Barton dataset. Garg <italic>et al</italic>. applied seven-fold cross-validation on Barton dataset and five-fold cross-valuation on Manesh dataset. All other results were obtained by three-fold cross-validation. <sup>1</sup>Mean absolute error. <sup>2</sup>Pearson's correlation coefficient. <sup>3</sup>Indicates that the corresponding result was not available from the literature.</p></table-wrap-foot></table-wrap><p>However, the construction of the proposed ASA predictor (which included PSSM-2SP generation and parameter determination) is based on SMA1 and SMA2, which are part of the Barton dataset. Thus, the results from the Carugo and Manesh datasets are helpful in investigating the overfitting effects during the construction process. The improvements to the two datasets by the proposed method are analogous to the improvement to the Barton dataset, suggesting that the overfitting effects of using SMA1 and SMA2 are negligible (Table <xref ref-type="table" rid="T6">6</xref>).</p><p>Furthermore, the predicted RSA values using the proposed method are transformed into binary ASA states (buried and exposed) for comparison with state ASA predictors. The predictors for comparison are PHDacc [<xref ref-type="bibr" rid="B5">5</xref>], Jnet [<xref ref-type="bibr" rid="B7">7</xref>], the information theory approach developed by Manesh <italic>et al</italic>. [<xref ref-type="bibr" rid="B16">16</xref>], NETASA [<xref ref-type="bibr" rid="B10">10</xref>], the probability profile method developed by Gianese <italic>et al</italic>. [<xref ref-type="bibr" rid="B20">20</xref>], the two-stage SVM [<xref ref-type="bibr" rid="B19">19</xref>] and two-stage SVR [<xref ref-type="bibr" rid="B27">27</xref>]. The two-stage SVR approach is also a real value ASA predictor, the results of which were transformed into binary ASA states. Table <xref ref-type="table" rid="T7">7</xref> shows a comparison of existing state ASA predictors. In this experiment, a set of 30 proteins from the Manesh dataset is used as the training set, and the remaining 185 proteins of the Manesh dataset are used as the test set. The proposed method achieves the best accuracy for most thresholds, except at 5% and 10% thresholds (Table <xref ref-type="table" rid="T7">7</xref>). Nevertheless, the proposed method still yields an accuracy rate &#x0003e;80% at 5% and 10% thresholds. These experimental results show that the present ASA predictor can classify the buried/exposed state of residues.</p><table-wrap position="float" id="T7"><label>Table 7</label><caption><p>Comparison of the present method and seven state ASA predictors on the Manesh dataset</p></caption><table frame="hsides" rules="groups"><thead><tr><td align="left">Method\Threshold (%)</td><td align="left">5</td><td align="left">9</td><td align="left">10</td><td align="left">16</td><td align="left">20</td><td align="left">25</td><td align="left">36</td><td align="left">50</td><td align="left">60</td><td align="left">70</td><td align="left">80</td><td align="left">90</td></tr></thead><tbody><tr><td align="left">Rost and Sander</td><td align="left">--<sup>1</sup></td><td align="left">74.6</td><td align="left">--</td><td align="left">75.0</td><td align="left">--</td><td align="left">--</td><td align="left">--</td><td align="left">--</td><td align="left">--</td><td align="left">--</td><td align="left">--</td><td align="left">--</td></tr><tr><td align="left">Cuff and Barton</td><td align="left">79.0</td><td align="left">--</td><td align="left">--</td><td align="left">--</td><td align="left">--</td><td align="left">75.0</td><td align="left">--</td><td align="left">--</td><td align="left">--</td><td align="left">--</td><td align="left">--</td><td align="left">--</td></tr><tr><td align="left">Manesh <italic>et al</italic>.</td><td align="left">--</td><td align="left">75.9</td><td align="left">--</td><td align="left">75.5</td><td align="left">--</td><td align="left">74.4</td><td align="left">74.1</td><td align="left">--</td><td align="left">--</td><td align="left">--</td><td align="left">--</td><td align="left">--</td></tr><tr><td align="left">Ahmad <italic>et al</italic>.</td><td align="left">74.6</td><td align="left">--</td><td align="left">71.2</td><td align="left">--</td><td align="left">--</td><td align="left">70.3</td><td align="left">--</td><td align="left">75.9</td><td align="left">--</td><td align="left">--</td><td align="left">--</td><td align="left">--</td></tr><tr><td align="left">Gianese <italic>et al</italic>.</td><td align="left">75.7</td><td align="left">--</td><td align="left">73.4</td><td align="left">--</td><td align="left">--</td><td align="left">71.6</td><td align="left">--</td><td align="left">76.2</td><td align="left">--</td><td align="left">--</td><td align="left">--</td><td align="left">--</td></tr><tr><td align="left">Nguyen and Rajapakse</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td align="left">(Two-stage SVM)<sup>2</sup></td><td align="left"><bold>82.9</bold></td><td align="left">--</td><td align="left"><bold>81.0</bold></td><td align="left">--</td><td align="left">78.6</td><td align="left">78.1</td><td align="left">--</td><td align="left">79.1</td><td align="left">83.4</td><td align="left">--</td><td align="left">--</td><td align="left">--</td></tr><tr><td align="left">Nguyen and Rajapakse</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td align="left">(Two-stage SVR)<sup>3</sup></td><td align="left">81.1</td><td align="left">78.7</td><td align="left">78.5</td><td align="left">77.9</td><td align="left">77.6</td><td align="left">77.3</td><td align="left">76.9</td><td align="left">79.5</td><td align="left">84.3</td><td align="left">89.9</td><td align="left">95.0</td><td align="left">97.5</td></tr><tr><td align="left">Our method</td><td align="left">80.9</td><td align="left"><bold>80.2</bold></td><td align="left">80.1</td><td align="left"><bold>79.4</bold></td><td align="left"><bold>78.7</bold></td><td align="left"><bold>78.5</bold></td><td align="left"><bold>78.4</bold></td><td align="left"><bold>80.8</bold></td><td align="left"><bold>85.3</bold></td><td align="left"><bold>90.7</bold></td><td align="left"><bold>95.0</bold></td><td align="left"><bold>97.8</bold></td></tr></tbody></table><table-wrap-foot><p>This table reports the accuracy (%) of alternative methods based on the training set of 30 proteins from the Manesh dataset to predict the remaining 185 proteins of Manesh. <sup>1</sup>Indicates that the corresponding result was not available from the literature. <sup>2</sup>Nguyen and Rajapakse proposed a two-stage SVM approach in 2005 which treats solvent accessibility as a classification problem [<xref ref-type="bibr" rid="B19">19</xref>], <sup>3</sup>and then proposed a two-stage SVR approach in 2006 which treats solvent accessibility as a regression problem [<xref ref-type="bibr" rid="B27">27</xref>].</p></table-wrap-foot></table-wrap></sec><sec><title>Prediction performance vs. amino acid type</title><p>This study develops a systematic process to identify appropriate residue groups for ASA prediction. However, some amino acid types are not included in the <italic>Charged</italic><sub><italic>sel </italic></sub>and <italic>Tiny</italic><sub><italic>sel </italic></sub>properties. This analysis investigates if the proposed PSSM-2SP improves these amino acid types. Table <xref ref-type="table" rid="T8">8</xref> compares the prediction performance for 20 amino acid types with and without the <italic>Charged</italic><sub><italic>sel </italic></sub>and <italic>Tiny</italic><sub><italic>sel </italic></sub>information. Table <xref ref-type="table" rid="T8">8</xref> reveals some important facts in current real value ASA prediction, such as amino acids that are more hydrophobic (I, L, V and C) are better predicted than those less hydrophobic (E, D, N and S). These MAE differences among amino acid types concur with and have been discussed in previous works [<xref ref-type="bibr" rid="B25">25</xref>,<xref ref-type="bibr" rid="B27">27</xref>]. Here, this study focuses on improving PSSM-2SP over the PSSM. The PSSM-2SP improves &#x02265; 0.7% MAE for most amino acid types, although the <italic>Charged</italic><sub><italic>sel </italic></sub>and <italic>Tiny</italic><sub><italic>sel </italic></sub>properties include only A, G, K and D (Table <xref ref-type="table" rid="T8">8</xref>). This can be explained by the multiple sequence alignment in constructing the PSSM-2SP. Namely, a non-A, -G, -K and -D residue is still affected by the <italic>Charged</italic><sub><italic>sel </italic></sub>and <italic>Tiny</italic><sub><italic>sel </italic></sub>properties when some of its homology sequences have A, G, K or D residues within the corresponding window.</p><table-wrap position="float" id="T8"><label>Table 8</label><caption><p>Comparison of PSSM and PSSM-2SP on the Barton dataset in terms of amino acid types</p></caption><table frame="hsides" rules="groups"><thead><tr><td></td><td></td><td align="center" colspan="3">MAE (%)</td></tr><tr><td></td><td></td><td colspan="3"><hr></hr></td></tr><tr><td align="left">Amino acid type</td><td align="left">Occurence (%)</td><td align="left">PSSM</td><td align="left">PSSM-2SP</td><td align="left">Improvement</td></tr></thead><tbody><tr><td align="left">I</td><td align="left">5.5</td><td align="left">9.7</td><td align="left">8.7</td><td align="left">1.0</td></tr><tr><td align="left">L</td><td align="left">8.5</td><td align="left">10.7</td><td align="left">9.8</td><td align="left">0.9</td></tr><tr><td align="left">V</td><td align="left">6.9</td><td align="left">10.6</td><td align="left">9.6</td><td align="left">1.0</td></tr><tr><td align="left">C</td><td align="left">0.9</td><td align="left">9.8</td><td align="left">8.9</td><td align="left">0.9</td></tr><tr><td align="left">A*</td><td align="left">8.7</td><td align="left">14.1</td><td align="left">13.3</td><td align="left">0.9</td></tr><tr><td align="left">G*</td><td align="left">7.8</td><td align="left">19.8</td><td align="left">19.5</td><td align="left">0.4</td></tr><tr><td align="left">M</td><td align="left">2.0</td><td align="left">12.3</td><td align="left">11.3</td><td align="left">0.9</td></tr><tr><td align="left">F</td><td align="left">3.9</td><td align="left">11.2</td><td align="left">10.2</td><td align="left">1.0</td></tr><tr><td align="left">Y</td><td align="left">3.6</td><td align="left">13.3</td><td align="left">13.0</td><td align="left">0.3</td></tr><tr><td align="left">W</td><td align="left">1.5</td><td align="left">12.4</td><td align="left">11.8</td><td align="left">0.6</td></tr><tr><td align="left">H</td><td align="left">2.2</td><td align="left">15.5</td><td align="left">15.1</td><td align="left">0.4</td></tr><tr><td align="left">K*</td><td align="left">5.9</td><td align="left">17.1</td><td align="left">15.8</td><td align="left">1.3</td></tr><tr><td align="left">R</td><td align="left">4.5</td><td align="left">17.7</td><td align="left">17.0</td><td align="left">0.7</td></tr><tr><td align="left">E</td><td align="left">6.0</td><td align="left">18.9</td><td align="left">17.8</td><td align="left">1.1</td></tr><tr><td align="left">Q</td><td align="left">3.7</td><td align="left">18.1</td><td align="left">17.2</td><td align="left">0.9</td></tr><tr><td align="left">D*</td><td align="left">5.9</td><td align="left">20.1</td><td align="left">19.2</td><td align="left">0.8</td></tr><tr><td align="left">N</td><td align="left">4.7</td><td align="left">20.4</td><td align="left">19.6</td><td align="left">0.8</td></tr><tr><td align="left">S</td><td align="left">6.2</td><td align="left">19.0</td><td align="left">18.3</td><td align="left">0.7</td></tr><tr><td align="left">T</td><td align="left">6.0</td><td align="left">16.9</td><td align="left">16.0</td><td align="left">0.9</td></tr><tr><td align="left">P</td><td align="left">4.7</td><td align="left">18.2</td><td align="left">17.4</td><td align="left">0.8</td></tr></tbody></table></table-wrap></sec></sec><sec><title>Conclusion</title><p>There is an enormous gap between the number of protein structures and the huge number of protein sequences. Thus, predicting protein structures directly from amino acid sequences remains one of the most important problems in life science. The PSSM generated by PSI-BLAST is a useful feature set for sequence-based methods in various bioinformatics problems. This study proposes a novel feature selection mechanism that enhances the PSSM-based features for real value ASA prediction. Based on the selected PSSM-2SP features, this study adopts two cascading SVRs to construct an ASA predictor. The performance of the proposed method is compared with that of five real value ASA predictors and seven state ASA predictors. Experimental results show that the proposed predictor performs best in evaluating datasets. It can predict real ASA values with an MAE of 14.2&#x02013;14.8% and predict state ASA with an accuracy of 78.4&#x02013;97.8%. These experimental results demonstrate that the selected features are informative for ASA prediction. Another contribution of this study is the proposed systematic process for generating novel PSSM-based features for regression problems. This is achieved by shrinking the initial physicochemical property from residues with extreme propensities. The feature selection mechanism in this study can be applied to other regression problems using the PSSM.</p></sec><sec sec-type="methods"><title>Methods</title><p>This study adopts an iterative selection process to determine which residues should be grouped together to generate novel features for real value ASA prediction. In each round, this process generates new residue groups, transforms the dataset into a vector representation according to the residue groups, and evaluates the residue groups by performing SVR on the transformed dataset. Evaluation results are used for construction of residue groups in the next round. This section first describes the workflow of the proposed iterative selection process, and then the details of constructing the feature vector and SVR algorithm.</p><sec><title>The proposed iterative selection process</title><p>Figure <xref ref-type="fig" rid="F1">1</xref> shows the workflow of the selection process. This iterative selection starts from an initial residue group <italic>G</italic>. In this implementation, nine of the ten physicochemical properties (Table <xref ref-type="table" rid="T3">3</xref>) are used as initial groups (the property <italic>Proline </italic>is not used since it includes only an amino acid type). Staring from these properties ensures that residues in the final residue group have similar physicochemical properties. The next step is to generate two sub-groups, <italic>G</italic><sub><italic>small </italic></sub>and <italic>G</italic><sub><italic>large</italic></sub>, from <italic>G</italic>. Suppose that <italic>G </italic>has <italic>n </italic>amino acid types, <italic>G</italic><sub><italic>small </italic></sub>then contains the smallest <italic>n</italic>-1 amino acid types of G in terms of solvent propensity. The solvent propensity of an amino acid type is estimated by averaging the RSA values of all residues of that amino acid type in the SMA1 and SMA2 datasets. Figure <xref ref-type="fig" rid="F2">2</xref> shows the RSA averages obtained by examining the residues in the SMA1 and SMA2 datasets. Similarly, <italic>G</italic><sub><italic>large </italic></sub>contains the largest <italic>n</italic>-1 amino acid types of G in terms of solvent propensity.</p><fig position="float" id="F1"><label>Figure 1</label><caption><p><bold>Workflow of the proposed iterative selection process.</bold> *<italic>G</italic><sub><italic>small </italic></sub>is generated by removing the residue with the largest average RSA from <italic>G</italic>, and <italic>G</italic><sub><italic>large </italic></sub>is generated by removing the residue with the smallest average RSA from <italic>G</italic>. **The performance of each residue group is measured according to the MAE delivered by SVR. |<italic>G</italic>| is the size of <italic>G</italic>.</p></caption><graphic xlink:href="1471-2105-9-S12-S12-1"/></fig><fig position="float" id="F2"><label>Figure 2</label><caption><p>The average RSA value of each amino acid type in the SMA1 and SMA2 datasets.</p></caption><graphic xlink:href="1471-2105-9-S12-S12-2"/></fig><p>The three residue groups, <italic>G</italic>, <italic>G</italic><sub><italic>small </italic></sub>and <italic>G</italic><sub><italic>large</italic></sub>, are then evaluated by using SMA1 to predict SMA2. The evaluation step is divided into two sub-steps as described in the following two subsections. If <italic>G </italic>is the best residue group of the three residue groups during evaluation, then the whole selection process is done; otherwise, <italic>G </italic>is replaced by the relatively better residue group between <italic>G</italic><sub><italic>small </italic></sub>and <italic>G</italic><sub><italic>large </italic></sub>in the evaluation step and the next round is started.</p><p>One of the most distinct features of this iterative selection process compared to conventional backward selection is that only two sub-groups are considered in each round. There are two reasons for this modification. First, residues in the final residue group are guaranteed to have similar solvent propensities by removing amino acid types from those with extreme propensities. The second advantage is respect to the computational concern. Conventional backward selection generates <italic>n </italic>sub-groups for a group with <italic>n </italic>elements and results in a time complexity of <italic>O</italic>(<italic>N</italic><sup>2</sup>), where <italic>N </italic>is the size of the initial residue group. The modification in this study reduces time complexity to <italic>O</italic>(<italic>N</italic>).</p></sec><sec><title>Encode residues as feature vectors</title><p>The first-stage of the proposed ASA predictor follows the practice of using PSSM-based features to encode residues. This sub-section first describes the construction of the original PSSM, and then that of the PSSMP according to a given residue group <italic>G</italic>. For a protein sequence, construction of the PSSM is achieved by first invoking the PSI-BLAST program [<xref ref-type="bibr" rid="B21">21</xref>] to the non-redundant (NR) database obtained from the NCBI, where low-complexity and transmembrane regions and coil-coil segments are removed as suggested by Jones [<xref ref-type="bibr" rid="B34">34</xref>]. The settings for PSI-BLAST in this study, including the cutting E-value threshold (<italic>e</italic>) of 10<sup>-3</sup>, multi-pass inclusion E-value threshold (<italic>h</italic>) of 2 &#x000d7; 10<sup>-3</sup>, and iteration count of 3, follow the suggestions of a previous study [<xref ref-type="bibr" rid="B35">35</xref>].</p><p>The PSSM profile generated by PSI-BLAST consists of the likelihood of a particular residue substitution at a specific position. These likelihood values are rescaled to [0,1] using the following logistic function [<xref ref-type="bibr" rid="B36">36</xref>]:</p><p><disp-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M5" name="1471-2105-9-S12-S12-i5" overflow="scroll">                     <mml:semantics>                        <mml:mrow>                           <mml:msup>                              <mml:mi>x</mml:mi>                              <mml:mo>&#x02032;</mml:mo>                           </mml:msup>                           <mml:mo>=</mml:mo>                           <mml:mfrac>                              <mml:mn>1</mml:mn>                              <mml:mrow>                                 <mml:mn>1</mml:mn>                                 <mml:mo>+</mml:mo>                                 <mml:mi>exp</mml:mi>                                 <mml:mo>&#x02061;</mml:mo>                                 <mml:mo stretchy="false">(</mml:mo>                                 <mml:mo>&#x02212;</mml:mo>                                 <mml:mi>x</mml:mi>                                 <mml:mo stretchy="false">)</mml:mo>                              </mml:mrow>                           </mml:mfrac>                           <mml:mo>,</mml:mo>                        </mml:mrow>                                             </mml:semantics>                  </mml:math></disp-formula></p><p>where <italic>x </italic>is the raw value in the PSSM profile and <italic>x</italic>' is the value corresponding to <italic>x </italic>after rescaling. Each position of a protein sequence is represented by a 21-dimensional vector where 20 elements take the likelihood values of 20 amino acid types from the rescaled PSSM profile; the last element is a terminal flag as most PSSM-based methods have introduced [<xref ref-type="bibr" rid="B27">27</xref>,<xref ref-type="bibr" rid="B29">29</xref>]. Finally, the feature vector based on the original PSSM for a residue comprises a window of positions. For example, the <italic>i</italic>-th residue in a protein sequence is represented as a <italic>w </italic>&#x000d7; 21 dimensional vector, includes the positions <italic>i</italic>-<italic>h</italic>, <italic>i</italic>-<italic>h</italic>+1,..., <italic>i</italic>,..., <italic>i</italic>+<italic>h </italic>of that sequence, where the window size is <italic>w </italic>= 2<italic>h</italic>+1.</p><p>After constructing the PSSM profile, the PSSMP profile according to residue group <italic>G </italic>can be generated easily by accumulating the PSSM profile values of residues in <italic>G </italic>to enlarge the profile by one dimension. That is, a one-group PSSMP feature set results in 21 likelihood values at a specific position, where 20 elements are the same as in the original PSSM, and the last value is the accumulated value. This is slightly different from the procedure used by Su and coworkers, which discards likelihood values of residues in <italic>G </italic>and forms a condensed PSSMP [<xref ref-type="bibr" rid="B29">29</xref>]. The resulting PSSMP profile is then rescaled to [0,1], added with a terminal flag and then formatted into the vector representation with a window size <italic>w</italic>. Consequently, a residue based on an <italic>n</italic>-group PSSMP is represented as a <italic>w </italic>&#x000d7; (21+<italic>n</italic>) dimensional feature vector. Figure <xref ref-type="fig" rid="F3">3</xref> shows an example of encoding a residue to its corresponding feature vector.</p><fig position="float" id="F3"><label>Figure 3</label><caption><p><bold>An example of encoding a residue to its corresponding feature vector</bold>. We encode the fifth residue (<italic>i </italic>= 5) of a protein (PDB ID: <ext-link ext-link-type="pdb" xlink:href="154L">154L</ext-link>) with window size 11 (<italic>w </italic>= 11 and <italic>h </italic>= 5). In this example, a position of the protein sequence is represented by a 23-dimensional vector (20 amino acid values, a terminal flag and two group values). The first row is a pseudo terminal residue where only the terminal flag is 1 and all other 22 values are zero. Finally, the <italic>i</italic>-th residue is encoded with its neighboring positions to form a 253-dimensional feature vector.</p></caption><graphic xlink:href="1471-2105-9-S12-S12-3"/></fig></sec><sec><title>Support vector regression (SVR)</title><p>Regression is a technique used for estimating an unknown continuous-valued function based on a set of samples consisting of a dependent variable (response variable) with one or more independent variables (explanatory variables). In real value ASA prediction, each sample (<italic>i.e.</italic>, each residue) is represented by a feature vector, <bold>v</bold>, and an associated RSA value, <italic>y</italic>. Each element in <bold>v </bold>is an independent variable, and <italic>y </italic>is the dependent variable. The SVR is a kernel regression technique that constructs a model based on support vectors. This model expresses <italic>y </italic>as a function of <bold>v </bold>with several parameters:</p><p><disp-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M6" name="1471-2105-9-S12-S12-i6" overflow="scroll">                     <mml:semantics>                        <mml:mrow>                           <mml:mi>y</mml:mi>                           <mml:mo>=</mml:mo>                           <mml:mi>b</mml:mi>                           <mml:mo>+</mml:mo>                           <mml:mstyle displaystyle="true">                              <mml:munder>                                 <mml:mo>&#x02211;</mml:mo>                                 <mml:mrow>                                    <mml:msub>                                       <mml:mstyle mathsize="normal" mathvariant="bold">                                          <mml:mi>s</mml:mi>                                       </mml:mstyle>                                       <mml:mi>i</mml:mi>                                    </mml:msub>                                    <mml:mtext>&#x000a0;is&#x000a0;a&#x000a0;support&#x000a0;vector</mml:mtext>                                 </mml:mrow>                              </mml:munder>                              <mml:mrow>                                 <mml:msub>                                    <mml:mi>w</mml:mi>                                    <mml:mi>i</mml:mi>                                 </mml:msub>                                 <mml:mi>K</mml:mi>                                 <mml:mo stretchy="false">(</mml:mo>                                 <mml:mstyle mathsize="normal" mathvariant="bold">                                    <mml:mi>v</mml:mi>                                 </mml:mstyle>                                 <mml:mo>,</mml:mo>                                 <mml:msub>                                    <mml:mstyle mathsize="normal" mathvariant="bold">                                       <mml:mi>s</mml:mi>                                    </mml:mstyle>                                    <mml:mi>i</mml:mi>                                 </mml:msub>                                 <mml:mo stretchy="false">)</mml:mo>                              </mml:mrow>                           </mml:mstyle>                           <mml:mo>,</mml:mo>                        </mml:mrow>                                             </mml:semantics>                  </mml:math></disp-formula></p><p>where <italic>K</italic>() is the kernel function, and <italic>b </italic>and <italic>w</italic><sub><italic>i </italic></sub>are numerical parameters determined by minimizing the prediction error on training samples. A training instance, <bold>s</bold><sub><italic>i</italic></sub>, is selected as a support vector when the associated weight <italic>w</italic><sub><italic>i </italic></sub>exceeds a user-specified threshold, <italic>C</italic>. In addition, SVR introduces the following two criteria to reduce the risk of overfitting when minimizing prediction error: 1) a user-specified parameter, <italic>&#x003b5;</italic>, defines a tube around the regression function in which errors are ignored; and 2) maximizing the flatness of the regression function. The problem is to find the support vectors and determine parameters <italic>b </italic>and <italic>w</italic><sub><italic>i</italic></sub>, which can be solved by constrained quadratic optimization [<xref ref-type="bibr" rid="B37">37</xref>]. The LIBSVM package (version 2.86) [<xref ref-type="bibr" rid="B33">33</xref>] is used for SVR implementation in this study. Table <xref ref-type="table" rid="T5">5</xref> lists the values of these user-defined parameters.</p></sec></sec><sec><title>Competing interests</title><p>The authors declare that they have no competing interests.</p></sec><sec><title>Authors' contributions</title><p>Author DTHC designed the methodology and conceived of this study. HYH, YTS and CPW designed the experiments and performed all calculations and analyses. All authors have read and approved this manuscript.</p></sec></body><back><ack><sec><title>Acknowledgements</title><p>The authors would like to thank the National Science Council of the Republic of China, Taiwan, for financially supporting this research under Contract Nos. NSC 97-2627-P-001-002, NSC 96-2320-B-006-027-MY2 and NSC 96-2221-E-006-232-MY2. Ted Knoy is appreciated for his editorial assistance.</p><p>This article has been published as part of <italic>BMC Bioinformatics </italic>Volume 9 Supplement 12, 2008: Asia Pacific Bioinformatics Network (APBioNet) Seventh International Conference on Bioinformatics (InCoB2008). The full contents of the supplement are available online at <ext-link ext-link-type="uri" xlink:href="http://www.biomedcentral.com/1471-2105/9?issue=S12"/>.</p></sec></ack><ref-list><ref id="B1"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Mount</surname><given-names>DW</given-names></name></person-group><source>Bioinformatics: sequence and genome analysis</source><year>2004</year><edition>2</edition><publisher-name>Cold Spring Harbor, N.Y.: Cold Spring Harbor Laboratory Press</publisher-name></citation></ref><ref id="B2"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Chan</surname><given-names>HS</given-names></name><name><surname>Dill</surname><given-names>KA</given-names></name></person-group><article-title>Origins of Structure in Globular-Proteins</article-title><source>Proc Natl Acad Sci USA</source><year>1990</year><volume>87</volume><fpage>6388</fpage><lpage>6392</lpage><pub-id pub-id-type="pmid">2385597</pub-id><pub-id pub-id-type="doi">10.1073/pnas.87.16.6388</pub-id></citation></ref><ref id="B3"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Raih</surname><given-names>MF</given-names></name><name><surname>Ahmad</surname><given-names>S</given-names></name><name><surname>Zheng</surname><given-names>R</given-names></name><name><surname>Mohamed</surname><given-names>R</given-names></name></person-group><article-title>Solvent accessibility in native and isolated domain environments: general features and implications to interface predictability</article-title><source>Biophys Chem</source><year>2005</year><volume>114</volume><fpage>63</fpage><lpage>69</lpage><pub-id pub-id-type="pmid">15792862</pub-id><pub-id pub-id-type="doi">10.1016/j.bpc.2004.10.005</pub-id></citation></ref><ref id="B4"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Holbrook</surname><given-names>SR</given-names></name><name><surname>Muskal</surname><given-names>SM</given-names></name><name><surname>Kim</surname><given-names>SH</given-names></name></person-group><article-title>Predicting Surface Exposure of Amino-Acids from Protein-Sequence</article-title><source>Protein Eng</source><year>1990</year><volume>3</volume><fpage>659</fpage><lpage>665</lpage><pub-id pub-id-type="pmid">2217139</pub-id><pub-id pub-id-type="doi">10.1093/protein/3.8.659</pub-id></citation></ref><ref id="B5"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Rost</surname><given-names>B</given-names></name><name><surname>Sander</surname><given-names>C</given-names></name></person-group><article-title>Conservation and Prediction of Solvent Accessibility in Protein Families</article-title><source>Proteins</source><year>1994</year><volume>20</volume><fpage>216</fpage><lpage>226</lpage><pub-id pub-id-type="pmid">7892171</pub-id><pub-id pub-id-type="doi">10.1002/prot.340200303</pub-id></citation></ref><ref id="B6"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Pascarella</surname><given-names>S</given-names></name><name><surname>De Persio</surname><given-names>R</given-names></name><name><surname>Bossa</surname><given-names>F</given-names></name><name><surname>Argos</surname><given-names>P</given-names></name></person-group><article-title>Easy method to predict solvent accessibility from multiple protein sequence alignments</article-title><source>Proteins</source><year>1998</year><volume>32</volume><fpage>190</fpage><lpage>199</lpage><pub-id pub-id-type="pmid">9714158</pub-id><pub-id pub-id-type="doi">10.1002/(SICI)1097-0134(19980801)32:2&#x0003c;190::AID-PROT5&#x0003e;3.0.CO;2-P</pub-id></citation></ref><ref id="B7"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Cuff</surname><given-names>JA</given-names></name><name><surname>Barton</surname><given-names>GJ</given-names></name></person-group><article-title>Application of multiple sequence alignment profiles to improve protein secondary structure prediction</article-title><source>Proteins</source><year>2000</year><volume>40</volume><fpage>502</fpage><lpage>511</lpage><pub-id pub-id-type="pmid">10861942</pub-id><pub-id pub-id-type="doi">10.1002/1097-0134(20000815)40:3&#x0003c;502::AID-PROT170&#x0003e;3.0.CO;2-Q</pub-id></citation></ref><ref id="B8"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Fariselli</surname><given-names>P</given-names></name><name><surname>Casadio</surname><given-names>R</given-names></name></person-group><article-title>RCNPRED: prediction of the residue co-ordination numbers in proteins</article-title><source>Bioinformatics</source><year>2001</year><volume>17</volume><fpage>202</fpage><lpage>203</lpage><pub-id pub-id-type="pmid">11238082</pub-id><pub-id pub-id-type="doi">10.1093/bioinformatics/17.2.202</pub-id></citation></ref><ref id="B9"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>X</given-names></name><name><surname>Pan</surname><given-names>XM</given-names></name></person-group><article-title>New method for accurate prediction of solvent accessibility from protein sequence</article-title><source>Proteins</source><year>2001</year><volume>42</volume><fpage>1</fpage><lpage>5</lpage><pub-id pub-id-type="pmid">11093255</pub-id><pub-id pub-id-type="doi">10.1002/1097-0134(20010101)42:1&#x0003c;1::AID-PROT10&#x0003e;3.0.CO;2-N</pub-id></citation></ref><ref id="B10"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ahmad</surname><given-names>S</given-names></name><name><surname>Gromiha</surname><given-names>MM</given-names></name></person-group><article-title>NETASA: neural network based prediction of solvent accessibility</article-title><source>Bioinformatics</source><year>2002</year><volume>18</volume><fpage>819</fpage><lpage>824</lpage><pub-id pub-id-type="pmid">12075017</pub-id><pub-id pub-id-type="doi">10.1093/bioinformatics/18.6.819</pub-id></citation></ref><ref id="B11"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Pollastri</surname><given-names>G</given-names></name><name><surname>Baldi</surname><given-names>P</given-names></name><name><surname>Fariselli</surname><given-names>P</given-names></name><name><surname>Casadio</surname><given-names>R</given-names></name></person-group><article-title>Prediction of coordination number and relative solvent accessibility in proteins</article-title><source>Proteins</source><year>2002</year><volume>47</volume><fpage>142</fpage><lpage>153</lpage><pub-id pub-id-type="pmid">11933061</pub-id><pub-id pub-id-type="doi">10.1002/prot.10069</pub-id></citation></ref><ref id="B12"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Thompson</surname><given-names>MJ</given-names></name><name><surname>Goldstein</surname><given-names>RA</given-names></name></person-group><article-title>Predicting solvent accessibility: Higher accuracy using Bayesian statistics and optimized residue substitution classes</article-title><source>Proteins</source><year>1996</year><volume>25</volume><fpage>38</fpage><lpage>47</lpage><pub-id pub-id-type="pmid">8727318</pub-id><pub-id pub-id-type="doi">10.1002/(SICI)1097-0134(199605)25:1&#x0003c;38::AID-PROT4&#x0003e;3.3.CO;2-H</pub-id></citation></ref><ref id="B13"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Mucchielli-Giorgi</surname><given-names>MH</given-names></name><name><surname>Hazout</surname><given-names>S</given-names></name><name><surname>Tuffery</surname><given-names>P</given-names></name></person-group><article-title>PredAcc: prediction of solvent accessibility</article-title><source>Bioinformatics</source><year>1999</year><volume>15</volume><fpage>176</fpage><lpage>177</lpage><pub-id pub-id-type="pmid">10089205</pub-id><pub-id pub-id-type="doi">10.1093/bioinformatics/15.2.176</pub-id></citation></ref><ref id="B14"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Richardson</surname><given-names>CJ</given-names></name><name><surname>Barlow</surname><given-names>DJ</given-names></name></person-group><article-title>The bottom line for prediction of residue solvent accessibility</article-title><source>Protein Eng</source><year>1999</year><volume>12</volume><fpage>1051</fpage><lpage>1054</lpage><pub-id pub-id-type="pmid">10611398</pub-id><pub-id pub-id-type="doi">10.1093/protein/12.12.1051</pub-id></citation></ref><ref id="B15"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Carugo</surname><given-names>O</given-names></name></person-group><article-title>Predicting residue solvent accessibility from protein sequence by considering the sequence environment</article-title><source>Protein Eng</source><year>2000</year><volume>13</volume><fpage>607</fpage><lpage>609</lpage><pub-id pub-id-type="pmid">11054454</pub-id><pub-id pub-id-type="doi">10.1093/protein/13.9.607</pub-id></citation></ref><ref id="B16"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Naderi-Manesh</surname><given-names>H</given-names></name><name><surname>Sadeghi</surname><given-names>M</given-names></name><name><surname>Arab</surname><given-names>S</given-names></name><name><surname>Movahedi</surname><given-names>AAM</given-names></name></person-group><article-title>Prediction of protein surface accessibility with information theory</article-title><source>Proteins</source><year>2001</year><volume>42</volume><fpage>452</fpage><lpage>459</lpage><pub-id pub-id-type="pmid">11170200</pub-id><pub-id pub-id-type="doi">10.1002/1097-0134(20010301)42:4&#x0003c;452::AID-PROT40&#x0003e;3.0.CO;2-Q</pub-id></citation></ref><ref id="B17"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Yuan</surname><given-names>Z</given-names></name><name><surname>Burrage</surname><given-names>K</given-names></name><name><surname>Mattick</surname><given-names>JS</given-names></name></person-group><article-title>Prediction of protein solvent accessibility using support vector machines</article-title><source>Proteins</source><year>2002</year><volume>48</volume><fpage>566</fpage><lpage>570</lpage><pub-id pub-id-type="pmid">12112679</pub-id><pub-id pub-id-type="doi">10.1002/prot.10176</pub-id></citation></ref><ref id="B18"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>H</given-names></name><name><surname>Park</surname><given-names>H</given-names></name></person-group><article-title>Prediction of protein relative solvent accessibility with support vector machines and long-range interaction 3D local descriptor</article-title><source>Proteins</source><year>2004</year><volume>54</volume><fpage>557</fpage><lpage>562</lpage><pub-id pub-id-type="pmid">14748002</pub-id><pub-id pub-id-type="doi">10.1002/prot.10602</pub-id></citation></ref><ref id="B19"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Nguyen</surname><given-names>MN</given-names></name><name><surname>Rajapakse</surname><given-names>JC</given-names></name></person-group><article-title>Prediction of protein relative solvent accessibility with a two-stage SVM approach</article-title><source>Proteins</source><year>2005</year><volume>59</volume><fpage>30</fpage><lpage>37</lpage><pub-id pub-id-type="pmid">15696542</pub-id><pub-id pub-id-type="doi">10.1002/prot.20404</pub-id></citation></ref><ref id="B20"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Gianese</surname><given-names>G</given-names></name><name><surname>Bossa</surname><given-names>F</given-names></name><name><surname>Pascarella</surname><given-names>S</given-names></name></person-group><article-title>Improvement in prediction of solvent accessibility by probability profiles</article-title><source>Protein Eng</source><year>2003</year><volume>16</volume><fpage>987</fpage><lpage>992</lpage><pub-id pub-id-type="pmid">14983079</pub-id><pub-id pub-id-type="doi">10.1093/protein/gzg139</pub-id></citation></ref><ref id="B21"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Altschul</surname><given-names>SF</given-names></name><name><surname>Madden</surname><given-names>TL</given-names></name><name><surname>Schaffer</surname><given-names>AA</given-names></name><name><surname>Zhang</surname><given-names>JH</given-names></name><name><surname>Zhang</surname><given-names>Z</given-names></name><name><surname>Miller</surname><given-names>W</given-names></name><name><surname>Lipman</surname><given-names>DJ</given-names></name></person-group><article-title>Gapped BLAST and PSI-BLAST: a new generation of protein database search programs</article-title><source>Nucleic Acids Res</source><year>1997</year><volume>25</volume><fpage>3389</fpage><lpage>3402</lpage><pub-id pub-id-type="pmid">9254694</pub-id><pub-id pub-id-type="doi">10.1093/nar/25.17.3389</pub-id></citation></ref><ref id="B22"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ahmad</surname><given-names>S</given-names></name><name><surname>Gromiha</surname><given-names>MM</given-names></name><name><surname>Sarai</surname><given-names>A</given-names></name></person-group><article-title>Real value prediction of solvent accessibility from amino acid sequence</article-title><source>Proteins</source><year>2003</year><volume>50</volume><fpage>629</fpage><lpage>635</lpage><pub-id pub-id-type="pmid">12577269</pub-id><pub-id pub-id-type="doi">10.1002/prot.10328</pub-id></citation></ref><ref id="B23"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Yuan</surname><given-names>Z</given-names></name><name><surname>Huang</surname><given-names>BX</given-names></name></person-group><article-title>Prediction of protein accessible surface areas by support vector regression</article-title><source>Proteins</source><year>2004</year><volume>57</volume><fpage>558</fpage><lpage>564</lpage><pub-id pub-id-type="pmid">15382233</pub-id><pub-id pub-id-type="doi">10.1002/prot.20234</pub-id></citation></ref><ref id="B24"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Adamczak</surname><given-names>R</given-names></name><name><surname>Porollo</surname><given-names>A</given-names></name><name><surname>Meller</surname><given-names>J</given-names></name></person-group><article-title>Accurate prediction of solvent accessibility using neural networks-based regression</article-title><source>Proteins</source><year>2004</year><volume>56</volume><fpage>753</fpage><lpage>767</lpage><pub-id pub-id-type="pmid">15281128</pub-id><pub-id pub-id-type="doi">10.1002/prot.20176</pub-id></citation></ref><ref id="B25"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>JY</given-names></name><name><surname>Lee</surname><given-names>HM</given-names></name><name><surname>Ahmad</surname><given-names>S</given-names></name></person-group><article-title>Prediction and evolutionary information analysis of protein solvent accessibility using multiple linear regression</article-title><source>Proteins</source><year>2005</year><volume>61</volume><fpage>481</fpage><lpage>491</lpage><pub-id pub-id-type="pmid">16170780</pub-id><pub-id pub-id-type="doi">10.1002/prot.20620</pub-id></citation></ref><ref id="B26"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Garg</surname><given-names>A</given-names></name><name><surname>Kaur</surname><given-names>H</given-names></name><name><surname>Raghava</surname><given-names>GPS</given-names></name></person-group><article-title>Real value prediction of solvent accessibility in proteins using multiple sequence alignment and secondary structure</article-title><source>Proteins</source><year>2005</year><volume>61</volume><fpage>318</fpage><lpage>324</lpage><pub-id pub-id-type="pmid">16106377</pub-id><pub-id pub-id-type="doi">10.1002/prot.20630</pub-id></citation></ref><ref id="B27"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Nguyen</surname><given-names>MN</given-names></name><name><surname>Rajapakse</surname><given-names>JC</given-names></name></person-group><article-title>Two-stage support vector regression approach for predicting accessible surface areas of amino acids</article-title><source>Proteins</source><year>2006</year><volume>63</volume><fpage>542</fpage><lpage>550</lpage><pub-id pub-id-type="pmid">16456847</pub-id><pub-id pub-id-type="doi">10.1002/prot.20883</pub-id></citation></ref><ref id="B28"><citation citation-type="other"><person-group person-group-type="author"><name><surname>Shimizu</surname><given-names>K</given-names></name><name><surname>Hirose</surname><given-names>S</given-names></name><name><surname>Noguchi</surname><given-names>T</given-names></name><name><surname>Muraoka</surname><given-names>Y</given-names></name></person-group><article-title>Predicting the protein disordered region using modified position specific scoring matrix</article-title><source>15th International Conference on Genome Informatics: December 16&#x02013;18 2004; Yokohama Pacifico, Japan</source><year>2004</year><fpage>150</fpage></citation></ref><ref id="B29"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Su</surname><given-names>CT</given-names></name><name><surname>Chen</surname><given-names>CY</given-names></name><name><surname>Ou</surname><given-names>YY</given-names></name></person-group><article-title>Protein disorder prediction by condensed PSSM considering propensity for order or disorder</article-title><source>BMC Bioinformatics</source><year>2006</year><volume>7</volume><fpage>319</fpage><pub-id pub-id-type="pmid">16796745</pub-id><pub-id pub-id-type="doi">10.1186/1471-2105-7-319</pub-id></citation></ref><ref id="B30"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kabsch</surname><given-names>W</given-names></name><name><surname>Sander</surname><given-names>C</given-names></name></person-group><article-title>Dictionary of Protein Secondary Structure &#x02013; Pattern-Recognition of Hydrogen-Bonded and Geometrical Features</article-title><source>Biopolymers</source><year>1983</year><volume>22</volume><fpage>2577</fpage><lpage>2637</lpage><pub-id pub-id-type="pmid">6667333</pub-id><pub-id pub-id-type="doi">10.1002/bip.360221211</pub-id></citation></ref><ref id="B31"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Eisenhaber</surname><given-names>F</given-names></name><name><surname>Argos</surname><given-names>P</given-names></name></person-group><article-title>Improved Strategy in Analytic Surface Calculation for Molecular-Systems &#x02013; Handling of Singularities and Computational-Efficiency</article-title><source>Journal of Computational Chemistry</source><year>1993</year><volume>14</volume><fpage>1272</fpage><lpage>1280</lpage><pub-id pub-id-type="doi">10.1002/jcc.540141103</pub-id></citation></ref><ref id="B32"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ooi</surname><given-names>T</given-names></name><name><surname>Oobatake</surname><given-names>M</given-names></name><name><surname>Nemethy</surname><given-names>G</given-names></name><name><surname>Scheraga</surname><given-names>HA</given-names></name></person-group><article-title>Accessible Surface-Areas as a Measure of the Thermodynamic Parameters of Hydration of Peptides</article-title><source>Proc Natl Acad Sci USA</source><year>1987</year><volume>84</volume><fpage>3086</fpage><lpage>3090</lpage><pub-id pub-id-type="pmid">3472198</pub-id><pub-id pub-id-type="doi">10.1073/pnas.84.10.3086</pub-id></citation></ref><ref id="B33"><citation citation-type="other"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>CC</given-names></name><name><surname>Lin</surname><given-names>CJ</given-names></name></person-group><article-title>LIBSVM: a library for support vector machines</article-title><year>2001</year><ext-link ext-link-type="uri" xlink:href="http://www.csie.ntu.edu.tw/~cjlin/libsvm"/></citation></ref><ref id="B34"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>DT</given-names></name></person-group><article-title>Protein secondary structure prediction based on position-specific scoring matrices</article-title><source>J Mol Biol</source><year>1999</year><volume>292</volume><fpage>195</fpage><lpage>202</lpage><pub-id pub-id-type="pmid">10493868</pub-id><pub-id pub-id-type="doi">10.1006/jmbi.1999.3091</pub-id></citation></ref><ref id="B35"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>DT</given-names></name><name><surname>Swindells</surname><given-names>MB</given-names></name></person-group><article-title>Getting the most from PSI-BLAST</article-title><source>Trends Biochem Sci</source><year>2002</year><volume>27</volume><fpage>161</fpage><lpage>164</lpage><pub-id pub-id-type="pmid">11893514</pub-id><pub-id pub-id-type="doi">10.1016/S0968-0004(01)02039-4</pub-id></citation></ref><ref id="B36"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>QD</given-names></name><name><surname>Yoon</surname><given-names>SJ</given-names></name><name><surname>Welsh</surname><given-names>WJ</given-names></name></person-group><article-title>Improved method for predicting beta-turn using support vector machine</article-title><source>Bioinformatics</source><year>2005</year><volume>21</volume><fpage>2370</fpage><lpage>2374</lpage><pub-id pub-id-type="pmid">15797917</pub-id><pub-id pub-id-type="doi">10.1093/bioinformatics/bti358</pub-id></citation></ref><ref id="B37"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Witten</surname><given-names>IH</given-names></name><name><surname>Frank</surname><given-names>E</given-names></name></person-group><source>Data mining: practical machine learning tools and techniques</source><year>2005</year><edition>2</edition><publisher-name>Amsterdam; Boston, MA: Morgan Kaufman</publisher-name></citation></ref></ref-list></back></article>