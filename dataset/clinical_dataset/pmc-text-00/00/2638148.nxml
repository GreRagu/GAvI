<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN" "archivearticle.dtd"><article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id><journal-title>BMC Bioinformatics</journal-title><issn pub-type="epub">1471-2105</issn><publisher><publisher-name>BioMed Central</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">19091031</article-id><article-id pub-id-type="pmc">2638148</article-id><article-id pub-id-type="publisher-id">1471-2105-9-S12-S8</article-id><article-id pub-id-type="doi">10.1186/1471-2105-9-S12-S8</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research</subject></subj-group></article-categories><title-group><article-title>Fast splice site detection using information content and feature reduction</article-title></title-group><contrib-group><contrib id="A1" corresp="yes" contrib-type="author"><name><surname>Baten</surname><given-names>AKMA</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>a.baten@pgrad.unimelb.edu.au</email></contrib><contrib id="A2" contrib-type="author"><name><surname>Halgamuge</surname><given-names>SK</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>saman@unimelb.edu.au</email></contrib><contrib id="A3" contrib-type="author"><name><surname>Chang</surname><given-names>BCH</given-names></name><xref ref-type="aff" rid="I2">2</xref><email>bchang1@gate.sinica.edu.tw</email></contrib></contrib-group><aff id="I1"><label>1</label>Biomechanical Engineering Research Group, Department of Mechanical Engineering, Melbourne School of Engineering, The University of Melbourne, Victoria 3010, Australia</aff><aff id="I2"><label>2</label>Institute of Plant and Microbial Biology, Academia Sinica, Taiwan</aff><pub-date pub-type="collection"><year>2008</year></pub-date><pub-date pub-type="epub"><day>12</day><month>12</month><year>2008</year></pub-date><volume>9</volume><issue>Suppl 12</issue><supplement><named-content content-type="supplement-title">Seventh International Conference on Bioinformatics (InCoB2008)</named-content><named-content content-type="supplement-editor">Shoba Ranganathan, Wen-Lian Hsu, Ueng-Cheng Yang and Tin Wee Tan</named-content></supplement><fpage>S8</fpage><lpage>S8</lpage><ext-link ext-link-type="uri" xlink:href="http://www.biomedcentral.com/1471-2105/9/S12/S8"/><permissions><copyright-statement>Copyright &#x000a9; 2008 Baten et al; licensee BioMed Central Ltd.</copyright-statement><copyright-year>2008</copyright-year><copyright-holder>Baten et al; licensee BioMed Central Ltd.</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.0"><p>This is an open access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/2.0"/>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</p><!--<rdf xmlns="http://web.resource.org/cc/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:dc="http://purl.org/dc/elements/1.1" xmlns:dcterms="http://purl.org/dc/terms"><Work xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:dcterms="http://purl.org/dc/terms/" rdf:about=""><license rdf:resource="http://creativecommons.org/licenses/by/2.0"/><dc:type rdf:resource="http://purl.org/dc/dcmitype/Text"/><dc:author>               Baten               AKMA                              a.baten@pgrad.unimelb.edu.au            </dc:author><dc:title>            Fast splice site detection using information content and feature reduction         </dc:title><dc:date>2008</dc:date><dcterms:bibliographicCitation>BMC Bioinformatics 9(Suppl 12): S8-. (2008)</dcterms:bibliographicCitation><dc:identifier type="sici">1471-2105(2008)9:Suppl 12&#x0003c;S8&#x0003e;</dc:identifier><dcterms:isPartOf>urn:ISSN:1471-2105</dcterms:isPartOf><License rdf:about="http://creativecommons.org/licenses/by/2.0"><permits rdf:resource="http://web.resource.org/cc/Reproduction" xmlns=""/><permits rdf:resource="http://web.resource.org/cc/Distribution" xmlns=""/><requires rdf:resource="http://web.resource.org/cc/Notice" xmlns=""/><requires rdf:resource="http://web.resource.org/cc/Attribution" xmlns=""/><permits rdf:resource="http://web.resource.org/cc/DerivativeWorks" xmlns=""/></License></Work></rdf>--></license></permissions><abstract><sec><title>Background</title><p>Accurate identification of splice sites in DNA sequences plays a key role in the prediction of gene structure in eukaryotes. Already many computational methods have been proposed for the detection of splice sites and some of them showed high prediction accuracy. However, most of these methods are limited in terms of their long computation time when applied to whole genome sequence data.</p></sec><sec><title>Results</title><p>In this paper we propose a hybrid algorithm which combines several effective and informative input features with the state of the art support vector machine (SVM). To obtain the input features we employ information content method based on Shannon's information theory, Shapiro's score scheme, and Markovian probabilities. We also use a feature elimination scheme to reduce the less informative features from the input data.</p></sec><sec><title>Conclusion</title><p>In this study we propose a new feature based splice site detection method that shows improved acceptor and donor splice site detection in DNA sequences when the performance is compared with various state of the art and well known methods.</p></sec></abstract><conference><conf-date>20&#x02013;23 October 2008</conf-date><conf-name>Asia Pacific Bioinformatics Network (APBioNet) Seventh International Conference on Bioinformatics (InCoB2008)</conf-name><conf-loc>Taipei, Taiwan</conf-loc></conference></article-meta></front><body><sec><title>Background</title><p>Over the past decades, the scientific community has experienced a major growth in numbers of sequence data. With the emergence of novel and efficient sequencing technology, DNA sequencing is now much faster. Sequencing of several genomes including the human genome have been completed successfully. This massive amount of sequence data demands sophisticated tools for the analysis of data.</p><p>Identifying genes accurately is one of the most important and challenging tasks in bioinformatics and it requires the prediction of the complete gene structure. Identification of splice sites is the core component of eukaryotic gene finding algorithms. Their success depends on the precise identification of the exon-intron structure and the splice sites. Most of the eukaryotic protein coding genes are characterized by exons and introns. Exons are the protein coding portion of a gene and they are segmented with intervening sequences of introns. The border between an exon and an intron is known as the splice site. The splice site upstream of an intron is called the donor splice site (in the direction 5' to 3') and one that is downstream of an intron is the acceptor splice site (in the direction 3' to 5'). The consensus sequence refers to the nucleotides, which are conserved or most frequently observed in a particular position. The acceptor and donor splice sites with consensus AG (corresponding to the end of an intron) and GT (corresponding to the beginning of an intron) dinucleotides respectively are known as canonical splice sites. Approximately 99% of the splice sites are canonical [<xref ref-type="bibr" rid="B1">1</xref>]. As AG and GT represent possible acceptor and donor splice sites, every AG and GT in a DNA sequence is a candidate acceptor or donor splice site and they need to be classified as either a real (true) splice site or a pseudo (false) splice site.</p><p>Over the years many computational methods have been proposed for the identification of splice sites. Most of those methods are designed to identify the apparent consensus AG and GT in the splicing junction. These methods can be largely classified into probabilistic methods [<xref ref-type="bibr" rid="B2">2</xref>-<xref ref-type="bibr" rid="B8">8</xref>], neural network and support vector machine methods [<xref ref-type="bibr" rid="B9">9</xref>-<xref ref-type="bibr" rid="B19">19</xref>], and methods based on discriminant analysis [<xref ref-type="bibr" rid="B20">20</xref>,<xref ref-type="bibr" rid="B21">21</xref>]. Neural networks and support vector machines (SVM) learn the complex features of neighbourhoods surrounding the consensus AG/GT dinucleotides by a complex non-linear transformation. Probabilistic models estimate position specific probabilities of splice sites by computing likelihoods of candidate signal sequences. The discriminant analysis uses several statistical measures to evaluate the presence of specific nucleotides, recognizing the splice sites without explicitly determining the probability distributions [<xref ref-type="bibr" rid="B18">18</xref>].</p><p>In DNA sequences, true consensus AG/GT dinucleotides are outnumbered by many false AG/GTs. However, nucleotides surrounding true AG/GTs show a certain nucleotide dependency and sequential relationship compared to those surrounding false AG/GTs. There are several methods which are particularly designed to capture this relationship and to identify true splice sites among numerous false ones. Weight matrix methods (WMM) and methods based on Markov models are popular methods of this category. WMM was successfully adopted in methods like NetPlantGene [<xref ref-type="bibr" rid="B22">22</xref>] and NNSplice [<xref ref-type="bibr" rid="B10">10</xref>]. Salzberg <italic>et al. </italic>and Zhang <italic>et al. </italic>[<xref ref-type="bibr" rid="B2">2</xref>,<xref ref-type="bibr" rid="B6">6</xref>], used a linear first order Markov model (MM1) also known as the weight array method (WAM) and they have achieved a good splice site prediction accuracy. MM1 only utilizes first order sequential relationship. It is desirable to use a higher order Markov model to capture the higher order and extended sequential relationship. However, the computational complexity increases polynomialy with the increase of the order of the Markov model, and also higher order Markov models require a large number of training samples. The maximal dependence decomposition (MDD) algorithm was proposed by Burge <italic>et al</italic>. [<xref ref-type="bibr" rid="B23">23</xref>] to overcome these limitations. MDD is a decision tree process and models the dependency between adjacent nucleotides. To take the advantages of both MDD and Markov models, Pertea <italic>et al. </italic>[<xref ref-type="bibr" rid="B4">4</xref>] proposed the GeneSplicer method which combines MDD and second order Markov models (MM2). GeneSplicer showed an improved splice site detection performance. More recently, Rajapakse <italic>et al. </italic>[<xref ref-type="bibr" rid="B17">17</xref>] proposed a complex splice site detection method by combining mostly second order Markov models with backpropagation neural networks (BPNN). This method showed an improved performance over GeneSplicer, however, BPNN is already computationally expensive and this method requires a larger sequence window. In contrast, a machine learning technique such as SVM has the advantage of inferring an optimal classifier from the training data. SVM has been used to classify splice site data with limited success [<xref ref-type="bibr" rid="B9">9</xref>,<xref ref-type="bibr" rid="B12">12</xref>,<xref ref-type="bibr" rid="B14">14</xref>-<xref ref-type="bibr" rid="B16">16</xref>].</p><p>Most of the existing splice site detection methods focused on the improvement of classification performance. However other studies suggest that, considering the increasing growth of sequence data, the focus of new methods should be towards developing faster methods [<xref ref-type="bibr" rid="B24">24</xref>-<xref ref-type="bibr" rid="B27">27</xref>]. In our previous work we showed an improved splice site detection performance by using several preprocessing methods including WMM0/MM0, WMM1, MM1 with SVM [<xref ref-type="bibr" rid="B18">18</xref>]. However, the training time and the number of input features to SVM is a major concern. SVM performs better when it is trained with the most important and meaningful features. So, the reduction of less important features may improve both the classification performance and training time of SVM. In this paper, we propose a feature selection strategy which reduces the less important features from the input data. We also combine the well studied information content method based on Shannon's information theory [<xref ref-type="bibr" rid="B28">28</xref>-<xref ref-type="bibr" rid="B30">30</xref>] and the Shapiro's score method [<xref ref-type="bibr" rid="B31">31</xref>] to extract meaningful information from sequence that can potentially identify splice sites. Our method showed an improved splice site detection performance when compared to the existing methods in terms of classification accuracy and training time.</p></sec><sec><title>Results</title><sec><title>Classification performance comparison</title><p>Our hybrid algorithm combines several effective and informative input features with the state of the art support vector machine (SVM). To obtain the input features we employ information content method based on Shannon's information theory, Shapiro's score scheme, and Markovian probabilities. We also use the F-score feature elimination scheme to reduce the less informative features from the input data. We use the publicly available NN269 [<xref ref-type="bibr" rid="B10">10</xref>] splice site dataset to evaluate the performance of our method. The MM1 parameters are calculated from the dataset and F-score method (refer to the method section) is applied to reduce the number of MM1 parameters, which is referred as Reduced MM1 SVM method. We also calculate the information content and Shapiro's score from the dataset and use the proposed the IC Shapiro SVM method, which is a linear combination of information content and Shapiro's score. We compare the performance of our methods with MM1 SVM method as proposed [<xref ref-type="bibr" rid="B18">18</xref>]. To evaluate the classification performance we use several performance evaluation methods such as the sensitivity, specificity, receiver operating characteristics curve (ROC), and the area under ROC (AUC) as described in the method section.</p><p>Figure <xref ref-type="fig" rid="F1">1</xref> shows the classification performance of different models for NN269 acceptor splice site data. The performance of the proposed Reduced MM1 SVM and IC Shapiro SVM is compared with the original MM1 SVM model [<xref ref-type="bibr" rid="B18">18</xref>]. As shown in Figure <xref ref-type="fig" rid="F1">1</xref>, the Reduced MM1 SVM model with GRBF kernel produces the best classification performance for acceptor splice sites. Reduced MM1 SVM with polynomial kernel produces the second best performance. MM1 SVM with polynomial kernel method [<xref ref-type="bibr" rid="B18">18</xref>], produces the third best performance while the performance of IC Shapiro SVM with polynomial kernel is not as good as others. Even though, Reduced MM1 SVM with GRBF kernel shows the best classification performance, from the ROC curve we can see all the models perform very closely and hence, to get a better measure of the classification performance we calculated the AUC covered by each model from the ROC. Computational speed is another important issue for the algorithms applied in this problem. In this regard, we also calculate the training time required for each classification models. For all our simulations we used an Intel P4 3.2 GHz system with 1 GB RAM. Both the AUC and training time for each of the models are shown in Table <xref ref-type="table" rid="T1">1</xref>. Figure <xref ref-type="fig" rid="F2">2</xref> shows the best two models for acceptor splice site identification in terms of best accuracy (Reduced MM1 SVM with GRBF kernel) and best training time (IC Shapiro SVM with polynomial kernel).</p><table-wrap position="float" id="T1"><label>Table 1</label><caption><p>AUC and training time for different models for NN269 acceptor splice sites.</p></caption><table frame="hsides" rules="groups"><thead><tr><td align="left"><bold>Model</bold></td><td align="left"><bold>SVM kernel</bold></td><td align="left"><bold>AUC</bold></td><td align="left"><bold>Training time until convergence (hh.mm.ss)</bold></td></tr></thead><tbody><tr><td align="left">Reduced MM1 SVM (Best in terms of accuracy)</td><td align="left">GRBF</td><td align="left"><bold>0.9741389</bold></td><td align="left"><bold>00.22.17</bold></td></tr><tr><td colspan="4"><hr></hr></td></tr><tr><td align="left">Reduced MM1 SVM</td><td align="left">Polynomial</td><td align="left">0.9695822</td><td align="left">00.10.48</td></tr><tr><td colspan="4"><hr></hr></td></tr><tr><td align="left">MM1 SVM [<xref ref-type="bibr" rid="B18">18</xref>]</td><td align="left">Polynomial</td><td align="left">0.9674048</td><td align="left">00.11.02</td></tr><tr><td colspan="4"><hr></hr></td></tr><tr><td align="left">IC Shapiro SVM (Best In terms of Time)</td><td align="left">Polynomial</td><td align="left"><bold>0.96287</bold></td><td align="left"><bold>00:01:18</bold></td></tr></tbody></table></table-wrap><fig position="float" id="F1"><label>Figure 1</label><caption><p>ROC curve showing the classification performance of different models for NN269 acceptor splice site data.</p></caption><graphic xlink:href="1471-2105-9-S12-S8-1"/></fig><fig position="float" id="F2"><label>Figure 2</label><caption><p>ROC curve showing the classification performance of best two models in terms of accuracy and training time for NN269 acceptor splice site data.</p></caption><graphic xlink:href="1471-2105-9-S12-S8-2"/></fig><p>As shown in Table <xref ref-type="table" rid="T1">1</xref>, Reduced MM1 SVM with GRBF kernel produces the best performance with an AUC area of 0.9741. Reduced MM1 SVM with polynomial kernel produces the second best performance with an AUC of 0.9695 while MM1 SVM with polynomial kernel [<xref ref-type="bibr" rid="B18">18</xref>] has an AUC of 0.9674. Though IC Shapiro SVM with polynomial kernel has an AUC of 0.9628, which is marginally worse than the best performing model, it produces the fastest training time. Table <xref ref-type="table" rid="T2">2</xref> shows the improvement of performance in terms of AUC and training time as compared to MM1 SVM Polynomial [<xref ref-type="bibr" rid="B18">18</xref>].</p><table-wrap position="float" id="T2"><label>Table 2</label><caption><p>AUC and training time improvement for different models compared to MM1-SVM method for NN269 acceptor splice sites.</p></caption><table frame="hsides" rules="groups"><thead><tr><td align="left"><bold>Model</bold></td><td align="left"><bold>SVM kernel</bold></td><td align="left"><bold>AUC</bold></td><td align="left"><bold>Training time until convergence (mm.ss)</bold></td><td align="left"><bold>Performance Improvement</bold></td><td align="left"><bold>Time Improvement</bold></td></tr></thead><tbody><tr><td align="left">MM1 SVM [<xref ref-type="bibr" rid="B18">18</xref>]</td><td align="left">Polynomial</td><td align="left">0.9674</td><td align="left">11.02</td><td align="left">-</td><td align="left">-</td></tr><tr><td colspan="6"><hr></hr></td></tr><tr><td align="left">Reduced MM1 SVM (Best in terms of accuracy)</td><td align="left">GRBF</td><td align="left">0.9741</td><td align="left">22.17</td><td align="left">0.69%</td><td align="left">-101.96%</td></tr><tr><td colspan="6"><hr></hr></td></tr><tr><td align="left">Reduced MM1 SVM</td><td align="left">Polynomial</td><td align="left">0.9695</td><td align="left">10.48</td><td align="left">0.2171%</td><td align="left">2.11%</td></tr><tr><td colspan="6"><hr></hr></td></tr><tr><td align="left">IC Shapiro SVM (Best In terms of Time)</td><td align="left">Polynomial</td><td align="left">0.9628</td><td align="left">01:18</td><td align="left">-0.4755%</td><td align="left">88.21%</td></tr></tbody></table></table-wrap><p>As shown in Table <xref ref-type="table" rid="T2">2</xref>, the best acceptor splice site detection performance is produced by Reduced MM1 SVM with GRBF kernel which is 0.69% superior then MM1 SVM with polynomial kernel. However, Reduced MM1 SVM GRBF requires much longer training time (more than 100%) than MM1 SVM Polynomial. Reduced MM1 SVM Polynomial improves the performance by 0.21% and it also 2.11% faster than MM1 SVM Polynomial. Finally, IC Shapiro SVM Polynomial is just 0.47% worse then MM1 SVM Polynomial, however, it shows a significant improvement in the training time and is 88.21% faster than MM1 SVM Polynomial.</p><p>Figure <xref ref-type="fig" rid="F3">3</xref> shows the classification performance of different models in terms of NN269 donor splice site dataset. The performance of all the models developed in this paper is compared with MM1 SVM Polynomial model [<xref ref-type="bibr" rid="B18">18</xref>]. As shown in Figure <xref ref-type="fig" rid="F3">3</xref>, the Reduced MM1 SVM model with GRBF kernel produces the best classification performance for donor splice sites. Reduced MM1 SVM with polynomial kernel produces the second best performance. Performance of all the models is very close except IC Shapiro SVM with polynomial kernel. The performance of the models shows the similar trend as that of acceptor splice site classification. We also calculate AUC and the training time required for each of the models which are shown in Table <xref ref-type="table" rid="T3">3</xref>. Figure <xref ref-type="fig" rid="F4">4</xref> shows the two best methods in terms of classification accuracy (Reduced MM1 SVM GRBF) and training time (IC Shapiro SVM Polynomial).</p><table-wrap position="float" id="T3"><label>Table 3</label><caption><p>AUC and training time for different models for NN269 donor splice sites.</p></caption><table frame="hsides" rules="groups"><thead><tr><td align="left"><bold>Model</bold></td><td align="left"><bold>SVM kernel</bold></td><td align="left"><bold>AUC</bold></td><td align="left"><bold>Training time until convergence (hh.mm.ss)</bold></td></tr></thead><tbody><tr><td align="left">Reduced MM1 SVM (Best in terms of accuracy)</td><td align="left">GRBF</td><td align="left"><bold>0.9790232</bold></td><td align="left"><bold>00:20:04</bold></td></tr><tr><td colspan="4"><hr></hr></td></tr><tr><td align="left">Reduced MM1 SVM</td><td align="left">Polynomial</td><td align="left">0.9764903</td><td align="left">00:09:30</td></tr><tr><td colspan="4"><hr></hr></td></tr><tr><td align="left">MM1 SVM</td><td align="left">Polynomial</td><td align="left">0.9761952</td><td align="left">00:10:02</td></tr><tr><td colspan="4"><hr></hr></td></tr><tr><td align="left">IC Shapiro SVM (Best In terms of Time)</td><td align="left">Polynomial</td><td align="left"><bold>0.9665982</bold></td><td align="left"><bold>00:02:59</bold></td></tr></tbody></table></table-wrap><fig position="float" id="F3"><label>Figure 3</label><caption><p>ROC curve showing the classification performance of different models for NN269 donor splice site data.</p></caption><graphic xlink:href="1471-2105-9-S12-S8-3"/></fig><fig position="float" id="F4"><label>Figure 4</label><caption><p>ROC curve showing the classification performance of best two models in terms of accuracy and training time for NN269 donor splice site data.</p></caption><graphic xlink:href="1471-2105-9-S12-S8-4"/></fig><p>As shown in Table <xref ref-type="table" rid="T3">3</xref>, Reduced MM1 SVM with GRBF kernel is the best model for donor splice site classification with an AUC area of 0.9790. Reduced MM1 SVM Polynomial is marginally worse then Reduced MM1 SVM GRBF and produces the second best performance with an AUC of 0.9764 while MM1 SVM with polynomial kernel [<xref ref-type="bibr" rid="B18">18</xref>] has an AUC of 0.9761. Following the same trend, IC Shapiro SVM Polynomial also produces the fastest training time. Table <xref ref-type="table" rid="T4">4</xref> shows the improvement of performance in terms of AUC and training time as compared to MM1 SVM Polynomial [<xref ref-type="bibr" rid="B18">18</xref>].</p><table-wrap position="float" id="T4"><label>Table 4</label><caption><p>AUC and training time improvement for different models compared to MM1-SVM method for NN269 donor splice sites.</p></caption><table frame="hsides" rules="groups"><thead><tr><td align="left"><bold>Model</bold></td><td align="left"><bold>SVM kernel</bold></td><td align="left"><bold>AUC</bold></td><td align="left"><bold>Training time until convergence (mm.ss)</bold></td><td align="left"><bold>Performance Improvement</bold></td><td align="left"><bold>Time Improvement</bold></td></tr></thead><tbody><tr><td align="left">MM1 SVM</td><td align="left">Polynomial</td><td align="left">0.9761</td><td align="left">10:02</td><td align="left">-</td><td align="left">-</td></tr><tr><td colspan="6"><hr></hr></td></tr><tr><td align="left">Reduced MM1 SVM (Best in terms of accuracy)</td><td align="left">GRBF</td><td align="left">0.9790</td><td align="left">20:04</td><td align="left">0.297%</td><td align="left">-100%</td></tr><tr><td colspan="6"><hr></hr></td></tr><tr><td align="left">Reduced MM1 SVM</td><td align="left">Polynomial</td><td align="left">0.9764</td><td align="left">09:30</td><td align="left">0.0102%</td><td align="left">5.31%</td></tr><tr><td colspan="6"><hr></hr></td></tr><tr><td align="left">IC Shapiro SVM (Best In terms of Time)</td><td align="left">Polynomial</td><td align="left">0.9665</td><td align="left">02:59</td><td align="left">-0.9835%</td><td align="left">70.26%</td></tr></tbody></table></table-wrap><p>As shown in Table <xref ref-type="table" rid="T4">4</xref>, Reduced MM1 SVM GRBF marginally produces the best acceptor splice site detection performance which is 0.29% superior then MM1 SVM with polynomial kernel. However, it requires much longer training time (more than 100%) than MM1 SVM Polynomial. Reduced MM1 SVM Polynomial performs almost equally as well as MM1 SVM Polynomial, though it is 5.31% faster. Finally, IC Shapiro SVM Polynomial is almost 1% worse then MM1 SVM Polynomial, however, it shows a significant improvement in the training time and is 70.26% faster than MM1 SVM Polynomial. All the parameters regarding the SVM implementations with GRBF and Polynomial kernels are provided in Additional file <xref ref-type="supplementary-material" rid="S1">1</xref>: Table S1.</p></sec></sec><sec><title>Discussions</title><p>One of the biological machineries involved in the splicing process is known as the Spliceosome, which binds in a splice site after determining the information available in that site. Information content and Shapiro's score are two well known methods to determine the information in splice sites [<xref ref-type="bibr" rid="B29">29</xref>,<xref ref-type="bibr" rid="B30">30</xref>]. Previously we have used other methods such as first order Markov model (MM1), first order weight matrix model (WMM1) and zero order Markov/Weight matrix model (MM0/WMM0) to capture such information [<xref ref-type="bibr" rid="B18">18</xref>]. However, our results in this paper show that information content and Shapiro's score are more capable of capturing more meaningful information than those methods we have used previously, which justifies the use of these methods to extract features. Our method based on information content and Shapiro's score is also proved to be much faster.</p><p>We also use the F-score feature ranking measure to select the most meaningful features and use it to eliminate less important features. We use the F-score measure to reduce MM1 parameters and when compared with MM1 SVM method [<xref ref-type="bibr" rid="B18">18</xref>], we find that Reduced MM1 SVM method based on reduced MM1 parameters performs better in terms of classification accuracy as shown in Figures <xref ref-type="fig" rid="F1">1</xref>, <xref ref-type="fig" rid="F2">2</xref>, <xref ref-type="fig" rid="F3">3</xref>, and <xref ref-type="fig" rid="F4">4</xref>. The performance of IC Shapiro SVM is marginally worse then the best performing methods. However, it shows much faster training time than others as IC Shapiro SVM uses much less number of features. This IC and Shapiro's score scheme and their integration as a set of features is an important step towards faster splice site identification and can be effectively used in the splice site detection for the whole genome where vast amount of sequences data is available. However, it is worthwhile to further investigate this method to improve its classification accuracy.</p></sec><sec><title>Conclusion</title><p>Modern sequencing techniques can produce a massive amount of data in short time and the number of sequence data is almost exponentially increasing. Fast splice site detection is very useful when we consider the very large volumes of available data for the training and testing of a method. To cope with such a large volume of data we also need faster methods. The fast splice site detection method we propose in this paper can also be applied to identify other signals in the sequence such as promoters and translation initiation sites.</p></sec><sec sec-type="methods"><title>Methods</title><sec><title>Proposed models</title><p>We propose several models for the identification of acceptor and donor splice sites. Corresponding to the two types of splice sites, the splice site classification problem is subdivided into two classification problems: acceptor splice site classification and donor splice site classification. Two separate models are constructed for the identification of acceptor splice sites and donor splice sites respectively.</p><p>All the proposed models consist of two phases. In phase one, sequence features are extracted, and in phase two, a support vector machine is trained with the selected features. Sequence features are extracted using first order Markov model (MM1), information content (IC), and Shapiro's score method (SS). The IC score and SS score for each splice site sequence are calculated and linearly combined together as one input to the SVM. The proposed models are listed in Table <xref ref-type="table" rid="T5">5</xref>.</p><table-wrap position="float" id="T5"><label>Table 5</label><caption><p>Proposed models and their description.</p></caption><table frame="hsides" rules="groups"><thead><tr><td align="left"><bold>Model</bold></td><td align="left"><bold>Description</bold></td></tr></thead><tbody><tr><td align="left">Reduced MM1 SVM Polynomial</td><td align="left">Only reduced MM1 parameters and SVM with polynomial kernel</td></tr><tr><td colspan="2"><hr></hr></td></tr><tr><td align="left">Reduced MM1 SVM GRBF</td><td align="left">Only reduced MM1 parameters and SVM with GRBF kernel</td></tr><tr><td colspan="2"><hr></hr></td></tr><tr><td align="left">IC Shapiro SVM Polynomial</td><td align="left">Information content, Shapiro's score and SVM with polynomial kernel</td></tr></tbody></table></table-wrap></sec><sec><title>Markov model</title><p>Markov model can be regarded as a finite state machine with Markov property. Let us consider a sequence of random variables <italic>X</italic><sub>1</sub>, <italic>X</italic><sub>2</sub>,..... <italic>X</italic><sub><italic>n </italic></sub>which takes on values from a finite state space <italic>A </italic>= {<italic>A</italic><sub>1</sub>, <italic>A</italic><sub>2</sub>,... <italic>A</italic><sub><italic>n</italic></sub>}. If the probability of transition from state <italic>A</italic><sub><italic>i </italic></sub>at time <italic>n </italic>to state <italic>A</italic><sub><italic>j </italic></sub>at time <italic>n </italic>+1 depends only on <italic>A</italic><sub><italic>i</italic></sub>, and not any previous history of process, then the process is said to have the Markov property or to be a Markov model or Markov chain.</p><p>DNA sequences can be represented by a Markov chain where each nucleotide represents a state in the Markov chain and whose observed state variables are drawn from the alphabet &#x003a9;<sub><italic>DNA </italic></sub>= {<italic>A</italic>, <italic>C</italic>, <italic>G</italic>, <italic>T</italic>}. If we consider a sequence of length <italic>l</italic>: {<italic>s</italic><sub>1</sub>, <italic>s</italic><sub>2</sub>,...., <italic>s</italic><sub><italic>l</italic></sub>}, where <italic>s</italic><sub><italic>i </italic></sub>&#x02208; {<italic>A</italic>, <italic>C</italic>, <italic>G</italic>, <italic>T</italic>}, &#x02200;<italic>i </italic>&#x02208; {1,...., <italic>l</italic>}, then the nucleotide <italic>S</italic><sub><italic>i </italic></sub>is the outcome of the <italic>i </italic>th state variable of the Markov model, and state transition is only allowed from state <italic>i </italic>to its adjacent state <italic>i </italic>+1. Hence, the model consists of states ordered in a series. It evolves from state <italic>s</italic><sub><italic>i </italic></sub>to <italic>s</italic><sub><italic>i</italic>+1 </sub>and emits symbols from the alphabet &#x003a9;<sub><italic>DNA</italic></sub>, where each state is characterized by a position-specific probabilistic parameter. Assuming a Markov chain of order <italic>k</italic>, the likelihood of a sequence given the model is:</p><p><disp-formula id="bmcM1"><label>(1)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M1" name="1471-2105-9-S12-S8-i1" overflow="scroll">                     <mml:semantics>                        <mml:mrow>                           <mml:mi>P</mml:mi>                           <mml:mrow>                              <mml:mo>(</mml:mo>                              <mml:mrow>                                 <mml:msub>                                    <mml:mi>s</mml:mi>                                    <mml:mn>1</mml:mn>                                 </mml:msub>                                 <mml:mo>,</mml:mo>                                 <mml:msub>                                    <mml:mi>s</mml:mi>                                    <mml:mn>2</mml:mn>                                 </mml:msub>                                 <mml:mo>,</mml:mo>                                 <mml:mn>.........</mml:mn>                                 <mml:mo>,</mml:mo>                                 <mml:msub>                                    <mml:mi>s</mml:mi>                                    <mml:mi>l</mml:mi>                                 </mml:msub>                              </mml:mrow>                              <mml:mo>)</mml:mo>                           </mml:mrow>                           <mml:mo>=</mml:mo>                           <mml:mstyle displaystyle="true">                              <mml:munderover>                                 <mml:mo>&#x0220f;</mml:mo>                                 <mml:mrow>                                    <mml:mi>i</mml:mi>                                    <mml:mo>=</mml:mo>                                    <mml:mn>1</mml:mn>                                 </mml:mrow>                                 <mml:mi>l</mml:mi>                              </mml:munderover>                              <mml:mrow>                                 <mml:msub>                                    <mml:mi>P</mml:mi>                                    <mml:mi>i</mml:mi>                                 </mml:msub>                                 <mml:mrow>                                    <mml:mo>(</mml:mo>                                    <mml:mrow>                                       <mml:msub>                                          <mml:mi>s</mml:mi>                                          <mml:mi>i</mml:mi>                                       </mml:msub>                                       <mml:mo>|</mml:mo>                                       <mml:msub>                                          <mml:mi>s</mml:mi>                                          <mml:mrow>                                             <mml:mi>i</mml:mi>                                             <mml:mo>&#x02212;</mml:mo>                                             <mml:mn>1</mml:mn>                                          </mml:mrow>                                       </mml:msub>                                    </mml:mrow>                                    <mml:mo>)</mml:mo>                                 </mml:mrow>                              </mml:mrow>                           </mml:mstyle>                           <mml:mo>,</mml:mo>                        </mml:mrow>                                             </mml:semantics>                  </mml:math></disp-formula></p><p>Where, the Markovian probability <italic>P</italic><sub><italic>i</italic></sub>(<italic>s</italic><sub><italic>i</italic></sub>) = <italic>P</italic>(<italic>s</italic><sub><italic>i</italic></sub>|<italic>s</italic><sub><italic>i</italic>-1</sub>, <italic>s</italic><sub><italic>i</italic>-2</sub>,...., <italic>s</italic><sub><italic>i</italic>-<italic>k</italic></sub>) denotes the conditional probability of a nucleotide at location <italic>i </italic>given the <italic>k </italic>predecessors. In the current application we use a first order Markov model to model the sequences and hence, <italic>k </italic>= 1.</p></sec><sec><title>Information content</title><p>Information content of splice sites was calculated based on Shannon's information theory [<xref ref-type="bibr" rid="B28">28</xref>]. Entropy Shannon defined the information in an event <italic>i</italic>, to be -log <italic>p</italic><sub><italic>i </italic></sub>where, <italic>p</italic><sub><italic>i </italic></sub>is the probability that the event <italic>i </italic>occurs. The information contained in a splice site can be computed by summing up the information contents (<italic>R</italic><sub><italic>i</italic></sub>, <italic>bits</italic>)of given nucleotides from individual positions, using the weight matrix generated from the frequency of each nucleotide at each position [<xref ref-type="bibr" rid="B29">29</xref>,<xref ref-type="bibr" rid="B30">30</xref>]. The individual information content of each individual splice site was calculated using the following equation [<xref ref-type="bibr" rid="B29">29</xref>,<xref ref-type="bibr" rid="B30">30</xref>]:</p><p><disp-formula id="bmcM2"><label>(2)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M2" name="1471-2105-9-S12-S8-i2" overflow="scroll">                     <mml:semantics>                        <mml:mrow>                           <mml:msub>                              <mml:mi>R</mml:mi>                              <mml:mrow>                                 <mml:mi>s</mml:mi>                                 <mml:mi>e</mml:mi>                                 <mml:mi>q</mml:mi>                                 <mml:mi>u</mml:mi>                                 <mml:mi>e</mml:mi>                                 <mml:mi>n</mml:mi>                                 <mml:mi>c</mml:mi>                                 <mml:mi>e</mml:mi>                              </mml:mrow>                           </mml:msub>                           <mml:mo stretchy="false">(</mml:mo>                           <mml:mi>l</mml:mi>                           <mml:mo stretchy="false">)</mml:mo>                           <mml:mo>=</mml:mo>                           <mml:mn>2</mml:mn>                           <mml:mo>+</mml:mo>                           <mml:mstyle displaystyle="true">                              <mml:munder>                                 <mml:mo>&#x02211;</mml:mo>                                 <mml:mrow>                                    <mml:mi>b</mml:mi>                                    <mml:mo>&#x02208;</mml:mo>                                    <mml:mi>A</mml:mi>                                    <mml:mo>,</mml:mo>                                    <mml:mi>C</mml:mi>                                    <mml:mo>,</mml:mo>                                    <mml:mi>G</mml:mi>                                    <mml:mo>,</mml:mo>                                    <mml:mi>T</mml:mi>                                 </mml:mrow>                              </mml:munder>                              <mml:mrow>                                 <mml:mi>f</mml:mi>                                 <mml:mo stretchy="false">(</mml:mo>                                 <mml:mi>b</mml:mi>                                 <mml:mo>,</mml:mo>                                 <mml:mi>l</mml:mi>                                 <mml:mo stretchy="false">)</mml:mo>                                 <mml:mo>&#x000d7;</mml:mo>                                 <mml:msub>                                    <mml:mrow>                                       <mml:mi>log</mml:mi>                                       <mml:mo>&#x02061;</mml:mo>                                    </mml:mrow>                                    <mml:mn>2</mml:mn>                                 </mml:msub>                                 <mml:mi>f</mml:mi>                                 <mml:mo stretchy="false">(</mml:mo>                                 <mml:mi>b</mml:mi>                                 <mml:mo>,</mml:mo>                                 <mml:mi>l</mml:mi>                                 <mml:mo stretchy="false">)</mml:mo>                              </mml:mrow>                           </mml:mstyle>                        </mml:mrow>                                             </mml:semantics>                  </mml:math></disp-formula></p><p>where, <italic>f</italic>(<italic>b</italic>, <italic>l</italic>) is the probability of base <italic>b </italic>at position <italic>l</italic>.</p><p>We first generated an individual information weight matrix from the frequencies of each nucleotide at each position to calculate the information content (<italic>R</italic><sub><italic>i</italic></sub>, <italic>bits</italic>) of each splice site sequence. The individual information weight matrix can be calculated by the following equation [<xref ref-type="bibr" rid="B29">29</xref>]:</p><p><disp-formula id="bmcM3"><label>(3)</label><italic>R</italic><sub><italic>iw</italic></sub>(<italic>b</italic>, <italic>l</italic>) = 2 + log<sub>2 </sub><italic>f</italic>(<italic>b</italic>, <italic>l</italic>)</disp-formula></p><p>The information content of each splice site was calculated by summing up <italic>R</italic><sub><italic>iw</italic></sub>(<italic>b</italic>, <italic>l</italic>) at each position of the splice site sequences. The relationship between <italic>R</italic><sub><italic>iw</italic></sub>(<italic>b, l</italic>) and <italic>R</italic><sub><italic>sequence </italic></sub>(<italic>l</italic>) is provided in Additional file <xref ref-type="supplementary-material" rid="S2">2</xref>.</p></sec><sec><title>Shapiro's score</title><p>Shapiro <italic>et al. </italic>[<xref ref-type="bibr" rid="B31">31</xref>] proposed a method to score the strength of splice sites based on percentage of each nucleotide at each position. First they create a frequency matrix of nucleotides in each of the positions of the splice site sequence. Shapiro's score for acceptor splice site is given by the equation [<xref ref-type="bibr" rid="B31">31</xref>]:</p><p><disp-formula id="bmcM4"><label>(4)</label><italic>SS</italic><sub><italic>acceptor </italic></sub>= 100*((<italic>t</italic>1-<italic>l</italic>1)/(<italic>h</italic>1-<italic>l</italic>1) + (<italic>t</italic>2-<italic>l</italic>2)/(<italic>h</italic>2-<italic>l</italic>2))/2</disp-formula></p><p>where, <italic>t</italic>1 is the sum of best 8 of 10 nucleotide percentages at position -13 to -4</p><p><italic>l</italic>1 is the sum of lowest 8 of 10 nucleotide percentages at position -13 to -4</p><p><italic>h</italic>1 is the sum of highest 8 of 10 percentages at position -13 to -4</p><p><italic>t</italic>2 is the sum of best nucleotide percentages at position -3 to + 1</p><p><italic>l</italic>2 is the sum of lowest nucleotide percentages at position -3 to + 1</p><p><italic>h</italic>2 is the sum of highest nucleotide percentages at position -3 to +1</p><p>Similarly, Shapiro's score for donor splice site is given by the equation [<xref ref-type="bibr" rid="B31">31</xref>]:</p><p><disp-formula id="bmcM5"><label>(5)</label><italic>SS</italic><sub><italic>donor </italic></sub>= 100*(<italic>t </italic>- min)/(max - min)</disp-formula></p><p>where, <italic>t </italic>is the sum of percentages at position -3 to + 7</p><p>min is the sum of lowest percentages at position -3 to + 7</p><p>max is the sum of highest percentages at position -3 to + 7</p></sec><sec><title>Sequence feature elimination based on F-score</title><p>Sequence feature elimination is an important step towards the classification task. Classifiers like neural networks, SVM's etc. perform better when they are trained with meaningful input data. Redundant data often causes misclassification and hence, the reduction of classification performance. So it is desirable to eliminate the less important features from the input data and to select those features that can potentially discriminate between true and false class. According to Dror <italic>et al. </italic>[<xref ref-type="bibr" rid="B32">32</xref>], there are three potential benefits of feature selection: improving the performance of the classifier, producing a cost-effective classifier, and providing a better understanding of the problem.</p><p>In this work, we select most informative acceptor and donor splice site features, and we used the F-score feature selection criteria also employed by Golub <italic>et al. </italic>[<xref ref-type="bibr" rid="B33">33</xref>] and Dror <italic>et al </italic>[<xref ref-type="bibr" rid="B32">32</xref>]. For each feature <italic>x</italic><sub><italic>j</italic></sub>, <italic>j </italic>= 1, 2,...., <italic>N</italic>, we calculate the mean <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M3" name="1471-2105-9-S12-S8-i3" overflow="scroll"><mml:semantics><mml:mrow><mml:msubsup><mml:mi>&#x003bc;</mml:mi><mml:mi>j</mml:mi><mml:mo>+</mml:mo></mml:msubsup></mml:mrow></mml:semantics></mml:math></inline-formula> (for positive/true class) and <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M4" name="1471-2105-9-S12-S8-i4" overflow="scroll"><mml:semantics><mml:mrow><mml:msubsup><mml:mi>&#x003bc;</mml:mi><mml:mi>j</mml:mi><mml:mo>&#x02212;</mml:mo></mml:msubsup></mml:mrow></mml:semantics></mml:math></inline-formula> (for negative/false class), standard deviation <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M5" name="1471-2105-9-S12-S8-i5" overflow="scroll"><mml:semantics><mml:mrow><mml:msubsup><mml:mi>&#x003c3;</mml:mi><mml:mi>j</mml:mi><mml:mo>+</mml:mo></mml:msubsup></mml:mrow></mml:semantics></mml:math></inline-formula> (for positive/true class) and <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M6" name="1471-2105-9-S12-S8-i6" overflow="scroll"><mml:semantics><mml:mrow><mml:msubsup><mml:mi>&#x003c3;</mml:mi><mml:mi>j</mml:mi><mml:mo>&#x02212;</mml:mo></mml:msubsup></mml:mrow></mml:semantics></mml:math></inline-formula> (for negative/false class). The F-score <italic>F</italic>(<italic>x</italic><sub><italic>j</italic></sub>) is calculated by:</p><p><disp-formula id="bmcM6"><label>(6)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M7" name="1471-2105-9-S12-S8-i7" overflow="scroll">                     <mml:semantics>                        <mml:mrow>                           <mml:mi>F</mml:mi>                           <mml:mrow>                              <mml:mo>(</mml:mo>                              <mml:mrow>                                 <mml:msub>                                    <mml:mi>x</mml:mi>                                    <mml:mi>j</mml:mi>                                 </mml:msub>                              </mml:mrow>                              <mml:mo>)</mml:mo>                           </mml:mrow>                           <mml:mo>=</mml:mo>                           <mml:mrow>                              <mml:mo>|</mml:mo>                              <mml:mrow>                                 <mml:mfrac>                                    <mml:mrow>                                       <mml:msubsup>                                          <mml:mi>&#x003bc;</mml:mi>                                          <mml:mi>j</mml:mi>                                          <mml:mo>+</mml:mo>                                       </mml:msubsup>                                       <mml:mo>&#x02212;</mml:mo>                                       <mml:msubsup>                                          <mml:mi>&#x003bc;</mml:mi>                                          <mml:mi>j</mml:mi>                                          <mml:mo>&#x02212;</mml:mo>                                       </mml:msubsup>                                    </mml:mrow>                                    <mml:mrow>                                       <mml:msubsup>                                          <mml:mi>&#x003c3;</mml:mi>                                          <mml:mi>j</mml:mi>                                          <mml:mo>+</mml:mo>                                       </mml:msubsup>                                       <mml:mo>&#x02212;</mml:mo>                                       <mml:msubsup>                                          <mml:mi>&#x003c3;</mml:mi>                                          <mml:mi>j</mml:mi>                                          <mml:mo>&#x02212;</mml:mo>                                       </mml:msubsup>                                    </mml:mrow>                                 </mml:mfrac>                              </mml:mrow>                              <mml:mo>|</mml:mo>                           </mml:mrow>                        </mml:mrow>                                             </mml:semantics>                  </mml:math></disp-formula></p></sec><sec><title>Support vector machine</title><p>The SVM is a statistical machine learning algorithm initially proposed by Vapnik [<xref ref-type="bibr" rid="B34">34</xref>-<xref ref-type="bibr" rid="B37">37</xref>] and applied to a wide range of pattern recognition problems [<xref ref-type="bibr" rid="B9">9</xref>,<xref ref-type="bibr" rid="B12">12</xref>,<xref ref-type="bibr" rid="B15">15</xref>,<xref ref-type="bibr" rid="B35">35</xref>,<xref ref-type="bibr" rid="B37">37</xref>,<xref ref-type="bibr" rid="B38">38</xref>]. It uses a hypothetical space of linear functions in a high dimensional feature space trained with a learning algorithm based on optimization theory. A SVM selects a small number of critical boundary samples (known as support vectors) from each class and builds a linear discriminant that separates them as widely as possible. In the case that no linear separation is possible, the 'kernel' technique is applied to map the training samples into a higher-dimensional space, and to learn a separator in that space [<xref ref-type="bibr" rid="B39">39</xref>]. SVM classification is an optimization problem given by:</p><p><disp-formula id="bmcM7"><label>(7)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M8" name="1471-2105-9-S12-S8-i8" overflow="scroll">                     <mml:semantics>                        <mml:mrow>                           <mml:mtext>Maximize&#x000a0;</mml:mtext>                           <mml:mi>L</mml:mi>                           <mml:mo>=</mml:mo>                           <mml:mstyle displaystyle="true">                              <mml:msubsup>                                 <mml:mo>&#x02211;</mml:mo>                                 <mml:mrow>                                    <mml:mi>i</mml:mi>                                    <mml:mo>=</mml:mo>                                    <mml:mn>1</mml:mn>                                 </mml:mrow>                                 <mml:mi>l</mml:mi>                              </mml:msubsup>                              <mml:mrow>                                 <mml:msub>                                    <mml:mi>&#x003b1;</mml:mi>                                    <mml:mi>i</mml:mi>                                 </mml:msub>                                 <mml:mo>&#x02212;</mml:mo>                                 <mml:mfrac>                                    <mml:mn>1</mml:mn>                                    <mml:mn>2</mml:mn>                                 </mml:mfrac>                                 <mml:mstyle displaystyle="true">                                    <mml:msubsup>                                       <mml:mo>&#x02211;</mml:mo>                                       <mml:mrow>                                          <mml:mi>i</mml:mi>                                          <mml:mo>,</mml:mo>                                          <mml:mi>j</mml:mi>                                          <mml:mo>=</mml:mo>                                          <mml:mn>1</mml:mn>                                       </mml:mrow>                                       <mml:mi>l</mml:mi>                                    </mml:msubsup>                                    <mml:mrow>                                       <mml:msub>                                          <mml:mi>&#x003b1;</mml:mi>                                          <mml:mi>i</mml:mi>                                       </mml:msub>                                       <mml:msub>                                          <mml:mi>&#x003b1;</mml:mi>                                          <mml:mi>j</mml:mi>                                       </mml:msub>                                       <mml:msub>                                          <mml:mi>y</mml:mi>                                          <mml:mi>i</mml:mi>                                       </mml:msub>                                       <mml:msub>                                          <mml:mi>y</mml:mi>                                          <mml:mi>j</mml:mi>                                       </mml:msub>                                       <mml:mtext>K</mml:mtext>                                       <mml:mrow>                                          <mml:mo>(</mml:mo>                                          <mml:mrow>                                             <mml:msub>                                                <mml:mtext>x</mml:mtext>                                                <mml:mtext>i</mml:mtext>                                             </mml:msub>                                             <mml:mo>,</mml:mo>                                             <mml:msub>                                                <mml:mtext>x</mml:mtext>                                                <mml:mtext>j</mml:mtext>                                             </mml:msub>                                          </mml:mrow>                                          <mml:mo>)</mml:mo>                                       </mml:mrow>                                    </mml:mrow>                                 </mml:mstyle>                              </mml:mrow>                           </mml:mstyle>                           <mml:mo>,</mml:mo>                        </mml:mrow>                                             </mml:semantics>                  </mml:math></disp-formula></p><p><disp-formula id="bmcM8"><label>(8)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M9" name="1471-2105-9-S12-S8-i9" overflow="scroll">                     <mml:semantics>                        <mml:mrow>                           <mml:mtable>                              <mml:mtr>                                 <mml:mtd>                                    <mml:mrow>                                       <mml:mtext>s</mml:mtext>                                       <mml:mo>.</mml:mo>                                       <mml:mtext>&#x000a0;t</mml:mtext>                                       <mml:mo>.</mml:mo>                                    </mml:mrow>                                 </mml:mtd>                                 <mml:mtd>                                    <mml:mrow>                                       <mml:mstyle displaystyle="true">                                          <mml:msubsup>                                             <mml:mo>&#x02211;</mml:mo>                                             <mml:mrow>                                                <mml:mi>i</mml:mi>                                                <mml:mo>=</mml:mo>                                                <mml:mn>1</mml:mn>                                             </mml:mrow>                                             <mml:mi>l</mml:mi>                                          </mml:msubsup>                                          <mml:mrow>                                             <mml:msub>                                                <mml:mi>&#x003b1;</mml:mi>                                                <mml:mi>i</mml:mi>                                             </mml:msub>                                             <mml:msub>                                                <mml:mi>y</mml:mi>                                                <mml:mi>i</mml:mi>                                             </mml:msub>                                             <mml:mo>=</mml:mo>                                             <mml:mn>0</mml:mn>                                          </mml:mrow>                                       </mml:mstyle>                                    </mml:mrow>                                 </mml:mtd>                              </mml:mtr>                           </mml:mtable>                        </mml:mrow>                                             </mml:semantics>                  </mml:math></disp-formula></p><p><disp-formula id="bmcM9"><label>(9)</label>0 &#x02264; <italic>&#x003b1;</italic><sub><italic>i </italic></sub>&#x02264; <italic>C</italic>, <italic>i </italic>= <italic>1</italic>,..., <italic>l</italic>,</disp-formula></p><p>where, <italic>l </italic>is the number of training examples, <italic>K </italic>is the kernel function, <bold><italic>x </italic></bold>is the input vectors, <italic>y </italic>is either -1 or +1 representing two different classes, <italic>&#x003b1; </italic>is the variable to be optimized and <italic>C </italic>is a trade-off parameter for generalization performance [<xref ref-type="bibr" rid="B35">35</xref>,<xref ref-type="bibr" rid="B36">36</xref>]. Each <italic>&#x003b1; </italic>corresponds to one particular training example and after the training process, only a subgroup of <italic>&#x003b1; </italic>will have non-zero values. This subgroup of <italic>&#x003b1; </italic>and their corresponding training examples are called the support vectors. In this study, two separate SVM classifiers are required, one for acceptor and one for donor. The class labels <italic>y </italic>in the two classifiers would then indicate true (<italic>y </italic>= +1) or false sites (<italic>y </italic>= -1) for acceptor and donor accordingly. Given a query DNA segment <italic>z</italic>, the trained SVM classifies based on the decision function:</p><p><disp-formula id="bmcM10"><label>(10)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M10" name="1471-2105-9-S12-S8-i10" overflow="scroll">                     <mml:semantics>                        <mml:mrow>                           <mml:mi>o</mml:mi>                           <mml:mrow>                              <mml:mo>(</mml:mo>                              <mml:mi>z</mml:mi>                              <mml:mo>)</mml:mo>                           </mml:mrow>                           <mml:mo>=</mml:mo>                           <mml:mtext>sign</mml:mtext>                           <mml:mrow>                              <mml:mo>[</mml:mo>                              <mml:mrow>                                 <mml:mstyle displaystyle="true">                                    <mml:munder>                                       <mml:mo>&#x02211;</mml:mo>                                       <mml:mrow>                                          <mml:mi>i</mml:mi>                                          <mml:mo>&#x02208;</mml:mo>                                          <mml:mi>&#x003bd;</mml:mi>                                       </mml:mrow>                                    </mml:munder>                                    <mml:mrow>                                       <mml:msub>                                          <mml:mi>&#x003b1;</mml:mi>                                          <mml:mi>i</mml:mi>                                       </mml:msub>                                       <mml:msub>                                          <mml:mi>y</mml:mi>                                          <mml:mi>i</mml:mi>                                       </mml:msub>                                       <mml:mi>K</mml:mi>                                       <mml:mrow>                                          <mml:mo>(</mml:mo>                                          <mml:mrow>                                             <mml:msub>                                                <mml:mi>x</mml:mi>                                                <mml:mi>i</mml:mi>                                             </mml:msub>                                             <mml:mo>,</mml:mo>                                             <mml:mi>z</mml:mi>                                          </mml:mrow>                                          <mml:mo>)</mml:mo>                                       </mml:mrow>                                    </mml:mrow>                                 </mml:mstyle>                              </mml:mrow>                              <mml:mo>]</mml:mo>                           </mml:mrow>                           <mml:mo>,</mml:mo>                        </mml:mrow>                                             </mml:semantics>                  </mml:math></disp-formula></p><p>where <italic>v </italic>is the set of support vectors.</p></sec><sec><title>Dataset</title><p>To evaluate the performance of the proposed models, we used publicly available NN269 [<xref ref-type="bibr" rid="B10">10</xref>] splice site dataset. The dataset is divided into two groups namely: the acceptor splice sites and the donor splice sites. It contains 1324 confirmed true acceptor splice sites, 5552 false acceptor sites, 1324 confirmed true donor sites, and 4922 false donor sites collected from 269 human genes. The pseudo or false acceptor/donor splice sites are those having AG/GT in the splicing junction but not a real acceptor or donor splice site according to the annotation. Acceptor splice sites have a window of 90 nucleotides (-70 to +20) with the consensus nucleotides AG at positions -69 and -70. This window includes the last 70 nucleotides of an intron and the first 20 nucleotides of the succeeding exon. On the other hand, donor splice sites have a window of 15 nucleotides (-7 to +8) with the consensus nucleotides GT at positions +1 and +2. This window includes the last 9 nucleotides of an exon and the first 6 nucleotides of the succeeding intron. The acceptor and donor splice site datasets are divided into a unique training and test dataset. The test datasets do not contain any sequence which is in training dataset. The training dataset contains 1116 true acceptor, 1116 true donor, 4672 false acceptor, and 4140 false donor sites. The test data set contains 208 true acceptor sites, 208 true donor sites, 881 false acceptor sites, and 782 false donor sites.</p></sec><sec><title>Model learning</title><p>The learning of the model is designed in two phases. Phase one consists of estimation of Markov parameters, scoring information content of sequences, and calculation of Shapiro's score. In phase two SVM is trained with polynomial and Gaussian kernels.</p><p>All the training sequences were aligned with respect to the consensus sequence for the estimation of the Markov parameters. We only use the true training sequences to create the Markov model. The estimates of the MM1 are the ratios of the frequencies of each dinucleotide in each sequence position as shown in the following equation [<xref ref-type="bibr" rid="B18">18</xref>].</p><p><disp-formula id="bmcM11"><label>(11)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M11" name="1471-2105-9-S12-S8-i11" overflow="scroll">                     <mml:semantics>                        <mml:mrow>                           <mml:msub>                              <mml:mover accent="true">                                 <mml:mi>P</mml:mi>                                 <mml:mo>^</mml:mo>                              </mml:mover>                              <mml:mi>i</mml:mi>                           </mml:msub>                           <mml:mrow>                              <mml:mo>(</mml:mo>                              <mml:mrow>                                 <mml:msub>                                    <mml:mi>s</mml:mi>                                    <mml:mi>i</mml:mi>                                 </mml:msub>                              </mml:mrow>                              <mml:mo>)</mml:mo>                           </mml:mrow>                           <mml:mo>=</mml:mo>                           <mml:mfrac>                              <mml:mrow>                                 <mml:mo>#</mml:mo>                                 <mml:mrow>                                    <mml:mo>(</mml:mo>                                    <mml:mrow>                                       <mml:msubsup>                                          <mml:mi>s</mml:mi>                                          <mml:mrow>                                             <mml:mi>i</mml:mi>                                             <mml:mo>&#x02212;</mml:mo>                                             <mml:mi>k</mml:mi>                                          </mml:mrow>                                          <mml:mi>i</mml:mi>                                       </mml:msubsup>                                    </mml:mrow>                                    <mml:mo>)</mml:mo>                                 </mml:mrow>                              </mml:mrow>                              <mml:mrow>                                 <mml:mo>#</mml:mo>                                 <mml:mrow>                                    <mml:mo>(</mml:mo>                                    <mml:mrow>                                       <mml:msubsup>                                          <mml:mi>s</mml:mi>                                          <mml:mrow>                                             <mml:mi>i</mml:mi>                                             <mml:mo>&#x02212;</mml:mo>                                             <mml:mi>k</mml:mi>                                          </mml:mrow>                                          <mml:mrow>                                             <mml:mi>i</mml:mi>                                             <mml:mo>&#x02212;</mml:mo>                                             <mml:mn>1</mml:mn>                                          </mml:mrow>                                       </mml:msubsup>                                    </mml:mrow>                                    <mml:mo>)</mml:mo>                                 </mml:mrow>                              </mml:mrow>                           </mml:mfrac>                           <mml:mo>,</mml:mo>                        </mml:mrow>                                             </mml:semantics>                  </mml:math></disp-formula></p><p>For a sequence of length n there are n-1 position specific probabilistic parameters [<xref ref-type="bibr" rid="B18">18</xref>]. As the length of the acceptor splice site is 90 nucleotides there are 89 MM1 parameters and for 15 nucleotide long donor splice site there are 14 MM1 parameters. We reduce the size of the MM1 parameters based on the F-score. We empirically selected the F-score value 0.20. There are many inputs with an f-score value less than 0.20 as shown in Figure <xref ref-type="fig" rid="F5">5</xref> and <xref ref-type="fig" rid="F6">6</xref>. However, their inclusion did not significantly improve the performance and increased the computational complexity and training time. As the f-score shows the position-specific discrimination between true and false splice sites, a higher F-score value indicates a better discrimination between true and false splice sites and conveys more information to the SVM. Based on the F-score values, position specific MM1 parameters are reduced from 89 to 19 for acceptor splice sites and from 14 to 9 MM1 parameters for donor splice sites. Based on the above discussion we propose several models which are listed in Table <xref ref-type="table" rid="T5">5</xref>.</p><fig position="float" id="F5"><label>Figure 5</label><caption><p>F-Score analysis of NN269 acceptor splice site.</p></caption><graphic xlink:href="1471-2105-9-S12-S8-5"/></fig><fig position="float" id="F6"><label>Figure 6</label><caption><p>F-Score analysis of NN269 donor splice site.</p></caption><graphic xlink:href="1471-2105-9-S12-S8-6"/></fig><p>A position specific nucleotide background matrix is required for the calculation of information content and Shapiro's scores. A generalized frequency matrix of the splice site regions of the whole genome is preferable as it gives the most reasonable statistics of the occurrence of nucleotides in the splice site. However, we only use the NN269 true training data to construct the frequency matrix. As we compared the performance of MM1 SVM [<xref ref-type="bibr" rid="B18">18</xref>] with that of IC Shapiro SVM, it is required that the same training data be used to create MM1 parameters, information content and Shapiro's scores. To calculate the information content score the individual information content weight matrix <italic>R</italic><sub><italic>iw </italic></sub>(<italic>b</italic>, <italic>l</italic>) is created from the nucleotide background matrix following equation (2) (refer to the method section). Then the information content is calculated by summing up <italic>R</italic><sub><italic>iw </italic></sub>(<italic>b</italic>, <italic>l</italic>) of the specified positions. Similarly the nucleotide background matrix is used to calculate the Shapiro's score for acceptor and donor splice sites following equations (3) and (4) respectively.</p><p>We used the leave one out cross validation technique is applied to determine the splice site prediction accuracy and to compare the predictive accuracy with other methods. The cross validation is performed by randomly partitioning the data into five independent subsets. Each of the subsets does not share any repeating sequences. Each model was trained by selecting four of the subsets (training data) and was tested on the remaining one. Finally, we took the average of the five prediction accuracies as the final prediction measure of the model.</p></sec><sec><title>Performance measures</title><p>The classification performance of the models is measured in terms of their sensitivity (<italic>S</italic><sub><italic>N</italic></sub>), and specificity (<italic>S</italic><sub><italic>P</italic></sub>). Sensitivity, also known as true positive rate (TPR), is defined as the percentage of correct prediction of true sites while specificity is the correct prediction of false sites as defined below:</p><p><disp-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M12" name="1471-2105-9-S12-S8-i12" overflow="scroll">                     <mml:semantics>                        <mml:mrow>                           <mml:mtable>                              <mml:mtr>                                 <mml:mtd>                                    <mml:mrow>                                       <mml:mi>S</mml:mi>                                       <mml:mi>e</mml:mi>                                       <mml:mi>n</mml:mi>                                       <mml:mi>s</mml:mi>                                       <mml:mi>i</mml:mi>                                       <mml:mi>t</mml:mi>                                       <mml:mi>i</mml:mi>                                       <mml:mi>v</mml:mi>                                       <mml:mi>i</mml:mi>                                       <mml:mi>t</mml:mi>                                       <mml:mi>y</mml:mi>                                       <mml:mrow>                                          <mml:mo>(</mml:mo>                                          <mml:mrow>                                             <mml:msub>                                                <mml:mi>S</mml:mi>                                                <mml:mi>N</mml:mi>                                             </mml:msub>                                          </mml:mrow>                                          <mml:mo>)</mml:mo>                                       </mml:mrow>                                       <mml:mo>=</mml:mo>                                       <mml:mfrac>                                          <mml:mrow>                                             <mml:mi>T</mml:mi>                                             <mml:mi>P</mml:mi>                                          </mml:mrow>                                          <mml:mrow>                                             <mml:mi>T</mml:mi>                                             <mml:mi>P</mml:mi>                                             <mml:mo>+</mml:mo>                                             <mml:mi>F</mml:mi>                                             <mml:mi>N</mml:mi>                                          </mml:mrow>                                       </mml:mfrac>                                    </mml:mrow>                                 </mml:mtd>                                 <mml:mtd>                                    <mml:mrow>                                       <mml:mi>S</mml:mi>                                       <mml:mi>p</mml:mi>                                       <mml:mi>e</mml:mi>                                       <mml:mi>c</mml:mi>                                       <mml:mi>i</mml:mi>                                       <mml:mi>f</mml:mi>                                       <mml:mi>i</mml:mi>                                       <mml:mi>c</mml:mi>                                       <mml:mi>i</mml:mi>                                       <mml:mi>t</mml:mi>                                       <mml:mi>y</mml:mi>                                       <mml:mrow>                                          <mml:mo>(</mml:mo>                                          <mml:mrow>                                             <mml:msub>                                                <mml:mi>S</mml:mi>                                                <mml:mi>P</mml:mi>                                             </mml:msub>                                          </mml:mrow>                                          <mml:mo>)</mml:mo>                                       </mml:mrow>                                       <mml:mo>=</mml:mo>                                       <mml:mfrac>                                          <mml:mrow>                                             <mml:mi>T</mml:mi>                                             <mml:mi>N</mml:mi>                                          </mml:mrow>                                          <mml:mrow>                                             <mml:mi>T</mml:mi>                                             <mml:mi>N</mml:mi>                                             <mml:mo>+</mml:mo>                                             <mml:mi>F</mml:mi>                                             <mml:mi>P</mml:mi>                                          </mml:mrow>                                       </mml:mfrac>                                    </mml:mrow>                                 </mml:mtd>                              </mml:mtr>                           </mml:mtable>                        </mml:mrow>                                             </mml:semantics>                  </mml:math></disp-formula></p><p>Where, TP, TN, FP, and FN stand for true positive rate, true negative rate, false positive rate, and false negative rate. They are defined in Table <xref ref-type="table" rid="T6">6</xref>[<xref ref-type="bibr" rid="B40">40</xref>].</p><table-wrap position="float" id="T6"><label>Table 6</label><caption><p>Definition of TP, TN, FP and FN</p></caption><table frame="hsides" rules="groups"><thead><tr><td></td><td align="left">Predicted positive</td><td align="left">Predicted negative</td></tr></thead><tbody><tr><td align="left">Real positive</td><td align="left">true positives, TP</td><td align="left">false negatives, FN</td></tr><tr><td colspan="3"><hr></hr></td></tr><tr><td align="left">Real negative</td><td align="left">true negatives, TN</td><td align="left">false positives, FP</td></tr></tbody></table></table-wrap><p>Also receiver operator curve (ROC) is drawn using the sensitivity and specificity values. ROC analysis is an effective and widely used method for assessing the classification performance [<xref ref-type="bibr" rid="B40">40</xref>]. When a ROC is created from the sensitivity (the y axis) and specificity (the x axis) of a model, the closer a curve follows the left-hand border and then the top of the border of the ROC plot, the more accurate the model is (refer to Figure <xref ref-type="fig" rid="F3">3</xref>, <xref ref-type="fig" rid="F4">4</xref>, <xref ref-type="fig" rid="F5">5</xref> and <xref ref-type="fig" rid="F6">6</xref>). We also calculate the area under ROC curve (AUC), as classification performance of some of the models are very close and may not clearly distinguish performance of two models when we view them in the ROC curve. However, AUC accurately measure the total ROC area covered by a model.</p></sec></sec><sec><title>Competing interests</title><p>The authors declare that they have no competing interests.</p></sec><sec><title>Authors' contributions</title><p>AKMAB provided the conception and design of this study, the implementation of the method and its analysis. BC and SKH contributed to the design of the study and the interpretation of the results. All authors contributed to the writing and critically revising the manuscript.</p></sec><sec sec-type="supplementary-material"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="S1"><caption><title>Additional file 1</title><p>AUC and SVM parameters for different models for NN269 acceptor and donor splice sites.</p></caption><media xlink:href="1471-2105-9-S12-S8-S1.pdf" mimetype="application" mime-subtype="pdf"><caption><p>Click here for file</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="S2"><caption><title>Additional file 2</title><p>Relationship between <italic>R</italic><sub><italic>iw </italic></sub>(<italic>b</italic>, <italic>l</italic>) and <italic>R</italic><sub><italic>sequence </italic></sub>(<italic>l</italic>).</p></caption><media xlink:href="1471-2105-9-S12-S8-S2.pdf" mimetype="application" mime-subtype="pdf"><caption><p>Click here for file</p></caption></media></supplementary-material></sec></body><back><ack><sec><title>Acknowledgements</title><p>We gratefully acknowledge the helpful discussions and comments provided by Dr. Arthur Hsu.</p><p>This article has been published as part of <italic>BMC Bioinformatics </italic>Volume 9 Supplement 12, 2008: Asia Pacific Bioinformatics Network (APBioNet) Seventh International Conference on Bioinformatics (InCoB2008). The full contents of the supplement are available online at <ext-link ext-link-type="uri" xlink:href="http://www.biomedcentral.com/1471-2105/9?issue=S12"/>.</p></sec></ack><ref-list><ref id="B1"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Burset</surname><given-names>M</given-names></name><name><surname>Seledtsov</surname><given-names>A</given-names></name><name><surname>Solovyeva</surname><given-names>VV</given-names></name></person-group><article-title>Analysis of canonical and non-canonical splice sites in mammalian genomes</article-title><source>Nucleic Acids Research</source><year>2000</year><volume>28</volume><fpage>4364</fpage><lpage>4375</lpage><pub-id pub-id-type="pmid">11058137</pub-id></citation></ref><ref id="B2"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Salzberg</surname><given-names>S</given-names></name></person-group><article-title>A method for identifying splice sites and translation start site in eucaryotic mRNA</article-title><source>Computer Applications in the Biosciences</source><year>1997</year><volume>13</volume><fpage>384</fpage><lpage>390</lpage></citation></ref><ref id="B3"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>T-M</given-names></name><name><surname>Chung-Chin</surname><given-names>Lu</given-names></name><name><surname>Wen-Hsiung</surname><given-names>Li</given-names></name></person-group><article-title>Prediction of splice sites with dependency graphs and their expanded bayesian networks</article-title><source>Bioinformatics</source><year>2005</year><volume>21</volume><fpage>471</fpage><lpage>482</lpage><pub-id pub-id-type="pmid">15374869</pub-id></citation></ref><ref id="B4"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Pertea</surname><given-names>M</given-names></name><name><surname>Xiao Ying</surname><given-names>L</given-names></name><name><surname>Salzberg</surname><given-names>SL</given-names></name></person-group><article-title>GeneSplicer: a new computational method for splice site detection</article-title><source>Nucleic Acids Research</source><year>2001</year><volume>29</volume><fpage>1185</fpage><lpage>1190</lpage><pub-id pub-id-type="pmid">11222768</pub-id></citation></ref><ref id="B5"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Marashi</surname><given-names>SA</given-names></name><name><surname>Changiz</surname><given-names>Eslahchi</given-names></name><name><surname>Pezeshk</surname><given-names>H</given-names></name><name><surname>Sadeghi</surname><given-names>M</given-names></name></person-group><article-title>Impact of RNA structure on the prediction of donor and acceptor splice sites</article-title><source>BMC Bioinformatics</source><year>2006</year><volume>7</volume><fpage>297</fpage><pub-id pub-id-type="pmid">16772025</pub-id></citation></ref><ref id="B6"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>M</given-names></name><name><surname>Marr</surname><given-names>T</given-names></name></person-group><article-title>A weight array method for splicing signal analysis</article-title><source>Comput Appl Biosci</source><year>1993</year><volume>9</volume><fpage>499</fpage><lpage>509</lpage><pub-id pub-id-type="pmid">8293321</pub-id></citation></ref><ref id="B7"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Castelo</surname><given-names>R</given-names></name><name><surname>Guigo</surname><given-names>R</given-names></name></person-group><article-title>Splice site identification by idlBNs</article-title><source>Bioinformatics</source><year>2004</year><volume>20</volume><fpage>69</fpage><lpage>76</lpage></citation></ref><ref id="B8"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Cai</surname><given-names>D</given-names></name><name><surname>Delcher</surname><given-names>A</given-names></name><name><surname>Kao</surname><given-names>B</given-names></name><name><surname>Kasif</surname><given-names>S</given-names></name></person-group><article-title>Modeling splice sites with Bayes networks</article-title><source>Bioinformatics</source><year>2000</year><volume>16</volume><fpage>152</fpage><lpage>158</lpage><pub-id pub-id-type="pmid">10842737</pub-id></citation></ref><ref id="B9"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ratsch</surname><given-names>G</given-names></name><name><surname>Sonnenburg</surname><given-names>S</given-names></name><name><surname>Schafer</surname><given-names>C</given-names></name></person-group><article-title>Learning Interpretable SVMs for Biological Sequence Classification</article-title><source>BMC Bioinformatics</source><year>2006</year><volume>7</volume><fpage>S9</fpage><pub-id pub-id-type="pmid">16723012</pub-id></citation></ref><ref id="B10"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Reese</surname><given-names>MG</given-names></name><name><surname>Eeckman</surname><given-names>F</given-names></name><name><surname>Kupl</surname><given-names>D</given-names></name><name><surname>Haussler</surname><given-names>D</given-names></name></person-group><article-title>Improved splice site detection in Genie</article-title><source>Journal of Computational Biology</source><year>1997</year><volume>4</volume><fpage>311</fpage><lpage>324</lpage><pub-id pub-id-type="pmid">9278062</pub-id></citation></ref><ref id="B11"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Brunak</surname><given-names>S</given-names></name><name><surname>Engelbrecht</surname><given-names>J</given-names></name><name><surname>Knudsen</surname><given-names>S</given-names></name></person-group><article-title>Prediction of mRNA donor and acceptor sites from the DNA sequence</article-title><source>Journal of Molecular Biology</source><year>1991</year><volume>220</volume><fpage>49</fpage><lpage>65</lpage><pub-id pub-id-type="pmid">2067018</pub-id></citation></ref><ref id="B12"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>YF</given-names></name><name><surname>Fan</surname><given-names>XD</given-names></name><name><surname>Li</surname><given-names>YD</given-names></name></person-group><article-title>Identifying splicing sites in eukaryotic RNA: Support vector machine approach</article-title><source>Computers in biology and medicine</source><year>2003</year><volume>33</volume><fpage>17</fpage><lpage>29</lpage><pub-id pub-id-type="pmid">12485627</pub-id></citation></ref><ref id="B13"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Reese</surname><given-names>MG</given-names></name></person-group><article-title>Application of a time-delay neural network to promoter annotation in the Drosophila melanogaster</article-title><source>Computer chem</source><year>2001</year><volume>26</volume><fpage>51</fpage><lpage>56</lpage></citation></ref><ref id="B14"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>XH-F</given-names></name><name><surname>Katherine</surname><given-names>AH</given-names></name><name><surname>Ilana</surname><given-names>H</given-names></name><name><surname>Christina</surname><given-names>SL</given-names></name><name><surname>Lawrence</surname><given-names>AC</given-names></name></person-group><article-title>Sequence information for the splicing of human pre-mRNA identified by support vector machine classification</article-title><source>Genome Research</source><year>2003</year><volume>13</volume><fpage>2637</fpage><lpage>2650</lpage><pub-id pub-id-type="pmid">14656968</pub-id></citation></ref><ref id="B15"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Sonnenburg</surname><given-names>S</given-names></name></person-group><article-title>New methods for detecting splice junction sites in DNA sequence</article-title><source>Master's Thesis</source><year>2002</year><publisher-name>Humbold University, Germany</publisher-name></citation></ref><ref id="B16"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Degroeve</surname><given-names>S</given-names></name><name><surname>Saeys</surname><given-names>Y</given-names></name><name><surname>Baets</surname><given-names>BD</given-names></name><name><surname>Rouze</surname><given-names>P</given-names></name><name><surname>Peer</surname><given-names>YVD</given-names></name></person-group><article-title>SpliceMachine: predicting splice sites from high-dimensional local context representations</article-title><source>Bioinformatics</source><year>2005</year><volume>21</volume><fpage>1332</fpage><lpage>1338</lpage><pub-id pub-id-type="pmid">15564294</pub-id></citation></ref><ref id="B17"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Rajapakse</surname><given-names>JCaHLS</given-names></name></person-group><article-title>Markov encoding for detecting signals in genomic sequences</article-title><source>IEEE/ACM Transactions on Computational Biology and Bioinformatics</source><year>2005</year><volume>2</volume><fpage>131</fpage><lpage>142</lpage><pub-id pub-id-type="pmid">17044178</pub-id></citation></ref><ref id="B18"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Baten</surname><given-names>AKMA</given-names></name><name><surname>Chang</surname><given-names>BCH</given-names></name><name><surname>Halgamuge</surname><given-names>SK</given-names></name><name><surname>Li</surname><given-names>J</given-names></name></person-group><article-title>Splice site identification using probabilistic parameters and SVM classification</article-title><source>BMC Bioinformatics</source><year>2006</year><volume>7</volume><pub-id pub-id-type="pmid">17254299</pub-id></citation></ref><ref id="B19"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Sonnenburg</surname><given-names>S</given-names></name><name><surname>Schweikert</surname><given-names>G</given-names></name><name><surname>Philips</surname><given-names>P</given-names></name><name><surname>Behr</surname><given-names>J</given-names></name><name><surname>R&#x000e4;tsch</surname><given-names>G</given-names></name></person-group><article-title>Accurate splice site prediction using support vector machines</article-title><source>BMC Bioinformatics</source><year>2007</year><volume>8</volume><pub-id pub-id-type="pmid">18269701</pub-id></citation></ref><ref id="B20"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Chuang</surname><given-names>JSaRD</given-names></name></person-group><article-title>Splice site prediction using a sparse network of winnows</article-title><source>Technical Report</source><year>2001</year><publisher-name>University of Illinois, Urbana-Champaign</publisher-name></citation></ref><ref id="B21"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>L</given-names></name></person-group><article-title>aLL: Splice site prediction with quadratic discriminant analysis using diversity measure</article-title><source>Nucleic Acids Research</source><year>2003</year><volume>31</volume><fpage>6214</fpage><lpage>6220</lpage><pub-id pub-id-type="pmid">14576308</pub-id></citation></ref><ref id="B22"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Hebsgaard</surname><given-names>SM</given-names></name><name><surname>korning</surname><given-names>PG</given-names></name><name><surname>Tolstrup</surname><given-names>N</given-names></name><name><surname>Engelbrecht</surname><given-names>J</given-names></name><name><surname>Rouze</surname><given-names>P</given-names></name><name><surname>Brunak</surname><given-names>S</given-names></name></person-group><article-title>Splice site prediction in Arabidopsis Thaliana pre-mRNA by combining local and global sequence information</article-title><source>Nucleic Acids Research</source><year>1996</year><volume>24</volume><fpage>3439</fpage><lpage>3452</lpage><pub-id pub-id-type="pmid">8811101</pub-id></citation></ref><ref id="B23"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Burge</surname><given-names>C</given-names></name></person-group><article-title>Modeling dependencies in pre-mRNA splicing signals</article-title><source>Computational methods in Molecular Biology</source><year>1998</year><volume>chapter 8</volume><publisher-name>Elsevier press</publisher-name><fpage>129</fpage><lpage>163</lpage></citation></ref><ref id="B24"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Saeys</surname><given-names>Y</given-names></name><name><surname>Degroeve</surname><given-names>S</given-names></name><name><surname>Aeyels</surname><given-names>D</given-names></name><name><surname>Peer</surname><given-names>Y Van de</given-names></name><name><surname>Rouze</surname><given-names>P</given-names></name></person-group><article-title>Fast feature selection using a simple estimation of distribution algorithm: a case study on splice site prediction</article-title><source>Bioinformatics</source><year>2003</year><volume>19</volume><publisher-name>Oxford Univ Press</publisher-name><fpage>179</fpage><lpage>188</lpage></citation></ref><ref id="B25"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Waddell</surname><given-names>P</given-names></name><name><surname>Kishino</surname><given-names>H</given-names></name><name><surname>Ota</surname><given-names>R</given-names></name></person-group><article-title>Very fast algorithms for evaluating the stability of ML and Bayesian phylogenetic trees from sequence data</article-title><source>Genome Informatics</source><year>2002</year><volume>13</volume><fpage>82</fpage><lpage>92</lpage><pub-id pub-id-type="pmid">14571377</pub-id></citation></ref><ref id="B26"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Buckingham</surname><given-names>S</given-names></name></person-group><article-title>Bioinformatics: Programmed for success</article-title><source>Nature</source><year>2003</year><volume>425</volume><fpage>209</fpage><lpage>215</lpage></citation></ref><ref id="B27"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Washietl</surname><given-names>S</given-names></name><name><surname>Hofacker</surname><given-names>I</given-names></name><name><surname>Stadler</surname><given-names>P</given-names></name></person-group><article-title>From The Cover: Fast and reliable prediction of noncoding RNAs</article-title><source>Proceedings of the National Academy of Sciences</source><year>2005</year><volume>102</volume><fpage>2454</fpage></citation></ref><ref id="B28"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Shannon</surname><given-names>CE</given-names></name></person-group><article-title>A mathematical theory of communication</article-title><source>Bell System Tech J</source><year>1948</year><volume>27</volume><fpage>379</fpage><lpage>423</lpage><comment>623&#x02013;656.</comment></citation></ref><ref id="B29"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Schneider</surname><given-names>TD</given-names></name></person-group><article-title>Information content of individual genetic sequences</article-title><source>Journal of Theoretical Biology</source><year>1997</year><volume>189</volume><fpage>427</fpage><lpage>441</lpage><pub-id pub-id-type="pmid">9446751</pub-id></citation></ref><ref id="B30"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Itoh</surname><given-names>H</given-names></name><name><surname>Washio</surname><given-names>T</given-names></name><name><surname>Masaru</surname><given-names>Tomita</given-names></name></person-group><article-title>Computational comparative analyses of alternative splicing regulation using full-length cDNA of various eukaryotes</article-title><source>RNA</source><year>2004</year><volume>10</volume><fpage>1005</fpage><lpage>1018</lpage><pub-id pub-id-type="pmid">15208437</pub-id></citation></ref><ref id="B31"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Shapiro</surname><given-names>MB</given-names></name><name><surname>Senapathy</surname><given-names>P</given-names></name></person-group><article-title>RNA splice junctions of different classes of eukaryotes: Sequence statistics and functional implications in gene expression</article-title><source>Nucleic Acids Research</source><year>1987</year><volume>15</volume><fpage>7155</fpage><lpage>7174</lpage><pub-id pub-id-type="pmid">3658675</pub-id></citation></ref><ref id="B32"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Dror</surname><given-names>G</given-names></name><name><surname>Sorek</surname><given-names>R</given-names></name><name><surname>Shamir</surname><given-names>R</given-names></name></person-group><article-title>Accurate identification of alternatively spliced exons using support vector machine</article-title><source>Bioinformatics</source><year>2004</year><volume>21</volume><fpage>897</fpage><lpage>901</lpage><pub-id pub-id-type="pmid">15531599</pub-id></citation></ref><ref id="B33"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Golub</surname><given-names>T</given-names></name><name><surname>Slomin</surname><given-names>D</given-names></name><name><surname>Tamayo</surname><given-names>P</given-names></name><name><surname>Huard</surname><given-names>C</given-names></name><name><surname>Gaasenbeek</surname><given-names>M</given-names></name><name><surname>Mesirov</surname><given-names>J</given-names></name><name><surname>Coller</surname><given-names>H</given-names></name><name><surname>Loh</surname><given-names>M</given-names></name><name><surname>Downing</surname><given-names>J</given-names></name><name><surname>Caliguiri</surname><given-names>M</given-names></name><name><surname>Bloomfield</surname><given-names>C</given-names></name><name><surname>Lander</surname><given-names>E</given-names></name></person-group><article-title>Molecular classification of cancer: class discovery and class prediction by gene expression monitoring</article-title><source>Science</source><year>1999</year><volume>286</volume><fpage>531</fpage><lpage>537</lpage><pub-id pub-id-type="pmid">10521349</pub-id></citation></ref><ref id="B34"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Cortes</surname><given-names>C</given-names></name><name><surname>Vapnik</surname><given-names>V</given-names></name></person-group><article-title>Support vector network, Machine Learning</article-title><source>Machine Learning</source><year>1995</year><volume>20</volume><fpage>273</fpage><lpage>293</lpage></citation></ref><ref id="B35"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Vapnik</surname><given-names>v</given-names></name></person-group><source>The nature of statistical learning theory</source><year>1995</year><publisher-name>Springer, New York</publisher-name><pub-id pub-id-type="pmid">8555380</pub-id></citation></ref><ref id="B36"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Cristianini</surname><given-names>N</given-names></name><name><surname>Shawe-Taylor</surname><given-names>J</given-names></name></person-group><source>An introduction to support vector machine and kernel based learning methods</source><year>2000</year><publisher-name>Cambridge University press, Cambridge</publisher-name></citation></ref><ref id="B37"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Drucker</surname><given-names>H</given-names></name><name><surname>Wu</surname><given-names>D</given-names></name><name><surname>Vapnik</surname><given-names>V</given-names></name></person-group><article-title>Support vector machines for spam categorization</article-title><source>IEEE transaction on Neural Networks</source><year>1995</year><volume>10</volume><fpage>1054</fpage><lpage>1084</lpage></citation></ref><ref id="B38"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Burge</surname><given-names>C</given-names></name></person-group><article-title>A tutorial on support vector machines for pattern recognition</article-title><source>Data Mining and Knowledge Discovery</source><year>1998</year><volume>2</volume><fpage>121</fpage><lpage>167</lpage></citation></ref><ref id="B39"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>H</given-names></name><name><surname>Wong</surname><given-names>L</given-names></name></person-group><article-title>Data mining tools for biological sequences</article-title><source>Journal of bioinformatics and computational biology</source><year>2003</year><volume>1</volume><fpage>139</fpage><lpage>160</lpage><pub-id pub-id-type="pmid">15290785</pub-id></citation></ref><ref id="B40"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Yeo</surname><given-names>G</given-names></name><name><surname>Burge</surname><given-names>CB</given-names></name></person-group><article-title>Maximum Entropy Modeling of Short Sequence Motifs with Applications to RNA Splicing Signals</article-title><source>Journal of Computational Biology</source><year>2004</year><volume>11</volume><fpage>377</fpage><lpage>394</lpage><pub-id pub-id-type="pmid">15285897</pub-id></citation></ref></ref-list></back></article>