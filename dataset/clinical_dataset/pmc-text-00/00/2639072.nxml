<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN" "archivearticle.dtd"><article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article" xml:lang="EN"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id><journal-id journal-id-type="publisher-id">bioinformatics</journal-id><journal-id journal-id-type="hwp">bioinfo</journal-id><journal-title>Bioinformatics</journal-title><issn pub-type="ppub">1367-4803</issn><issn pub-type="epub">1460-2059</issn><publisher><publisher-name>Oxford University Press</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">19073593</article-id><article-id pub-id-type="pmc">2639072</article-id><article-id pub-id-type="doi">10.1093/bioinformatics/btn631</article-id><article-id pub-id-type="publisher-id">btn631</article-id><article-categories><subj-group subj-group-type="heading"><subject>Original Papers</subject><subj-group><subject>Data and Text Mining</subject></subj-group></subj-group></article-categories><title-group><article-title>Evaluating contributions of natural language parsers to protein&#x02013;protein interaction extraction</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Miyao</surname><given-names>Yusuke</given-names></name><xref ref-type="aff" rid="AFF1"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Sagae</surname><given-names>Kenji</given-names></name><xref ref-type="aff" rid="AFF1"><sup>2</sup></xref></contrib><contrib contrib-type="author"><name><surname>S&#x000e6;tre</surname><given-names>Rune</given-names></name><xref ref-type="aff" rid="AFF1"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Matsuzaki</surname><given-names>Takuya</given-names></name><xref ref-type="aff" rid="AFF1"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Tsujii</surname><given-names>Jun'ichi</given-names></name><xref ref-type="aff" rid="AFF1"><sup>1</sup></xref><xref ref-type="aff" rid="AFF1"><sup>3</sup></xref><xref ref-type="aff" rid="AFF1"><sup>4</sup></xref></contrib></contrib-group><aff id="AFF1"><sup>1</sup>Department of Computer Science, University of Tokyo, Tokyo, Japan, <sup>2</sup>Institute for Creative Technologies, University of Southern California, CA, USA, <sup>3</sup>School of Computer Science, University of Manchester and <sup>4</sup>National Center for Text Mining, Manchester, UK</aff><author-notes><corresp id="COR1">*To whom correspondence should be addressed.</corresp><fn><p>Associate Editor: Jonathan Wren</p></fn></author-notes><pub-date pub-type="ppub"><day>1</day><month>2</month><year>2009</year></pub-date><pub-date pub-type="epub"><day>9</day><month>12</month><year>2008</year></pub-date><pub-date pub-type="pmc-release"><day>9</day><month>12</month><year>2008</year></pub-date><volume>25</volume><issue>3</issue><fpage>394</fpage><lpage>400</lpage><history><date date-type="received"><day>18</day><month>9</month><year>2008</year></date><date date-type="rev-recd"><day>9</day><month>11</month><year>2008</year></date><date date-type="accepted"><day>3</day><month>12</month><year>2008</year></date></history><permissions><copyright-statement>&#x000a9; 2008 The Author(s)</copyright-statement><copyright-year>2008</copyright-year><license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by-nc/2.0/uk/"><p><!--CREATIVE COMMONS-->This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/2.0/uk/">http://creativecommons.org/licenses/by-nc/2.0/uk/</ext-link>) which permits unrestricted non-commercial use, distribution, and reproduction in any medium, provided the original work is properly cited.</p></license></permissions><abstract><p><bold>Motivation:</bold> While text mining technologies for biomedical research have gained popularity as a way to take advantage of the explosive growth of information in text form in biomedical papers, selecting appropriate natural language processing (NLP) tools is still difficult for researchers who are not familiar with recent advances in NLP. This article provides a comparative evaluation of several state-of-the-art natural language parsers, focusing on the task of extracting protein&#x02013;protein interaction (PPI) from biomedical papers. We measure how each parser, and its output representation, contributes to accuracy improvement when the parser is used as a component in a PPI system.</p><p><bold>Results:</bold> All the parsers attained improvements in accuracy of PPI extraction. The levels of accuracy obtained with these different parsers vary slightly, while differences in parsing speed are larger. The best accuracy in this work was obtained when we combined Miyao and Tsujii's Enju parser and Charniak and Johnson's reranking parser, and the accuracy is better than the state-of-the-art results on the same data.</p><p><bold>Availability:</bold> The PPI extraction system used in this work (AkanePPI) is available online at <ext-link ext-link-type="uri" xlink:href="http://www-tsujii.is.s.u-tokyo.ac.jp/-100downloads/downloads.cgi">http://www-tsujii.is.s.u-tokyo.ac.jp/-100downloads/downloads.cgi</ext-link>. The evaluated parsers are also available online from each developer's site.</p><p><bold>Contact:</bold> <email>yusuke@is.s.u-tokyo.ac.jp</email></p></abstract></article-meta></front><body><sec sec-type="intro" id="SEC1"><title>1 INTRODUCTION</title><p>Text mining has recently emerged as a way to harvest specific pieces of information from the rapidly growing body of biomedical literature. While the use of shallow text processing techniques is now common for tasks such as the identification of proteins and other entities in biomedical papers (Kim <italic>et al</italic>., <xref ref-type="bibr" rid="B18">2004</xref>; Yeh <italic>et al</italic>., <xref ref-type="bibr" rid="B42">2005</xref>), researchers are now addressing more complex tasks, such as the identification of protein&#x02013;protein interactions (PPI), using advanced natural language parsing approaches that analyze the syntactic and semantic structure of text (Bunescu <italic>et al</italic>., <xref ref-type="bibr" rid="B5">2005</xref>; Hirschman <italic>et al</italic>., <xref ref-type="bibr" rid="B15">2007</xref>; N&#x000e9;dellec, <xref ref-type="bibr" rid="B29">2005</xref>; Pyysalo <italic>et al</italic>., <xref ref-type="bibr" rid="B33">2007a</xref>). However, parsing natural language is an intricate endeavor, where a wide range of possible approaches and open research questions exist, making the choice of a natural language parsing component a burden for researchers without close familiarity with current trends in natural language processing (NLP). Through a series of experiments, we investigate different aspects of state-of-the-art parsing approaches that affect practical performance of information extraction in biomedical papers. Although accuracy figures for different parsers are commonly reported in the NLP literature, such figures are usually computed using artificial metrics that, while useful for parser development, may not be indicative of overall task performance when the parser is used as a component in a biomedical text mining system.</p><p>Due to the creation of biomedical treebanks (Kulick <italic>et al</italic>., <xref ref-type="bibr" rid="B21">2004</xref>; Tateisi <italic>et al</italic>., <xref ref-type="bibr" rid="B39">2005</xref>) and rapid progress of data-driven parsers (Nivre <italic>et al</italic>., <xref ref-type="bibr" rid="B30">2007</xref>), there are now fast, robust and accurate syntactic parsers for text in the biomedical domain. Recent research shows that the accuracy for parsing of biomedical text is now in the 80&#x02013;90% range (Clegg and Shepherd, <xref ref-type="bibr" rid="B8">2007</xref>; Pyysalo <italic>et al</italic>., <xref ref-type="bibr" rid="B34">2007b</xref>; Sagae <italic>et al</italic>., <xref ref-type="bibr" rid="B37">2008a</xref>). However, to be of interest outside the parsing or computational linguistics communities, such accurate syntactic analysis must be shown to improve the performance of overall systems that perform meaningful tasks with biomedical data. This has started to happen, for example, in the task of automatically identifying PPI described in scientific papers. Intuitively, syntactic relationships between words should be valuable in determining possible interactions between entities present in text. Recent PPI extraction systems have confirmed this intuition (Airola <italic>et al</italic>., <xref ref-type="bibr" rid="B1">2008</xref>; Erkan <italic>et al</italic>., <xref ref-type="bibr" rid="B11">2007</xref>; Fundel <italic>et al</italic>., <xref ref-type="bibr" rid="B12">2007</xref>; Katrenko and Adriaans, <xref ref-type="bibr" rid="B17">2006</xref>; Kim <italic>et al</italic>., <xref ref-type="bibr" rid="B19">2008</xref>; Miyao <italic>et al</italic>., <xref ref-type="bibr" rid="B27">2008</xref>; S&#x000e6;tre <italic>et al</italic>., <xref ref-type="bibr" rid="B35">2007</xref>; Sagae <italic>et al</italic>., <xref ref-type="bibr" rid="B38">2008b</xref>).</p><p>While, it is now relatively clear that syntactic parsing is useful in information extraction from the large natural language corpora in bioinformatics, several questions remain regarding the benefits and costs of different parsing approaches and different syntactic representations: how syntactic analyses should be used in a practical setting, whether further improvements in parsing technologies will result in further improvements in practical systems, and how much effort should be spent on comparing and benchmarking parsers for biomedical data. We attempt to shed some light on these matters by performing a comparative evaluation of state-of-the-art syntactic parsers based on different frameworks: dependency parsing, phrase structure parsing and deep parsing. Our approach to parser evaluation is to measure accuracy improvement in the task of identifying PPI information in biomedical papers, by incorporating the output of different parsers as statistical features in a machine learning classifier (Erkan <italic>et al</italic>., <xref ref-type="bibr" rid="B11">2007</xref>; Katrenko and Adriaans, <xref ref-type="bibr" rid="B17">2006</xref>; S&#x000e6;tre <italic>et al</italic>., <xref ref-type="bibr" rid="B35">2007</xref>; Yakushiji <italic>et al</italic>., <xref ref-type="bibr" rid="B41">2005</xref>). PPI identification is an informative task for parser evaluation, since it is a biomedical information extraction application of practical utility, and because recent studies have shown the effectiveness of syntactic parsing in this task. Since our evaluation method is applicable to any parser output, and is grounded in a real application, it allows for a fair comparison of syntactic parsers based on different frameworks. In addition, we present experiments that show the relationship of the accuracy of parsers and the accuracy of the larger PPI system that includes the parser. We investigate the effects of domain-specific treebank size (the amount of available manually annotated training data for syntactic parsers) and final system performance, and obtain results that should be informative to researchers in bioinformatics who deal with natural language, as well as to members of the parsing community who are interested in the practical impact of parsing research in biomedical applications.</p></sec><sec id="SEC2"><title>2 NATURAL LANGUAGE PARSERS</title><p>This article focuses on eight representative parsers that are classified into three parsing frameworks: <italic>dependency parsing</italic>, <italic>phrase structure parsing</italic> and <italic>deep parsing</italic>.</p><sec id="SEC2.1"><title>2.1 Dependency parsing</title><p>Dependency parsing has recently been extensively studied in parsing research, partly because the shared tasks of CoNLL 2006 and 2007 focused on data-driven dependency parsing (Nivre <italic>et al</italic>., <xref ref-type="bibr" rid="B30">2007</xref>). The aim of dependency parsing is to compute a tree structure of a sentence, where nodes are words and edges represent the relationships among the words.</p><p><xref ref-type="fig" rid="F1">Figure 1</xref> shows a parsing result for the sentence &#x02018;<italic>IL-8 recognizes and activates CXCR1</italic>&#x02019;, in the dependency tree format used in the 2006 and 2007 CoNLL shared tasks on dependency parsing (which we call the &#x02018;CoNLL&#x02019; format). An advantage of dependency parsing is that dependency trees are a reasonable approximation of the semantics of sentences, and are readily usable in NLP applications. For example, the subject and the object of &#x02018;<italic>recognizes</italic>&#x02019; are explicitly represented in this format. Furthermore, the efficiency of dependency parsing compares favorably to phrase structure parsing or deep parsing. While a number of methods have been proposed for dependency parsing, this article focuses on the following two representative parsers.<fig id="F1" position="float"><label>Fig. 1.</label><caption><p>CoNLL-X dependency tree (CoNLL).</p></caption><graphic xlink:href="btn631f1"/></fig></p><p>MST: McDonald and Pereira's (<xref ref-type="bibr" rid="B24">2006</xref>) dependency parser (http://sourceforge.net/projects/mstparser) based on Eisner's (<xref ref-type="bibr" rid="B10">1996</xref>) algorithm for projective dependency parsing.</p><p>KSDEP: Sagae and Tsujii's (<xref ref-type="bibr" rid="B36">2007</xref>) dependency parser, (<ext-link ext-link-type="uri" xlink:href="http://www.cs.cmu.edu/sagae/parser/">http://www.cs.cmu.edu/sagae/parser/</ext-link>), based on a probabilistic shift-reduce algorithm.</p></sec><sec id="SEC2.2"><title>2.2 Phrase structure parsing</title><p>Owing largely to the Penn Treebank (Marcus <italic>et al</italic>., <xref ref-type="bibr" rid="B22">1994</xref>), the mainstream of data-driven parsing research has been dedicated to phrase structure parsing. These parsers output Penn Treebank-style phrase structure trees (which we call the &#x02018;PTB&#x02019; format), as shown in <xref ref-type="fig" rid="F2">Figure 2</xref>. While most state-of-the-art phrase structure parsers are based on probabilistic context-free grammars (PCFGs), the parameterization of the probabilistic model of each parser varies. In this work, we chose the following four parsers.<fig id="F2" position="float"><label>Fig. 2.</label><caption><p>Penn Treebank-style phrase structure tree (PTB).</p></caption><graphic xlink:href="btn631f2"/></fig></p><p>NO-RERANK: Charniak's (<xref ref-type="bibr" rid="B6">2000</xref>) parser, based on a lexicalized PCFG model of phrase structure trees (<ext-link ext-link-type="uri" xlink:href="http://bllip.cs.brown.edu/resources.shtml">http://bllip.cs.brown.edu/resources.shtml</ext-link>). The probabilities of CFG rules are parameterized on carefully hand-tuned information, such as lexical heads and symbols of ancestor/sibling nodes.</p><p>RERANK: Charniak and Johnson's (<xref ref-type="bibr" rid="B7">2005</xref>) reranking parser. The reranker of this parser receives <italic>n</italic>-best<xref ref-type="fn" rid="FN1"><sup>1</sup></xref> parse results from NO-RERANK, and selects the most likely parse result by using a maximum entropy model with manually engineered features.</p><p>BERKELEY: Berkeley's parser (Petrov and Klein <xref ref-type="bibr" rid="B31">2007</xref>) (<ext-link ext-link-type="uri" xlink:href="http://nlp.cs.berkeley.edu/Main.html#Parsing">http://nlp.cs.berkeley.edu/Main.html#Parsing</ext-link>). The parameterization of this parser is optimized automatically by assigning latent variables to each non-terminal node and estimating the parameters of the latent variables by the expectation maximization algorithm.</p><p>STANFORD: Stanford's unlexicalized parser (Klein and Manning, <xref ref-type="bibr" rid="B20">2003</xref>) (<ext-link ext-link-type="uri" xlink:href="http://nlp.stanford.edu/software/lex-parser.shtml">http://nlp.stanford.edu/software/lex-parser.shtml</ext-link>). Unlike NO-RERANK, probabilities are not parameterized on lexical heads.</p><p>Since the PTB format does not directly represent the grammatical functions between words, it is difficult to use it directly in applications. In <xref ref-type="fig" rid="F2">Figure 2</xref>, it is not clear how the syntactic arguments (e.g. the subject and the object) of verbs are identified. An ordinary solution is the conversion of PTB trees into some form of dependency-based representations. This article adopts three representations that can be converted from PTB trees.</p><p>CoNLL: while this representation is the default output for dependency parsers, it can also be obtained from the PTB format by applying constituent-to-dependency conversion (<ext-link ext-link-type="uri" xlink:href="http://nlp.cs.lth.se/pennconverter/">http://nlp.cs.lth.se/pennconverter/</ext-link>).(Johansson and Nugues, <xref ref-type="bibr" rid="B16">2007</xref>). It should be noted, however, that this conversion cannot work perfectly with automatic parsing, because the conversion program relies on additional information (function tags and empty categories) of the original Penn Treebank, which are not produced by the parsers listed above.</p><p>HD: dependency trees of syntactic heads (<xref ref-type="fig" rid="F3">Fig. 3</xref>). We first determine lexical heads of non-terminal nodes by using Collins' head detection algorithm (<ext-link ext-link-type="uri" xlink:href="http://www.cis.upenn.edu/dbikel/software.html">http://www.cis.upenn.edu/dbikel/software.html</ext-link> (Bikel, <xref ref-type="bibr" rid="B2">2004</xref>). We then convert lexicalized trees into dependencies between lexical heads. This format can represent dependency relations similar to CoNLL, although relation types are not sufficient to identify important grammatical relations. For example, in <xref ref-type="fig" rid="F3">Figure 3</xref>, the subject and the object relations are assigned the same relation types, NP, and are not distinguishable.<fig id="F3" position="float"><label>Fig. 3.</label><caption><p>Head dependencies (HD).</p></caption><graphic xlink:href="btn631f3"/></fig></p><p>SD: the Stanford dependency format (<xref ref-type="fig" rid="F4">Fig. 4</xref>). This format was originally proposed for extracting dependency relations useful for practical applications (de Marneffe <italic>et al</italic>., <xref ref-type="bibr" rid="B9">2006</xref>). A program to convert PTB is attached to the Stanford parser. Although the concept looks similar to CoNLL, this representation does not necessarily form a tree structure, and is designed to express more fine-grained relations, such as apposition. In <xref ref-type="fig" rid="F4">Figure 4</xref>, &#x02018;nsubj&#x02019; and &#x02018;dobj&#x02019; indicate the nominal subject and direct object, which are more fine-grained relation types than CoNLL dependencies. Research groups for biomedical NLP recently adopted this representation for corpus annotation (Pyysalo <italic>et al</italic>., <xref ref-type="bibr" rid="B33">2007a</xref>) and parser evaluation (Clegg and Shepherd, <xref ref-type="bibr" rid="B8">2007</xref>; Pyysalo <italic>et al</italic>., <xref ref-type="bibr" rid="B34">2007b</xref>).<fig id="F4" position="float"><label>Fig. 4.</label><caption><p>Stanford dependencies (SD).</p></caption><graphic xlink:href="btn631f4"/></fig></p></sec><sec id="SEC2.3"><title>2.3 Deep parsing</title><p>Deep parsing aims to compute in-depth syntactic and semantic structures based on syntactic theories, such as HPSG (Pollard and Sag, <xref ref-type="bibr" rid="B32">1994</xref>). Recent research developments have allowed for efficient and robust deep parsing of real-world texts (Miyao and Tsujii, <xref ref-type="bibr" rid="B26">2008</xref>). Deep parsers can compute theory-specific syntactic/semantic structures, and predicate argument structures (PAS) that are often used in parser evaluation and applications. PAS is a graph structure that represents the relations among words (<xref ref-type="fig" rid="F5">Fig. 5</xref>). The concept is therefore similar to CoNLL dependencies, though PAS expresses deeper relations, such as long distance dependencies, and may include shared structures. For example, the subject (ARG1) and the object (ARG2) of &#x02018;<italic>activates</italic>&#x02019; are explicitly represented in <xref ref-type="fig" rid="F5">Figure 5</xref>, while not in the other formats.<fig id="F5" position="float"><label>Fig. 5.</label><caption><p>Predicate argument structure (PAS).</p></caption><graphic xlink:href="btn631f5"/></fig></p><p>In this work, we used two variants of the Enju parser (Miyao and Tsujii, <xref ref-type="bibr" rid="B26">2008</xref>) (<ext-link ext-link-type="uri" xlink:href="http://www-tsujii.is.s.u-tokyo.ac.jp/enju/">http://www-tsujii.is.s.u-tokyo.ac.jp/enju/</ext-link>).</p><p>ENJU: an HPSG-based parser derived from the Penn Treebank.</p><p>ENJU-GENIA: a variant of ENJU, which is adapted to biomedical texts, by the method of (Hara <italic>et al</italic>. <xref ref-type="bibr" rid="B14">2007</xref>).</p><p>In addition to the PAS format, the PTB format can also be created from Enju's output by using tree structure matching (Matsuzaki and Tsujii, <xref ref-type="bibr" rid="B23">2008</xref>), but this conversion is imperfect because the forms of PTB and Enju's output are not entirely compatible. We can also obtain the CoNLL.HD and SD formats, because they can be converted from PTB. That is, five parse representations are available for the Enju parser.</p></sec></sec><sec sec-type="methods" id="SEC3"><title>3 METHODS</title><p>In our approach to parser evaluation, we measure the accuracy of a PPI extraction system, in which the parser output is embedded as statistical features of a machine learning classifier. We run the classifier with features of every possible combination of a parser and a parse representation, by applying conversions between representations when necessary.</p><sec id="SEC3.1"><title>3.1 PPI extraction</title><p>PPI extraction is an information extraction task to identify protein pairs that are mentioned as interacting in biomedical papers. Because the number of biomedical papers is growing rapidly, it is becoming difficult for biomedical researchers to find all papers relevant to their research; thus, there is an emerging need for reliable text mining technologies, such as automatic PPI extraction from texts.</p><p><xref ref-type="fig" rid="F6">Figure 6</xref> shows two sentences that include protein names: the former sentence mentions a protein interaction, while the latter does not. Given a protein pair, PPI extraction is a task of binary classification; for example, &#x02329;IL-8, CXCR1&#x0232a; is a positive example, and &#x02329;RBP, TTR&#x0232a; is a negative example. Recent studies on PPI extraction demonstrated that syntactic/semantic relationships between target proteins are effective features for machine learning classifiers (Erkan <italic>et al</italic>., <xref ref-type="bibr" rid="B11">2007</xref>; Katrenko and Adriaans, <xref ref-type="bibr" rid="B17">2006</xref>; S&#x000e6;tre <italic>et al</italic>., <xref ref-type="bibr" rid="B35">2007</xref>). For the protein pair IL-8 and CXCR1 in <xref ref-type="fig" rid="F6">Figure 6</xref>, a dependency parser outputs a dependency tree; partly shown in <xref ref-type="fig" rid="F1">Figure 1</xref>. From this dependency tree, we can extract the dependency path shown in <xref ref-type="fig" rid="F7">Figure 7</xref>, which appears to be a strong clue in knowing that these proteins are mentioned as interacting.<fig id="F6" position="float"><label>Fig. 6.</label><caption><p>Sentences including protein names.</p></caption><graphic xlink:href="btn631f6"/></fig><fig id="F7" position="float"><label>Fig. 7.</label><caption><p>Dependency path.</p></caption><graphic xlink:href="btn631f7"/></fig></p><p>We follow the PPI extraction method of (S&#x000e6;tre <italic>et al</italic>. <xref ref-type="bibr" rid="B35">2007</xref>), which is based on support vector machines with SubSet Tree Kernels (Moschitti, <xref ref-type="bibr" rid="B28">2006</xref>), while using different parsers and parse representations. Two types of features are incorporated in the classifier. The first is bag-of-words features, which are regarded as a strong baseline for PPI extraction systems. Lemmas of words before, between and after the pair of target proteins are included, and a linear kernel is used for these features. This kernel is included in all our models. The other type of feature is parser output features. For dependency-based parse representations, a dependency path is encoded as a flat tree as depicted in <xref ref-type="fig" rid="F8">Figure 8</xref> (prefix &#x02018;r&#x02019; denotes reverse relations). Because a tree kernel measures the similarity of trees by counting common subtrees, it is expected that the system finds effective subsequences of dependency paths. For the PTB representation, we directly encode phrase structure trees.<fig id="F8" position="float"><label>Fig. 8.</label><caption><p>Tree representation of a dependency path.</p></caption><graphic xlink:href="btn631f8"/></fig></p><p>We also measure the accuracy obtained by the ensemble of two parsers/representations. This experiment indicates differences or overlaps in the information conveyed by two different parsers or parse representations.</p></sec><sec id="SEC3.2"><title>3.2 Conversion of parser output representations</title><p>It is widely believed that the choice of the representation format for parser output may greatly affect the performance of applications, although this has not been extensively investigated. We should, therefore, evaluate the parser performance in multiple parse representations. In this article, we create multiple parse representations by converting each parser's default output into other representations when possible. This experiment can also be considered to be a comparative evaluation of parse representations, thus providing an indication for selecting an appropriate parse representation for similar information extraction and text mining tasks.</p><p><xref ref-type="table" rid="T1">Table 1</xref> lists the formats for parser output used in this work, and <xref ref-type="fig" rid="F9">Figure 9</xref> shows our scheme for representation conversion. Although only CoNLL is available for dependency parsers, we can create four representations for the phrase structure parsers, and five for the deep parsers. Dotted arrows in <xref ref-type="fig" rid="F9">Figure 9</xref> indicate imperfect conversion, in which the conversion inherently introduces errors, and may decrease the accuracy. We should, therefore, take caution when comparing the results obtained by imperfect conversion.<fig id="F9" position="float"><label>Fig. 9.</label><caption><p>Conversion of parser output representations.</p></caption><graphic xlink:href="btn631f9"/></fig><table-wrap id="T1" position="float"><label>Table 1.</label><caption><p>Parser output representations</p></caption><table frame="hsides" rules="groups"><tbody align="left"><tr><td rowspan="1" colspan="1">CoNLL</td><td rowspan="1" colspan="1">Dependency trees used in CoNLL 2006 and 2007</td></tr><tr><td rowspan="1" colspan="1">PTB</td><td rowspan="1" colspan="1">Penn Treebank-style phrase structure trees</td></tr><tr><td rowspan="1" colspan="1">HD</td><td rowspan="1" colspan="1">Dependency trees of lexical heads</td></tr><tr><td rowspan="1" colspan="1">SD</td><td rowspan="1" colspan="1">Stanford dependency graphs</td></tr><tr><td rowspan="1" colspan="1">PAS</td><td rowspan="1" colspan="1">Predicate argument structures</td></tr></tbody></table></table-wrap></p></sec><sec id="SEC3.3"><title>3.3 Parser retraining with GENIA</title><p>The domain of our target text is different from the Wall Street Journal (WSJ) portion of the Penn Treebank, which is the <italic>de facto</italic> standard data for parser training. Because all the parsers listed in Section sec:syntactic_parsers were originally trained with the WSJ data (except for ENJU-GENIA), we retrain the parsers with the GENIA Treebank<xref ref-type="fn" rid="FN2"><sup>2</sup></xref> (8127 sentences), which is a treebank of biomedical paper abstracts annotated according to the guideline of the Penn Treebank (Tateisi <italic>et al</italic>., <xref ref-type="bibr" rid="B39">2005</xref>). Since all these parsers have programs for training with a PTB-style treebank, we use those programs for retraining with default parameter settings.</p><p>In preliminary experiments, we found that dependency parsers attain higher dependency accuracy when trained only with GENIA. We therefore use only GENIA as the training data for the retraining of dependency parsers. For the other parsers, we use the concatenation of WSJ and GENIA for the retraining, while the reranker of RERANK was not retrained due to the high cost. Also for the training of ENJU-GENIA, the same set of the WSJ and GENIA was used.</p><p>Since all the parsers except NO-RERANK and RERANK require an external POS tagger, <monospace>geniatagger</monospace>.(Tsuruoka <italic>et al</italic>., <xref ref-type="bibr" rid="B40">2005</xref>) is used with these parsers.</p></sec><sec id="SEC3.4"><title>3.4 Evaluating the relationships between parser accuracy, treebank size and PPI accuracy</title><p>In addition to investigating the impact of different parsers and different syntactic representations on PPI identification accuracy, we also examine how the parse accuracy of a single parser affects the PPI accuracy. To this end, we retrain one of the parsers (KSDEP) with varying amounts of training text, resulting in several different versions of the same parser, having different levels of accuracy. This allows us to establish a relationship between the accuracy of the parser and the amount of training data used to create the parser. When the parser is used as a component in the PPI identification system, we can determine the relationship between the size of the dataset used to train the parser, the parser's accuracy, and the overall PPI system's accuracy. This provides a rough guide for what level of accuracy to expect in the PPI task when a new parser is used, as long as the accuracy of the parser is known.</p></sec></sec><sec sec-type="results" id="SEC4"><title>4 RESULTS</title><sec id="SEC4.1"><title>4.1 Data</title><p>In the following experiments, we used AIMed (Bunescu and Mooney, <xref ref-type="bibr" rid="B3">2004</xref>), which is a popular dataset for the evaluation of PPI extraction systems. The data consists of 225 biomedical paper abstracts (1970 sentences), which are sentence-split, tokenized and annotated with proteins and PPIs. We use the gold protein annotations given in the data, and multi-word protein names are concatenated and treated as single words. The accuracy is measured by abstract-wise 10-fold cross-validation and the one-answer-per-occurrence criterion (Giuliano <italic>et al</italic>., <xref ref-type="bibr" rid="B13">2006</xref>). A prediction threshold for the support vector machine (SVM) is moved to adjust the balance of precision and recall, and the maximum <italic>f</italic>-score is reported for each experiment.</p></sec><sec id="SEC4.2"><title>4.2 Comparison of accuracy improvements</title><p><xref ref-type="table" rid="T2">Table 2</xref> shows the time used by each parser for parsing the entire AIMed corpus, and the PPI accuracy obtained by using the output from each parser with different parse representation. The row &#x02018;baseline&#x02019; indicates the accuracy obtained with bag-of-words features only.<table-wrap id="T2" position="float"><label>Table 2.</label><caption><p>Parsing time and accuracy (precision/recall/f -score) on the PPI task</p></caption><table frame="hsides" rules="groups"><thead align="left"><tr><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1">Time (s)</th><th rowspan="1" colspan="1">CoNLL</th><th rowspan="1" colspan="1">PTB</th><th rowspan="1" colspan="1">HD</th><th rowspan="1" colspan="1">SD</th><th rowspan="1" colspan="1">PAS</th></tr></thead><tbody align="left"><tr><td rowspan="1" colspan="1">MST</td><td rowspan="1" colspan="1">425</td><td rowspan="1" colspan="1">49.1/65.6/55.9</td><td rowspan="1" colspan="1">N/A</td><td rowspan="1" colspan="1">N/A</td><td rowspan="1" colspan="1">N/A</td><td rowspan="1" colspan="1">N/A</td></tr><tr><td rowspan="1" colspan="1">KSDEP</td><td rowspan="1" colspan="1">111</td><td rowspan="1" colspan="1">51.6/67.5/58.3</td><td rowspan="1" colspan="1">N/A</td><td rowspan="1" colspan="1">N/A</td><td rowspan="1" colspan="1">N/A</td><td rowspan="1" colspan="1">N/A</td></tr><tr><td rowspan="1" colspan="1">NO-RERANK</td><td rowspan="1" colspan="1">1372</td><td rowspan="1" colspan="1">53.9/60.3/56.8</td><td rowspan="1" colspan="1">51.3/54.9/52.8</td><td rowspan="1" colspan="1">53.1/60.2/56.3</td><td rowspan="1" colspan="1">54.6/58.1/56.2</td><td rowspan="1" colspan="1">N/A</td></tr><tr><td rowspan="1" colspan="1">RERANK</td><td rowspan="1" colspan="1">2125</td><td rowspan="1" colspan="1">52.8/61.5/56.6</td><td rowspan="1" colspan="1">48.3/58.0/52.6</td><td rowspan="1" colspan="1">52.1/60.3/55.7</td><td rowspan="1" colspan="1">53.0/61.1/56.7</td><td rowspan="1" colspan="1">N/A</td></tr><tr><td rowspan="1" colspan="1">BERKELEY</td><td rowspan="1" colspan="1">1198</td><td rowspan="1" colspan="1">52.7/60.3/56.0</td><td rowspan="1" colspan="1">48.0/59.9/53.1</td><td rowspan="1" colspan="1">54.9/54.6/54.6</td><td rowspan="1" colspan="1">50.5/63.2/55.9</td><td rowspan="1" colspan="1">N/A</td></tr><tr><td rowspan="1" colspan="1">STANFORD</td><td rowspan="1" colspan="1">1645</td><td rowspan="1" colspan="1">49.3/62.8/55.1</td><td rowspan="1" colspan="1">44.5/64.7/52.5</td><td rowspan="1" colspan="1">49.0/62.0/54.5</td><td rowspan="1" colspan="1">54.6/57.5/55.8</td><td rowspan="1" colspan="1">N/A</td></tr><tr><td rowspan="1" colspan="1">ENJU</td><td rowspan="1" colspan="1">727</td><td rowspan="1" colspan="1">54.4/59.7/56.7</td><td rowspan="1" colspan="1">48.3/60.6/53.6</td><td rowspan="1" colspan="1">56.7/55.6/56.0</td><td rowspan="1" colspan="1">54.4/59.3/56.6</td><td rowspan="1" colspan="1">52.0/63.8/57.2</td></tr><tr><td rowspan="1" colspan="1">ENJU-GENIA</td><td rowspan="1" colspan="1">821</td><td rowspan="1" colspan="1">56.4/57.4/56.7</td><td rowspan="1" colspan="1">46.5/63.9/53.7</td><td rowspan="1" colspan="1">53.4/60.2/56.4</td><td rowspan="1" colspan="1">55.2/58.3/56.5</td><td rowspan="1" colspan="1">57.5/59.8/58.4</td></tr><tr><td rowspan="1" colspan="1">Baseline</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td colspan="2" align="center" rowspan="1">48.2/54.9/51.1</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr></tbody></table></table-wrap></p><p><xref ref-type="table" rid="T2">Table 2</xref> clearly shows that all the parsers achieved better results than the baseline, demonstrating contributions of these parsers to PPI extraction. Differences among parsers are relatively smaller than the differences from the baseline, proving that dependency parsing, phrase structure parsing and deep parsing perform equally well in this task. Among these parsers, KSDEP and ENJU-GENIA performed better than the other parsers, and NO-RERANK.RERANK and ENJU come next.</p><p>While the accuracy level of PPI extraction is similar, parsing speed differs considerably for different parsing frameworks. The dependency parsers are much faster than the other parsers, while the phrase structure parsers are relatively slower, and the deep parsers are in between. It is noteworthy that the dependency parsers achieved comparable accuracy with the other parsers, while they are more efficient.</p><p>The experimental results also demonstrate that the PTB format is worse than the other representations with respect to contributions to accuracy improvements. Although phrase structure parsers are popular in the NLP community, dependency-based formats are shown to contribute more to this task, probably because they express syntactic/semantic relations among words more explicitly, as shown in <xref ref-type="fig" rid="F7">Figure 7</xref>. The conversion from PTB to dependency-based representations is, therefore, desirable for this task, although it is possible that better results might be obtained with PTB if a different feature extraction mechanism is used. Among dependency-based representations.HD is slightly worse, indicating that surface syntactic relations are insufficient for this task. It should be noted that CoNLL attained competitive or superior performance to HD and SD in spite of the imperfect conversion from PTB to CoNLL. This might be a reason for the high performances of the dependency parsers that directly compute CoNLL dependencies. The results for ENJU-CoNLL and ENJU-PAS show that PAS contributes to a larger accuracy improvement than the CoNLL representation. This result implies that, deep relations, such as long-distance dependencies, might contribute to accuracy improvements, although this does not necessarily mean the superiority of PAS to CoNLL, because two imperfect conversions, i.e.PAS-to-PTB and PTB-to-CoNLL, are applied for creating ENJU-CoNLL.</p></sec><sec id="SEC4.3"><title>4.3 Parser ensemble results</title><p><xref ref-type="table" rid="T3">Table 3</xref> shows the accuracy obtained with ensembles of two parsers/representations (excluding the PTB format). Bracketed figures denote improvements from the accuracy with only the single best (of the two) parser/representation used. The results show that the task accuracy improves when using a double parser/representation ensemble. Interestingly, the accuracy improvements are observed even for ensembles of different representations from the same parser. This indicates that a single parse representation is insufficient for expressing the true potential of a parser. Effectiveness of combining two parsers is also attested by the fact that it resulted in larger improvements. Especially, large improvements were observed when ENJU-PAS is combined with another parser/representation. This indicates that the ENJU-PAS format expresses different information from others, and differences in information conveyed by these parsers/representations complementarily contributed to accuracy improvement. The best accuracy was achieved by the combination of ENJU-PAS and RERANK-CoNLL. Further investigation of the sources of these improvements will illustrate the advantages and disadvantages of these parsers and representations, leading us to better parsing models and a better design for parse representations.<table-wrap id="T3" position="float"><label>Table 3.</label><caption><p>Results of parser/representation ensemble (f -score)</p></caption><table frame="hsides" rules="groups"><thead align="left"><tr><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1">RERANK CoNLL</th><th rowspan="1" colspan="1">HD</th><th rowspan="1" colspan="1">SD</th><th rowspan="1" colspan="1">ENJU CoNLL</th><th rowspan="1" colspan="1">HD</th><th rowspan="1" colspan="1">SD</th><th rowspan="1" colspan="1">PAS</th></tr></thead><tbody align="left"><tr><td rowspan="1" colspan="1">KSDEP</td><td rowspan="1" colspan="1">CoNLL</td><td rowspan="1" colspan="1">58.5 (+0.2)</td><td rowspan="1" colspan="1">57.1 (-1.2)</td><td rowspan="1" colspan="1">58.4 (+0.1)</td><td rowspan="1" colspan="1">58.5 (+0.2)</td><td rowspan="1" colspan="1">58.0 (-0.3)</td><td rowspan="1" colspan="1">59.1 (+0.8)</td><td rowspan="1" colspan="1">59.0 (+0.7)</td></tr><tr><td rowspan="1" colspan="1">RERANK</td><td rowspan="1" colspan="1">CoNLL</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">56.7 (+0.1)</td><td rowspan="1" colspan="1">57.1 (+0.4)</td><td rowspan="1" colspan="1">58.3 (+1.6)</td><td rowspan="1" colspan="1">57.3 (+0.7)</td><td rowspan="1" colspan="1">58.7 (+2.1)</td><td rowspan="1" colspan="1">59.5 (+2.3)</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">HD</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">56.8 (+0.1)</td><td rowspan="1" colspan="1">57.2 (+0.5)</td><td rowspan="1" colspan="1">56.5 (+0.5)</td><td rowspan="1" colspan="1">56.8 (+0.2)</td><td rowspan="1" colspan="1">57.6 (+0.4)</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">SD</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">58.3 (+1.6)</td><td rowspan="1" colspan="1">58.3 (+1.6)</td><td rowspan="1" colspan="1">56.9 (+0.2)</td><td rowspan="1" colspan="1">58.6 (+1.4)</td></tr><tr><td rowspan="1" colspan="1">ENJU</td><td rowspan="1" colspan="1">CoNLL</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">57.0 (+0.3)</td><td rowspan="1" colspan="1">57.2 (+0.5)</td><td rowspan="1" colspan="1">58.4 (+1.2)</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">HD</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">57.1 (+0.5)</td><td rowspan="1" colspan="1">58.1 (+0.9)</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">SD</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">58.3 (+1.1)</td></tr></tbody></table></table-wrap></p></sec><sec id="SEC4.4"><title>4.4 The impact of treebank size and parser accuracy</title><p><xref ref-type="fig" rid="F10">Figure 10</xref> shows the parse accuracy for KSDEP and the accuracy of PPI extraction, when the parser is trained with varying amounts of data. This figure demonstrates that increasing the size of the parser training set contributes to increasing parse accuracy. Training the parser with only 100 sentences results in parse accuracy of about 72.5%. Accuracy rises sharply with additional training data until the size of the training set reaches about 1000 sentences (about 82.5% accuracy). From there, accuracy climbs consistently, but slowly, until 85.6% accuracy is reached with 8000 sentences of training data.<fig id="F10" position="float"><label>Fig. 10.</label><caption><p>Parser training set size (number of sentences) versus parse accuracy and PPI extraction accuracy (<italic>f</italic>-score).</p></caption><graphic xlink:href="btn631f10"/></fig></p><p><xref ref-type="fig" rid="F10">Figure 10</xref> also shows the relationship between the amount of parser training data and the accuracy of PPI extraction. This shows that the accuracy of PPI extraction generally increases with the use of more sentences to train the parser. Although it may appear that further increasing the training data for the parser may not improve the PPI extraction accuracy, we see that the two curves match each other to a large extent. This is supported by the strong correlation between parse accuracy and PPI accuracy, shown in <xref ref-type="fig" rid="F11">Figure 11</xref>. While this suggests that training the parser with a larger treebank may result in improved accuracy in PPI extraction, we observe that a 1% absolute improvement in parser accuracy corresponds roughly to a 0.25 improvement in PPI extraction accuracy. Our results suggest that to obtain even a 1% improvement in parser accuracy by using more parser training data, the size of the treebank used for training would have to increase greatly.<fig id="F11" position="float"><label>Fig. 11.</label><caption><p>Parser accuracy (<italic>f</italic>-score) versus PPI extraction accuracy (<italic>f</italic>-score).</p></caption><graphic xlink:href="btn631f11"/></fig></p></sec><sec id="SEC4.5"><title>4.5 Comparison with previous results on PPI extraction</title><p>PPI extraction experiments on AIMed have been reported repeatedly, although the figures cannot be compared directly because of the differences in data preprocessing and the number of target protein pairs (Airola <italic>et al</italic>., <xref ref-type="bibr" rid="B1">2008</xref>; S&#x000e6;tre <italic>et al</italic>., <xref ref-type="bibr" rid="B35">2007</xref>). <xref ref-type="table" rid="T4">Table 4</xref> compares our best result with previously reported accuracy figures. Among these, (Giuliano <italic>et al</italic>. <xref ref-type="bibr" rid="B13">2006</xref>) and (Mitsumori <italic>et al</italic>. <xref ref-type="bibr" rid="B25">2006</xref>) do not rely on natural language parsing, while the former applied SVMs with kernels on surface strings and the latter is similar to our baseline method. (Bunescu and Mooney <xref ref-type="bibr" rid="B4">2005</xref>) applied SVMs with subsequence kernels to the same task, although they provided only a precision&#x02013;recall graph, and its maximum <italic>f</italic>-score is around 50. Since we did not run experiments on protein-pairwise cross-validation, our system cannot be compared directly to the results reported by (Erkan <italic>et al</italic>. <xref ref-type="bibr" rid="B11">2007</xref>) and (Katrenko and Adriaans <xref ref-type="bibr" rid="B17">2006</xref>), but (S&#x000e6;tre <italic>et al</italic>. <xref ref-type="bibr" rid="B35">2007</xref>) presented better results than theirs using protein-pairwise cross-validation.<table-wrap id="T4" position="float"><label>Table 4.</label><caption><p>Comparison with previous results on PPI extraction (f -score)</p></caption><table frame="hsides" rules="groups"><tbody align="left"><tr><td rowspan="1" colspan="1">Bag-of-words features</td><td rowspan="1" colspan="1">51.1</td></tr><tr><td rowspan="1" colspan="1">Yakushiji <italic>et al</italic>. (<xref ref-type="bibr" rid="B41">2005</xref>)</td><td rowspan="1" colspan="1">33.4</td></tr><tr><td rowspan="1" colspan="1">Mitsumori <italic>et al</italic>. (<xref ref-type="bibr" rid="B25">2006</xref>)</td><td rowspan="1" colspan="1">47.7</td></tr><tr><td rowspan="1" colspan="1">Giuliano <italic>et al</italic>. (<xref ref-type="bibr" rid="B13">2006</xref>)<sup>3</sup></td><td rowspan="1" colspan="1">52.4</td></tr><tr><td rowspan="1" colspan="1">S&#x000e6;tre <italic>et al</italic>. (2007)</td><td rowspan="1" colspan="1">52.0</td></tr><tr><td rowspan="1" colspan="1">Airola <italic>et al</italic>. (<xref ref-type="bibr" rid="B1">2008</xref>)</td><td rowspan="1" colspan="1">56.4</td></tr><tr><td rowspan="1" colspan="1">This article</td><td rowspan="1" colspan="1">59.5</td></tr></tbody></table></table-wrap></p></sec></sec><sec sec-type="conclusions" id="SEC5"><title>5 CONCLUSIONS</title><p>We have presented our attempts to evaluate contributions of natural language parsers and their representations to PPI extraction. The basic idea is to measure the accuracy improvements of the PPI extraction task by incorporating the parser output as statistical features of a machine learning classifier. Experiments showed that state-of-the-art parsers improved PPI extraction accuracy, and the obtained accuracy is better than previously reported accuracy on the same data. These parsers attain accuracy levels that are on par with each other, while parsing speed differs considerably. We also observed that a 1% absolute improvement in parser accuracy corresponds roughly to a 0.25% point improvement in PPI extraction accuracy.</p><p>A shortcoming of our experiments is that there is no guarantee that the results obtained with our PPI extraction system can be generalized to other dataset and tasks. Although we cannot assert the superiority of parsers/representations under arbitrary cricumstances with only the results presented here, our methodology lays the foundation for future task-based evaluations using different PPI dataset and possibly other information extraction tasks. Such evaluations are indispensable for a more general understanding of the performance characteristics of different parsers in specific applications in bioinformatics, and our methodology provides a template for how these evaluations may be conducted.</p><p><italic>Funding</italic>: This work was partially supported by Grant-in-Aid for Specially Promoted Research (MEXT, Japan); Genome Network Project (MEXT, Japan); Grant-in-Aid for Young Scientists (MEXT, Japan).</p><p><italic>Conflict of Interest</italic>: none declared.</p></sec></body><back><fn-group><fn id="FN1"><p><sup>1</sup>We set <italic>n</italic>=50 in this article.</p></fn><fn id="FN2"><p><sup>2</sup>The domains of GENIA and AIMed are not exactly the same, because they are collected independently from PubMed.</p></fn></fn-group><ref-list><title>References</title><ref id="B1"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Airola</surname><given-names>A</given-names></name><etal/></person-group><article-title>A graph kernel for protein-protein interaction extraction.</article-title><source>Proceedings of BioNLP.</source><year>2008</year><publisher-name>Columbus</publisher-name><fpage>1</fpage><lpage>9</lpage></citation></ref><ref id="B2"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Bikel</surname><given-names>DM</given-names></name></person-group><article-title>Intricacies of Collins' parsing model</article-title><source>Comput. Linguist.</source><year>2004</year><volume>30</volume><fpage>479</fpage><lpage>511}</lpage></citation></ref><ref id="B3"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Bunescu</surname><given-names>R</given-names></name><name><surname>Mooney</surname><given-names>RJ</given-names></name></person-group><article-title>Collective information extraction with relational markov networks.</article-title><source>Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics.</source><year>2004</year><publisher-loc>Barcelona</publisher-loc><fpage>439</fpage><lpage>446</lpage></citation></ref><ref id="B4"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Bunescu</surname><given-names>RC</given-names></name><name><surname>Mooney</surname><given-names>RJ</given-names></name></person-group><article-title>Subsequence kernels for relation extraction.</article-title><source>Proceedings of the 19th Annual Conference on Neural Information Processing Systems.</source><year>2005</year><publisher-loc>Vancouver</publisher-loc></citation></ref><ref id="B5"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Bunescu</surname><given-names>RC</given-names></name><etal/></person-group><article-title>Comparative experiments on learning information extractors for proteins and their interactions</article-title><source>Artif. Intell. Med.</source><year>2005</year><volume>33</volume><fpage>139</fpage><lpage>155</lpage><pub-id pub-id-type="pmid">15811782</pub-id></citation></ref><ref id="B6"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Charniak</surname><given-names>E</given-names></name></person-group><article-title>A maximum-entropy-inspired parser.</article-title><source>Proceedings of the First Conference on North American Chapter of the Association for Computational Linguistics.</source><year>2000</year><publisher-loc>Seattle</publisher-loc><fpage>132</fpage><lpage>139</lpage></citation></ref><ref id="B7"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Charniak</surname><given-names>E</given-names></name><name><surname>Johnson</surname><given-names>M</given-names></name></person-group><article-title>Coarse-to-fine n-best parsing and MaxEnt discriminative reranking.</article-title><source>Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics.</source><year>2005</year><publisher-name>Ann Arbor</publisher-name></citation></ref><ref id="B8"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Clegg</surname><given-names>AB</given-names></name><name><surname>Shepherd</surname><given-names>AJ</given-names></name></person-group><article-title>Benchmarking natural-language parsers for biological applications using dependency graphs</article-title><source>BMC Bioinformatics</source><year>2007</year><volume>8</volume><fpage>24</fpage><pub-id pub-id-type="pmid">17254351</pub-id></citation></ref><ref id="B9"><citation citation-type="book"><person-group person-group-type="author"><name><surname>de Marneffe</surname><given-names>M-C</given-names></name><etal/></person-group><article-title>Generating typed dependency parses from phrase structure parses.</article-title><source>Proceedings of the Fifth International Conference on Language Resources and Evaluation.</source><year>2006</year><publisher-loc>Genoa</publisher-loc></citation></ref><ref id="B10"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Eisner</surname><given-names>JM</given-names></name></person-group><article-title>Three new probabilistic models for dependency parsing: an exploration.</article-title><source>Proceedings of the 16th International Conference on Computational Linguistics.</source><year>1996</year><publisher-loc>Copenhagen</publisher-loc></citation></ref><ref id="B11"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Erkan</surname><given-names>G</given-names></name><etal/></person-group><article-title>Semi-supervised classification for extracting protein interaction sentences using dependency parsing.</article-title><source>Proceedings of the 2007 Conference on Empirical Methods in Natural Language Processing and Conference on Computational Natural Language Learning.</source><year>2007</year><publisher-loc>Prague</publisher-loc></citation></ref><ref id="B12"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Fundel</surname><given-names>K</given-names></name><etal/></person-group><article-title>RelEx &#x02014; relation extraction using dependency parse trees</article-title><source>Bioinformatics</source><year>2007</year><volume>23</volume><fpage>365</fpage><lpage>371</lpage><pub-id pub-id-type="pmid">17142812</pub-id></citation></ref><ref id="B13"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Giuliano</surname><given-names>C</given-names></name><etal/></person-group><article-title>Exploiting shallow linguistic information for relation extraction from biomedical literature.</article-title><source>Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics.</source><year>2006</year><publisher-name>Trento</publisher-name></citation></ref><ref id="B14"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Hara</surname><given-names>T</given-names></name><etal/></person-group><article-title>Evaluating impact of re-training a lexical disambiguation model on domain adaptation of an HPSG parser.</article-title><source>Proceedings of the 10th International Conference on Parsing Technology.</source><year>2007</year><publisher-loc>Prague</publisher-loc></citation></ref><ref id="B15"><citation citation-type="book"><person-group person-group-type="editor"><name><surname>Hirschman</surname><given-names>L</given-names></name><etal/></person-group><source>Proceeding of Second BioCreative Challenge Evaluation Workshop.</source><year>2007</year><publisher-loc>Madrid</publisher-loc><publisher-name>Centro Nacional de Investigaciones Oncologicas</publisher-name></citation></ref><ref id="B16"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Johansson</surname><given-names>R</given-names></name><name><surname>Nugues</surname><given-names>P</given-names></name></person-group><article-title>Extended constituent-to-dependency conversion for English.</article-title><source>Proceedings of the 16th Nordic Conference of Computational Linguistics.</source><year>2007</year><publisher-loc>Tartu</publisher-loc></citation></ref><ref id="B17"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Katrenko</surname><given-names>S</given-names></name><name><surname>Adriaans</surname><given-names>P</given-names></name></person-group><article-title>Learning relations from biomedical corpora using dependency trees.</article-title><source>Proceedings of the First International Workshop on Knowledge Discovery and Emergent Complexity in Bioinformatics.</source><year>2006</year><publisher-loc>Ghent</publisher-loc><fpage>61</fpage><lpage>80</lpage></citation></ref><ref id="B18"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>J-D</given-names></name><etal/></person-group><article-title>Introduction to the bio-entity recognition task at JNLPBA.</article-title><source>Proceedings of the Joint Workshop on Natural Language Processing in Biomedicine and its Applications.</source><year>2004</year><publisher-loc>Geneva</publisher-loc><fpage>70</fpage><lpage>75</lpage></citation></ref><ref id="B19"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>S</given-names></name><etal/></person-group><article-title>Kernel approaches for genic interaction extraction</article-title><source>Bioinformatics</source><year>2008</year><volume>24</volume><fpage>118</fpage><lpage>126</lpage><pub-id pub-id-type="pmid">18003645</pub-id></citation></ref><ref id="B20"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Klein</surname><given-names>D</given-names></name><name><surname>Manning</surname><given-names>CD</given-names></name></person-group><article-title>Accurate unlexicalized parsing.</article-title><source>Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics.</source><year>2003</year><publisher-loc>Sapporo</publisher-loc></citation></ref><ref id="B21"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Kulick</surname><given-names>S</given-names></name><etal/></person-group><article-title>Integrated annotation for biomedical information extraction.</article-title><source>Proceedings of Biolink 2004: Linking Biological Literature, Ontologies and Databases.</source><year>2004</year><publisher-loc>Granada</publisher-loc></citation></ref><ref id="B22"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Marcus</surname><given-names>M</given-names></name><etal/></person-group><article-title>Building a large annotated corpus of English: The Penn Treebank</article-title><source>Comput. Linguist.</source><year>1994</year><volume>19</volume><fpage>313</fpage><lpage>330</lpage></citation></ref><ref id="B23"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Matsuzaki</surname><given-names>T</given-names></name><name><surname>Tsujii</surname><given-names>J</given-names></name></person-group><article-title>Comparative parser performance analysis across grammar frameworks through automatic tree conversion using synchronous grammars.</article-title><source>Proceedings of the 22nd International Conference on Computational Linguistics.</source><year>2008</year><publisher-loc>Manchester</publisher-loc></citation></ref><ref id="B24"><citation citation-type="book"><person-group person-group-type="author"><name><surname>McDonald</surname><given-names>R</given-names></name><name><surname>Pereira</surname><given-names>F</given-names></name></person-group><article-title>Online learning of approximate dependency parsing algorithms.</article-title><source>Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics.</source><year>2006</year><publisher-loc>Trento</publisher-loc></citation></ref><ref id="B25"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Mitsumori</surname><given-names>T</given-names></name><etal/></person-group><article-title>Extracting protein-protein interaction information from biomedical text with SVM</article-title><source>IEICE Trans. Inf. Syst.</source><year>2006</year><volume>E89-D</volume><fpage>2464</fpage><lpage>2466</lpage></citation></ref><ref id="B26"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Miyao</surname><given-names>Y</given-names></name><name><surname>Tsujii</surname><given-names>J</given-names></name></person-group><article-title>Feature forest models for probabilistic HPSG parsing</article-title><source>Comput. Linguist.</source><year>2008</year><volume>34</volume><fpage>35</fpage><lpage>80</lpage></citation></ref><ref id="B27"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Miyao</surname><given-names>Y</given-names></name><etal/></person-group><article-title>Task-oriented evaluation of syntactic parsers and their representations.</article-title><source>Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies.</source><year>2008</year><publisher-name>Columbus</publisher-name></citation></ref><ref id="B28"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Moschitti</surname><given-names>A</given-names></name></person-group><article-title>Making tree kernels practical for natural language processing.</article-title><source>Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics.</source><year>2006</year><publisher-loc>Trento</publisher-loc></citation></ref><ref id="B29"><citation citation-type="book"><person-group person-group-type="author"><name><surname>N&#x000e9;dellec</surname><given-names>C</given-names></name></person-group><article-title>Learning language in logic &#x02014; genic interaction extraction challenge.</article-title><source>Proceedings of the Fourth Learning Language in Logic Workshop.</source><year>2005</year><publisher-loc>Bonn</publisher-loc></citation></ref><ref id="B30"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Nivre</surname><given-names>J</given-names></name><etal/></person-group><article-title>The CoNLL 2007 shared task on dependency parsing.</article-title><source>Proceedings of the 2007 Conference on Empirical Methods in Natural Language Processing and Conference on Computational Natural Language Learning.</source><year>2007</year><publisher-loc>Prague</publisher-loc><fpage>915</fpage><lpage>932</lpage></citation></ref><ref id="B31"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Petrov</surname><given-names>S</given-names></name><name><surname>Klein</surname><given-names>D</given-names></name></person-group><article-title>Improved inference for unlexicalized parsing.</article-title><source>Proceedings of the Human Language Technologies: The Annual Conference of the North American Chapter of the Association for Computational Linguistics.</source><year>2007</year><publisher-loc>Rochester</publisher-loc></citation></ref><ref id="B32"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Pollard</surname><given-names>C</given-names></name><name><surname>Sag</surname><given-names>IA</given-names></name></person-group><source>Head-Driven Phrase Structure Grammar.</source><year>1994</year><publisher-loc>Chicago</publisher-loc><publisher-name>University of Chicago Press</publisher-name></citation></ref><ref id="B33"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Pyysalo</surname><given-names>S</given-names></name><etal/></person-group><article-title>BioInfer: a corpus for information extraction in the biomedical domain</article-title><source>BMC Bioinformatics</source><year>2007a</year><volume>8</volume><fpage>50</fpage><pub-id pub-id-type="pmid">17291334</pub-id></citation></ref><ref id="B34"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Pyysalo</surname><given-names>S</given-names></name><etal/></person-group><article-title>On the unification of syntactic annotations under the Stanford dependency scheme: a case study on BioInfer and GENIA.</article-title><source>Proceedings of BioNLP.</source><year>2007b</year><publisher-loc>Prague</publisher-loc><fpage>25</fpage><lpage>32</lpage></citation></ref><ref id="B35"><citation citation-type="book"><person-group person-group-type="author"><name><surname>S&#x000e6;tre</surname><given-names>R</given-names></name><etal/></person-group><article-title>Syntactic features for protein-protein interaction extraction.</article-title><source>Proceedings of the 2nd International Symposium on Languages in Biology and Medicine.</source><year>2007</year><publisher-loc>Singapore</publisher-loc></citation></ref><ref id="B36"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Sagae</surname><given-names>K</given-names></name><name><surname>Tsujii</surname><given-names>J</given-names></name></person-group><article-title>Dependency parsing and domain adaptation with LR models and parser ensembles.</article-title><source>Proceedings of the 2007 Conference on Empirical Methods in Natural Language Processing and Conference on Computational Natural Language Learning.</source><year>2007</year><publisher-loc>Prague</publisher-loc></citation></ref><ref id="B37"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Sagae</surname><given-names>K</given-names></name><etal/></person-group><article-title>Challenges in mapping of syntactic representations for framework-independent parser evaluation.</article-title><source>the Workshop on Automated Syntatic Annotations for Interoperable Language Resources.</source><year>2008a</year><publisher-loc>Hong Kong</publisher-loc></citation></ref><ref id="B38"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Sagae</surname><given-names>K</given-names></name><etal/></person-group><article-title>Evaluating the effects of treebank size in a practical application for parsing.</article-title><source>Proceedings of the ACL-08 workshop on Software Engineering, Testing, and Quality Assurance for Natural Language Processing.</source><year>2008b</year><publisher-name>Columbus</publisher-name></citation></ref><ref id="B39"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Tateisi</surname><given-names>Y</given-names></name><etal/></person-group><article-title>Syntax annotation for the GENIA corpus.</article-title><source>Proceedings of the Second International Joint Conference on Natural Language Processing: Companion Volume Including Posters/Demos and Tutorial Abstracts.</source><year>2005</year><publisher-name>Jeju</publisher-name></citation></ref><ref id="B40"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Tsuruoka</surname><given-names>Y</given-names></name><etal/></person-group><article-title>Developing a robust part-of-speech tagger for biomedical text.</article-title><source>10th Panhellenic Conference on Informatics.</source><year>2005</year><publisher-loc>Volos</publisher-loc></citation></ref><ref id="B41"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Yakushiji</surname><given-names>A</given-names></name><etal/></person-group><article-title>Biomedical information extraction with predicate-argument structure patterns.</article-title><source>First International Symposium on Semantic Mining in Biomedicine.</source><year>2005</year><publisher-loc>Hinxton</publisher-loc></citation></ref><ref id="B42"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Yeh</surname><given-names>A</given-names></name><etal/></person-group><article-title>BioCreAtIvE task 1A: gene mention finding evaluation</article-title><source>BMC Bioinformatics</source><year>2005</year><volume>6</volume><issue>Suppl. 1</issue><fpage>S2</fpage><pub-id pub-id-type="pmid">15960832</pub-id></citation></ref></ref-list></back></article>