<?xml-stylesheet type="text/xsl" href="ViewNLM-v2.3.xsl"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd"><article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="review-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">J Educ Eval Health Prof</journal-id><journal-id journal-id-type="publisher-id">JEEHP</journal-id><journal-title-group><journal-title>Journal of Educational Evaluation for Health Professions</journal-title></journal-title-group><issn pub-type="epub">1975-5937</issn><publisher><publisher-name>National Health Personnel Licensing Examination Board of the Republic of Korea</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">19224002</article-id><article-id pub-id-type="pmc">2631201</article-id><article-id pub-id-type="doi">10.3352/jeehp.2007.4.1</article-id><article-categories><subj-group subj-group-type="heading"><subject>Review</subject></subj-group></article-categories><title-group><article-title>Reconsidering the Cut Score of Korean National Medical Licensing Examination</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Ahn</surname><given-names>Duck Sun</given-names></name><xref ref-type="aff" rid="A1"/></contrib><contrib contrib-type="author"><name><surname>Ahn</surname><given-names>Sowon</given-names></name><xref ref-type="aff" rid="A1"/></contrib></contrib-group><aff id="A1">Department of Medical Education, College of Medicine, Korea University, Seoul, Korea.</aff><author-notes><corresp>Corresponding: <email>dsahn@korea.ac.kr</email></corresp></author-notes><pub-date pub-type="collection"><year>2007</year></pub-date><pub-date pub-type="epub"><day>28</day><month>4</month><year>2007</year></pub-date><volume>4</volume><elocation-id>1</elocation-id><history><date date-type="received"><day>10</day><month>2</month><year>2007</year></date><date date-type="accepted"><day>16</day><month>4</month><year>2007</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2007, National Health Personnel Licensing Examination Board of the Republic of Korea</copyright-statement><copyright-year>2007</copyright-year><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.0/"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><abstract><p>After briefly reviewing theories of standard setting we analyzed the problems of the current cut scores. Then, we reported the results of need assessment on the standard setting among medical educators and psychometricians. Analyses of the standard setting methods of developed countries were reported as well. Based on these findings, we suggested the Bookmark and the modified Angoff methods as alternative methods for setting standard. Possible problems and challenges were discussed when these methods were applied to the National Medical Licensing Examination.</p></abstract><kwd-group><kwd>Cut Score</kwd><kwd>Standard Setting</kwd><kwd>Bookmark Method</kwd><kwd>Modified Angoff Method</kwd><kwd>Psychometrics</kwd></kwd-group></article-meta></front><body><sec sec-type="intro"><title>INTRODUCTION</title><p>Recently the need for reliable and valid licensing examinations for health personnel is increasing in importance in Korea. This is due to its direct relation to the quality of health personnel and subsequently the nation's health. The National Health Personnel Licensing Examination Board (NHPLEB) currently uses a cut score of 60-40% (which means 60% correct responses of overall tests and 40% correct responses of each subject) as a license requirement. These cut scores have been applied to various national examinations in Korea and are regarded as reasonable. From the perspective of psychometrics, however, it is not a valid way to set a cut score, especially for a licensing examination that is intended to discern those who acquire minimum competence from those who do not.</p><p>In this review, we first examined theories of standard setting and analyzed problems of the current cut scores. Then, we reported the results of need assessment on the standard setting among medical educators and psychometricians. Analyses of the standard setting methods of developed countries were reported as well. Based on these findings, we suggested new methods of standard setting and discussed possible problems and challenges when applied to National Medical Licensing Examination (NMLE).</p></sec><sec><title>THEORIES OF SETTING CUT SCORES</title><p>A cut score indicates the minimum level of knowledge or skill that a candidate must have acquired to perform health professions. Cut scores are professionally expressed value on candidates' competency, which reflects educational philosophy and consensus among those related. This means that setting cut scores should be understood not as a mathematical technique but as a complex policy-making process.</p><p>Setting cut scores usually progresses as follows: 1) Deciding on the type of standard (absolute vs. relative standards), 2) Deciding on the method for setting standards, 3) Selecting the judges, 4) Holding the standard setting meeting, 5) Calculating the standard, 6) Checking the results [<xref ref-type="bibr" rid="B1">1</xref>].</p><p>There are several methods to set standards. Generally accepted methods are as follows; contrasting groups method, borderline group method, Nedelsky's method, Angoff's method, Ebel's method, and so on (for details, refer to [<xref ref-type="bibr" rid="B2">2</xref>]). Among these, the Angoff method had been the most popular method used for multiple-choice tests by the 1990s [<xref ref-type="bibr" rid="B3">3</xref>]. However, this method has a fundamental drawback, which is that it is practically impossible to estimate the probability that a minimally acceptable person would answer each item correctly. To accommodate this drawback, several modifications were suggested, one of which will be described in detail later in this paper.</p></sec><sec><title>ISSUES WITH CURRENT CUT SCORES</title><p>The current 60-40% system was arbitrarily set under Japanese colonial rule, with no educational and philosophical basis. In addition, it can result in gross misclassification, such as the unfortunate failure of the competent and the fortunate pass of the non-competent depending on test difficulty.</p><p><xref ref-type="table" rid="T1">Table 1</xref> clearly demonstrates this phenomenon. In <xref ref-type="table" rid="T1">Table 1</xref>,the pass rate is approximately 95%. However, the pass rates of 2001 and 2003 drop to approximately 85%, lower than other years. Though not shown in <xref ref-type="table" rid="T1">Table 1</xref>, the pass rate of 1995 and 1996 was about 70%, a rate that brought mass confusion among examinees.</p><p>In principle, the difficulty of criterion-referenced test such as licensing examination is not adjusted before examination in consideration of optimal passing rate. In Korea, it is not practically possible to adjust the degree of difficulty in advance due to the drainage of test items. Instead, examiners are expected to make good questions asking basic knowledge and skill that are required to perform health professions. Since the current 60-40% criterion does not reflect this minimum level of competence, it should be changed.</p></sec><sec><title>RESULTS OF NEED ASSESSMENT</title><p>Surveys were conducted to gather input from psychometricians, medical educators, and examiners. There were 38 respondents for the survey, and it was carried out from Januray 7th to 12th in 2005. We asked whether and why they thought the current cut score was valid and their suggestions for improvement. The results are in <xref ref-type="table" rid="T2">Table 2</xref>.</p><p>The followings are suggestions for improvement. First, most of the respondents believed that absolute evaluation should be retained. To do so, transformed scores can be a viable alternative. Second, examination objectives should be developed. Third, investment in faculty training for the item development is required. Fourth, scientific and systematic methodology is needed to analyze test items, to control the degree of difficulty. Fifth, item bank should hold more realistic items. Sixth, there should be flexibility in setting the cut score. For example, the Angoff method provides such flexibility. Finally, the cut score should be set under the agreement among stakeholders such as NHPLEB, medical representatives, and so on.</p></sec><sec><title>STANDARD SETTING METHODS OF THE DEVELOPED COUNTRIES</title><p>We analyzed the standard setting methods of several developed countries. The results are summarized in <xref ref-type="table" rid="T3">Table 3</xref>. From the table, we can see that the basic principles of standard setting are well maintained. That is, they stick to absolute standards, and put much effort into keeping the process of standard setting rational and reasonable. These results suggest Korea should adopt the standard setting method based on scientific methods of psychometrics.</p></sec><sec><title>SUGGESTIONS FOR STANDARD SETTING</title><p>We reached the agreement that Bookmark [<xref ref-type="bibr" rid="B4">4</xref>] and modified Angoff methods are appropriate considering the current situation in Korea. We intended to compare the two methods by applying them to real tests to increase the accuracy and validity of the results of the present study. However, we encountered a few realistic problems in carrying out such an empirical study. First, as a rule the NHPLEB does not release previous test items. Second, when releasing test items, the NHPLEB requested the research be carried out in the presence of NHPLEB personnel, which was not possible in terms of the time and resources allocated to this research. We therefore did not carry out an empirical study but instead described the process of the two methods. Both methods were recently applied to National Assessment of Educational Achievement in Korea.</p><sec><title>The bookmark method</title><p>In 2002, the Bookmark standard setting was applied to discern those who achieved basic competency from those who did not among 3rd year elementary school students. It was the first application of the Bookmark method in Korea. The method allows a standard setting panel to be accustomed to the characteristics of the test and provides the panel with the results of standard application. The panel consists of subject experts. For example, the panel for setting national basic performance level in reading consists of professors of Korean language education, experienced teachers and researchers, administrators, and parents. The Bookmark method proceeds as follows [<xref ref-type="bibr" rid="B5">5</xref>].</p><p>      <list list-type="simple"><list-item><p>a) The panel received an ordered item booklet (OIB), which lists items in order of difficulty, from the easiest to the hardest. To make the OIB, item response theory (IRT) was applied and 2/3 probability of correct response was used as a scale score to represent examinee ability.</p></list-item><list-item><p>b) The panel was divided into small groups-typically groups of six to eight people. In small groups, the panel examined each item in the OIB and discussed knowledge and skills required to answer the item correctly.</p></list-item><list-item><p>c) After the group discussion, each panelist determined a cut score by placing a bookmark in the OIB based on his or her own judgment of what students with basic performance level should know and be able to do. The scale score of the marked item was the first demarcation.</p></list-item><list-item><p>d) The panel engaged in the small group discussion again to compromise differences in their opinions. The panelists then marked their choice on the OIB, which was the second demarcation.</p></list-item><list-item><p>e) Two small groups were combined into a mid-sized group to prevent one specific individual from dominating the discussion in small groups. After the group discussion, the panel was given another opportunity to change their choice and placed the bookmark on the OIB.</p></list-item><list-item><p>f) Finally, all panelists gathered in one place and discussed their choice of bookmarks. After the discussion, they were given a final opportunity to change their choice. They then placed the final bookmark on the OIB.</p></list-item><list-item><p>g) All the bookmark placements in the final round were gathered and the median was calculated to set the panel's recommended cut score.</p></list-item><list-item><p>h) Based on the cut score, the panel examined the items before the bookmark and wrote performance-level descriptors that represent a summary of the knowledge, skills, and abilities that students with the basic performance level must be able to demonstrate.</p></list-item></list>   </p><p>The bookmark method compensates for the drawback of the Angoff's method, which is that the panel cannot correctly estimate item difficulty. In addition, people with little psychometric knowledge can understand the meaning and implication of the cut score because the bookmark method provides performance-level descriptors. Considering these theoretical merits, combined with the practical application of the method to the diagnostic assessment of the 3rd year elementary students, the bookmark method can be a viable alternative in setting the standard of national medical licensing examination.</p></sec><sec><title>Modified angoff</title><p>In the original Angoff method, there was no details of how to run an operational cut score study. Due to the lack of specificity in the original method, many modifications were suggested. The following is a general process of modified Angoff methods.</p><p>      <list list-type="simple"><list-item><p>a) The choice of a panel: Generally, the panel consists of subject experts, teachers, related administrators, and so on. In case of medical licensing examination, the panel may include doctors and professors of basic science and clinic, medical administrators, and so on. The panel should be content experts and know well the characteristics of examinees. There are diverse opinions on the appropriate number of the panel, but at least 10 panelists are required, while 15~20 panelists are ideal [<xref ref-type="bibr" rid="B6">6</xref>-<xref ref-type="bibr" rid="B9">9</xref>].</p></list-item><list-item><p>b) Achievement Level Description (ALD): Conceptualizing achievement level starts from policy definition. Government agency such as the Ministry of Education &#x00026; Human Resources Development or the Ministry of Health &#x00026; Welfare provides a policy definition of achievement levels. Based on this policy definition, the panel discusses and describes performance of each level. This description specifies what students at each level should know and be able to do in terms of knowledge, skills, and behaviors and provides an operational definition. Exemplary items can be provided as well. To save time, the facilitator may provide preliminary ALD with the panel, so that the panel starts to set the standard with some consensus on the characteristics of a borderline group.</p></list-item><list-item><p>c) Practice: The panel practices with exemplary items. In case different types of items are mixed, they practice with each type of item. Especially for performance item, actual performance data should be provided, so that the panel can get a sense of the level of examinees.</p></list-item><list-item><p>d) The first round of estimation: The panel is divided into small groups of three or four people. The panel solves actual items on the exam. After solving the exam, they check their answers with correct ones. Then, they estimate the probability of correct answers of a borderline group of examinees for each item. After individual estimation, the results are collected and the cut score is set at the sum of medians of each item. The cut score is posted and the result of cut score application is provided, so that the panel has opportunity to check whether it is realistic and change it if necessary.</p></list-item><list-item><p>e) The second round of estimation: The panel is divided into mid-sized groups. Based on ADL and their experiences at the first round, they exchange their opinions. Then, they estimate the probability of correct answer of a borderline group of examinees for each item.</p></list-item><list-item><p>f) The third round of estimation: All the panelists gather at one place and discuss. The focus is on the items showing large deviations. After the discussion, they make third estimations. The results are collected and posted. If the third round is enough, the cut point obtained at the third round becomes the final cut score. The cut score is transformed into a scale score.</p></list-item><list-item><p>g) Description of minimum competency: If required, the panel writes what students at each level are able to do by analyzing items and students' response to the items.</p></list-item></list></p><p>The modified Angoff method is widely used in foreign counties. The method has been applied to National Assessment of Educational Achievement since 2003 by Korea Institute of Curriculum &#x00026; Evaluation (for details, see [<xref ref-type="bibr" rid="B10">10</xref>]). Since it is based on experts' judgments and psychometric methods, the use of this method in setting the standard by the NHPLEB may enhance its expertise. In addition, the NHPLEB may be better prepared for any action taken by examinees who feel the cut score is unfair, because the method provides firm rationale behind the cut score.</p></sec><sec><title>Bookmark vs. Modified Angoff Methods</title><p>The two methods are compared in terms of process, time and cost, and advantages and disadvantages. The results are shown in <xref ref-type="table" rid="T4">Table 4</xref>. Comparing all these aspects, the Bookmark method is more recommended than the modified Angoff method theoretically. However, the modified Angoff method seems more realistic in Korea considering that IRT cannot be applied to the NMLE.</p></sec></sec><sec><title>PRACTICAL ISSUES IN APPLYINGTHE METHODS</title><p>For the Bookmark and modified Angoff methods to be applied, there are a few practical issues to consider.</p><p>Need for committee: In a test-centered approach in setting the standards, there should be a committee for each subject. Since there are three subjects in NMLE, three committees are required. If twenty members are set for each committee, 60 members are in need, which would incur considerable costs. Insufficient budgeting, and consequent insufficient committee size, can lead to the loss of validity in setting the standard.</p><p>Need for psychometric analysis: Both methods recommended in the present paper are based on scientific analysis of psychometrics. Therefore, to apply the methods, classical item analysis and IRT should be applied in advance. For example, OIB in the Bookmark method requires pre-analysis based on IRT. The OIB costs extra time and cost, but it lessens the burden of the panel.</p><p>Need for extra cost: To apply a scientific and valid method,extra cost is inevitable.</p><p>No need for amendment of medical law: A question arises as to the need for amendment of medical law with a new standard setting method. However, the current law can be maintained even with a new method. One way to do so is to transform raw scores to scale scores. In <xref ref-type="fig" rid="F1">Fig. 1</xref>, the cut score of raw scores is 250, which is transformed to 60. If amendment of the law can be done without much argument, changing the current law is another way to deal with legal issues.</p><p>Test equating method: In general, the cut score is not set every year. Instead, a statistical technique is applied to make different tests comparable. This is called test equating [<xref ref-type="bibr" rid="B11">11</xref>, <xref ref-type="bibr" rid="B12">12</xref>]. If tests are equated, the same cut score can be used continuously. However, it is not practically possible in Korea to apply test equating methods due to a drainage of test items. In this case, where the cut score is set every year, comparison of cut scores across different years would be reasonable.</p></sec><sec sec-type="conclusions"><title>CONCLUSION</title><p>In the present paper, we attempted to suggest a valid and reasonable way to set the cut score of the NMLE. Based on the review of various theories, the need assessment, and the results of the analyses of foreign countries' systems, we suggested the Bookmark and the modified Angoff methods as viable alternatives to the current system. To apply these new methods, several issues must be resolved beforehand. First, the philosophical meaning of licensing examination itself should be reconsidered. Under the current fixed cut score, test difficulty should be adjusted in advance in order to prevent a radical change in pass rates, which violates the concept of licensing or certifying examinations.</p><p>Second, philosophical reconsideration of the standard setting is required. The current 60-40% was set without any philosophical or educational rationale. Therefore, we need to set the cut score based on the meaning and philosophy of license examination.</p><p>Third, the issue of security and copyright of test items should be resolved. Currently, the NHPLEB as a rule does not release test items. However, examinees release the items to their peers after their examination, making it possible to almost restore the original test. This is obviously infringement of copyright. In Korea, however, this kind of act is not regarded as serious and those related show no moral remorse. This common practice of plagiarism should be controlled in the near future.</p><p>We hope our research facilitates the discussion of the standard setting in Korea, and contributes to produce competent medical professionals.</p></sec></body><back><fn-group><fn fn-type="other"><p>This article is available from: <ext-link ext-link-type="uri" xlink:href="http://jeehp.org/">http:// jeehp.org/</ext-link></p></fn></fn-group><ack><title>ACKNOWLEDGEMENTS</title><p>Support for this research was provided by National Health Personnel Licensing Examination Board of Korea.</p></ack><ref-list><ref id="B1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Norcini</surname><given-names>JJ</given-names></name></person-group><article-title>Setting standards on educational tests</article-title><source>Med Educ</source><year>2003</year><volume>37</volume><fpage>464</fpage><lpage>469</lpage><pub-id pub-id-type="pmid">12709190</pub-id></element-citation></ref><ref id="B2"><label>2</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Zieky</surname><given-names>MJ</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Cizek</surname><given-names>GJ</given-names></name></person-group><article-title>So much has changed: How the setting of cutscores has evolved since the 1980s</article-title><source>Setting per formance standards</source><year>2001</year><publisher-loc>Mahwah (NJ)</publisher-loc><publisher-name>Lawrence Erlbaum Assoociates</publisher-name><fpage>19</fpage><lpage>52</lpage></element-citation></ref><ref id="B3"><label>3</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Mehrens</surname><given-names>WA</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Crocker</surname><given-names>L</given-names></name><name><surname>Zieky</surname><given-names>M</given-names></name></person-group><article-title>Methodological issues in standard setting for educational exams</article-title><source>Proceedings of Joint Conference on Standard Setting for Large-Scale Assessments</source><year>c2005</year><conf-date>1994 Oct 5-7</conf-date><conf-loc>Washington, DC</conf-loc><publisher-loc>Washington, DC</publisher-loc><publisher-name>U.S. Government Printing Office</publisher-name><fpage>221</fpage><lpage>263</lpage></element-citation></ref><ref id="B4"><label>4</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Lewis</surname><given-names>DM</given-names></name><name><surname>Mitzel</surname><given-names>HC</given-names></name><name><surname>Green</surname><given-names>DR</given-names></name></person-group><article-title>Standard setting: a bookmark approach</article-title><source>IRT-based standard setting procedures utilizing behavioral anchoring. The 1996 Council of Chief State School Officers National Conference on Large-Scale Assessment</source><conf-date>1996 June</conf-date><conf-loc>Pheonix, AZ</conf-loc></element-citation></ref><ref id="B5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>G</given-names></name></person-group><article-title>A psychometric approach to setting a passing score on Korean National Medical Licensing Examination</article-title><source>J Educ Eval Health Prof</source><year>2004</year><volume>1</volume><fpage>5</fpage><lpage>14</lpage></element-citation></ref><ref id="B6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mehrens</surname><given-names>WA</given-names></name><name><surname>Popham</surname><given-names>WJ</given-names></name></person-group><article-title>How to evaluate the legal defensibility of high-stakes tests</article-title><source>Appl Meas Educ</source><year>1992</year><volume>5</volume><fpage>265</fpage><lpage>283</lpage></element-citation></ref><ref id="B7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cizek</surname><given-names>GJ</given-names></name></person-group><article-title>An NCME instructional module on: Setting passing scores</article-title><source>Educa Meas: Issues Pract</source><year>1996</year><volume>15</volume><issue>2</issue><fpage>20</fpage><lpage>31</lpage></element-citation></ref><ref id="B8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Norcini</surname><given-names>JJ</given-names></name><name><surname>Shea</surname><given-names>JA</given-names></name></person-group><article-title>The credibility and comparability of standards</article-title><source>Appl Meas Educ</source><year>1997</year><volume>10</volume><fpage>39</fpage><lpage>59</lpage></element-citation></ref><ref id="B9"><label>9</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Zieky</surname><given-names>MJ</given-names></name><name><surname>Livingston</surname><given-names>SA</given-names></name></person-group><source>Manual for setting standards on the basic skills assessment tests</source><year>1977</year><publisher-loc>Princeton (NJ)</publisher-loc><publisher-name>Educational Testing Service</publisher-name></element-citation></ref><ref id="B10"><label>10</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Bahn</surname><given-names>JC</given-names></name></person-group><article-title>Scale and test equating of National Assessment of Educational Achievement</article-title><source>2004 Annual Fall Meeting of the Korean Society for the Study of Education</source><conf-date>2004 October 29-30</conf-date><conf-loc>Daejeon, KR</conf-loc><comment>Korean</comment></element-citation></ref><ref id="B11"><label>11</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kolen</surname><given-names>MJ</given-names></name><name><surname>Brennan</surname><given-names>RL</given-names></name></person-group><source>Test equating: methods and practices</source><year>1995</year><publisher-loc>New York (NY)</publisher-loc><publisher-name>Springer-Verlag</publisher-name></element-citation></ref><ref id="B12"><label>12</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>G</given-names></name><name><surname>Lewis</surname><given-names>DM</given-names></name></person-group><article-title>A generalizability theory approach toward estimating standard errors of cut scores set using the Bookmark standard setting procedure</article-title><source>2001 annual meeting of the National Council on Measurement in Education</source><conf-date>2001 April 11-13</conf-date><conf-loc>Seattle, WA</conf-loc></element-citation></ref></ref-list></back><floats-group><fig id="F1" position="float"><label>Fig. 1</label><caption><p>An example of the application of the current 60% cut score.</p></caption><graphic xlink:href="jeehp-4-1-g001"/></fig><table-wrap id="T1" position="float"><label>Table 1</label><caption><p>Pass rate of Korean National Medical Licensing Examination</p></caption><graphic xlink:href="jeehp-4-1-i001"/></table-wrap><table-wrap id="T2" position="float"><label>Table 2</label><caption><p>Results of need assessment (N=38)</p></caption><graphic xlink:href="jeehp-4-1-i002"/></table-wrap><table-wrap id="T3" position="float"><label>Table 3</label><caption><p>Standard setting methods of the developed countries</p></caption><graphic xlink:href="jeehp-4-1-i003"/><table-wrap-foot><fn><p>OSCE: Objective Structured Clinical Examination; MCQ: Multiple Choice Questions.</p></fn></table-wrap-foot></table-wrap><table-wrap id="T4" position="float"><label>Table 4</label><caption><p>Comparison of the bookmark and modified Angoff methods</p></caption><graphic xlink:href="jeehp-4-1-i004"/><table-wrap-foot><fn><p>OIB: Ordered Item Booklet.</p></fn></table-wrap-foot></table-wrap></floats-group></article>