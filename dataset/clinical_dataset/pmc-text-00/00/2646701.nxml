<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN" "archivearticle.dtd"><article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id><journal-title>BMC Bioinformatics</journal-title><issn pub-type="epub">1471-2105</issn><publisher><publisher-name>BioMed Central</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">19178740</article-id><article-id pub-id-type="pmc">2646701</article-id><article-id pub-id-type="publisher-id">1471-2105-10-38</article-id><article-id pub-id-type="doi">10.1186/1471-2105-10-38</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title>On reliable discovery of molecular signatures</article-title></title-group><contrib-group><contrib id="A1" corresp="yes" contrib-type="author"><name><surname>Nilsson</surname><given-names>Roland</given-names></name><xref ref-type="aff" rid="I1">1</xref><xref ref-type="aff" rid="I2">2</xref><email>rnilsson@broad.mit.edu</email></contrib><contrib id="A2" contrib-type="author"><name><surname>Bj&#x000f6;rkegren</surname><given-names>Johan</given-names></name><xref ref-type="aff" rid="I2">2</xref><email>johan.bjorkegren@ki.se</email></contrib><contrib id="A3" contrib-type="author"><name><surname>Tegn&#x000e9;r</surname><given-names>Jesper</given-names></name><xref ref-type="aff" rid="I1">1</xref><xref ref-type="aff" rid="I2">2</xref><email>jesper.tegner@ki.se</email></contrib></contrib-group><aff id="I1"><label>1</label>Computational Biology, Department of Physics, Link&#x000f6;ping University, SE58183 Link&#x000f6;ping, Sweden</aff><aff id="I2"><label>2</label>Unit of Computational Medicine, King Gustav V Research Institute, Department of Medicine, Karolinska Institutet, SE17176 Stockholm, Sweden</aff><pub-date pub-type="collection"><year>2009</year></pub-date><pub-date pub-type="epub"><day>29</day><month>1</month><year>2009</year></pub-date><volume>10</volume><fpage>38</fpage><lpage>38</lpage><ext-link ext-link-type="uri" xlink:href="http://www.biomedcentral.com/1471-2105/10/38"/><history><date date-type="received"><day>2</day><month>4</month><year>2008</year></date><date date-type="accepted"><day>29</day><month>1</month><year>2009</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2009 Nilsson et al; licensee BioMed Central Ltd.</copyright-statement><copyright-year>2009</copyright-year><copyright-holder>Nilsson et al; licensee BioMed Central Ltd.</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.0"><p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/2.0"/>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</p><!--<rdf xmlns="http://web.resource.org/cc/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:dc="http://purl.org/dc/elements/1.1" xmlns:dcterms="http://purl.org/dc/terms"><Work xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:dcterms="http://purl.org/dc/terms/" rdf:about=""><license rdf:resource="http://creativecommons.org/licenses/by/2.0"/><dc:type rdf:resource="http://purl.org/dc/dcmitype/Text"/><dc:author>               Nilsson               Roland                                             rnilsson@broad.mit.edu            </dc:author><dc:title>            On reliable discovery of molecular signatures         </dc:title><dc:date>2009</dc:date><dcterms:bibliographicCitation>BMC Bioinformatics 10(1): 38-. (2009)</dcterms:bibliographicCitation><dc:identifier type="sici">1471-2105(2009)10:1&#x0003c;38&#x0003e;</dc:identifier><dcterms:isPartOf>urn:ISSN:1471-2105</dcterms:isPartOf><License rdf:about="http://creativecommons.org/licenses/by/2.0"><permits rdf:resource="http://web.resource.org/cc/Reproduction" xmlns=""/><permits rdf:resource="http://web.resource.org/cc/Distribution" xmlns=""/><requires rdf:resource="http://web.resource.org/cc/Notice" xmlns=""/><requires rdf:resource="http://web.resource.org/cc/Attribution" xmlns=""/><permits rdf:resource="http://web.resource.org/cc/DerivativeWorks" xmlns=""/></License></Work></rdf>--></license></permissions><abstract><sec><title>Background</title><p>Molecular signatures are sets of genes, proteins, genetic variants or other variables that can be used as markers for a particular phenotype. Reliable signature discovery methods could yield valuable insight into cell biology and mechanisms of human disease. However, it is currently not clear how to control error rates such as the false discovery rate (FDR) in signature discovery. Moreover, signatures for cancer gene expression have been shown to be unstable, that is, difficult to replicate in independent studies, casting doubts on their reliability.</p></sec><sec><title>Results</title><p>We demonstrate that with modern prediction methods, signatures that yield accurate predictions may still have a high FDR. Further, we show that even signatures with low FDR may fail to replicate in independent studies due to limited statistical power. Thus, neither stability nor predictive accuracy are relevant when FDR control is the primary goal. We therefore develop a general statistical hypothesis testing framework that for the first time provides FDR control for signature discovery. Our method is demonstrated to be correct in simulation studies. When applied to five cancer data sets, the method was able to discover molecular signatures with 5% FDR in three cases, while two data sets yielded no significant findings.</p></sec><sec><title>Conclusion</title><p>Our approach enables reliable discovery of molecular signatures from genome-wide data with current sample sizes. The statistical framework developed herein is potentially applicable to a wide range of prediction problems in bioinformatics.</p></sec></abstract></article-meta></front><body><sec><title>Background</title><p>Molecular signatures are sets of genes, mRNA transcripts, proteins, genetic variants or other variables that can be used as markers for a particular cell or tissue phenotype, such as a cancerous or diabetic state. Signatures have a two-fold purpose: they may be useful for disease diagnosis or risk assessment (<italic>prediction</italic>), but they may also implicate molecules not previously known to be involved in the underlying molecular pathology (<italic>discovery</italic>), as illustrated in Figure <xref ref-type="fig" rid="F1">1A</xref>. Signature discovery differs from simple correlation or differential expression testing in that molecular signatures may account for multivariate effects and consists only of the variables most directly correlated with given phenotype. The signature approach has been especially popular for cancer diagnosis based on gene expression profiling, and several studies have proposed signatures for specific cancer types [<xref ref-type="bibr" rid="B1">1</xref>-<xref ref-type="bibr" rid="B5">5</xref>]. A prominent example is the breast cancer signature discovered by van't Veer <italic>et al</italic>. [<xref ref-type="bibr" rid="B4">4</xref>], which is currently being validated in a clinical trial [<xref ref-type="bibr" rid="B6">6</xref>].</p><fig position="float" id="F1"><label>Figure 1</label><caption><p><bold>Signature discovery</bold>. Molecular signatures (1) are markers for a particular cell or tissue phenotype. Signatures are discovered from a given set of molecular profiles (e.g., gene expression profiles) together with phenotype labels (2). Signatures have dual uses, both as predictive models (3) and for discovery of molecular mechanisms (4). While it is well-known how to assess predictive accuracy (5), the method proposed herein is the first to control signature FDR (6), enabling reliably discovery.</p></caption><graphic xlink:href="1471-2105-10-38-1"/></fig><p>Unfortunately, existing computational approaches often fail to distinguish between the different objectives of prediction and discovery. If molecular signatures are to be used for discovery, then the primary objective is to control the false discovery rate (FDR) with respect to the optimal (true) signature. On the other hand, if the end goal is an accurate predictor, then the FDR of the gene signature is not important in itself. However, it has hitherto not been possible to directly address FDR control, since an operational definition of the optimal signature (a "gold standard") has not been available. Therefore, current methods for signature discovery resort to optimizing prediction accuracy, implicitly assuming that the FDR is thereby kept reasonably low, even though there is no <italic>a priori </italic>reason to assume that this is the case. Recently, the <italic>stability </italic>of a signature, that is, the expected overlap between signatures derived from replicated experiments, has been suggested as an alternative quality measure [<xref ref-type="bibr" rid="B7">7</xref>,<xref ref-type="bibr" rid="B8">8</xref>]. Signatures derived from cancer gene expression data have been found to be unstable, raising concerns that existing signature discovery methods may not be sound [<xref ref-type="bibr" rid="B9">9</xref>,<xref ref-type="bibr" rid="B10">10</xref>]. While the stability measure seems intuitively reasonable and cleverly avoids the gold standard problem, it has not been shown that low stability actually indicates high FDR.</p><p>In this paper, we build upon a recently discovered operational definition of the optimal signature to study the actual FDR in signature discovery. First, we demonstrate that high FDR can occur even with very accurate predictors. Therefore, current methods for signature discovery that focus on optimizing prediction accuracy offer no means of controlling the FDR. Second, we show that signatures can be highly unstable even when the FDR is kept low. Thus, reliable signature discovery may be possible in spite of the recent reports of unstable signatures in cancer [<xref ref-type="bibr" rid="B9">9</xref>,<xref ref-type="bibr" rid="B10">10</xref>]. Third, we propose a novel hypothesis testing procedure based on our definition of the optimal signature that for the first time directly addresses signature FDR. We show that our method achieves FDR control on simulated data. Application to well-known cancer data sets uncovers three novel molecular signatures for leukemia, colon and breast cancer.</p></sec><sec><title>Results</title><sec><title>The optimal signature</title><p>For simplicity, we will consider a two-class prediction setting throughout, although the methods could be generalized to other prediction problems as well. A <italic>predictor </italic>is then a function <italic>g </italic>:<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M1" name="1471-2105-10-38-i1" overflow="scroll"><mml:semantics><mml:mrow><mml:mi mathvariant="script">X</mml:mi><mml:mo>&#x021a6;</mml:mo><mml:mi mathvariant="script">Y</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula>, where we take <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M2" name="1471-2105-10-38-i2" overflow="scroll"><mml:semantics><mml:mi mathvariant="script">X</mml:mi></mml:semantics></mml:math></inline-formula> = &#x0211d;<sup><italic>n </italic></sup>and <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M3" name="1471-2105-10-38-i3" overflow="scroll"><mml:semantics><mml:mi mathvariant="script">Y</mml:mi></mml:semantics></mml:math></inline-formula> = {-1, +1}. The <italic>accuracy </italic>of a predictor <italic>g </italic>is 1 minus the probability of error or <italic>risk R</italic>(<italic>g</italic>) = <italic>P</italic>(<italic>g</italic>(<italic>X</italic>) &#x02260; <italic>Y</italic>). An optimal predictor, denoted <italic>g</italic>* is one with maximal accuracy. An optimal signature can be defined as a minimal set of variables <italic>S</italic>* such that the optimal predictor obtained using only these variables is at least as accurate as any predictor obtained with any other set, that is,</p><p><disp-formula id="bmcM1"><label>(1)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M4" name="1471-2105-10-38-i4" overflow="scroll"><mml:semantics><mml:mrow><mml:mo>&#x02200;</mml:mo><mml:mi>S</mml:mi><mml:mo>:</mml:mo><mml:mo>&#x02200;</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>:</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>g</mml:mi><mml:mrow><mml:msup><mml:mi>S</mml:mi><mml:mo>&#x02217;</mml:mo></mml:msup></mml:mrow><mml:mo>&#x02217;</mml:mo></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02264;</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:semantics></mml:math></disp-formula></p><p>where <italic>gS </italic>denotes a predictor on the subspace <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M5" name="1471-2105-10-38-i2" overflow="scroll"><mml:semantics><mml:mi mathvariant="script">X</mml:mi></mml:semantics></mml:math></inline-formula><sub><italic>S </italic></sub>of <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M6" name="1471-2105-10-38-i2" overflow="scroll"><mml:semantics><mml:mi mathvariant="script">X</mml:mi></mml:semantics></mml:math></inline-formula> corresponding to the variable set <italic>S</italic>. Unfortunately, this criterion does not yield a unique <italic>S</italic>* in general, and there are examples of data distributions such that no tractable (polynomial-time) algorithms exist for computing <italic>S</italic>* [[<xref ref-type="bibr" rid="B11">11</xref>], pp. 562]. Consequently, most research has focused on heuristic algorithms for discovering approximate signatures with near-optimal prediction accuracy [<xref ref-type="bibr" rid="B12">12</xref>].</p><p>While this approach has been largely successful at attaining good predictive accuracy, the lack of a "gold standard" has rendered direct evaluation of error rates for signature discovery algorithms impossible. To address this problem, we have recently shown [<xref ref-type="bibr" rid="B13">13</xref>] that using a mild restriction on the class of data distributions, the set <italic>S</italic>* becomes unique and can be expressed as</p><p><disp-formula id="bmcM2"><label>(2)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M7" name="1471-2105-10-38-i5" overflow="scroll"><mml:semantics><mml:mrow><mml:msup><mml:mi>S</mml:mi><mml:mo>&#x02217;</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mi>i</mml:mi><mml:mo>:</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>g</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>...</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>...</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>}</mml:mo></mml:mrow><mml:mo>&#x02217;</mml:mo></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x0003e;</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>g</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>...</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>}</mml:mo></mml:mrow><mml:mo>&#x02217;</mml:mo></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>}</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:semantics></mml:math></disp-formula></p><p>That is, <italic>S</italic>* consists precisely of the variables <italic>i </italic>such that the error probability of the optimal predictor <italic>g</italic>* increases when <italic>i </italic>is removed. The required restriction is that the data density <italic>f </italic>(<italic>x</italic>) is everywhere strictly positive. This condition is satisfied by nearly all commonly used statistical models, including the exponential family, and we believe that it is reasonable for biological data. A formal proof of the correctness of (2) is given in Additional File <xref ref-type="supplementary-material" rid="S1">1</xref>.</p><p>Note that <italic>S</italic>* may be quite different from the set of variables that are marginally correlated with the phenotype (<italic>e.g</italic>., differentially expressed genes). This is because some correlated variables may be "redundant" for prediction: while these do contain information about the phenotype, that information is also present in other variables, so that the redundant variables are excluded from <italic>S</italic>*. Indeed, it can be proved that <italic>S</italic>* only contains variables <italic>X</italic><sub><italic>i </italic></sub>that are conditionally dependent on <italic>Y </italic>regardless of what other variable set is conditioned on [<xref ref-type="bibr" rid="B13">13</xref>]. In this sense, <italic>S* </italic>constitutes the variables "directly" correlated with <italic>Y</italic>. Moreover, some variables may be predictive only when considered together with certain other variables in a multivariate fashion, and thus <italic>S</italic>* may contain variables that are not detectable by standard univariate methods [<xref ref-type="bibr" rid="B14">14</xref>].</p><p>The simple form (2) immediately suggests a general, linear-time, asymptotically correct algorithm for discovering <italic>S</italic>* from data, as described elsewhere [<xref ref-type="bibr" rid="B13">13</xref>]. Here, we make use of the fact that (2) permits <italic>S</italic>* to be calculated for any given data distribution, thus providing the gold standard required for evaluating signature discovery methods and developing hypothesis testing procedures.</p></sec><sec><title>Accurate predictions despite high signature FDR</title><p>First, we tested whether high prediction accuracy implies a low false discovery rate with respect to <italic>S</italic>*. We performed a simulation study on a simple two-class prediction problem using a multivariate normal distribution with <italic>n </italic>= 1, 000 variables, of which 10% were in <italic>S</italic>* (see Methods for details). In each run, a signature <italic>S </italic>was chosen to achieve a given power and FDR with respect to <italic>S</italic>*, whereafter a Support Vector Machine (SVM) classifier was trained on a sample from the corresponding subspace of the data distribution. We found that FDR as high as 50% did not degrade predictive accuracy discernably, provided that statistical power was sufficient (Figure <xref ref-type="fig" rid="F2">2</xref>). Thus, prediction accuracy is not a valid measure of the reliability of a signature in terms of false positives.</p><fig position="float" id="F2"><label>Figure 2</label><caption><p><bold>Good predictive accuracy despite high FDR</bold>. Probability of prediction error for the Support Vector Machine (gray level) as a function of signature false discovery rate (FDR) and statistical power (fraction of true positives). Nearly horizontal level curves indicate weak dependence on FDR.</p></caption><graphic xlink:href="1471-2105-10-38-2"/></fig><p>The likely reason for this behavior is that modern predictive methods such as the SVM have internal mechanisms for suppressing noise (regularization). They are therefore rather insensitive to false positives within the signature. For prediction purposes, it is more important that the signature does contain some true positives genes, while a large fraction of irrelevant genes may be tolerated without degrading predictive accuracy. As a consequence, discovering signatures by optimizing prediction accuracy should not be expected control FDR, as we will further demonstrate below.</p></sec><sec><title>Unstable Signatures with Low FDR</title><p>To investigate the relation between signature stability and FDR, we conducted a second simulation experiment, again with <italic>n </italic>= 1, 000 variables. Here, each variable was conditionally independent of all others within each class, so that <italic>S</italic>* has the form</p><p><disp-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M8" name="1471-2105-10-38-i6" overflow="scroll"><mml:semantics><mml:mrow><mml:msup><mml:mi>S</mml:mi><mml:mo>&#x02217;</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mi>i</mml:mi><mml:mo>:</mml:mo><mml:mi mathvariant="double-struck">E</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo><mml:mo>&#x02260;</mml:mo><mml:mi mathvariant="double-struck">E</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo><mml:mo>}</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:semantics></mml:math></disp-formula></p><p>and can be discovered by simply testing the marginal distributions for a nonzero mean difference. For this we used Student's t-test with the Benjamini-Hochberg correction for FDR control, since the t-test has optimal power in this case and the FDR can be controlled exactly [<xref ref-type="bibr" rid="B15">15</xref>]. Nevertheless, we found that the resulting signatures can be very unstable (Figure <xref ref-type="fig" rid="F3">3</xref>). For small effect sizes where power was low, stability was also low, despite a stringent FDR. Conversely, with strong effects and high power, stability was high, even with a high FDR. Also, the dependence of stability on FDR was different between low- and high-power regimes, indicating that the relationship between these measures is complicated and data-dependent. Clearly, unstable signatures need not contain many false positives. In the low power regime, the situation is rather that small signatures are being selected more or less at random from a large set of true positives, resulting in small overlap between experiments (Figure <xref ref-type="fig" rid="F3">3</xref>). Hence, in situations where many genes are weakly associated with a given phenotype and power is limited, it is simply not feasible to reproduce molecular signatures in independent experiments, even with the most stringent and correct methods. This implies that the lack of reproducibility observed for cancer gene expression signatures [<xref ref-type="bibr" rid="B7">7</xref>,<xref ref-type="bibr" rid="B8">8</xref>] is not necessarily problematic. The same mechanism may also account for the low reproducibility of whole-genome association studies of complex diseases [<xref ref-type="bibr" rid="B16">16</xref>], where many genes are believed to be weakly associated with a given disease trait.</p><fig position="float" id="F3"><label>Figure 3</label><caption><p><bold>Signatures with low FDR may be unstable</bold>. Left, statistical power <italic>vs</italic>. effect size (arbitrary units) for varying FDR. Middle, stability, defined as the average normalized overlap between two signatures <italic>vs</italic>. effect size and FDR. Right, illustration of how power affects stability.</p></caption><graphic xlink:href="1471-2105-10-38-3"/></fig></sec><sec><title>A Statistical Framework for Signature Discovery</title><p>The above results show that neither predictive accuracy nor stability are relevant measures of signature FDR. To directly control false discovery rates for signature discovery, we instead propose a general method for directly testing the hypothesis <italic>i </italic>&#x02208; <italic>S</italic>* for each variable. From equation (2) it follows that a generally applicable test statistic is</p><p><disp-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M9" name="1471-2105-10-38-i7" overflow="scroll"><mml:semantics><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>g</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>...</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>...</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>}</mml:mo></mml:mrow><mml:mo>&#x02217;</mml:mo></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>g</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>...</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>}</mml:mo></mml:mrow><mml:mo>&#x02217;</mml:mo></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:semantics></mml:math></disp-formula></p><p>where <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M10" name="1471-2105-10-38-i8" overflow="scroll"><mml:semantics><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:semantics></mml:math></inline-formula> is an estimated error probability, for example a cross-validated error estimate. This statistic is asymptotically correct for any data distribution, that is, with a sufficiently large sample size, the globally optimal solution will always be found [<xref ref-type="bibr" rid="B13">13</xref>]. However, the sample sizes required for reasonable performance could be very large, since the error rate estimate <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M11" name="1471-2105-10-38-i8" overflow="scroll"><mml:semantics><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:semantics></mml:math></inline-formula> is uncertain. For particular types of predictors, it is therefore preferable to develop specialized statistics. As we are interested in applications to gene expression data, where simple prediction rules tend to work well, we here consider linear classifiers of the form <italic>g</italic>(<italic>x</italic>) = sign (&#x02211;<sub><italic>i</italic></sub><italic>w</italic><sub><italic>i</italic></sub><italic>x</italic><sub><italic>i</italic></sub>). It is easy to see that in this case, equation (2) reduces to</p><p><disp-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M12" name="1471-2105-10-38-i9" overflow="scroll"><mml:semantics><mml:mrow><mml:msup><mml:mi>S</mml:mi><mml:mo>&#x02217;</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mi>i</mml:mi><mml:mo>:</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mo>&#x02217;</mml:mo></mml:msubsup><mml:mo>&#x02260;</mml:mo><mml:mn>0</mml:mn><mml:mo>}</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:semantics></mml:math></disp-formula></p><p>where <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M13" name="1471-2105-10-38-i10" overflow="scroll"><mml:semantics><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mo>&#x02217;</mml:mo></mml:msubsup></mml:mrow></mml:semantics></mml:math></inline-formula> denote the weights of the optimal classifier. Assuming that the classifier used is consistent, we have that <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M14" name="1471-2105-10-38-i10" overflow="scroll"><mml:semantics><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mo>&#x02217;</mml:mo></mml:msubsup></mml:mrow></mml:semantics></mml:math></inline-formula>[<italic>w</italic><sub><italic>i</italic></sub>] &#x02192; <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M15" name="1471-2105-10-38-i10" overflow="scroll"><mml:semantics><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mo>&#x02217;</mml:mo></mml:msubsup></mml:mrow></mml:semantics></mml:math></inline-formula> as sample size increases. Hence, in this case we can equivalently test the null hypothesis <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M16" name="1471-2105-10-38-i11" overflow="scroll"><mml:semantics><mml:mi mathvariant="double-struck">E</mml:mi></mml:semantics></mml:math></inline-formula>[<italic>w</italic><sub><italic>i</italic></sub>] = 0. More complicated parametric forms such as polynomials in <italic>x</italic><sub><italic>i </italic></sub>could be used in a similar way, although the number of weights would increase accordingly.</p><p>Since the statistical distribution of <italic>w</italic><sub><italic>i </italic></sub>is unknown, we used a bootstrap technique to test whether <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M17" name="1471-2105-10-38-i11" overflow="scroll"><mml:semantics><mml:mi mathvariant="double-struck">E</mml:mi></mml:semantics></mml:math></inline-formula>[<italic>w</italic><sub><italic>i</italic></sub>] = 0. By sampling with replacement from the given data set and re-training the classifier on each sample, we obtain <italic>B </italic>vectors <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M18" name="1471-2105-10-38-i12" overflow="scroll"><mml:semantics><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mn>1</mml:mn><mml:mo>&#x02217;</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:mn>...</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mi>B</mml:mi><mml:mo>&#x02217;</mml:mo></mml:msubsup></mml:mrow></mml:semantics></mml:math></inline-formula>. For each variable <italic>i</italic>, the corresponding <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M19" name="1471-2105-10-38-i13" overflow="scroll"><mml:semantics><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:mrow><mml:mo>&#x02217;</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:mn>...</mml:mn><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mo>&#x02217;</mml:mo></mml:msubsup></mml:mrow></mml:semantics></mml:math></inline-formula> are then used to obtain a bootstrap confidence interval for <italic>w</italic><sub><italic>i</italic></sub>. This interval is inverted to obtain a bootstrap <italic>p</italic>-values <italic>p</italic><sub><italic>i </italic></sub>for each variable <italic>i </italic>(that is, the null hypothesis is rejected at level <italic>&#x003b1; </italic>if the (1 - <italic>&#x003b1;</italic>) confidence interval does not cover zero). Importantly, this procedure preserves the full dependency structure of the data distribution. Finally, FDR control was performed using the Benjamini-Hochberg procedure [<xref ref-type="bibr" rid="B15">15</xref>].</p></sec><sec><title>Simulation Experiments</title><p>To validate our method, we conducted simulations using two-class data with 1, 000 variables and 100 samples. To model the variable dependencies often present in gene expression data, we used a class-conditional multivariate Gaussian distribution with precision matrices generated randomly as previously described [<xref ref-type="bibr" rid="B17">17</xref>]. For this distribution class, it is straightforward to calculate <italic>S</italic>* (see methods). We chose sampling parameters so that <italic>S</italic>* constituted approx. 200 variables on average (since <italic>S</italic>* depends on the randomly chosen covariance matrix, its size fluctuates somewhat). We evaluated three linear classification methods: the Support Vector Machine (SVM) [<xref ref-type="bibr" rid="B18">18</xref>], the Kernel Fisher Discriminant (KFD) [<xref ref-type="bibr" rid="B19">19</xref>] and the Weighted Voting (WV) algorithm of Golub <italic>et al</italic>. [<xref ref-type="bibr" rid="B2">2</xref>]. Since the results were highly similar for all of these, we here only present results for the SVM (see Additional File <xref ref-type="supplementary-material" rid="S2">2</xref> for KFD and VW). For each learning method and across a range of effect sizes, our bootstrap test produced correct <italic>p</italic>-values, while power increased with increasing effect size (Figure <xref ref-type="fig" rid="F4">4A</xref>). This demonstrates that the bootstrap test is sound. After correcting for multiplicity using the procedure of Benjamini and Hochberg [<xref ref-type="bibr" rid="B15">15</xref>], we verified that our method did control FDR at nominal levels (Figure <xref ref-type="fig" rid="F4">4B</xref>). Power was limited however, especially for predictors with low accuracy. We therefore expect that for high-dimensional data, predictors must be quite accurate in order to yield reliable signatures. We also verified that the power of our bootstrap method approaches 1 as sample size increases, as one would expect (see Additional File <xref ref-type="supplementary-material" rid="S2">2</xref>). However, power depends on a number of distribution properties, and it is difficult to make predictions about the sample sizes required in practise from simulations.</p><fig position="float" id="F4"><label>Figure 4</label><caption><p><bold>Controlling error rates for gene signatures</bold>. <bold>A: </bold>Realized level and power for the bootstrap test at 5% nominal level. <bold>B: </bold>Realized FDR, power and stability for signatures selected by the bootstrap test after Benjamini-Hochberg (BH) correction. Here the nominal FDR was set at 5%. <bold>C: </bold>Same as (B) for signatures selected by recursive feature elimination (RFE). <bold>D: </bold>Same as (B) for signatures selected as the top 200 genes. Acc, classifier accuracy.</p></caption><graphic xlink:href="1471-2105-10-38-4"/></fig><p>We repeated the simulation study using the popular Recursive Feature Elimination (RFE) method [<xref ref-type="bibr" rid="B20">20</xref>] to discover signatures. While this method did produce accurate predictive models (data not shown), we observed that FDR was high (above 40% in this experiment) and depended on the effect size in an unpredictable manner. Indeed, optimizing prediction accuracy by RFE does not guarantee a reliable signature. High FDR was also observed when choosing the signature <italic>S </italic>as a fixed-size "top list" by the rank according to the <italic>w</italic><sub><italic>g </italic></sub>statistics (Figure <xref ref-type="fig" rid="F4">4D</xref>). We have also previously observed high FDR for other methods that optimize the signature for prediction accuracy [<xref ref-type="bibr" rid="B21">21</xref>]. Often, these methods attempt to include more variables in the signature when the prediction problem is harder, thus sacrificing FDR control for better predictive accuracy. Conversely, for less difficult prediction problems, many true positives may be removed from the signature because they do not influence predictive power discernably.</p></sec><sec><title>Application to Cancer Gene Expression</title><p>We applied our method together with the SVM prediction method to analyze a number of publicly available cancer gene expression data sets (Table <xref ref-type="table" rid="T1">1</xref>). For the data sets by van't Veer [<xref ref-type="bibr" rid="B4">4</xref>] and Wang [<xref ref-type="bibr" rid="B5">5</xref>] where the SVM had poor accuracy, the bootstrap method did not call any genes significant. Note that these signatures may still be useful for prediction; the fact that no genes are called significant merely demonstrates that it is not possible to ascertain which genes are responsible for the predictive accuracy. For the remaining data sets, we found that higher predictive accuracy tends to result in greater power, in accordance with our simulation results. The largest signature, obtained for the data set by Golub <italic>et al</italic>. [<xref ref-type="bibr" rid="B2">2</xref>], contained over 500 genes at 5% FDR (see Additional Files <xref ref-type="supplementary-material" rid="S3">3</xref>, <xref ref-type="supplementary-material" rid="S4">4</xref> and <xref ref-type="supplementary-material" rid="S5">5</xref> for complete gene lists).</p><table-wrap position="float" id="T1"><label>Table 1</label><caption><p>Results on cancer gene expression data</p></caption><table frame="hsides" rules="groups"><thead><tr><td align="left">Data set (ref.)</td><td align="center"><italic>n</italic></td><td align="center">MCF,%</td><td align="right">CV,%</td><td align="center">TA,%(ref.)</td><td align="center">BS</td><td align="center">BS<sub>0</sub></td><td align="center">RFE</td><td align="center">RFE<sub>0</sub></td><td align="center">DE</td></tr></thead><tbody><tr><td align="left">Golub (2)</td><td align="center">72</td><td align="center">32</td><td align="right">97.0 &#x000b1; 4.2</td><td align="center">99.3 (28)</td><td align="center">537</td><td align="center">0</td><td align="center">35</td><td align="center">154</td><td align="center">1007</td></tr><tr><td align="left">Singh (4)</td><td align="center">136</td><td align="center">43</td><td align="right">92.6 &#x000b1; 3.0</td><td align="center">81.1 (27)</td><td align="center">99</td><td align="center">0</td><td align="center">48</td><td align="center">312</td><td align="center">3807</td></tr><tr><td align="left">Alon (1)</td><td align="center">62</td><td align="center">35</td><td align="right">81 &#x000b1; 7.2</td><td align="center">97.9 (29)</td><td align="center">19</td><td align="center">0</td><td align="center">55</td><td align="center">94</td><td align="center">303</td></tr><tr><td align="left">Wang (6)</td><td align="center">286</td><td align="center">37</td><td align="right">65 &#x000b1; 4.3</td><td align="center">N/A</td><td align="center">0</td><td align="center">0</td><td align="center">261</td><td align="center">1250</td><td align="center">106</td></tr><tr><td align="left">van't Veer (5)</td><td align="center">97</td><td align="center">47</td><td align="right">62 &#x000b1; 8.4</td><td align="center">N/A</td><td align="center">0</td><td align="center">0</td><td align="center">42</td><td align="center">153</td><td align="center">1</td></tr></tbody></table><table-wrap-foot><p>Results are ordered by prediction accuracy. <italic>n</italic>, number of samples; MCF, minority class frequency; CVA, balanced cross-validated prediction accuracy, mean &#x000b1; std.dev.; TA, balanced prediction accuracy of bootstrap signature on an independent test set (reference given in parentheses); BS, significant genes using the bootstrap with SVM at 5% FDR; RFE, genes chosen by recursive feature elimination; BS<sub>0 </sub>and RFE<sub>0</sub>, gene chosen by the bootstrap and RFE methods respectively on randomized data. DE, differentially expressed genes using the t-test at 5% FDR.</p></table-wrap-foot></table-wrap><p>As a negative control, we applied our bootstrap test on randomized versions of each original data set where the phenotype values were randomly permuted, corresponding to the complete null hypothesis. This yielded zero significant genes in each case, confirming that we do not obtain spurious findings. In contrast, when applying the RFE method to randomized data, we consistently obtained even larger signatures than with the real data sets. We also tested each signature on an independent data set, confirming that the signatures are indeed predictive.</p><p>For comparison, we performed a conventional differential expression test for each data set using the t-test statistic with the Benjamini-Hochberg correction (Table <xref ref-type="table" rid="T1">1</xref>). This identified a substantially larger set of genes than the bootstrap method &#x02013; in one case, more than half of the genes tested were significant. This illustrates the ability of the gene signature approach to distinguish the genes directly related to the phenotype variable from a much larger set of differentially expressed genes: many of the latter turn out to be "redundant" for prediction, meaning that they are correlated with the phenotype only indirectly, through genes in <italic>S</italic>*.</p></sec></sec><sec><title>Discussion</title><p>Molecular signatures offer a systematic way to focus on the genes most directly associated with a given phenotype, and may yield valuable insights into the underlying biological system. It is therefore unfortunate that the reliability of signatures <italic>per se </italic>is poorly understood. Since no gold standard for signature discovery has been available, validation of discovered signatures often amounts to mining the scientific literature for documented connections between the phenotype being studied and the elements (genes) of a hypothesized signature. However, this approach is necessarily biased and rather speculative: it is by no means clear that a gene should be included in a predictive signature simply because it is somehow "related" to the phenotype. For example, approximately 25% of all known human genes have some documented relation to cancer [<xref ref-type="bibr" rid="B14">14</xref>], but it is unlikely that all of these should be included in an optimal signature for cancer prediction.</p><p>To address this issue, we have herein developed a statistical method for signature discovery based on a formal definition of the "gold standard" optimal signature. This allows for assessing the reliability of signatures without detailed knowledge of the biological system. To our knowledge, our method is the first to provide statistical guarantees for the reliability of molecular signatures, although we note that random forests are similar to our bootstrap testing scheme and also give indications of what variables are important for prediction.</p><p>For two of the gene expression data sets investigated, including the well-studied cancer data by van't Veer <italic>et al</italic>. [<xref ref-type="bibr" rid="B4">4</xref>], our method did not call any genes significant, indicating that these data sets did not contain sufficient information to uncover gene signatures at the specified false discovery rate (5%). We emphasize that this does not necessarily mean that it is infeasible to construct predictive models for these studies, but merely that it is difficult to determine which genes are responsible for the predictive accuracy. In this sense, discovering reliable gene signatures can be a harder problem than obtaining accurate predictors. Prediction and signature discovery are two separate problems, and must be treated differently.</p><p>For simplicity, we have here restricted our analysis to two-class problems and linear predictors. However, the proposed method is applicable to any learning method for which a reasonably well-powered statistic can be derived to test the signature null hypothesis. Continuous phenotype variables can easily be addressed by substituting the classification methods used herein for regression methods, such as ridge regression [<xref ref-type="bibr" rid="B22">22</xref>] or the relevance vector machine [<xref ref-type="bibr" rid="B23">23</xref>]. General methods for handling non-linear dependencies have also been described [<xref ref-type="bibr" rid="B13">13</xref>,<xref ref-type="bibr" rid="B24">24</xref>], although it is unclear whether signature discovery from gene expression data would benefit from these more complex models with currently available sample sizes.</p><p>Some technical issues remain to be considered. First, testing the null hypothesis <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M20" name="1471-2105-10-38-i11" overflow="scroll"><mml:semantics><mml:mi mathvariant="double-struck">E</mml:mi></mml:semantics></mml:math></inline-formula>[<italic>w</italic><sub><italic>i</italic></sub>] = 0 is technically correct only in the limit of large samples where <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M21" name="1471-2105-10-38-i11" overflow="scroll"><mml:semantics><mml:mi mathvariant="double-struck">E</mml:mi></mml:semantics></mml:math></inline-formula>[<italic>w</italic><sub><italic>i</italic></sub>] &#x02192; <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M22" name="1471-2105-10-38-i10" overflow="scroll"><mml:semantics><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mo>&#x02217;</mml:mo></mml:msubsup></mml:mrow></mml:semantics></mml:math></inline-formula>. While our simulation studies indicate correct behavior for the sample sizes tested, this issue warrants further study. Second, bootstrap hypothesis testing is known to provide only approximate <italic>p</italic>-values, satisfying the inequality <italic>P</italic>(<italic>p </italic>&#x02264; <italic>&#x003b1;</italic>) &#x02264; <italic>&#x003b1; </italic>+ <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M23" name="1471-2105-10-38-i14" overflow="scroll"><mml:semantics><mml:mi mathvariant="script">O</mml:mi></mml:semantics></mml:math></inline-formula>(1/<italic>l</italic>), where <italic>l </italic>is the sample size [<xref ref-type="bibr" rid="B25">25</xref>]. While the additional term <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M24" name="1471-2105-10-38-i14" overflow="scroll"><mml:semantics><mml:mi mathvariant="script">O</mml:mi></mml:semantics></mml:math></inline-formula>(1/<italic>l</italic>) was negligible in our simulations, this should be verified in each particular case before applying bootstrap testing. A possible future improvement could be to estimate this term from simulations and correct the bootstrap <italic>p</italic>-values accordingly, thereby "calibrating" the method.</p></sec><sec><title>Conclusion</title><p>As we have shown, neither predictive accuracy nor stability constitute valid measures of FDR for molecular signatures. Indeed, highly accurate predictions may be obtained despite an FDR as high as 50% (Figure <xref ref-type="fig" rid="F2">2</xref>), while in situations where many weak effects are present and statistical power is low, signatures can be unstable at an FDR as low as 2.5% (Figure <xref ref-type="fig" rid="F3">3</xref>). This analysis explains at least some of the difficulties with reproducing cancer gene expression signatures [<xref ref-type="bibr" rid="B7">7</xref>,<xref ref-type="bibr" rid="B8">8</xref>] and possibly also the similar reproducibility problems of recent association studies in complex diseases [<xref ref-type="bibr" rid="B16">16</xref>]. Moreover, it suggests that this lack of reproducibility need not be problematic.</p><p>We have developed and validated a statistical hypothesis testing framework that for the first time provides false discovery rates control for signature discovery. In application to cancer gene expression, we have showed that reliable signature discovery is feasible with currently available sample sizes. Many important problems in bioinformatics are prediction problems and may benefit from reliable signature discovery. We therefore hope that our method will be of general interest.</p></sec><sec sec-type="methods"><title>Methods</title><p>Signature stability is defined as the normalized expected overlap between two signatures <italic>S, S' </italic>derived from independent, replicate experimental data sets,</p><p><disp-formula id="bmcM3"><label>(3)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M25" name="1471-2105-10-38-i15" overflow="scroll"><mml:semantics><mml:mrow><mml:mtext>Stability</mml:mtext><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>S</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>S</mml:mi><mml:mo>&#x02229;</mml:mo><mml:msup><mml:mi>S</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>max</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mo>{</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>S</mml:mi><mml:mo>&#x0222a;</mml:mo><mml:msup><mml:mi>S</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:semantics></mml:math></disp-formula></p><p>where <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M26" name="1471-2105-10-38-i11" overflow="scroll"><mml:semantics><mml:mi mathvariant="double-struck">E</mml:mi></mml:semantics></mml:math></inline-formula> denotes statistical expectation. The stability is always between 0 (no expected overlap) and 1 (complete overlap).</p><p>Simulations were performed with data drawn from two-class multivariate Gaussian distributions <italic>f </italic>(<italic>x </italic>| <italic>y</italic>) = <italic>N </italic>(<italic>y&#x003bc;</italic>, &#x003a3;) with equal class frequencies, covariance matrix &#x003a3; independent of the class (phenotype) variable <italic>y </italic>and varying degrees of class separation to achieve different effect sizes. Results were averaged over 100 randomly selected Gaussian distributions. for each parameter setting tested. We measure the effect size of the resulting prediction problem by the expected SVM accuracy. Here the accuracy was computed exactly for each SVM from the data density: for any given <italic>&#x003bc; </italic>and &#x003a3;, a separating hyperplane with normal vector <italic>w </italic>has classification accuracy</p><p><disp-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M27" name="1471-2105-10-38-i16" overflow="scroll"><mml:semantics><mml:mrow><mml:mtext>Acc</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mtext>erf</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mi>w</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mi>&#x003bc;</mml:mi></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>w</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mi>&#x003a3;</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:semantics></mml:math></disp-formula></p><p>where <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M28" name="1471-2105-10-38-i17" overflow="scroll"><mml:semantics><mml:mrow><mml:mtext>erf</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:msup><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>&#x0222b;</mml:mo><mml:mn>0</mml:mn><mml:mi>x</mml:mi></mml:msubsup><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mstyle><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula> is the error function.</p><p>To evaluate signature error rates, we used the fact that for <italic>f </italic>(<italic>x </italic>| <italic>y</italic>) = <italic>N </italic>(<italic>y&#x003bc;</italic>, &#x003a3;), the optimal separating hyperplane has normal vector <italic>w</italic>* = &#x003a3;<sup>-1 </sup><italic>&#x003bc;</italic>, and so the optimal set <italic>S</italic>* can be determined as the nonzero components <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M29" name="1471-2105-10-38-i10" overflow="scroll"><mml:semantics><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mo>&#x02217;</mml:mo></mml:msubsup></mml:mrow></mml:semantics></mml:math></inline-formula> of this vector.</p><p>For hypothesis testing, we used a parametric bootstrap with <italic>B </italic>= 50 repetitions, fitting a Gaussian distribution <italic>N </italic>(<italic>&#x003bc;</italic><sub><italic>i</italic></sub>, <italic>&#x003c3;</italic><sub><italic>i</italic></sub>) to the observed <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M30" name="1471-2105-10-38-i18" overflow="scroll"><mml:semantics><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mi>g</mml:mi></mml:mrow><mml:mo>&#x02217;</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:mn>...</mml:mn><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mo>&#x02217;</mml:mo></mml:msubsup></mml:mrow></mml:semantics></mml:math></inline-formula> prior to computing two-sided <italic>p</italic>-values. In preliminary studies, the difference between this method and a nonparametric bootstrap with <italic>B </italic>= 1000 was negligible, while the parametric version is computationally more efficient since a much smaller <italic>B </italic>can be used. The SVM [<xref ref-type="bibr" rid="B18">18</xref>], KFD [<xref ref-type="bibr" rid="B19">19</xref>] and VW [<xref ref-type="bibr" rid="B2">2</xref>] methods were implemented as previously described. In all experiments, the SVM <italic>C</italic>-parameter and the KFD regularization parameter were set to 1. Recursive Feature Elimination (RFE) was performed as previously described [<xref ref-type="bibr" rid="B20">20</xref>], using the radius-margin bound [<xref ref-type="bibr" rid="B26">26</xref>] as accuracy measure and removing 20% of the genes in each iteration.</p><p>Microarray data sets [<xref ref-type="bibr" rid="B1">1</xref>-<xref ref-type="bibr" rid="B5">5</xref>] were preprocessed by removing genes displaying small variation, keeping the 5,000 most variable genes in each case, except for the data sets by van't Veer <italic>et al</italic>. [<xref ref-type="bibr" rid="B4">4</xref>] and Alon <italic>et al</italic>. [<xref ref-type="bibr" rid="B1">1</xref>] which were preprocessed in a similar fashion by the original authors. Genes were normalized to zero mean and unit standard deviation prior to SVM training, following standard practise for kernel methods. Independent test data sets [<xref ref-type="bibr" rid="B27">27</xref>-<xref ref-type="bibr" rid="B29">29</xref>] were normalized in the same fashion. No other preprocessing was done prior to classifier training or testing.</p><p>Since many data sets were had low minor class frequencies are (Table <xref ref-type="table" rid="T1">1</xref>), performance was evaluated with the balanced accuracy measure</p><p><disp-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M31" name="1471-2105-10-38-i19" overflow="scroll"><mml:semantics><mml:mrow><mml:msub><mml:mrow><mml:mtext>Acc</mml:mtext></mml:mrow><mml:mrow><mml:mtext>balanced</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mtext>Acc</mml:mtext></mml:mrow><mml:mo>+</mml:mo></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mtext>Acc</mml:mtext></mml:mrow><mml:mo>&#x02212;</mml:mo></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:semantics></mml:math></disp-formula></p><p>where Acc<sub>+ </sub>and Acc<sub>- </sub>are the accuracy measures for each class. Except for the independent test sets, these were measured by cross-validation, where in each round a randomized set consisting of 2/3 of the samples was used for training, and the remaining 1/3 was used for testing. Splits were balanced so that class frequencies were equal between training/test data. Mean and standard deviation of the balanced test error over 50 cross-validation repetitions are reported.</p></sec><sec><title>Authors' contributions</title><p>RN, JB and JT designed research; RN performed research; RN and JT wrote the paper.</p></sec><sec sec-type="supplementary-material"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="S1"><caption><title>Additional file 1</title><p><bold>Proofs.</bold> This document provides proofs of uniqueness and optimality of the optimal signature <italic>S</italic>*.</p></caption><media xlink:href="1471-2105-10-38-S1.pdf" mimetype="application" mime-subtype="pdf"><caption><p>Click here for file</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="S2"><caption><title>Additional file 2</title><p><bold>KFD and WV methods, and convergence with increasing sample size.</bold> This figure shows the results corresponding to Figure <xref ref-type="fig" rid="F4">4</xref> for the Kernel Fisher Discriminant (A-B) and Weighted Voting classification methods (C-D). Also shown is the convergence of the bootstrap method for the SVM classifier (E), where power approaches 1 as sample size increases.</p></caption><media xlink:href="1471-2105-10-38-S2.pdf" mimetype="application" mime-subtype="pdf"><caption><p>Click here for file</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="S3"><caption><title>Additional file 3</title><p><bold>Gene signature for the Alon data set.</bold> Excel file detailing the gene signature discovered by the bootstrap method using the SVM classifier. The corresponding signature from Recursive Features elimination is also provided for reference.</p></caption><media xlink:href="1471-2105-10-38-S3.xls" mimetype="application" mime-subtype="vnd.ms-excel"><caption><p>Click here for file</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="S4"><caption><title>Additional file 4</title><p><bold>Gene signature for the Golub data set.</bold> Excel file detailing the gene signature discovered by the bootstrap method using the SVM classifier. The corresponding signature from Recursive Features elimination is also provided for reference.</p></caption><media xlink:href="1471-2105-10-38-S4.xls" mimetype="application" mime-subtype="vnd.ms-excel"><caption><p>Click here for file</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="S5"><caption><title>Additional file 5</title><p><bold>Gene signature for the Singh data set. </bold>Excel file detailing the gene signature discovered by the bootstrap method using the SVM classifier. The corresponding signature from Recursive Features elimination is also provided for reference.</p></caption><media xlink:href="1471-2105-10-38-S5.xls" mimetype="application" mime-subtype="vnd.ms-excel"><caption><p>Click here for file</p></caption></media></supplementary-material></sec></body><back><ack><sec><title>Acknowledgements</title><p>The authors would like to thank Drs. Jos&#x000e9; M. Pe&#x000f1;a and Albert Compte for helpful discussions. This work was supported by grants from the Ph.D. Programme in Medical Bioinformatics at Karolinska Institutet (RN), Clinical Gene Networks AB, Vinnova (JT), Swedish Research Council (JT) and Link&#x000f6;ping University.</p></sec></ack><ref-list><ref id="B1"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Alon</surname><given-names>U</given-names></name><name><surname>Barkai</surname><given-names>N</given-names></name><name><surname>Notterman</surname><given-names>DA</given-names></name><name><surname>Gish</surname><given-names>K</given-names></name><name><surname>Ybarra</surname><given-names>S</given-names></name><name><surname>Mack</surname><given-names>D</given-names></name><name><surname>Levine</surname><given-names>AJ</given-names></name></person-group><article-title>Broad patterns of gene expression revealed by clustering analysis of tumor and normal colon tissues probed by oligonucleotide arrays</article-title><source>Proc Natl Acad Sci U S A</source><year>1999</year><volume>96</volume><fpage>6745</fpage><lpage>6750</lpage><pub-id pub-id-type="pmid">10359783</pub-id><pub-id pub-id-type="doi">10.1073/pnas.96.12.6745</pub-id></citation></ref><ref id="B2"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Golub</surname><given-names>TR</given-names></name><name><surname>Slonim</surname><given-names>DK</given-names></name><name><surname>Tamayo</surname><given-names>P</given-names></name><name><surname>Huard</surname><given-names>C</given-names></name><name><surname>Gaasenbeek</surname><given-names>M</given-names></name><name><surname>Mesirov</surname><given-names>J</given-names></name><name><surname>Coller</surname><given-names>H</given-names></name><name><surname>Loh</surname><given-names>M</given-names></name><name><surname>Downing</surname><given-names>J</given-names></name><name><surname>Caligiuri</surname><given-names>M</given-names></name><name><surname>Bloomfield</surname><given-names>C</given-names></name><name><surname>Lander</surname><given-names>ES</given-names></name></person-group><article-title>Molecular classifiation of cancer: class discovery and class prediction by gene expression monitoring</article-title><source>Science</source><year>1999</year><volume>286</volume><fpage>531</fpage><lpage>537</lpage><pub-id pub-id-type="pmid">10521349</pub-id><pub-id pub-id-type="doi">10.1126/science.286.5439.531</pub-id></citation></ref><ref id="B3"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Singh</surname><given-names>D</given-names></name><name><surname>Febbo</surname><given-names>PG</given-names></name><name><surname>Ross</surname><given-names>K</given-names></name><name><surname>Jackson</surname><given-names>DG</given-names></name><name><surname>Manola</surname><given-names>J</given-names></name><name><surname>Ladd</surname><given-names>C</given-names></name><name><surname>Tamayo</surname><given-names>P</given-names></name><name><surname>Renshaw</surname><given-names>AA</given-names></name><name><surname>D'Amico</surname><given-names>AV</given-names></name><name><surname>Richie</surname><given-names>JP</given-names></name><name><surname>Lander</surname><given-names>ES</given-names></name><name><surname>Loda</surname><given-names>M</given-names></name><name><surname>Kanto3</surname><given-names>PW</given-names></name><name><surname>Golub</surname><given-names>TR</given-names></name><name><surname>Sellers</surname><given-names>WR</given-names></name></person-group><article-title>Gene expression correlates of clinical prostate cancer behavior</article-title><source>Cancer Cell</source><year>2002</year><volume>1</volume><fpage>203</fpage><lpage>209</lpage><pub-id pub-id-type="pmid">12086878</pub-id><pub-id pub-id-type="doi">10.1016/S1535-6108(02)00030-2</pub-id></citation></ref><ref id="B4"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>van't Veer</surname><given-names>LJ</given-names></name><name><surname>Dai</surname><given-names>H</given-names></name><name><surname>Vijver</surname><given-names>MJ Van De</given-names></name><name><surname>He</surname><given-names>YD</given-names></name><name><surname>Hart</surname><given-names>AAM</given-names></name><name><surname>Mao</surname><given-names>M</given-names></name><name><surname>Peterse</surname><given-names>HL</given-names></name><name><surname>Kooy</surname><given-names>K Van Der</given-names></name><name><surname>Marton</surname><given-names>MJ</given-names></name><name><surname>Witteveen</surname><given-names>AT</given-names></name><name><surname>Schreiber</surname><given-names>GJ</given-names></name><name><surname>Kerkhoven</surname><given-names>RM</given-names></name><name><surname>Roberts</surname><given-names>C</given-names></name><name><surname>Linsley</surname><given-names>PS</given-names></name><name><surname>Bernards</surname><given-names>R</given-names></name><name><surname>Friend</surname><given-names>SH</given-names></name></person-group><article-title>Gene expression profiling predicts clinical outcome of breast cancer</article-title><source>Nature</source><year>2002</year><volume>415</volume><fpage>530</fpage><lpage>536</lpage><pub-id pub-id-type="pmid">11823860</pub-id><pub-id pub-id-type="doi">10.1038/415530a</pub-id></citation></ref><ref id="B5"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Klijn</surname><given-names>JG</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Sieuwerts</surname><given-names>AM</given-names></name><name><surname>Look</surname><given-names>MP</given-names></name><name><surname>Yang</surname><given-names>F</given-names></name><name><surname>Talantov</surname><given-names>D</given-names></name><name><surname>Timmermans</surname><given-names>M</given-names></name><name><surname>Meijer-van Gelder</surname><given-names>ME</given-names></name><name><surname>Yu</surname><given-names>J</given-names></name><name><surname>Jatkoe</surname><given-names>T</given-names></name><name><surname>Berns</surname><given-names>EM</given-names></name><name><surname>Atkins</surname><given-names>D</given-names></name><name><surname>Foekens</surname><given-names>JA</given-names></name></person-group><article-title>Gene-expression profiles to predict distant metastasis of lymph-node-negative primary breast cancer</article-title><source>Lancet</source><year>2005</year><volume>365</volume><fpage>671</fpage><lpage>679</lpage><pub-id pub-id-type="pmid">15721472</pub-id></citation></ref><ref id="B6"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Bogaerts</surname><given-names>J</given-names></name><name><surname>Cardoso</surname><given-names>F</given-names></name><name><surname>Buyse</surname><given-names>M</given-names></name><name><surname>Braga</surname><given-names>S</given-names></name><name><surname>Loi</surname><given-names>S</given-names></name><name><surname>Harrison</surname><given-names>JA</given-names></name><name><surname>Bines</surname><given-names>J</given-names></name><name><surname>Mook</surname><given-names>S</given-names></name><name><surname>Decker</surname><given-names>N</given-names></name><name><surname>Ravdin</surname><given-names>P</given-names></name><name><surname>Therasse</surname><given-names>P</given-names></name><name><surname>Rutgers</surname><given-names>E</given-names></name><name><surname>van't Veer</surname><given-names>LJ</given-names></name><name><surname>Piccart</surname><given-names>M</given-names></name></person-group><article-title>Gene signature evaluation as a prognostic tool: challenges in the design of the MINDACT trial</article-title><source>Nat Clin Pract Oncol</source><year>2006</year><volume>3</volume><fpage>540</fpage><lpage>551</lpage><pub-id pub-id-type="pmid">17019432</pub-id><pub-id pub-id-type="doi">10.1038/ncponc0591</pub-id></citation></ref><ref id="B7"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Michiels</surname><given-names>S</given-names></name><name><surname>Koscielny</surname><given-names>S</given-names></name><name><surname>Hill</surname><given-names>C</given-names></name></person-group><article-title>Prediction of cancer outcome with microarrays: a multiple random validation strategy</article-title><source>Lancet</source><year>2005</year><volume>365</volume><fpage>488</fpage><lpage>492</lpage><pub-id pub-id-type="pmid">15705458</pub-id><pub-id pub-id-type="doi">10.1016/S0140-6736(05)17866-0</pub-id></citation></ref><ref id="B8"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ein-Dor</surname><given-names>L</given-names></name><name><surname>Kela</surname><given-names>I</given-names></name><name><surname>Getz</surname><given-names>G</given-names></name><name><surname>Givol</surname><given-names>D</given-names></name><name><surname>Domany</surname><given-names>E</given-names></name></person-group><article-title>Outcome signature genes in breast cancer: is there a unique set?</article-title><source>Bioinformatics</source><year>2005</year><volume>21</volume><fpage>171</fpage><lpage>178</lpage><pub-id pub-id-type="pmid">15308542</pub-id><pub-id pub-id-type="doi">10.1093/bioinformatics/bth469</pub-id></citation></ref><ref id="B9"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ein-Dor</surname><given-names>L</given-names></name><name><surname>Zuk</surname><given-names>O</given-names></name><name><surname>Domany</surname><given-names>E</given-names></name></person-group><article-title>Thousands of samples are needed to generate a robust gene list for predicting outcome in cancer</article-title><source>Proc Natl Acad Sci U S A</source><year>2006</year><volume>103</volume><fpage>5923</fpage><lpage>5928</lpage><pub-id pub-id-type="pmid">16585533</pub-id><pub-id pub-id-type="doi">10.1073/pnas.0601231103</pub-id></citation></ref><ref id="B10"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ioannidis</surname><given-names>JP</given-names></name></person-group><article-title>Microarrays and molecular research: noise discovery?</article-title><source>Lancet</source><year>2005</year><volume>365</volume><fpage>454</fpage><lpage>455</lpage><pub-id pub-id-type="pmid">15705441</pub-id></citation></ref><ref id="B11"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Devroye</surname><given-names>L</given-names></name><name><surname>Gy&#x000f6;rfi</surname><given-names>L</given-names></name><name><surname>Lugosi</surname><given-names>G</given-names></name></person-group><source>A probabilistic theory of pattern recognition Applications of mathematics</source><year>1996</year><publisher-name>New York: Springer-Verlag</publisher-name></citation></ref><ref id="B12"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Guyon</surname><given-names>I</given-names></name><name><surname>Elisseeff</surname><given-names>A</given-names></name></person-group><article-title>An introduction to variable and feature selection</article-title><source>Journ Mach Learn Res</source><year>2003</year><volume>3</volume><fpage>1157</fpage><lpage>1182</lpage><pub-id pub-id-type="doi">10.1162/153244303322753616</pub-id></citation></ref><ref id="B13"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Nilsson</surname><given-names>R</given-names></name><name><surname>Pe&#x000f1;a</surname><given-names>JM</given-names></name><name><surname>Bj&#x000f6;rkegren</surname><given-names>J</given-names></name><name><surname>Tegn&#x000e9;r</surname><given-names>J</given-names></name></person-group><article-title>Consistent feature selection for pattern recognition in polyomial time</article-title><source>Jour of Mach Learn Res</source><year>2007</year><volume>8</volume><fpage>589</fpage><lpage>612</lpage></citation></ref><ref id="B14"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Nilsson</surname><given-names>R</given-names></name><name><surname>Pe&#x000f1;a</surname><given-names>JM</given-names></name><name><surname>Bj&#x000f6;rkegren</surname><given-names>J</given-names></name><name><surname>Tegn&#x000e9;r</surname><given-names>J</given-names></name></person-group><article-title>Detecting multivariate differentially expressed genes</article-title><source>BMC Bioinformatics</source><year>2007</year><volume>8</volume><fpage>150</fpage><pub-id pub-id-type="pmid">17490475</pub-id><pub-id pub-id-type="doi">10.1186/1471-2105-8-150</pub-id></citation></ref><ref id="B15"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Benjamini</surname><given-names>Y</given-names></name><name><surname>Hochberg</surname><given-names>Y</given-names></name></person-group><article-title>Controlling the false discovery rate: a practical and powerful approach to multiple testing</article-title><source>J R Statist Soc B</source><year>1995</year><volume>57</volume><fpage>289</fpage><lpage>300</lpage></citation></ref><ref id="B16"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Frayling</surname><given-names>TM</given-names></name></person-group><article-title>Genome-wide association studies provide new insights into type 2 diabetes aetiology</article-title><source>Nat Rev Genet</source><year>2007</year><volume>8</volume><fpage>657</fpage><lpage>662</lpage><pub-id pub-id-type="pmid">17703236</pub-id><pub-id pub-id-type="doi">10.1038/nrg2178</pub-id></citation></ref><ref id="B17"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Sch&#x000e4;fer</surname><given-names>J</given-names></name><name><surname>Strimmer</surname><given-names>K</given-names></name></person-group><article-title>An empirical Bayes approach to inferring large-scale gene association networks</article-title><source>Bioinformatics</source><year>2005</year><volume>21</volume><fpage>754</fpage><lpage>764</lpage><pub-id pub-id-type="pmid">15479708</pub-id><pub-id pub-id-type="doi">10.1093/bioinformatics/bti062</pub-id></citation></ref><ref id="B18"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Cortes</surname><given-names>C</given-names></name><name><surname>Vapnik</surname><given-names>V</given-names></name></person-group><article-title>Support-Vector Networks</article-title><source>Mach Learn</source><year>1995</year><volume>20</volume><fpage>273</fpage><lpage>297</lpage></citation></ref><ref id="B19"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Mika</surname><given-names>S</given-names></name><name><surname>Ratsch</surname><given-names>G</given-names></name><name><surname>Weston</surname><given-names>J</given-names></name><name><surname>Scholkopf</surname><given-names>B</given-names></name><name><surname>Muller</surname><given-names>K</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Hen YH, Larsen J, Wilson E</surname></name></person-group><article-title>Fisher Discriminant Analysis with Kernels</article-title><source>Proceedings of IEEE Neural Networks for Signal Processing Workshop</source><year>1999</year><fpage>41</fpage><lpage>48</lpage></citation></ref><ref id="B20"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Guyon</surname><given-names>I</given-names></name><name><surname>Weston</surname><given-names>J</given-names></name><name><surname>Barnhill</surname><given-names>S</given-names></name><name><surname>Vapnik</surname><given-names>V</given-names></name></person-group><article-title>Gene Selection for Cancer Classification using Support Vector Machines</article-title><source>Mach Learn</source><year>2002</year><volume>46</volume><fpage>389</fpage><lpage>422</lpage><pub-id pub-id-type="doi">10.1023/A:1012487302797</pub-id></citation></ref><ref id="B21"><citation citation-type="other"><person-group person-group-type="author"><name><surname>Nilsson</surname><given-names>R</given-names></name><name><surname>Pe&#x000f1;a</surname><given-names>JM</given-names></name><name><surname>Bj&#x000f6;rkegren</surname><given-names>J</given-names></name><name><surname>Tegn&#x000e9;r</surname><given-names>J</given-names></name></person-group><article-title>Evaluating feature selection for SVMs in high dimensions</article-title><source>Proceedings of the 17th European Conference on Machine Learning</source><year>2006</year><fpage>719</fpage><lpage>726</lpage></citation></ref><ref id="B22"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Heorl</surname><given-names>A</given-names></name><name><surname>Kennard</surname><given-names>R</given-names></name></person-group><article-title>Ridge regression: biased estimation of nonorthogonal problems</article-title><source>Technometrics</source><year>1970</year><volume>12</volume><fpage>69</fpage><lpage>82</lpage><pub-id pub-id-type="doi">10.2307/1267352</pub-id></citation></ref><ref id="B23"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Tipping</surname><given-names>ME</given-names></name></person-group><article-title>Sparse Bayesian learning and the relevance vector machine</article-title><source>Journ Mach Learn Res</source><year>2001</year><volume>1</volume><fpage>211</fpage><lpage>244</lpage><pub-id pub-id-type="doi">10.1162/15324430152748236</pub-id></citation></ref><ref id="B24"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Li</surname><given-names>F</given-names></name><name><surname>Yang</surname><given-names>Y</given-names></name><name><surname>Xing</surname><given-names>EP</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Weiss Y</surname></name></person-group><article-title>From LASSO regression to feature vector machine</article-title><source>Advances in Neural Information Processing Systems 18</source><year>2005</year><publisher-name>MIT Press, Cambridge</publisher-name><fpage>411</fpage><lpage>418</lpage></citation></ref><ref id="B25"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Efron</surname><given-names>B</given-names></name><name><surname>Tibshirani</surname><given-names>RJ</given-names></name></person-group><source>An introduction to the bootstrap</source><year>1993</year><publisher-name>Chapman &#x00026; Hall, Inc. New York</publisher-name></citation></ref><ref id="B26"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Vapnik</surname><given-names>VN</given-names></name></person-group><source>Statistical Learning Theory</source><year>1998</year><publisher-name>John Wiley and Sons, Inc. New Jersey</publisher-name></citation></ref><ref id="B27"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>Y</given-names></name><name><surname>Landsittel</surname><given-names>D</given-names></name><name><surname>Jing</surname><given-names>L</given-names></name><name><surname>Nelson</surname><given-names>J</given-names></name><name><surname>Ren</surname><given-names>B</given-names></name><name><surname>Liu</surname><given-names>L</given-names></name><name><surname>McDonald</surname><given-names>C</given-names></name><name><surname>Thomas</surname><given-names>R</given-names></name><name><surname>Dhir</surname><given-names>R</given-names></name><name><surname>Finkelstein</surname><given-names>S</given-names></name><name><surname>Michalopoulos</surname><given-names>G</given-names></name><name><surname>Becich</surname><given-names>M</given-names></name><name><surname>Luo</surname><given-names>JH</given-names></name></person-group><article-title>Gene expression alterations in prostate cancer predicting tumor aggression and preceding development of malignancy</article-title><source>J Clin Oncol</source><year>2004</year><volume>22</volume><fpage>2790</fpage><lpage>2799</lpage><pub-id pub-id-type="pmid">15254046</pub-id><pub-id pub-id-type="doi">10.1200/JCO.2004.05.158</pub-id></citation></ref><ref id="B28"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Campo Dell'Orto</surname><given-names>M</given-names></name><name><surname>Zangrando</surname><given-names>A</given-names></name><name><surname>Trentin</surname><given-names>L</given-names></name><name><surname>Li</surname><given-names>R</given-names></name><name><surname>Liu</surname><given-names>W</given-names></name><name><surname>te Kronnie</surname><given-names>G</given-names></name><name><surname>Basso</surname><given-names>G</given-names></name><name><surname>Kohlmann</surname><given-names>A</given-names></name></person-group><article-title>New data on robustness of gene expression signatures in leukemia: comparison of three distinct total RNA preparation procedures</article-title><source>BMC Genomics</source><year>2007</year><volume>8</volume><fpage>188</fpage><pub-id pub-id-type="pmid">17587440</pub-id><pub-id pub-id-type="doi">10.1186/1471-2164-8-188</pub-id></citation></ref><ref id="B29"><citation citation-type="other"><article-title>Available from the NCBI Gene Expression Omnibus, accession GSE10960</article-title><ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/geo/"/></citation></ref></ref-list></back></article>