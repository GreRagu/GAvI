<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN" "archivearticle.dtd"><article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">J Neurophysiol</journal-id><journal-id journal-id-type="publisher-id">jn</journal-id><journal-title>Journal of Neurophysiology</journal-title><issn pub-type="ppub">0022-3077</issn><issn pub-type="epub">1522-1598</issn><publisher><publisher-name>American Physiological Society</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">17122317</article-id><article-id pub-id-type="pmc">2637604</article-id><article-id pub-id-type="publisher-id">J00745-6</article-id><article-id pub-id-type="doi">10.1152/jn.00745.2006</article-id><article-categories><subj-group subj-group-type="heading"><subject>Articles</subject></subj-group></article-categories><title-group><article-title>Reward Value Coding Distinct From Risk Attitude-Related Uncertainty Coding in Human Reward Systems</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Tobler</surname><given-names>Philippe N.</given-names></name><xref ref-type="aff" rid="N0x1c6b850N0x3ad4ad8">1</xref></contrib><contrib contrib-type="author"><name><surname>O'Doherty</surname><given-names>John P.</given-names></name><xref ref-type="aff" rid="N0x1c6b850N0x3ad4ad8">2</xref><xref ref-type="aff" rid="N0x1c6b850N0x3ad4ad8">3</xref></contrib><contrib contrib-type="author"><name><surname>Dolan</surname><given-names>Raymond J.</given-names></name><xref ref-type="aff" rid="N0x1c6b850N0x3ad4ad8">2</xref></contrib><contrib contrib-type="author"><name><surname>Schultz</surname><given-names>Wolfram</given-names></name><xref ref-type="aff" rid="N0x1c6b850N0x3ad4ad8">1</xref></contrib></contrib-group><aff id="N0x1c6b850N0x3ad4ad8"><label>1</label>Department of Physiology, Development and Neuroscience, University of Cambridge, Cambridge, United Kingdom; <label>2</label>Wellcome Department of Imaging Neuroscience, Institute of Neurology, London, United Kingdom; and <label>3</label>Division of Humanities and Social Sciences, California Institute of Technology, Pasadena, California</aff><author-notes><fn><p>Address for reprint requests and other correspondence: P. N. Tobler, Dept. of Physiology, Development and Neuroscience, University of Cambridge, Downing Street, Cambridge CB2 3DY, UK (E-mail: <email>pnt21&#x00040;cam.ac.uk</email>)</p></fn></author-notes><pub-date pub-type="ppub"><month>2</month><year>2007</year></pub-date><pub-date pub-type="epub"><day>22</day><month>11</month><year>2006</year></pub-date><pub-date pub-type="pmc-release"><day>1</day><month>2</month><year>2007</year></pub-date><!-- PMC Release delay is 0 months and 0 days and was based on the copyright element. --><volume>97</volume><issue>2</issue><fpage>1621</fpage><lpage>1632</lpage><history><date date-type="received"><day>19</day><month>7</month><year>2006</year></date><date date-type="accepted"><day>19</day><month>11</month><year>2006</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2007, American Physiological Society</copyright-statement><license license-type="open-access"><p>This document may be redistributed and reused, subject to <ext-link ext-link-type="uri" xlink:href="http://www.the-aps.org/publications/journals/funding_addendum_policy.htm">www.the-aps.org/publications/journals/funding_addendum_policy.htm</ext-link>.</p></license></permissions><self-uri xlink:title="pdf" xlink:href="z9k00207001621.pdf"/><abstract><p>When deciding between different options, individuals are guided by the expected (mean) value of the different outcomes and by the associated degrees of uncertainty. We used functional magnetic resonance imaging to identify brain activations coding the key decision parameters of expected value (magnitude and probability) separately from uncertainty (statistical variance) of monetary rewards. Participants discriminated behaviorally between stimuli associated with different expected values and uncertainty. Stimuli associated with higher expected values elicited monotonically increasing activations in distinct regions of the striatum, irrespective of different combinations of magnitude and probability. Stimuli associated with higher uncertainty (variance) elicited increasing activations in the lateral orbitofrontal cortex. Uncertainty-related activations covaried with individual risk aversion in lateral orbitofrontal regions and risk-seeking in more medial areas. Furthermore, activations in expected value-coding regions in prefrontal cortex covaried differentially with uncertainty depending on risk attitudes of individual participants, suggesting that separate prefrontal regions are involved in risk aversion and seeking. These data demonstrate the distinct coding in key reward structures of the two basic and crucial decision parameters, expected value, and uncertainty.</p></abstract></article-meta><notes><fn-group><fn><p>The costs of publication of this article were defrayed in part by the payment of page charges. The article must therefore be hereby marked &#x0201c;<italic>advertisement</italic>&#x0201d; in accordance with 18 U.S.C. Section 1734 solely to indicate this fact.</p></fn></fn-group></notes></front><body><sec><title>INTRODUCTION</title><p>Every day we make decisions about which outcomes to pursue, but we don't even know how the brain processes the most simple parameters that determine our decisions. <xref ref-type="bibr" rid="r41">Pascal (1948)</xref> used the emerging probability theory to postulate a formal description of decision-making. He conjectured that humans tend to choose the option with the highest expected (mean) value of the probability distribution of outcomes (expected value as sum of all probability-weighted values of the distribution, the first moment of a distribution). However, most realistic choices involve some degree of uncertainty of the outcome, and individuals need to take the uncertainty into account when making decisions. Uncertainty can be expressed by the variance of the probability distribution (variance as sum of probability-weighted differences from expected value, the 2nd moment). Variance reflects the spread of a distribution and indicates how far each possible value is away from the expected value. Variance is perceived as &#x0201c;risk&#x0201d; and refers to how much the decision-maker is uncertain or risks to gain, not to gain, or to lose relative to the expected (mean) value when the probabilities are known (<xref ref-type="bibr" rid="r30">Kreps 1990</xref>; <xref ref-type="bibr" rid="r42">Real 1991</xref>). Probability by itself is not a good, monotonic measure for uncertainty. For example, in a two-outcome situation (reward vs. no reward), uncertainty is maximal at <italic>P</italic> &#x0003d; 0.5 and decreases toward higher and lower probabilities as it becomes increasingly certain that something or nothing will be obtained, respectively. Modern economic decision theories, such as expected utility theory and prospect theory, build on the basic terms of expected value and uncertainty and incorporate them into the scalar decision variables of utility and prospect, respectively (<xref ref-type="bibr" rid="r22">Huang and Litzenberger 1988</xref>; <xref ref-type="bibr" rid="r26">Kahneman and Tversky 1979</xref>; <xref ref-type="bibr" rid="r30">Kreps 1990</xref>; <xref ref-type="bibr" rid="r50">Von Neuman and Morgenstern 1944</xref>).</p><p>Just as we need to understand the function of the retina before investigating visual perception, we need to understand the neural processing of expected value and variance that constitute the most basic input variables for economic decision-making. As expected value is the summed product of magnitude and probability, a neural signal for expected value should reflect the product irrespective of its components. Previous studies report distinct neural signals for magnitude and probability in striatum and orbitofrontal cortex (<xref ref-type="bibr" rid="r7">Breiter et al. 2001</xref>; <xref ref-type="bibr" rid="r12">Critchley et al. 2001</xref>; <xref ref-type="bibr" rid="r15">Delgado et al. 2003</xref>; <xref ref-type="bibr" rid="r16">Dreher et al. 2006</xref>; <xref ref-type="bibr" rid="r17">Elliott et al. 2003</xref>; <xref ref-type="bibr" rid="r27">Knutson et al. 2001</xref>, <xref ref-type="bibr" rid="r5">2005</xref>; <xref ref-type="bibr" rid="r39">O'Doherty et al. 2001</xref>; <xref ref-type="bibr" rid="r49">Volz et al. 2003</xref>) but without describing a common signal related to expected value irrespective of the two components (<xref ref-type="bibr" rid="r47">Tobler et al. 2005</xref>). The mathematical decomposition of expected utility into expected value and variance (<xref ref-type="bibr" rid="r22">Huang and Litzenberger 1988</xref>; <xref ref-type="bibr" rid="r46">Stephens and Krebs 1986</xref>) and the variations in risk attitude among different behavioral situations (<xref ref-type="bibr" rid="r10">Caraco et al. 1980</xref>, <xref ref-type="bibr" rid="r11">1990</xref>) suggest that some brain structures might process uncertainty separately from expected value.</p><p>Various brain structures appear to be engaged in situations involving uncertainty. The altered risk sensitivity and gambling in humans and animals after brain lesions suggest that the orbitofrontal cortex is involved in processing information about the uncertainty of outcomes (<xref ref-type="bibr" rid="r3">Bechara et al. 1994</xref>, <xref ref-type="bibr" rid="r2">2000</xref>; <xref ref-type="bibr" rid="r21">Hsu et al. 2005</xref>; <xref ref-type="bibr" rid="r36">Miller 1985</xref>; <xref ref-type="bibr" rid="r37">Mobini et al. 2002</xref>; <xref ref-type="bibr" rid="r45">Sanfey et al. 2003</xref>). The anterior cingulate is active with choice conflicts during financial risk-taking (<xref ref-type="bibr" rid="r31">Kuhnen and Knutson 2005</xref>), the amygdala, orbitofrontal, and dorsolateral prefrontal cortex are engaged in ambiguous situations with unknown probabilities (<xref ref-type="bibr" rid="r21">Hsu et al. 2005</xref>; <xref ref-type="bibr" rid="r23">Huettel et al. 2006</xref>), and the midbrain and striatum are involved in the coding of variance combined with magnitude or probability (<xref ref-type="bibr" rid="r16">Dreher et al. 2006</xref>) and in classification learning (<xref ref-type="bibr" rid="r1">Aron et al. 2004</xref>). However, neural signals reflecting the simple uncertainty of reward well separated from the coding of other decision variables such as expected value have not been located.</p></sec><sec sec-type="methods"><title>METHODS</title><sec><title>Participants</title><p>Sixteen right-handed healthy participants (mean age: 27 yr; range: 20&#x02013;41 yr; 8 females) were investigated. Participants were preassessed to exclude prior histories of neurological or psychiatric illness. All participants gave informed consent, and the study was approved by the Joint Ethics Committee of the National Hospital for Neurology and Neurosurgery (UK).</p></sec><sec><title>Behavioral procedure</title><p>Participants were placed on a moveable bed in the scanner with light head restraint to limit head movement during image acquisition. Participants viewed a computer monitor through a mirror fitted on top of the head coil. To study the processing of economic parameters independent of choice, subjects performed in a simple conditioning paradigm in the scanner. We determined individual risk attitudes in a separate choice task outside the scanner (see following text). At the beginning of a trial in the main paradigm, single visual stimuli appeared for 1.5 s in one of the four quadrants of the monitor. Outcomes appeared 1 s after the stimulus for 0.5 s below the stimulus on the monitor such that outcome and stimulus presentation co-terminated. Intertrial intervals varied between 1 and 8 s according to a Poisson distribution with a mean of 3 s. In each trial, we randomly presented one of twelve visual stimuli, each predicting reward with a specific magnitude and probability. We used four levels of reward magnitude, which varied between 100 and 400 points in steps of 100, and five levels of reward probability, which varied between <italic>P</italic> &#x0003d; 0.0 and <italic>P</italic> &#x0003d; 1.0 in steps of 0.25. The stimuli and the rewarded versus unrewarded outcomes alternated randomly within the boundaries defined by the probabilities (48 trials for <italic>P</italic> &#x0003d; 1.0; e.g., 36 rewarded and 12 unrewarded trials for <italic>P</italic> &#x0003d; 0.75), thus producing a measured mean of reward identical to the expected value. Throughout the experiment, the total points accumulated were displayed and updated in rewarded trials at the time of reward delivery. Four percent of the total points were predictably paid out as British pence at the end of the experiment.</p><p>The visual stimuli were specific combinations of attributes drawn from two visual dimensions, shape and color, indicating reward magnitude and probability, respectively. For example (<xref rid="f1" ref-type="fig">Fig. 1<italic>B</italic></xref>), four orange circles could predict 400 points with <italic>P</italic> &#x0003d; 0.5, whereas two dark red circles could predict 200 points with <italic>P</italic> &#x0003d; 1.0. Both stimuli were associated with different combinations of magnitude and probability but the same expected value (200 points). We counterbalanced the meaning of dimensions (shape or color of stimuli) and the direction in which they changed (for shape: number of circles per stimulus; for color: relative level of yellow or red) across participants. Stimulus delivery was controlled using Cogent 2000 software (Wellcome Department of Imaging Neuroscience, London, UK) as implemented in Matlab 6.5 (Mathworks, Natick, MA).</p><p>The first two moments of the 12 probability distributions associated with the 12 respective stimuli were calculated according to the following formulae: expected value (EV) &#x0003d; &#x003a3;<sub><italic>i</italic></sub> (<italic>m<sub>i</sub></italic> &#x000d7; <italic>p<sub>i</sub></italic>); variance &#x0003d; &#x0005b;&#x003a3;<sub><italic>i</italic></sub> (<italic>m<sub>i</sub></italic> &#x02212; EV)<sup>2</sup>&#x0005d;/<italic>n,</italic> which is equivalent to <italic>p</italic> &#x000d7; (<italic>m<sub>i</sub></italic> &#x02013;EV)<sup>2</sup> &#x0002b; (1 &#x02212; <italic>p</italic>) &#x000d7; (0 &#x02013;EV)<sup>2</sup>.</p><p>In the formulae, <italic>m</italic> is magnitude of reward, <italic>p</italic> is probability of reward, <italic>n</italic> is number of elements (outcomes associated with each stimulus), and <italic>i</italic> is index i &#x0003d; 1&#x02026;<italic>n.</italic> Our probability distributions have <italic>n</italic> &#x0003d; 1, 2, or 4 elements for <italic>P</italic> &#x0003d; 0.0 or 1.0, <italic>P</italic> &#x0003d; 0.5, and <italic>P</italic> &#x0003d; 0.25 or 0.75, respectively.</p><p>The conditioning procedure comprised a training and a testing phase. In the training phase, participants learned the meaning of the stimuli and how to perform the task while each stimulus was presented in eight consecutive trials. Earnings in the training phase did not contribute to the monetary earnings of participants, but accumulated points were nevertheless displayed. Participants were in the scanner during the training phase while structural scans were taken. Functional data were acquired in the test phase, comprising two sessions, each with 24 randomly alternating presentations of each stimulus. The task remained the same as during the training phase, but outcomes contributed to total earnings. In both training and testing phase, stimuli appeared in one of the four quadrants of the screen. The quadrant of stimulus appearance varied randomly between trials. Participants were instructed to press one of four buttons corresponding to the spatial quadrant of stimulus presentation. If they failed to press the correct button within 900 ms, the trial was aborted, a red &#x0201c;X&#x0201d; appeared, and 100 points were subtracted from the accumulated earnings. Error trials were repeated, and reported results correspond to correct trials in the testing phase.</p></sec><sec><title>Data acquisition and analysis</title><p>Participants rated the pleasantness of visual stimuli before and after the experiment on a scale ranging from 5 &#x0003d; very pleasant to &#x02212;5 &#x0003d; very unpleasant. We evaluated ratings statistically by repeated-measures ANOVA. An interaction analysis between trial type and time (before and after the experiment) tested for changes in pleasantness ratings induced by the conditioning procedure. In addition, we tested preference of participants among two concurrently presented stimuli, both before and after the experiment. Pairs of stimuli either had the same or, in control trials, different expected value. The preference tests served to assess risk attitudes within the range of magnitudes and probabilities used. Participants chose between stimuli associated with low and high uncertainty but the same expected value. Each time the participant chose the more certain stimulus, the factor of risk aversion increased by one, whereas choosing the more uncertain stimulus decreased it by one (<italic>n</italic> &#x0003d; 4 choices). A positive average factor indicated risk aversion, a negative factor indicated risk-seeking, and a zero factor risk neutrality.</p><p>We acquired gradient echo T2&#x0002a;-weighted echo-planar images (EPIs) with blood-oxygen-level-dependent (BOLD) contrast on a Siemens Sonata 1.5 Tesla scanner (slices/volume, 33; repetition time, 2.97 s). Depending on performance of participants, 405&#x02013;500 volumes were collected per session, together with five &#x0201c;dummy&#x0201d; volumes at the start of the scanning session. Scan onset times varied randomly relative to stimulus onset times. A T1-weighted structural image was also acquired for each participant. Signal dropout in basal frontal and medial temporal structures due to susceptibility artifact was reduced by using a tilted plane of acquisition (30&#x000b0; to the anterior commissure-posterior commissure line, rostral &#x0003e; caudal). Imaging parameters were: echo time, 50 ms; field-of-view, 192 mm. The in-plane resolution was 3 &#x000d7; 3 mm; with a slice thickness of 2 mm and an interslice gap of 1 mm. High-resolution T1-weighted structural scans were coregistered to their mean EPIs and averaged together to permit anatomical localization of the functional activations at the group level.</p><p>Statistical Parametric Mapping (SPM2; Functional Imaging Laboratory, London, UK) served to spatially realign functional data, normalize them to a standard EPI template and smooth them using an isometric Gaussian kernel with a full width at half-maximum of 10 mm. We used a standard rapid event-related fMRI approach in which evoked hemodynamic responses to each trial type are estimated separately by convolving a canonical hemodynamic response function with the onsets for each trial type and regressing these trial regressors against the measured fMRI signal (<xref ref-type="bibr" rid="r14">Dale and Buckner 1997</xref>; <xref ref-type="bibr" rid="r25">Josephs and Henson 1999</xref>). This approach makes use of the fact that the hemodynamic response function summates in an approximately linear fashion over time (<xref ref-type="bibr" rid="r6">Boynton et al. 1996</xref>). By presenting trials in strictly random order and using randomly varying intertrial intervals, it is possible to separate out fMRI responses to rapidly presented events without waiting for the hemodynamic response to reach baseline after each single trial (<xref ref-type="bibr" rid="r14">Dale and Buckner 1997</xref>; <xref ref-type="bibr" rid="r25">Josephs and Henson 1999</xref>). Functional data were analyzed by constructing a set of stick functions at the event-onset times for each of the 12 trial types. Rewarded and unrewarded trial types were modeled separately. The stick function regressors were convolved with a canonical hemodynamic response function (HRF). In separate time course analyses, we made no assumptions about the shape of activations and used eight finite impulse responses per trial, each response separated from the next by one scan (2.97 s). Participant-specific movement parameters were modeled as covariates of no interest.</p><p>The general linear model served to compute trial type-specific betas, reflecting the strength of covariance between the brain activation and the canonical response function for a given condition at each voxel for each participant (see <xref ref-type="bibr" rid="r20">Friston et al. 1994</xref> for detailed descriptions). The effects of interest (betas, percent of signal change) were calculated relative to an implicit baseline. Although the numbers of stimuli were counterbalanced during the experiment, the numbers of rewarded versus unrewarded trials varied due to the different reward probabilities. To compensate for different trial numbers in the general linear model, we equalized the weights of the less-frequent events by multiplication. Using random-effects analysis, the relevant contrasts of parameter estimates were entered into a series of one-way <italic>t</italic>-test, simple regressions or repeated-measures ANOVAs with nonsphericity correction where appropriate. We used thresholding strategy as described previously (<xref ref-type="bibr" rid="r40">O'Doherty et al. 2002</xref>, <xref ref-type="bibr" rid="r15">2003</xref>). For each analysis, in a priori brain regions identified in previous neuroimaging studies of reward processing (<xref ref-type="bibr" rid="r40">O'Doherty et al. 2002</xref>, <xref ref-type="bibr" rid="r15">2003</xref>), including striatum and prefrontal cortex, we report activations above a threshold of <italic>P</italic> &#x0003c; 0.001 (uncorrected) with a minimum cluster size of 5 voxels in all participants. For time course plots, we also used MarsBaR (<xref ref-type="bibr" rid="r8">Brett et al. 2002</xref>), making no assumptions about the shape of activations, and applying eight finite impulse responses per trial, each response separated from the next by one scan (2.97 s). The dependent measure in time course plots is percentage signal change measured within spheres of 10 mm around peak voxels. Reported voxels conform to MNI (Montreal Neurological Institute) coordinate space, with the right side of the image corresponding to the right side of the brain.</p></sec></sec><sec><title>RESULTS</title><p>We used functional magnetic resonance imaging (fMRI) to investigate how human reward structures process expected reward value separately from uncertainty. We used an orthogonal design that fully dissociated reward magnitude, probability, expected value, and uncertainty. We used all-or-none binary probability distributions in which the probability of obtaining a reward varied between <italic>P</italic> &#x0003d; 0 and <italic>P</italic> &#x0003d; 1. Different conditioned stimuli were associated with different reward magnitudes and probabilities, and thus expected values as their product (<xref rid="f1" ref-type="fig">Fig. 1</xref>, <italic>A</italic> and <italic>B</italic>). Our aim was to investigate the basic parameters as potential inputs to neural decision processes rather than the decision processes themselves. Therefore we used imperative situations in which we had full control over these parameters rather than behavioral choices.</p><p>The general linear model used for data analysis comprised separate regressors for the different stimuli associated with magnitude, probability, expected value, and uncertainty. Subsequent tests assumed that expected value-related brain activations covary with expected value without discriminating between different combinations of magnitude and probability that yield the same expected value. To identify uncertainty-related brain activations, the analysis assumed that uncertainty is highest for <italic>P</italic> &#x0003d; 0.5, where receiving or not receiving a reward is equally likely, and decreases toward lower and higher probabilities (variance as inverted U function of probability, <xref rid="f1" ref-type="fig">Fig. 1<italic>C</italic></xref>). Consequently, brain activations reflecting uncertainty would follow variance as inverted U function of probability. By contrast, a straightforward value signal would covary monotonically with the full range of probabilities from <italic>P</italic> &#x0003d; 0.0 to 1.0 (<xref rid="f1" ref-type="fig">Fig. 1<italic>C</italic></xref>). The distinction between the inverted U and the linear covariations with probability guided us in searching for separate brain signals for uncertainty and expected value.</p><p>Previous neurophysiological studies guided our selection of investigated brain structures. Dopamine responses covary differentially with expected value and uncertainty (<xref ref-type="bibr" rid="r19">Fiorillo et al. 2003</xref>; <xref ref-type="bibr" rid="r47">Tobler et al. 2005</xref>). As fMRI primarily reflects afferent inputs to an area (<xref ref-type="bibr" rid="r32">Logothetis et al. 2001</xref>) and as the main projection areas of dopamine neurons are the striatum and prefrontal cortex (<xref ref-type="bibr" rid="r33">Lynd-Balta and Haber 1994</xref>; <xref ref-type="bibr" rid="r51">Williams and Goldman-Rakic 1998</xref>), we searched for striatal and prefrontal regions showing differential relations to expected value and uncertainty. We used the results from the linear regressions to search for brain activity that increased phasically at the time of conditioned stimuli when reward magnitude, probability, expected value, or uncertainty increased.</p><sec><title>Behavioral performance</title><p>We measured the pleasantness of stimuli before and after conditioning. Pleasantness ratings did not vary before conditioning &#x0005b;ANOVA: <italic>F</italic>(1,11) &#x0003c; 0.77, <italic>P</italic> &#x0003e; 0.67; regression: <italic>r</italic> &#x0003c; 0.12, <italic>P</italic> &#x0003e; 0.29&#x0005d; but did afterward &#x0005b;<italic>F</italic>(1,11) &#x0003d; 10.01, <italic>P</italic> &#x0003c; 0.0001&#x0005d;, as a function of magnitude and probability (for both, <italic>r</italic> &#x0003e; 0.55, <italic>P</italic> &#x0003c; 0.0001; <xref rid="f1" ref-type="fig">Fig. 1</xref>, <italic>D</italic> and <italic>E</italic>; <xref ref-type="table" rid="t1">Table 1</xref>). After the experiment, pleasantness ratings were higher with higher expected value (<italic>r</italic> &#x0003d; 0.53, <italic>P</italic> &#x0003c; 0.0001; <xref rid="f1" ref-type="fig">Fig. 1<italic>F</italic></xref>) but did not vary within pairs of stimuli that had the same expected value but different magnitude-probability combinations (<italic>t</italic><sub>63</sub> &#x0003d; &#x02212;0.14, <italic>P</italic> &#x0003e; 0.89). Reaction time was significantly shorter for the highest compared with lowest expected reward value and showed weak negative correlation with probability (590 vs. 601 ms, <italic>t</italic><sub>2368</sub> &#x0003d; 2.3, <italic>P</italic> &#x0003c; 0.05; <italic>r</italic> &#x0003d; &#x02212;0.85, <italic>P</italic> &#x0003c; 0.08) without changing significantly with magnitude. In separate choice tests, stimuli with higher expected value were preferred more often following conditioning compared with before (83 vs. 50&#x00025;, <italic>t</italic><sub>47</sub> &#x0003d; 4.85, <italic>P</italic> &#x0003c; 0.0001). Thus participants discriminated the stimuli according to magnitude and probability and combined these two parameters in a manner that indicated they used expected value for choice preferences.</p><p>Preference tests in separate choice trials revealed that 6 of the 16 participants were risk averse, 7 were risk seeking, and 3 were risk neutral &#x0005b;average preference factors (mean &#x000b1; SE): risk averters 1.8 &#x000b1; 0.3; risk seekers &#x02212;2 &#x000b1; 0.2; scale ranging from &#x0002b;4 to &#x02013;4, see <sc>methods</sc>&#x0005d;. We measured the sensitivity (slope) of pleasantness ratings to variance for each participant and regressed this measure against individual risk attitude. We found a significant negative correlation with risk aversion (<xref rid="f1" ref-type="fig">Fig. 1<italic>G</italic></xref>), indicating that the more the participants were risk averse, the more they found uncertain outcomes unpleasant. These results suggest that the pleasantness ratings according to variance reflected individual risk attitudes.</p></sec><sec><title>Coding of expected value in striatum</title><p>To first locate activations reflecting magnitude and probability, we regressed responses to reward-predicting stimuli separately against increases in these two parameters. We found significant correlations with brain activity for both parameters in caudate and ventro-medial putamen (<xref rid="f2" ref-type="fig">Fig. 2</xref>, <italic>A</italic> and <italic>G</italic>). Similar increases were seen in the time courses of activations averaged across all participants (<xref rid="f2" ref-type="fig">Fig. 2</xref>, <italic>B</italic> and <italic>H</italic>) and with regressions of average activations onto magnitude and probability (<xref rid="f2" ref-type="fig">Fig. 2</xref>, <italic>C</italic> and <italic>I</italic>). These correlations were similar when the data were analyzed separately in rewarded and unrewarded trials (<xref rid="f2" ref-type="fig">Fig. 2</xref>, <italic>D&#x02013;F</italic> and <italic>J&#x02013;L</italic>). In addition, a medial prefrontal region showed increasing activations only with probability but not magnitude, as described before (<xref ref-type="bibr" rid="r29">Knutson et al. 2005</xref>).</p><p>Having established striatal regions coding magnitude and probability, we aimed to locate striatal activations coding expected value. We regressed brain activation against expected value and found significant correlations in the medial and posterior striatum (<xref rid="f3" ref-type="fig">Fig. 3</xref>, <italic>A</italic> and <italic>E</italic>), which were also apparent in the averaged time courses (<xref rid="f3" ref-type="fig">Fig. 3</xref>, <italic>B</italic> and <italic>F</italic>). The activations increased significantly with expected value (<xref rid="f3" ref-type="fig">Fig. 3</xref>, <italic>C</italic> and <italic>G</italic>) but not with variance (<xref rid="f4" ref-type="fig">Fig. 4<italic>D</italic></xref>). The inverse, decreasing activations with increasing expected value, was not found in the striatum (<italic>P</italic> &#x0003e; 0.05). Regressions of brain activation against expected value differed significantly from regressions against reaction time in ventral striatum (<xref rid="f3" ref-type="fig">Fig. 3<italic>H</italic></xref>) but not in dorsal striatum (higher activation with both expected value and slower reactions; <xref rid="f3" ref-type="fig">Fig. 3<italic>D</italic></xref>). These data suggest separate coding between expected value and the motivational effects associated with increasing rewards.</p><p>Besides covarying with magnitude and probability, the coding of expected value would require that neural changes with one parameter compensate opposite changes in the other parameter, such that activations with different magnitude-probability combinations resulting in the same multiplicative product would be indistinguishable. In applying this test, we found similar striatal activations for the same expected values resulting from different magnitude-probability combinations (<xref rid="f4" ref-type="fig">Fig. 4<italic>A</italic></xref>). For example, activations differed insignificantly between stimuli predicting 100 reward points with <italic>P</italic> &#x0003d; 1.0 and 200 points with <italic>P</italic> &#x0003d; 0.5 (expected value 100 points), but activations were higher than for stimuli associated with an expected value of 50 points and lower than for stimuli associated with an expected value of 150 points. Despite the constancy for different magnitude-probability combinations, the striatal regions activated with expected value (<xref rid="f3" ref-type="fig">Fig. 3</xref>, <italic>A</italic> and <italic>E</italic>) were sensitive to individual variations in magnitude and probability (<xref rid="f4" ref-type="fig">Fig. 4<italic>B</italic></xref>). Taken together, activations in the striatum seemed to combine reward magnitude and probability multiplicatively into a common signal of expected value but were unrelated to variance.</p><p>As expected value covaries with both magnitude and probability, we found, not surprisingly, that the striatal region coding expected value overlapped partly with regions coding magnitude and probability (<xref rid="f2" ref-type="fig">Figs. 2</xref>, <italic>A</italic> and <italic>G</italic>, and <xref rid="f4" ref-type="fig">4<italic>C</italic></xref>). The lack of coding of expected value in the larger, nonoverlapping parts may be due to lack of sensitivity to one of the parameters or to lack of multiplicative coding, an issue requiring further experimentation.</p><p>In addition, a dorsolateral prefrontal region showed partly overlapping coding of magnitude, probability and expected value using the regression model but lesser coding when time courses were plotted and when multiplicative combinations were tested (<xref rid="f5" ref-type="fig">Fig. 5</xref>). Parts of medial and orbital frontal cortex showed graded coding with expected value in the regression model (<xref ref-type="table" rid="t2">Table 2</xref>, bottom). Decreasing activations with increasing expected value were found only in the insula.</p></sec><sec><title>Uncertainty coding in orbitofrontal cortex</title><p>To locate activations reflecting uncertainty separate from expected value, we used the general linear model and tested for changes in variance, separate from expected value, across the full range of probabilities for two levels of magnitude (0&#x02013;100 and 0&#x02013;200 points, <xref rid="f1" ref-type="fig">Fig. 1</xref>, <italic>B</italic> and <italic>C</italic>). Variance followed an inverted U function across increasing probabilities, whereas expected value increased monotonically with probability (<xref rid="f1" ref-type="fig">Fig. 1<italic>C</italic></xref>).</p><p>We found significant correlations of averaged brain activation with variance in the lateral orbitofrontal cortex (<xref rid="f6" ref-type="fig">Fig. 6<italic>A</italic></xref>), which occurred also in time courses (<xref rid="f6" ref-type="fig">Fig. 6<italic>B</italic></xref>). The activations correlated with variance (<xref rid="f6" ref-type="fig">Fig. 6<italic>C</italic></xref>) but not expected value (<xref rid="f6" ref-type="fig">Fig. 6<italic>D</italic></xref>). We then aimed to relate the activations to risk sensitivity and regressed the goodness of fit of uncertainty-related brain activation in all participants against their individual risk attitudes. We found positive correlations with risk aversion in lateral orbitofrontal cortex (<xref rid="f7" ref-type="fig">Fig. 7</xref>, <italic>A&#x02013;C</italic>) and, significantly different, with risk-seeking more medially (<xref rid="f7" ref-type="fig">Fig. 7</xref>, <italic>D&#x02013;F</italic>).</p><p>These data suggest that activations in orbitofrontal cortex process uncertainty irrespective of changes in expected value. Moreover, uncertainty coding appears to be differentially related to the risk attitude of participants in medial and lateral orbitofrontal regions.</p></sec><sec><title>Combined coding of expected value and uncertainty in prefrontal cortex</title><p>Whereas the results in the preceding text demonstrate discrete coding of expected value and uncertainty, we aimed to find brain regions that code both parameters in combination. A region in middle prefrontal cortex showed increased activation with expected value irrespective of risk attitude (<xref rid="f8" ref-type="fig">Fig. 8</xref>, <italic>B, C, F,</italic> and <italic>G</italic>). However, activations in the same voxels decreased differentially with variance in risk-averse participants (<xref rid="f8" ref-type="fig">Fig. 8</xref>, <italic>D</italic> and <italic>H</italic>) but increased with variance in risk seekers (<xref rid="f8" ref-type="fig">Fig. 8</xref>, <italic>E</italic> and <italic>I</italic>). The difference in slope was statistically significant (<italic>P</italic> &#x0003c; 0.0001). Using this same regression model, we found two other prefrontal regions that showed selective uncertainty coding depending on individual risk attitude in the voxels coding reward value. An anterior superior frontal gyrus region showed decreases with variance only in risk-averse participants (<xref rid="f9" ref-type="fig">Fig. 9</xref>, <italic>A&#x02013;G</italic>), whereas a caudal inferior frontal gyrus region showed increased activation with variance only in risk seekers (<xref rid="f9" ref-type="fig">Fig. 9</xref>, <italic>F&#x02013;J</italic>), suggesting that different value-coding prefrontal areas subserve the evaluation of risk depending on individual risk attitudes.</p></sec></sec><sec><title>DISCUSSION</title><p>This study shows that the two basic economic decision parameters, expected value and uncertainty of reward, were coded in distinct structures of the human brain. The coding of expected value involved the striatum and, to a lesser extent, parts of frontal cortex. The responses covaried with expected value irrespective of different combinations of magnitude and probability, although some regions of striatum and frontal cortex coded specifically only magnitude or probability. These activations were unrelated to reward uncertainty. By contrast, the coding of reward uncertainty as measured by variance involved regions in the orbitofrontal cortex. Uncertainty responses correlated with individual risk attitudes without reflecting reward value. Although expected value and uncertainty appear to be coded mostly separately from each other, some prefrontal regions showed value-related activations that covaried with uncertainty depending on individual risk attitudes. Taken together the data suggest that crucial parameters for reward-directed decision-making were coded in the prime reward structures of the human brain.</p><p>The coding of expected value in some striatal regions occurred irrespectively of different multiplicative combinations of reward magnitude and probability. This was unlikely due to insensitivity of these regions to magnitude or probability as these regions showed increasing responses when these parameters varied independently (<xref rid="f4" ref-type="fig">Fig. 4<italic>B</italic></xref>). Neither was expected value coding due to simple coincidence or conjunction of magnitude and probability coding. To achieve expected value coding irrespective of magnitude-probability combinations would require closely matching response gains, so that response reduction with one parameter is compensated by response augmentation with the other parameter. Unmatched gains for magnitude and probability responses would not lead to unchanged brain responses when decrease in one parameter together with increase in the other results in the same expected value. The required matching of response gains for magnitude and probability in regions in which both variables are processed make the coding of expected value a remarkable achievement of neural coding.</p><p>Apart from the activations reflecting expected value we confirmed previous results indicating separate, regionally distinct relationships of striatal activations to reward magnitude (<xref ref-type="bibr" rid="r7">Breiter et al. 2001</xref>; <xref ref-type="bibr" rid="r15">Delgado et al. 2003</xref>; <xref ref-type="bibr" rid="r39">O'Doherty et al. 2001</xref>) and probability (<xref ref-type="bibr" rid="r16">Dreher et al. 2006</xref>), with the exception of a block design study that failed to find magnitude relationships (<xref ref-type="bibr" rid="r17">Elliott et al. 2003</xref>). A previous study found covariations with magnitude in nucleus accumbens but not with probability or expected value (<xref ref-type="bibr" rid="r29">Knutson et al. 2005</xref>). However, that study used an anticipatory delay between cues and outcomes in a contingent action-outcome design including loss trials, which may preclude direct comparisons with the present study. Thus it had been unclear until now whether these separate reward parameters might be coded in combination as expected value in parts of the human brain and specifically in the striatum. The present results suggest that fMRI activations reflecting reward magnitude, probability, and expected value occur in separate striatal regions and well separated from uncertainty coding.</p><p>Activations in ventromedial prefrontal regions increased with reward probability. Previous imaging studies found also no relation of medial prefrontal responses to variations in reward magnitude, irrespective of probability being kept constant or varied (<xref ref-type="bibr" rid="r28">Knutson et al. 2003</xref>, <xref ref-type="bibr" rid="r5">2005</xref>). These results together suggest a preferential relation of ventromedial prefrontal activation with reward probability rather than magnitude. The preferential ventromedial prefrontal coding of reward probability contrasts with the distinct relationships to both reward magnitude and probability in the striatum. Thus our findings confirm that some reward structures process the basic reward components of magnitude and probability separately. It would be interesting to ask what the function of such independent coding might be. In the St. Petersburg Paradox, individuals typically refuse to pay all their finite possessions for options associated with infinite magnitude and expected value, but at near-zero probability (<xref ref-type="bibr" rid="r4">Bernoulli 1954</xref>). Thus they remain sensitive to independent variations in the components of expected value, and the presently observed separate coding of probability and magnitude may support such sensitivity.</p><p>The short trial duration of 1.5 s might have compromised the separation of activations in relation to the cues and rewards. However, we analyzed rewarded trials separately from unrewarded trials and found comparable results. The separations suggest that the observed relationships to reward magnitude, probability, and expected value reflect predominantly responses to the specific cues rather than the rewards. The similar activations in rewarded and unrewarded trials would rule out major contributions of reward prediction error coding that should differ across the different degrees of positive and negative reward prediction errors in probability schedules (<xref ref-type="bibr" rid="r34">McClure et al. 2003</xref>; <xref ref-type="bibr" rid="r38">O'Doherty et al. 2003</xref>). Despite the motivating influences of expected value on behavioral reaction times, we found no correlation of expected value coding to this behavioral parameter, suggesting that the activations did not reflect simple motivational factors suggested to play a role in reward processing in monkey premotor cortex (<xref ref-type="bibr" rid="r44">Roesch and Olson 2003</xref>). Although penalty and perception of outcome control can influence striatal reward processes (<xref ref-type="bibr" rid="r48">Tricomi et al. 2004</xref>), our experiments held these variables constant and the described activations should not be due to them.</p><p>Phasic responses of dopamine neurons are consistently stronger to stimuli associated with higher reward magnitude, probability, and expected value (<xref ref-type="bibr" rid="r19">Fiorillo et al. 2003</xref>; <xref ref-type="bibr" rid="r47">Tobler et al. 2005</xref>). Conversely, striatal output neurons show equal proportions of both increasing and decreasing responses during expectation and receipt of increasing reward magnitudes (<xref ref-type="bibr" rid="r13">Cromwell and Schultz 2003</xref>), although probability and expected value remain to be investigated. The striatum forms the primary target region of dopamine projections (e.g., <xref ref-type="bibr" rid="r33">Lynd-Balta and Haber 1994</xref>), and hemodynamic responses measured by fMRI primarily reflect input activity (<xref ref-type="bibr" rid="r32">Logothetis et al. 2001</xref>). Accordingly, the presently observed increasing magnitude-related striatal activations resemble more closely possible inputs from dopamine neurons rather than local striatal activity. Moreover, the similarity between the currently observed striatal activations and phasic dopamine responses extends to probability and expected value. It is thus conceivable that the observed striatal activations are partly driven by dopaminergic inputs, although dilatory effects on the vascular system (e.g., <xref ref-type="bibr" rid="r24">Hughes et al. 1986</xref>) cannot be entirely excluded. In addition, nondopaminergic inputs to the striatum or intrinsic computations within the striatum might be responsible for the nonhomogeneous, differential coding of magnitude and probability separate from expected value.</p><p>A major current finding consists of separate regions in the striatum and lateral orbitofrontal cortex that show distinct activations with expected value and uncertainty. Expected value and uncertainty of choice options are important parameters that determine behavioral preferences. They often vary independently when individual risk attitudes change over situations and time (<xref ref-type="bibr" rid="r10">Caraco et al. 1980</xref>, <xref ref-type="bibr" rid="r11">1990</xref>; <xref ref-type="bibr" rid="r46">Stephens and Krebs 1986</xref>). It is therefore advantageous for agents to have an independent neuronal representation of both to choose according to individual risk preference while retaining sensitivity to variations in expected value. Thus by independently representing expected value and uncertainty, the currently observed striatal and orbitofrontal activations could make independent contributions to decisions involving risky choices.</p><p>The presently observed orbitofrontal activations with uncertainty relate well to the behavioral alterations in risky situations induced by lesions in orbitofrontal cortex (<xref ref-type="bibr" rid="r3">Bechara et al. 1994</xref>, <xref ref-type="bibr" rid="r2">2000</xref>; <xref ref-type="bibr" rid="r21">Hsu et al. 2005</xref>; <xref ref-type="bibr" rid="r36">Miller 1985</xref>; <xref ref-type="bibr" rid="r37">Mobini et al. 2002</xref>; <xref ref-type="bibr" rid="r45">Sanfey et al. 2003</xref>). Our findings may also help to explain the altered orbitofrontal activations during risky decisions in drug addicts (<xref ref-type="bibr" rid="r5">Bolla et al. 2005</xref>; <xref ref-type="bibr" rid="r18">Ersche et al. 2005</xref>). The present results do not necessarily exclude a role of the striatum in coding uncertainty at longer time scales than tested presently. Dopamine neurons show a slower, more sustained uncertainty signal (<xref ref-type="bibr" rid="r19">Fiorillo et al. 2003</xref>) that might induce striatal uncertainty-related activations (<xref ref-type="bibr" rid="r1">Aron et al. 2004</xref>). Other regions coding uncertainty could include the posterior cingulate and parietal cortex (<xref ref-type="bibr" rid="r23">Huettel et al. 2006</xref>; <xref ref-type="bibr" rid="r35">McCoy and Platt 2005</xref>), although the present study failed to find substantial uncertainty-related activations in these regions.</p><p>The lateral orbitofrontal cortex showed stronger uncertainty-related activity with increasing individual risk aversion, whereas medial orbitofrontal activations correlated with increasing risk-seeking. Thus uncertainty responses are differentially modulated by individual risk attitudes in the two orbitofrontal regions. Individual risk attitudes are crucial in determining the utility of uncertain rewards. Expected utility theory postulates that the utility of a reward decreases with increasing uncertainty for a risk-averse individual but increases for a risk seeker. The negative and positive influences of uncertainty increase with increasing degrees of individual risk-avoiding and -seeking behavior, respectively. The differential orbitofrontal relationships of uncertainty coding to individual risk attitudes may contribute to the varying influences of uncertain rewards on utility for the individual decision maker.</p><p>Different prefrontal regions showed different forms of combined coding of expected value and variance. Taylor series expansion suggests that the expected utility of an option can be approximated by its mean and variance (and additional higher moments) (<xref ref-type="bibr" rid="r22">Huang and Litzenberger 1988</xref>; <xref ref-type="bibr" rid="r46">Stephens and Krebs 1986</xref>). As a consequence, expected value and uncertainty can separately influence the expected utility of an outcome. Risk-averse individuals aim to maximize expected reward value as well as minimize variance, whereas risk-seekers tend to maximize both expected value and variance. A variety of species, such as bumblebees (<xref ref-type="bibr" rid="r43">Real et al. 1982</xref>) and juncos (<xref ref-type="bibr" rid="r9">Caraco and Lima 1985</xref>), are sensitive to both expected value and variance. The present activations directly reflect the influence of individual risk attitude on uncertainty coding in voxels that also show expected value coding, both for risk averters and risk seekers. Although these activations may involve separate individual neurons, the close proximity of value and uncertainty coding may suggest an involvement of prefrontal cortex in the computation of an integrated expected utility signal. The selective influence of individual risk aversion on decreasing uncertainty coding contrasts with the selective influence of risk seeking on positive uncertainty coding in a different prefrontal region and may suggest that activations in different prefrontal regions underlie the pronounced differences between risk averters and risk seekers in choice preferences involving uncertain outcomes.</p><p>In conclusion, we show that reward structures of the human brain separately encode basic microeconomic reward parameters. Specifically, the striatum carries rather distinct representations of reward magnitude, probability, and expected value. Separate activations in the orbitofrontal cortex increase with reward uncertainty and correlate with individual risk attitudes. The data suggest largely distinct contributions of reward structures to the coding of value and uncertainty of reward-predicting stimuli. The particular prefrontal activations combining expected value and uncertainty into a single response may provide the basis for an expected utility signal. Thereby the presently observed activations may serve as a basis for economic decision-making.</p></sec><sec><title>GRANTS</title><p>This study was supported by the Wellcome Trust, the Swiss National Science Foundation and the Roche Research Foundation. R. J. Dolan and W. Schultz are supported by Wellcome Trust Programme Grants, W. Schultz by a Wellcome Trust Principal Research Fellowship.</p></sec></body><back><ack><p>We thank P. Bossaerts, Y. Christopoulos, L. Gregorios-Pippas, R. Henson, and K. Miyapuram for discussions and/or comments.</p></ack><ref-list><title>REFERENCES</title><ref id="r1"><label>Aron et al. 2004</label><citation citation-type="journal"><name><surname>Aron</surname><given-names>AR</given-names></name>, Shohamy D, Clark J, Myers C, Gluck MA, Poldrack RA. Human midbrain sensitivity to cognitive feedback and uncertainty during classification learning. <source>J Neurophysiol</source> <volume>92</volume>: <fpage>1144</fpage>&#x02013;1152, <year>2004</year>.<pub-id pub-id-type="pmid">15014103</pub-id></citation></ref><ref id="r2"><label>Bechara et al. 2000</label><citation citation-type="journal"><name><surname>Bechara</surname><given-names>A</given-names></name>, Damasio H, Damasio AR. Emotion, decision-making and the orbitofrontal cortex. <source>Cereb Cortex</source> <volume>10</volume>: <fpage>295</fpage>&#x02013;307, <year>2000</year>.<pub-id pub-id-type="pmid">10731224</pub-id></citation></ref><ref id="r3"><label>Bechara et al. 1994</label><citation citation-type="journal"><name><surname>Bechara</surname><given-names>A</given-names></name>, Damasio AR, Damasio H, Anderson SW. Insensitivity to future consequences following damage to human prefrontal cortex. <source>Cognition</source> <volume>50</volume>: <fpage>7</fpage>&#x02013;15, <year>1994</year>.<pub-id pub-id-type="pmid">8039375</pub-id></citation></ref><ref id="r4"><label>Bernoulli 1954</label><citation citation-type="journal"><name><surname>Bernoulli</surname><given-names>D</given-names></name> Exposition of a new theory on the measurement of risk (translated from Latin). <source>Econometrica</source> <volume>22</volume>: <fpage>23</fpage>&#x02013;36, <year>1954</year>.</citation></ref><ref id="r5"><label>Bolla et al. 2005</label><citation citation-type="journal"><name><surname>Bolla</surname><given-names>KI</given-names></name>, Eldreth DA, Matochik JA, Cadet JL. Neural substrates of faulty decision-making in abstinent marijuana users. <source>Neuroimage</source> <volume>26</volume>: <fpage>480</fpage>&#x02013;492, <year>2005</year>.<pub-id pub-id-type="pmid">15907305</pub-id></citation></ref><ref id="r6"><label>Boynton et al. 1996</label><citation citation-type="journal"><name><surname>Boynton</surname><given-names>GM</given-names></name>, Engel SA, Glover GH, Heeger DJ. Linear systems analysis of functional magnetic resonance imaging in human V1. <source>J Neurosci</source> <volume>16</volume>: <fpage>4207</fpage>&#x02013;4221, <year>1996</year>.<pub-id pub-id-type="pmid">8753882</pub-id></citation></ref><ref id="r7"><label>Breiter et al. 2001</label><citation citation-type="journal"><name><surname>Breiter</surname><given-names>HC</given-names></name>, Aharon I, Kahneman D, Dale A, Shizgal P. Functional imaging of neural responses to expectancy and experience of monetary gains and losses. <source>Neuron</source> <volume>30</volume>: <fpage>619</fpage>&#x02013;639, <year>2001</year>.<pub-id pub-id-type="pmid">11395019</pub-id></citation></ref><ref id="r8"><label>Brett et al. 2002</label><citation citation-type="other"><name><surname>Brett</surname><given-names>M</given-names></name>, Anton J-L, Valabregue R, Poline J-B. Region of interest analysis using an SPM toolbox (Abstract). <source>8th International Conferance on Functional Mapping of the Human Brain, Sendai, Japan.</source> June <year>2002</year>.</citation></ref><ref id="r9"><label>Caraco and Lima 1985</label><citation citation-type="journal"><name><surname>Caraco</surname><given-names>T</given-names></name>, Lima SL. Foraging juncos: Interaction of reward mean and variability. <source>Anim Behav</source> <volume>33</volume>: <fpage>216</fpage>&#x02013;224, <year>1985</year>.</citation></ref><ref id="r10"><label>Caraco et al. 1980</label><citation citation-type="journal"><name><surname>Caraco</surname><given-names>T</given-names></name>, Martindale S, Whitham TS. An empirical demonstration of risk-sensitive foraging preferences. <source>Anim Behav</source> <volume>28</volume>: <fpage>820</fpage>&#x02013;830, <year>1980</year>.</citation></ref><ref id="r11"><label>Caraco et al. 1990</label><citation citation-type="journal"><name><surname>Caraco</surname><given-names>T</given-names></name>, Blankenhorn WU, Gregory GM, Newman JA, Recer GM, Zwicker SM. Risk-sensitivity: ambient temperature affects foraging choice. <source>Anim Behav</source> <volume>39</volume>: <fpage>338</fpage>&#x02013;345, <year>1990</year>.</citation></ref><ref id="r12"><label>Critchley et al. 2001</label><citation citation-type="journal"><name><surname>Critchley</surname><given-names>HD</given-names></name>, Mathias CJ, Dolan RJ. Neural activity in the human brain relating to uncertainty and arousal during anticipation. <source>Neuron</source> <volume>29</volume>: <fpage>537</fpage>&#x02013;545, <year>2001</year>.<pub-id pub-id-type="pmid">11239442</pub-id></citation></ref><ref id="r13"><label>Cromwell and Schultz 2003</label><citation citation-type="journal"><name><surname>Cromwell</surname><given-names>HC</given-names></name>, Schultz W. Effects of expectations for different reward magnitudes on neuronal activity in primate striatum. <source>J Neurophysiol</source> <volume>89</volume>: <fpage>2823</fpage>&#x02013;2838, <year>2003</year>.<pub-id pub-id-type="pmid">12611937</pub-id></citation></ref><ref id="r14"><label>Dale and Buckner 1997</label><citation citation-type="journal"><name><surname>Dale</surname><given-names>AM</given-names></name>, Buckner RL. Selective averaging of rapidly presented individual trials using fMRI. <source>Hum Brain Mapp</source> <volume>5</volume>: <fpage>329</fpage>&#x02013;340, <year>1997</year>.</citation></ref><ref id="r15"><label>Delgado et al. 2003</label><citation citation-type="journal"><name><surname>Delgado</surname><given-names>MR</given-names></name>, Locke HM, Stenger VA, Fiez JA. Dorsal striatum responses to reward and punishment: effects of valence and magnitude manipulations. <source>Cogn Affect Behav Neurosci</source> <volume>3</volume>: <fpage>27</fpage>&#x02013;38, <year>2003</year>.<pub-id pub-id-type="pmid">12822596</pub-id></citation></ref><ref id="r16"><label>Dreher et al. 2006</label><citation citation-type="journal"><name><surname>Dreher</surname><given-names>JC</given-names></name>, Kohn P, Berman KF. Neural coding of distinct statistical properties of reward information in humans. <source>Cereb Cortex</source> <volume>16</volume>: <fpage>561</fpage>&#x02013;573, <year>2006</year>.<pub-id pub-id-type="pmid">16033924</pub-id></citation></ref><ref id="r17"><label>Elliott et al. 2003</label><citation citation-type="journal"><name><surname>Elliott</surname><given-names>R</given-names></name>, Newman JL, Longe OA, Deakin JF. Differential response patterns in the striatum and orbitofrontal cortex to financial reward in humans: a parametric functional magnetic resonance imaging study. <source>J Neurosci</source> <volume>23</volume>: <fpage>303</fpage>&#x02013;307, <year>2003</year>.<pub-id pub-id-type="pmid">12514228</pub-id></citation></ref><ref id="r18"><label>Ersche et al. 2005</label><citation citation-type="journal"><name><surname>Ersche</surname><given-names>KD</given-names></name>, Fletcher PC, Lewis SJ, Clark L, Stocks-Gee G, London M, Deakin JB, Robbins TW, Sahakian BJ. Abnormal frontal activations related to decision-making in current and former amphetamine and opiate dependent individuals. <source>Psychopharmacology</source> <volume>180</volume>: <fpage>612</fpage>&#x02013;623, <year>2005</year>.<pub-id pub-id-type="pmid">16163533</pub-id></citation></ref><ref id="r19"><label>Fiorillo et al. 2003</label><citation citation-type="journal"><name><surname>Fiorillo</surname><given-names>CD</given-names></name>, Tobler PN, Schultz W. Discrete coding of reward probability and uncertainty by dopamine neurons. <source>Science</source> <volume>299</volume>: <fpage>1898</fpage>&#x02013;1902, <year>2003</year>.<pub-id pub-id-type="pmid">12649484</pub-id></citation></ref><ref id="r20"><label>Friston et al. 1994</label><citation citation-type="journal"><name><surname>Friston</surname><given-names>KJ</given-names></name>, Holmes AP, Worsley KJ, Poline JP, Frith CD, Frackowiak RSJ. Statistical parametric maps in functional imaging: a general linear approach. <source>Hum Brain Mapp</source> <volume>2</volume>: <fpage>189</fpage>&#x02013;210, <year>1994</year>.</citation></ref><ref id="r21"><label>Hsu et al. 2005</label><citation citation-type="journal"><name><surname>Hsu</surname><given-names>M</given-names></name>, Bhatt M, Adolphs R, Tranel D, Camerer CF. Neural systems responding to degrees of uncertainty in human decision-making. <source>Science</source> <volume>310</volume>: <fpage>1680</fpage>&#x02013;1683, <year>2005</year>.<pub-id pub-id-type="pmid">16339445</pub-id></citation></ref><ref id="r22"><label>Huang and Litzenberger 1988</label><citation citation-type="other"><name><surname>Huang</surname><given-names>C-F</given-names></name>, Litzenberger RH. <source>Foundations for Financial Economics.</source> Upper Saddle River, NJ: Prentice-Hall, <year>1988</year>.</citation></ref><ref id="r23"><label>Huettel et al. 2006</label><citation citation-type="journal"><name><surname>Huettel</surname><given-names>SA</given-names></name>, Stowe CJ, Gordon EM, Warner BT, Platt ML. Neural signatures of economic preferences for risk and ambiguity. <source>Neuron</source> <volume>49</volume>: <fpage>765</fpage>&#x02013;775, <year>2006</year>.<pub-id pub-id-type="pmid">16504951</pub-id></citation></ref><ref id="r24"><label>Hughes et al. 1986</label><citation citation-type="journal"><name><surname>Hughes</surname><given-names>A</given-names></name>, Thom S, Martin G, Redman D, Hasan S, Sever P. The action of a dopamine (DA1) receptor agonist, fenoldopam in human vasculature in vivo and in vitro. <source>Br J Clin Pharmacol</source> <volume>22</volume>: <fpage>535</fpage>&#x02013;540, <year>1986</year>.<pub-id pub-id-type="pmid">2878679</pub-id></citation></ref><ref id="r25"><label>Josephs and Henson 1999</label><citation citation-type="journal"><name><surname>Josephs</surname><given-names>O</given-names></name>, Henson RN. Event-related functional magnetic resonance imaging: modelling, inference and optimization. <source>Philos Trans R Soc Lond B Biol Sci</source> <volume>354</volume>: <fpage>1215</fpage>&#x02013;1228, <year>1999</year>.<pub-id pub-id-type="pmid">10466147</pub-id></citation></ref><ref id="r26"><label>Kahneman and Tversky 1979</label><citation citation-type="journal"><name><surname>Kahneman</surname><given-names>D</given-names></name>, Tversky A. Prospect theory: an analysis of decision under risk. <source>Econometrica</source> <volume>47</volume>: <fpage>263</fpage>&#x02013;291, <year>1979</year>.</citation></ref><ref id="r27"><label>Knutson et al. 2001</label><citation citation-type="journal"><name><surname>Knutson</surname><given-names>B</given-names></name>, Adams CM, Fong GW, Hommer D. Anticipation of increasing monetary reward selectively recruits nucleus accumbens. <source>J Neurosci</source> <volume>21</volume>: <fpage>RC159</fpage>, <year>2001</year>.<pub-id pub-id-type="pmid">11459880</pub-id></citation></ref><ref id="r28"><label>Knutson et al. 2003</label><citation citation-type="journal"><name><surname>Knutson</surname><given-names>B</given-names></name>, Fong GW, Bennett SM, Adams CM, Hommer D. A region of mesial prefrontal cortex tracks monetarily rewarding outcomes: characterization with rapid event-related fMRI. <source>Neuroimage</source> <volume>18</volume>: <fpage>263</fpage>&#x02013;272, <year>2003</year>.<pub-id pub-id-type="pmid">12595181</pub-id></citation></ref><ref id="r29"><label>Knutson et al. 2005</label><citation citation-type="journal"><name><surname>Knutson</surname><given-names>B</given-names></name>, Taylor J, Kaufman M, Peterson R, Glover G. Distributed neural representation of expected value. <source>J Neurosci</source> <volume>25</volume>: <fpage>4806</fpage>&#x02013;4812, <year>2005</year>.<pub-id pub-id-type="pmid">15888656</pub-id></citation></ref><ref id="r30"><label>Kreps 1990</label><citation citation-type="other"><name><surname>Kreps</surname><given-names>DM</given-names></name> <source>A Course in Microeconomic Theory.</source> Harlow, UK: Pearson Education, <year>1990</year>.</citation></ref><ref id="r31"><label>Kuhnen and Knutson 2005</label><citation citation-type="journal"><name><surname>Kuhnen</surname><given-names>CM</given-names></name>, Knutson B. The neural basis of financial risk taking. <source>Neuron</source> <volume>47</volume>: <fpage>763</fpage>&#x02013;770, <year>2005</year>.<pub-id pub-id-type="pmid">16129404</pub-id></citation></ref><ref id="r32"><label>Logothetis et al. 2001</label><citation citation-type="journal"><name><surname>Logothetis</surname><given-names>NK</given-names></name>, Pauls J, Augath M, Trinath T, Oeltermann A. Neurophysiological investigation of the basis of the fMRI signal. <source>Nature</source> <volume>412</volume>: <fpage>150</fpage>&#x02013;157, <year>2001</year>.<pub-id pub-id-type="pmid">11449264</pub-id></citation></ref><ref id="r33"><label>Lynd-Balta and Haber 1994</label><citation citation-type="journal"><name><surname>Lynd-Balta</surname><given-names>E</given-names></name>, Haber SN. The organization of midbrain projections to the ventral striatum in the primate. <source>Neuroscience</source> <volume>59</volume>: <fpage>609</fpage>&#x02013;623, <year>1994</year>.<pub-id pub-id-type="pmid">7516505</pub-id></citation></ref><ref id="r34"><label>McClure et al. 2003</label><citation citation-type="journal"><name><surname>McClure</surname><given-names>SM</given-names></name>, Berns GS, Montague PR. Temporal prediction errors in a passive learning task activate human striatum. <source>Neuron</source> <volume>38</volume>: <fpage>339</fpage>&#x02013;346, <year>2003</year>.<pub-id pub-id-type="pmid">12718866</pub-id></citation></ref><ref id="r35"><label>McCoy and Platt 2005</label><citation citation-type="journal"><name><surname>McCoy</surname><given-names>AN</given-names></name>, Platt ML. Risk-sensitive neurons in macaque posterior cingulate cortex. <source>Nat Neurosci</source> <volume>8</volume>: <fpage>1220</fpage>&#x02013;1227, <year>2005</year>.<pub-id pub-id-type="pmid">16116449</pub-id></citation></ref><ref id="r36"><label>Miller 1985</label><citation citation-type="journal"><name><surname>Miller</surname><given-names>LA</given-names></name> Cognitive risk-taking after frontal or temporal lobectomy. I. Synthesis of fragmented visual information. <source>Neuropsychologia</source> <volume>23</volume>: <fpage>359</fpage>&#x02013;369, <year>1985</year>.<pub-id pub-id-type="pmid">4022303</pub-id></citation></ref><ref id="r37"><label>Mobini et al. 2002</label><citation citation-type="journal"><name><surname>Mobini</surname><given-names>S</given-names></name>, Body S, Ho M-Y, Bradshaw CM, Szabadi E, Deakin JFW, Anderson IM. Effects of lesions of the orbitofrontal cortex on sensitivity to delayed and probabilistic reinforcement. <source>Psychopharmacology</source> <volume>160</volume>: <fpage>290</fpage>&#x02013;298, <year>2002</year>.<pub-id pub-id-type="pmid">11889498</pub-id></citation></ref><ref id="r38"><label>O'Doherty et al. 2003</label><citation citation-type="journal"><name><surname>O'Doherty</surname><given-names>JP</given-names></name>, Dayan P, Friston K, Critchley H, Dolan RJ. Temporal difference models and reward-related learning in the human brain. <source>Neuron</source> <volume>38</volume>: <fpage>329</fpage>&#x02013;337, <year>2003</year>.<pub-id pub-id-type="pmid">12718865</pub-id></citation></ref><ref id="r39"><label>O'Doherty et al. 2001</label><citation citation-type="journal"><name><surname>O'Doherty</surname><given-names>J</given-names></name>, Kringelbach ML, Rolls ET, Hornak J, Andrews C. Abstract reward and punishment representations in the human orbitofrontal cortex. <source>Nat Neurosci</source> <volume>4</volume>: <fpage>95</fpage>&#x02013;102, <year>2001</year>.<pub-id pub-id-type="pmid">11135651</pub-id></citation></ref><ref id="r40"><label>O'Doherty et al. 2002</label><citation citation-type="journal"><name><surname>O'Doherty</surname><given-names>JP</given-names></name>, Deichmann R, Critchley HD, Dolan RJ. Neural responses during anticipation of a primary taste reward. <source>Neuron</source> <volume>33</volume>: <fpage>815</fpage>&#x02013;826, <year>2002</year>.<pub-id pub-id-type="pmid">11879657</pub-id></citation></ref><ref id="r41"><label>Pascal 1948</label><citation citation-type="other"><name><surname>Pascal</surname><given-names>B</given-names></name> Great shorter works (translated from French). Philadelphia, PA: Westminster, <year>1948</year>.</citation></ref><ref id="r42"><label>Real 1991</label><citation citation-type="journal"><name><surname>Real</surname><given-names>LA</given-names></name> Animal choice behavior and the evolution of cognitive architecture. <source>Science</source> <volume>253</volume>: <fpage>980</fpage>&#x02013;986, <year>1991</year>.<pub-id pub-id-type="pmid">1887231</pub-id></citation></ref><ref id="r43"><label>Real et al. 1982</label><citation citation-type="journal"><name><surname>Real</surname><given-names>L</given-names></name>, Ott J, Silverfine E. On the trade-off between the mean and the variance in foraging: an experimental analysis with bumblebees. <source>Ecol</source> <volume>63</volume>: <fpage>1617</fpage>&#x02013;1623, <year>1982</year>.</citation></ref><ref id="r44"><label>Roesch and Olson 2003</label><citation citation-type="journal"><name><surname>Roesch</surname><given-names>MR</given-names></name>, Olson CR. Impact of expected reward on neuronal activity in prefrontal cortex, frontal and supplementary eye fields and premotor cortex. <source>J Neurophysiol</source> <volume>90</volume>: <fpage>1766</fpage>&#x02013;1789, <year>2003</year>.<pub-id pub-id-type="pmid">12801905</pub-id></citation></ref><ref id="r45"><label>Sanfey et al. 2003</label><citation citation-type="journal"><name><surname>Sanfey</surname><given-names>AG</given-names></name>, Hastie R, Colvin MK, Grafman J. Phineas gauged: decision-making and the human prefrontal cortex. <source>Neuropsychologia</source> <volume>41</volume>: <fpage>1218</fpage>&#x02013;1229, <year>2003</year>.<pub-id pub-id-type="pmid">12753961</pub-id></citation></ref><ref id="r46"><label>Stephens and Krebs 1986</label><citation citation-type="other"><name><surname>Stephens</surname><given-names>JW</given-names></name>, Krebs JR. <source>Foraging Theory.</source> Princeton, NJ: University Press, <year>1986</year>.</citation></ref><ref id="r47"><label>Tobler et al. 2005</label><citation citation-type="journal"><name><surname>Tobler</surname><given-names>PN</given-names></name>, Fiorillo CD, Schultz W. Adaptive coding of reward value by dopamine neurons. <source>Science</source> <volume>307</volume>: <fpage>1642</fpage>&#x02013;1645, <year>2005</year>.<pub-id pub-id-type="pmid">15761155</pub-id></citation></ref><ref id="r48"><label>Tricomi et al. 2004</label><citation citation-type="journal"><name><surname>Tricomi</surname><given-names>EM</given-names></name>, Delgado MR, Fiez JA. Modulation of caudate activity by action contingency. <source>Neuron</source> <volume>41</volume>: <fpage>281</fpage>&#x02013;292, <year>2004</year>.<pub-id pub-id-type="pmid">14741108</pub-id></citation></ref><ref id="r49"><label>Volz et al. 2003</label><citation citation-type="journal"><name><surname>Volz</surname><given-names>KG</given-names></name>, Schubotz RI, von Cramon DY. Predicting events of varying probability: uncertainty investigated by fMRI. <source>Neuroimage</source> <volume>19</volume>: <fpage>271</fpage>&#x02013;280, <year>2003</year>.<pub-id pub-id-type="pmid">12814578</pub-id></citation></ref><ref id="r50"><label>Von Neumann and Morgenstern 1944</label><citation citation-type="other"><name><surname>Von Neumann</surname><given-names>J</given-names></name>, Morgenstern O. <source>Theory of Games and Economic Behavior.</source> Princeton, NJ: University Press, <year>1944</year>.</citation></ref><ref id="r51"><label>Williams and Goldman-Rakic 1998</label><citation citation-type="journal"><name><surname>Williams</surname><given-names>SM</given-names></name>, Goldman-Rakic PS. Widespread origin of the primate mesofrontal dopamine system. <source>Cereb Cortex</source> <volume>8</volume>: <fpage>321</fpage>&#x02013;345, <year>1998</year>.<pub-id pub-id-type="pmid">9651129</pub-id></citation></ref></ref-list></back><floats-wrap><fig position="float" id="f1"><label>FIG. 1.</label><caption><p>Experimental design and pleasantness ratings. <italic>A</italic>: behavioral task. Single stimuli were presented randomly in 1 of the 4 quadrants of a monitor for 1.5 s, and participants indicated the quadrant in which stimuli appeared with a button press. Stimuli were associated with different combinations of reward magnitude and probability (see <italic>B</italic>). Reward consisted of points, 4&#x00025; of which was paid out as British pence to subjects at the end of the experiment. Throughout the experiment, the total of points accumulated was displayed and updated after reward delivery. Trial types alternated randomly. <italic>B</italic>: experimental design. Twelve different stimuli were associated with different reward magnitudes (ordinate) and probabilities (abscissa) as shown. Expected value of stimuli (sum of probability-weighted magnitudes) is indicated below stimuli and increases with distance from origin. We disentangled expected value from magnitude and probability by associating different stimuli with the same expected value but different combinations of magnitude and probability. <italic>C</italic>: relation of expected value (EV) and uncertainty (measured as variance) to probability. <italic>D&#x02013;F</italic>: average change in pleasantness rating in all participants as a function of magnitude (<italic>D</italic>), probability (<italic>E</italic>), and expected value (<italic>F;</italic> 16 participants, error bars represent SE). The scale ranged from &#x02013;5 (very unpleasant) to &#x0002b;5 (very pleasant). <xref ref-type="table" rid="t1">Table 1</xref> shows absolute ratings before and after experiment. <italic>G</italic>: sensitivity of change in pleasantness as function of risk attitude. Risk attitudes were determined in independent choice trials (16 participants). Sensitivity was determined as slope in pleasantness change against the variance of the binary probability distribution associated with each stimulus.</p></caption><graphic xlink:href="z9k0020779740001"></graphic></fig><fig position="float" id="f2"><label>FIG. 2.</label><caption><p>Coding of reward magnitude and probability in striatum. <italic>A</italic>: activation in caudate covarying with increasing reward magnitude (peak at &#x02013;12/2/6; <xref ref-type="table" rid="t2">Table 2</xref>, <italic>top</italic>). <italic>B</italic>: time courses of responses to stimuli associated with different reward magnitudes, averaged across 16 participants. <italic>C</italic>: regression of averaged activation on magnitude (16 participants). Activations are further averaged across 2nd and 3rd (peak) time points shown in <italic>B. D&#x02014;F</italic>: same as <italic>A&#x02013;C</italic> but with time courses separated according to reward being delivered or not. <italic>G</italic>: activation in ventral striatum covarying with increasing probability (peak at &#x02013;10/4/&#x02212;4; <xref ref-type="table" rid="t2">Table 2</xref>, <italic>middle</italic>). <italic>H</italic>: time courses of responses to stimuli associated with different probabilities, averaged across 16 participants. <italic>I</italic>: regression of average activation on probability (16 participants). Activations are further averaged across 2nd and 3rd (peak) time points shown in <italic>H. J&#x02013;K</italic>: same as <italic>G&#x02013;I</italic> but with time courses separated according to reward being delivered or not. In this and all other figures, the right side of the image corresponds to the right side of the brain and circles around activations serve as visual aid.</p></caption><graphic xlink:href="z9k0020779740002"></graphic></fig><fig position="float" id="f3"><label>FIG. 3.</label><caption><p>Coding of different expected reward values in striatum. <italic>A</italic> and <italic>E</italic>: stronger activations in caudate close to internal capsule (<italic>A</italic>) and posterior striatum (<italic>E</italic>) to stimuli associated with higher expected reward value (peaks at &#x02013;8/12/6 and 16/&#x02212;6/4; <xref ref-type="table" rid="t2">Table 2</xref>, <italic>bottom</italic>). <italic>B</italic> and <italic>F</italic>: time courses of increasing responses to stimuli associated with increasing expected value, averaged across 16 participants. <italic>C</italic> and <italic>G</italic>: regression of peak activations on expected value (shaded areas in <italic>B</italic> and <italic>F,</italic> respectively). <italic>D</italic> and <italic>H</italic>: dissociation of coding of expected value in areas shown in <italic>A</italic> and <italic>E,</italic> respectively, from behavioral reaction time (data in <italic>D</italic> and <italic>H</italic> replotted from <italic>C</italic> and <italic>G,</italic> respectively). Abscissas were centered according to means of expected value and reaction time and scaled to SD to facilitate comparisons. Differences in regressions in <italic>D</italic> were insignificant for dorsal striatal region shown in <italic>A,</italic> but regressions in <italic>H</italic> were significant for ventral striatum shown in <italic>E.</italic></p></caption><graphic xlink:href="z9k0020779740003"></graphic></fig><fig position="float" id="f4"><label>FIG. 4.</label><caption><p>Coding of expected reward value irrespective of magnitude and probability in striatum. <italic>A</italic>: striatal activation to different pairs of stimuli with same expected value. For each pair, peak activations differed insignificantly (shaded areas) despite different magnitude-probability combinations for the same expected value (mean difference between activations within pairs &#x0003c;0.004&#x00025; signal change, <italic>P</italic> &#x0003e; 0.78). However, activations varied across expected values (left to right; ANOVA <italic>P</italic> &#x0003c; 0.01). <italic>B</italic>: coding of magnitude and probabilty in striatal region marked by circle in <xref rid="f3" ref-type="fig">Fig. 3<italic>A.</italic></xref> Probability was constant at <italic>P</italic> &#x0003d; 0.5 for variations in magnitude, and magnitude was constant at an average 150 points for variations in probability (mean of 100 and 200 points with equal numbers). <italic>C</italic>: separate but partly overlapping striatal regions that show increased activations with increasing reward magnitude (<italic>r</italic> &#x0003d; 0.98, <italic>P</italic> &#x0003c; 0.05), probability (<italic>r</italic> &#x0003d; 0.99, <italic>P</italic> &#x0003c; 0.01) and expected value (<italic>r</italic> &#x0003d; 0.90, <italic>P</italic> &#x0003c; 0.05), respectively. <italic>D</italic>: lack of correlation between striatal activations and variance.</p></caption><graphic xlink:href="z9k0020779740004"></graphic></fig><fig position="float" id="f5"><label>FIG. 5.</label><caption><p>Coding of magnitude, probability and expected value in lateral prefrontal cortex. Common and distinct increases in activation to stimuli associated with increasing reward magnitude, probability and expected value as indicated by different colors (<italic>r</italic> &#x0003d; 0.84, <italic>P</italic> &#x0003d; 0.09; <xref ref-type="table" rid="t2">Table 2</xref>).</p></caption><graphic xlink:href="z9k0020779740005"></graphic></fig><fig position="float" id="f6"><label>FIG. 6.</label><caption><p>Differential coding of reward uncertainty but not expected value in lateral orbitofrontal cortex. <italic>A</italic>: stronger activation to stimuli associated with higher variance as revealed by general linear model searching for inverted U relation of activation to probability (peak at &#x02013;42/30/&#x02212;20). <italic>B</italic>: time courses of increasing responses to stimuli associated with increasing variance, averaged across 16 participants. <italic>C</italic> and <italic>D</italic>: significant correlations of average peak activation with variance (<italic>C</italic>) but not expected value (<italic>D;</italic> shaded area in <italic>B</italic>).</p></caption><graphic xlink:href="z9k0020779740006"></graphic></fig><fig position="float" id="f7"><label>FIG. 7.</label><caption><p>Relation of uncertainty-related orbitofrontal activations to individual risk attitudes. <italic>A&#x02013;C</italic>: covariation in lateral orbitofrontal cortex with increasing risk aversion across participants (peak at 36/46/&#x02212;16). The contrast estimates (betas) of individual participants are regressed against risk aversion in <italic>B</italic> and compared by averaged bar plots in <italic>C</italic> (<italic>P</italic> &#x0003c; 0.001; unpaired <italic>t</italic>-test in 7 risk seekers and 6 risk averters). <italic>D&#x02013;F</italic>: covariation in medial orbitofrontal cortex with risk-seeking (&#x0003d; inverse relation to risk aversion; peak at &#x02013;10/52/&#x02212;2). <italic>E</italic> and <italic>F</italic>: risk correlations in analogy to <italic>B</italic> and <italic>C.</italic> Abscissa shows risk aversion as expressed by preference factors (&#x02212;4 most risk-seeking, &#x0002b;4 most risk aversion). To obtain these graphs, we correlated the uncertainty-related activations to individual risk attitude in 2 steps. First, we determined in each participant the contrast estimates (beta) reflecting the goodness of fit between the brain activations and the uncertainty defined by the 5 probabilities used (variance as inverted U function of probability). Then we regressed the obtained contrast estimates (beta) of all participants to their individual risk preference factors assessed behaviorally and searched for brain areas showing positive (<italic>A</italic>) or negative correlations (<italic>D</italic>). We visualized the correlations with risk aversion by plotting the regressions with the betas in <italic>B</italic> and <italic>E.</italic></p></caption><graphic xlink:href="z9k0020779740007"></graphic></fig><fig position="float" id="f8"><label>FIG. 8.</label><caption><p>Combined coding of reward value and uncertainty. <italic>A</italic>: middle prefrontal region showing significant correlation with a differential expected value-variance model (peak at 32/44/10). The model assumed covariation with expected value and variance (1st level) and in addition positive covariation with expected value and higher variance-coding slopes for risk seekers compared with risk averters (2nd level). <italic>B</italic> and <italic>C</italic>: correlations of signal change with expected value separately for 6 risk-averse participants and 7 risk seekers. The difference in slope was not significant (<italic>P</italic> &#x0003e; 0.47). <italic>D</italic> and <italic>E</italic>: significantly different correlations of signal change with variance depending on risk aversion (6 participants; <italic>D</italic>) or risk seekers (7 participants; <italic>E</italic>) as assessed by behavioral preferences. Individual data points in b-e are from peak changes of responses (shaded areas in <italic>F&#x02013;I</italic>). <italic>F</italic> and <italic>G</italic>: time courses of activations with expected value in 6 risk-averse participants (<italic>F</italic>) and 7 risk seekers (<italic>G</italic>). <italic>H</italic> and <italic>I</italic>: time courses of activations with variance in 6 risk-averse participants (<italic>H</italic>) and 7 risk seekers (<italic>I</italic>).</p></caption><graphic xlink:href="z9k0020779740008"></graphic></fig><fig position="float" id="f9"><label>FIG. 9.</label><caption><p>Reward value coding combined with differential uncertainty coding according to individual risk attitude. <italic>A&#x02013;E</italic>: differential prefrontal uncertainty coding in risk-averse participants. <italic>A</italic>: region in superior frontal gyrus showing selective decreased activation with variance in 6 risk averters without variance coding in seven risk seekers (peak at 18/62/10). <italic>B&#x02013;E</italic>: correlations of signal change with expected value and variance. <italic>F&#x02013;J</italic>: differential prefrontal uncertainty coding in risk-seeking participants. <italic>F</italic>: region in inferior frontal gyrus showing selective increased activation with variance in 7 risk seekers without variance coding in 6 risk averters (peak at 48/22/8). <italic>G&#x02013;J</italic>: correlations of signal change with expected value and variance. Same regression model for <italic>A</italic> and <italic>F</italic> as used for <xref rid="f8" ref-type="fig">Fig. 8</xref>.</p></caption><graphic xlink:href="z9k0020779740009"></graphic></fig><table-wrap position="float" id="t1"><label>TABLE 1.</label><caption><p>Pleasantness ratings before and after training</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="1" rowspan="1" align="center" valign="bottom"/><th colspan="1" rowspan="1" align="center" valign="bottom">Before Training</th><th colspan="1" rowspan="1" align="center" valign="bottom">After Training</th></tr></thead><tbody><tr><td colspan="1" rowspan="1" align="left" valign="top">Magnitude</td><td colspan="1" rowspan="1" align="center" valign="top"/><td colspan="1" rowspan="1" align="center" valign="top"/></tr><tr><td colspan="1" rowspan="1" align="left" valign="top">&#x02003;&#x02003;&#x02003;&#x02003;100</td><td colspan="1" rowspan="1" align="center" valign="top">1.5 &#x000b1; 0.4</td><td colspan="1" rowspan="1" align="center" valign="top">1.0 &#x000b1; 0.4</td></tr><tr><td colspan="1" rowspan="1" align="left" valign="top">&#x02003;&#x02003;&#x02003;&#x02003;200</td><td colspan="1" rowspan="1" align="center" valign="top">1.7 &#x000b1; 0.4</td><td colspan="1" rowspan="1" align="center" valign="top">1.7 &#x000b1; 0.3</td></tr><tr><td colspan="1" rowspan="1" align="left" valign="top">&#x02003;&#x02003;&#x02003;&#x02003;300</td><td colspan="1" rowspan="1" align="center" valign="top">1.4 &#x000b1; 0.4</td><td colspan="1" rowspan="1" align="center" valign="top">2.6 &#x000b1; 0.3</td></tr><tr><td colspan="1" rowspan="1" align="left" valign="top">&#x02003;&#x02003;&#x02003;&#x02003;400</td><td colspan="1" rowspan="1" align="center" valign="top">1.3 &#x000b1; 0.5</td><td colspan="1" rowspan="1" align="center" valign="top">3.5 &#x000b1; 0.4</td></tr><tr><td colspan="1" rowspan="1" align="left" valign="top">Probability</td><td colspan="1" rowspan="1" align="center" valign="top"/><td colspan="1" rowspan="1" align="center" valign="top"/></tr><tr><td colspan="1" rowspan="1" align="left" valign="top">&#x02003;&#x02003;&#x02003;&#x02003;0</td><td colspan="1" rowspan="1" align="center" valign="top">1.2 &#x000b1; 0.3</td><td colspan="1" rowspan="1" align="center" valign="top">&#x02212;0.3 &#x000b1; 0.4</td></tr><tr><td colspan="1" rowspan="1" align="left" valign="top">&#x02003;&#x02003;&#x02003;&#x02003;0.25</td><td colspan="1" rowspan="1" align="center" valign="top">1.4 &#x000b1; 0.4</td><td colspan="1" rowspan="1" align="center" valign="top">0.5 &#x000b1; 0.4</td></tr><tr><td colspan="1" rowspan="1" align="left" valign="top">&#x02003;&#x02003;&#x02003;&#x02003;0.5</td><td colspan="1" rowspan="1" align="center" valign="top">1.6 &#x000b1; 0.3</td><td colspan="1" rowspan="1" align="center" valign="top">1.3 &#x000b1; 0.3</td></tr><tr><td colspan="1" rowspan="1" align="left" valign="top">&#x02003;&#x02003;&#x02003;&#x02003;0.75</td><td colspan="1" rowspan="1" align="center" valign="top">1.1 &#x000b1; 0.4</td><td colspan="1" rowspan="1" align="center" valign="top">2.1 &#x000b1; 0.2</td></tr><tr><td colspan="1" rowspan="1" align="left" valign="top">&#x02003;&#x02003;&#x02003;&#x02003;1.0</td><td colspan="1" rowspan="1" align="center" valign="top">2.0 &#x000b1; 0.4</td><td colspan="1" rowspan="1" align="center" valign="top">2.7 &#x000b1; 0.2</td></tr></tbody></table><table-wrap-foot><fn><p>Values are means &#x000b1; SE.</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="t2"><label>TABLE 2.</label><caption><p>Areas more strongly activated by stimuli associated with larger reward magnitude, probability, and expected value</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="1" rowspan="1" align="center" valign="bottom"/><th colspan="1" rowspan="1" align="center" valign="bottom">Hemisphere</th><th colspan="1" rowspan="1" align="center" valign="bottom"><italic>x</italic></th><th colspan="1" rowspan="1" align="center" valign="bottom"><italic>y</italic></th><th colspan="1" rowspan="1" align="center" valign="bottom"><italic>z</italic></th><th colspan="1" rowspan="1" align="center" valign="bottom"><italic>Z</italic> Score</th></tr></thead><tbody><tr><td colspan="1" rowspan="1" align="left" valign="top">Magnitude</td><td colspan="1" rowspan="1" align="center" valign="top"/><td colspan="1" rowspan="1" align="center" valign="top"/><td colspan="1" rowspan="1" align="center" valign="top"/><td colspan="1" rowspan="1" align="center" valign="top"/><td colspan="1" rowspan="1" align="center" valign="top"/></tr><tr><td colspan="1" rowspan="1" align="left" valign="top">&#x02003;&#x02003;&#x02003;&#x02003;Striatum (caudate)</td><td colspan="1" rowspan="1" align="center" valign="top">Left</td><td colspan="1" rowspan="1" align="char" char="." valign="top">&#x02212;12</td><td colspan="1" rowspan="1" align="char" char="." valign="top">2</td><td colspan="1" rowspan="1" align="char" char="." valign="top">6</td><td colspan="1" rowspan="1" align="char" char="." valign="top">3.5</td></tr><tr><td colspan="1" rowspan="1" align="left" valign="top">&#x02003;&#x02003;&#x02003;&#x02003;Striatum (posterior putamen)</td><td colspan="1" rowspan="1" align="center" valign="top">Right</td><td colspan="1" rowspan="1" align="char" char="." valign="top">18</td><td colspan="1" rowspan="1" align="char" char="." valign="top">&#x02212;6</td><td colspan="1" rowspan="1" align="char" char="." valign="top">2</td><td colspan="1" rowspan="1" align="char" char="." valign="top">4.1</td></tr><tr><td colspan="1" rowspan="1" align="left" valign="top">&#x02003;&#x02003;&#x02003;&#x02003;Medial prefrontal cortex</td><td colspan="1" rowspan="1" align="center" valign="top">Right</td><td colspan="1" rowspan="1" align="char" char="." valign="top">12</td><td colspan="1" rowspan="1" align="char" char="." valign="top">36</td><td colspan="1" rowspan="1" align="char" char="." valign="top">36</td><td colspan="1" rowspan="1" align="char" char="." valign="top">3.4</td></tr><tr><td colspan="1" rowspan="1" align="left" valign="top">&#x02003;&#x02003;&#x02003;&#x02003;Lateral prefrontal cortex</td><td colspan="1" rowspan="1" align="center" valign="top">Right</td><td colspan="1" rowspan="1" align="char" char="." valign="top">50</td><td colspan="1" rowspan="1" align="char" char="." valign="top">16</td><td colspan="1" rowspan="1" align="char" char="." valign="top">6</td><td colspan="1" rowspan="1" align="char" char="." valign="top">4.3</td></tr><tr><td colspan="1" rowspan="1" align="left" valign="top">Probability</td><td colspan="1" rowspan="1" align="center" valign="top"/><td colspan="1" rowspan="1" align="center" valign="top"/><td colspan="1" rowspan="1" align="center" valign="top"/><td colspan="1" rowspan="1" align="center" valign="top"/><td colspan="1" rowspan="1" align="center" valign="top"/></tr><tr><td colspan="1" rowspan="1" align="left" valign="top">&#x02003;&#x02003;&#x02003;&#x02003;Striatum (ventral putamen)</td><td colspan="1" rowspan="1" align="center" valign="top">Left</td><td colspan="1" rowspan="1" align="char" char="." valign="top">&#x02212;10</td><td colspan="1" rowspan="1" align="char" char="." valign="top">4</td><td colspan="1" rowspan="1" align="char" char="." valign="top">&#x02212;4</td><td colspan="1" rowspan="1" align="char" char="." valign="top">4.0</td></tr><tr><td colspan="1" rowspan="1" align="left" valign="top">&#x02003;&#x02003;&#x02003;&#x02003;Midbrain</td><td colspan="1" rowspan="1" align="center" valign="top">Right</td><td colspan="1" rowspan="1" align="char" char="." valign="top">18</td><td colspan="1" rowspan="1" align="char" char="." valign="top">&#x02212;18</td><td colspan="1" rowspan="1" align="char" char="." valign="top">&#x02212;12</td><td colspan="1" rowspan="1" align="char" char="." valign="top">3.6</td></tr><tr><td colspan="1" rowspan="1" align="left" valign="top"/><td colspan="1" rowspan="1" align="center" valign="top">Left</td><td colspan="1" rowspan="1" align="char" char="." valign="top">&#x02212;20</td><td colspan="1" rowspan="1" align="char" char="." valign="top">&#x02212;16</td><td colspan="1" rowspan="1" align="char" char="." valign="top">&#x02212;14</td><td colspan="1" rowspan="1" align="char" char="." valign="top">3.6</td></tr><tr><td colspan="1" rowspan="1" align="left" valign="top">&#x02003;&#x02003;&#x02003;&#x02003;Posterior orbitofrontal cortex</td><td colspan="1" rowspan="1" align="center" valign="top">Right</td><td colspan="1" rowspan="1" align="char" char="." valign="top">18</td><td colspan="1" rowspan="1" align="char" char="." valign="top">18</td><td colspan="1" rowspan="1" align="char" char="." valign="top">&#x02212;14</td><td colspan="1" rowspan="1" align="char" char="." valign="top">4.7</td></tr><tr><td colspan="1" rowspan="1" align="left" valign="top">&#x02003;&#x02003;&#x02003;&#x02003;Medial orbitofrontal cortex</td><td colspan="1" rowspan="1" align="center" valign="top">Left</td><td colspan="1" rowspan="1" align="char" char="." valign="top">&#x02212;2</td><td colspan="1" rowspan="1" align="char" char="." valign="top">48</td><td colspan="1" rowspan="1" align="char" char="." valign="top">&#x02212;12</td><td colspan="1" rowspan="1" align="char" char="." valign="top">3.4</td></tr><tr><td colspan="1" rowspan="1" align="left" valign="top">&#x02003;&#x02003;&#x02003;&#x02003;Ventromedial prefrontal cortex</td><td colspan="1" rowspan="1" align="center" valign="top">Right</td><td colspan="1" rowspan="1" align="char" char="." valign="top">8</td><td colspan="1" rowspan="1" align="char" char="." valign="top">58</td><td colspan="1" rowspan="1" align="char" char="." valign="top">10</td><td colspan="1" rowspan="1" align="char" char="." valign="top">3.3</td></tr><tr><td colspan="1" rowspan="1" align="left" valign="top"/><td colspan="1" rowspan="1" align="center" valign="top">Left</td><td colspan="1" rowspan="1" align="char" char="." valign="top">&#x02212;4</td><td colspan="1" rowspan="1" align="char" char="." valign="top">64</td><td colspan="1" rowspan="1" align="char" char="." valign="top">8</td><td colspan="1" rowspan="1" align="char" char="." valign="top">3.2</td></tr><tr><td colspan="1" rowspan="1" align="left" valign="top">&#x02003;&#x02003;&#x02003;&#x02003;Lateral prefrontal cortex</td><td colspan="1" rowspan="1" align="center" valign="top">Right</td><td colspan="1" rowspan="1" align="char" char="." valign="top">52</td><td colspan="1" rowspan="1" align="char" char="." valign="top">26</td><td colspan="1" rowspan="1" align="char" char="." valign="top">&#x02212;2</td><td colspan="1" rowspan="1" align="char" char="." valign="top">3.5</td></tr><tr><td colspan="1" rowspan="1" align="left" valign="top"/><td colspan="1" rowspan="1" align="center" valign="top">Right</td><td colspan="1" rowspan="1" align="char" char="." valign="top">28</td><td colspan="1" rowspan="1" align="char" char="." valign="top">42</td><td colspan="1" rowspan="1" align="char" char="." valign="top">26</td><td colspan="1" rowspan="1" align="char" char="." valign="top">3.4</td></tr><tr><td colspan="1" rowspan="1" align="left" valign="top"/><td colspan="1" rowspan="1" align="center" valign="top">Left</td><td colspan="1" rowspan="1" align="char" char="." valign="top">&#x02212;34</td><td colspan="1" rowspan="1" align="char" char="." valign="top">48</td><td colspan="1" rowspan="1" align="char" char="." valign="top">10</td><td colspan="1" rowspan="1" align="char" char="." valign="top">3.8</td></tr><tr><td colspan="1" rowspan="1" align="left" valign="top">Expected value</td><td colspan="1" rowspan="1" align="center" valign="top"/><td colspan="1" rowspan="1" align="center" valign="top"/><td colspan="1" rowspan="1" align="center" valign="top"/><td colspan="1" rowspan="1" align="center" valign="top"/><td colspan="1" rowspan="1" align="center" valign="top"/></tr><tr><td colspan="1" rowspan="1" align="left" valign="top">&#x02003;&#x02003;&#x02003;&#x02003;Striatum (caudate)</td><td colspan="1" rowspan="1" align="center" valign="top">Left</td><td colspan="1" rowspan="1" align="char" char="." valign="top">&#x02212;8</td><td colspan="1" rowspan="1" align="char" char="." valign="top">12</td><td colspan="1" rowspan="1" align="char" char="." valign="top">6</td><td colspan="1" rowspan="1" align="char" char="." valign="top">3.9</td></tr><tr><td colspan="1" rowspan="1" align="left" valign="top">&#x02003;&#x02003;&#x02003;&#x02003;Striatum (posterior putamen)</td><td colspan="1" rowspan="1" align="center" valign="top">Right</td><td colspan="1" rowspan="1" align="char" char="." valign="top">16</td><td colspan="1" rowspan="1" align="char" char="." valign="top">&#x02212;6</td><td colspan="1" rowspan="1" align="char" char="." valign="top">4</td><td colspan="1" rowspan="1" align="char" char="." valign="top">3.8</td></tr><tr><td colspan="1" rowspan="1" align="left" valign="top">&#x02003;&#x02003;&#x02003;&#x02003;Orbitofrontal/inferior frontal cortex</td><td colspan="1" rowspan="1" align="center" valign="top">Left</td><td colspan="1" rowspan="1" align="char" char="." valign="top">&#x02212;30</td><td colspan="1" rowspan="1" align="char" char="." valign="top">34</td><td colspan="1" rowspan="1" align="char" char="." valign="top">0</td><td colspan="1" rowspan="1" align="char" char="." valign="top">3.4</td></tr><tr><td colspan="1" rowspan="1" align="left" valign="top">&#x02003;&#x02003;&#x02003;&#x02003;Medial prefrontal cortex</td><td colspan="1" rowspan="1" align="center" valign="top">Right</td><td colspan="1" rowspan="1" align="char" char="." valign="top">14</td><td colspan="1" rowspan="1" align="char" char="." valign="top">46</td><td colspan="1" rowspan="1" align="char" char="." valign="top">18</td><td colspan="1" rowspan="1" align="char" char="." valign="top">3.3</td></tr><tr><td colspan="1" rowspan="1" align="left" valign="top">&#x02003;&#x02003;&#x02003;&#x02003;Lateral prefrontal cortex</td><td colspan="1" rowspan="1" align="center" valign="top">Right</td><td colspan="1" rowspan="1" align="char" char="." valign="top">52</td><td colspan="1" rowspan="1" align="char" char="." valign="top">28</td><td colspan="1" rowspan="1" align="char" char="." valign="top">8</td><td colspan="1" rowspan="1" align="char" char="." valign="top">3.9</td></tr></tbody></table></table-wrap></floats-wrap></article>