<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN" "archivearticle.dtd"><article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article" xml:lang="EN"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><journal-title>PLoS ONE</journal-title><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">19225571</article-id><article-id pub-id-type="pmc">2640429</article-id><article-id pub-id-type="publisher-id">08-PONE-RA-06607R1</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0004536</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline"><subject>Mathematics/Fourier Analysis</subject><subject>Neuroscience/Theoretical Neuroscience</subject><subject>Neuroscience/Psychology</subject><subject>Computer Science/Natural and Synthetic Vision</subject><subject>Neuroscience/Natural and Synthetic Vision</subject></subj-group></article-categories><title-group><article-title>Performance Characterization of Watson Ahumada Motion Detector Using Random Dot Rotary Motion Stimuli</article-title><alt-title alt-title-type="running-head">Performance Characterisation</alt-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Jain</surname><given-names>Siddharth</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="corresp" rid="cor1"><sup>&#x0002a;</sup></xref><xref ref-type="author-notes" rid="fn1"><sup>&#x000a4;</sup></xref></contrib></contrib-group><aff id="aff1"><addr-line>EECS Department, University of California, Berkeley, California, United States of America</addr-line></aff><contrib-group><contrib contrib-type="editor"><name><surname>Greene</surname><given-names>Ernest</given-names></name><role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1">University of Southern California, United States of America</aff><author-notes><corresp id="cor1">&#x0002a; E-mail: <email>fd97207@yahoo.com</email></corresp><fn fn-type="con"><p>Conceived and designed the experiments: SJ. Performed the experiments: SJ. Analyzed the data: SJ. Wrote the paper: SJ.</p></fn><fn id="fn1" fn-type="current-aff"><label>&#x000a4;</label><p>Current address: Bellevue, Washington, United States of America</p></fn></author-notes><pub-date pub-type="collection"><year>2009</year></pub-date><pub-date pub-type="epub"><day>19</day><month>2</month><year>2009</year></pub-date><volume>4</volume><issue>2</issue><elocation-id>e4536</elocation-id><history><date date-type="received"><day>28</day><month>9</month><year>2008</year></date><date date-type="accepted"><day>30</day><month>12</month><year>2008</year></date></history><copyright-statement>Jain. This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</copyright-statement><copyright-year>2009</copyright-year><abstract><p>The performance of Watson &#x00026; Ahumada's model of human visual motion sensing is compared against human psychophysical performance. The stimulus consists of random dots undergoing rotary motion, displayed in a circular annulus. The model matches psychophysical observer performance with respect to most parameters. It is able to replicate some key psychophysical findings such as invariance of observer performance to dot density in the display, and decrease of observer performance with frame duration of the display.</p><p>Associated with the concept of rotary motion is the notion of a center about which rotation occurs. One might think that for accurate estimation of rotary motion in the display, this center must be accurately known. A simple vector analysis reveals that this need not be the case. Numerical simulations confirm this result, and may explain the position invariance of MST(d) cells. Position invariance is the experimental finding that rotary motion sensitive cells are insensitive to where in their receptive field rotation occurs.</p><p>When all the dots in the display are randomly drawn from a uniform distribution, illusory rotary motion is perceived. This case was investigated by Rose &#x00026; Blake previously, who termed the illusory rotary motion the omega effect. Two important experimental findings are reported concerning this effect. First, although the display of random dots evokes perception of rotary motion, the direction of motion perceived does not depend on what dot pattern is shown. Second, the time interval between spontaneous flips in perceived direction is lognormally distributed (mode&#x02248;2 s). These findings suggest the omega effect fits in the category of a typical bistable illusion, and therefore the processes that give rise to this illusion may be the same processes that underlie much of other bistable phenomenon.</p></abstract><counts><page-count count="14"/></counts></article-meta></front><body><sec id="s1"><title>Introduction</title><p>Many models of visual motion perception have been proposed <xref ref-type="bibr" rid="pone.0004536-Adelson1">&#x0005b;1&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-vanSanten1">&#x0005b;2&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-Watson1">&#x0005b;3&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-Johnston1">&#x0005b;4&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-Perrone1">&#x0005b;5&#x0005d;</xref>. Although much research has since been done on studies of human visual motion perception, little work has been done to psychophysically characterize the performance of these models. This is important for obvious reasons. A correct model of motion sensing should match human psychophysical performance on motion detection, and also agree with what is known currently about the neurophysiology of motion sensitive cells in the brain.</p><p>This paper presents a psychophysical performance characterisation of Watson &#x00026; Ahumada's model of visual motion sensing <xref ref-type="bibr" rid="pone.0004536-Watson1">&#x0005b;3&#x0005d;</xref>, the first one to do so in my knowledge. The ability of Watson Ahumada motion detector to detect motion in random dot kinematograms is compared against human psychophysical performance. The stimulus, termed the racetrack, consists of random dots displayed in a circular annulus. The dot pattern is refreshed periodically, and a certain fraction of dots are correlated to move either clockwise (CW) or counter-clockwise (CCW) in the next frame. By varying the fraction of dots to be correlated, the amount of motion signal in the display can be controlled (see <xref ref-type="supplementary-material" rid="pone.0004536.s001">Movies S1</xref>, <xref ref-type="supplementary-material" rid="pone.0004536.s002">S2</xref>, <xref ref-type="supplementary-material" rid="pone.0004536.s003">S3</xref> for illustration). There are many other parameters that can be varied, and performance of both the model and human observers is measured.</p><p>The model is able to match human performance with respect to most, but not all, stimulus parameters. For example, it is found that human observers are insensitive to the dot density in the display. The model shows similar behavior. The invariance of observer performance to dot density provides strong evidence against motion models based on matching dots to their nearest neighbors in the next frame <xref ref-type="bibr" rid="pone.0004536-Ullman1">&#x0005b;6&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-Dawson1">&#x0005b;7&#x0005d;</xref>. Such models predict that observer performance should decrease with increase in dot density, according to the probability of mismatch formula <xref ref-type="bibr" rid="pone.0004536-Williams1">&#x0005b;8&#x0005d;</xref>. This is because as the dot density increases, the chances that the nearest neighbor is not in fact the correlated partner from the previous frame increase. Another experimental finding is that a frame duration of about 30 ms is found to be optimal for motion perception. I explain this result in terms of the spatiotemporal receptive field (STRF) structure of motion sensitive cells. At any time instant <italic>t</italic>, the response of such cells is roughly based on the value of the spatiotemporal stimulus from time <italic>t-T</italic> to <italic>t</italic>, with <italic>T</italic> of the order of 200 ms. When the frame duration is of the order of <italic>T</italic> or higher, the input is mostly constant within a window of <italic>T</italic> ms and therefore the cells fail to detect any motion. On the other hand if frame duration is very low the input may be changing at a rate that the cells cannot handle. This will again result in failure of cells to respond optimally.</p><p>The motion in racetrack is rotary as opposed to the more commonly encountered translational case. Associated with the concept of rotary motion is the notion of a center about which rotation occurs. One might think that for accurate estimation of rotary motion in the display, this center must be accurately known. A simple vector analysis presented in this paper reveals that this need not be the case. Numerical simulations confirm this result, and may explain the position invariance of MST(d) cells. Position invariance is the experimental finding that cells that are sensitive to rotary motion are insensitive to where in their receptive field rotation occurs <xref ref-type="bibr" rid="pone.0004536-Graziano1">&#x0005b;9&#x0005d;</xref>.</p><p>A special case of the racetrack is when all dots are randomly drawn from a uniform distribution in each frame, i.e., there are no correlated dots. One would expect that in this case the perception would be that of random twinkling noise, since there is no motion embedded in the stimulus. However, about two-thirds of observers report perception of rotary motion. This illusory motion was investigated by Rose &#x00026; Blake previously, who termed the phenomenon the omega effect <xref ref-type="bibr" rid="pone.0004536-Rose1">&#x0005b;10&#x0005d;</xref>. The omega effect is a classic example of paternicity, the tendency of the brain to find meaningful patterns in meaningless noise <xref ref-type="bibr" rid="pone.0004536-Shermer1">&#x0005b;11&#x0005d;</xref>. Two important results concerning this effect are reported in this paper. First, although the display of random dots evokes perception of rotary motion, the direction of motion perceived does not depend on what dot pattern is shown. Second, the time interval between spontaneous flips in perceived direction is lognormally distributed (mode&#x02248;2 s).</p><p>It may be worthwhile to mention some aspects of the &#x0201c;<xref ref-type="sec" rid="s2">Materials &#x00026; Methods</xref>&#x0201d; in this paper that are distinct from the traditional psychophysics paradigm. In the experiments described here, each trial has a 60 s duration. During this time, the direction of rotation changes randomly and the observer is faced with the task of continuously tracking the direction of rotation. Observer performance is calculated by cross correlating observer response with actual direction of rotation. The maximum value of the normalized cross correlation function denoted by &#x003c7; is taken to be a measure of observer performance. This method is distinct from traditional psychophysics paradigm, in which the display is shown to observer for fraction of a second, and the observer has to judge if motion was perceived CW or CCW. After many trials the confusion matrix and <italic>d&#x02032;</italic> is calculated <xref ref-type="bibr" rid="pone.0004536-Green1">&#x0005b;12&#x0005d;</xref>. The reason for the new method is none, except that it naturally occurred to me. Also it is my opinion that sub-second trial duration may not provide enough time for visual system of observer to reach steady state. One would expect that trial duration should be such that the percent correct and <italic>d&#x02032;</italic> should be independent of trial duration. This can only happen if the system is in steady state. A side-benefit of the new method is that it enables the calculation of reaction time of the observer. This is the time delay at which the normalized cross correlation function reaches its maximum value. It is found that for most observers, reaction time ranges from 0.5&#x02013;2 s depending on how easy it is to detect motion in the display.</p><p>In summary, the paper can be said to have three main contributions:</p><list list-type="order"><list-item><p>It presents a psychophysical performance characterisation of Watson &#x00026; Ahumada's model of visual motion sensing. The model is found to provide a good fit to the experimental data for most, but not all, stimulus parameters.</p></list-item><list-item><p>It shows that for accurate estimation of rotary motion in a display, it is not necessary that the center of rotation be accurately known. This may explain the fact that rotary motion sensitive cells found in MST/MSTd areas of the brain are insensitive to where in their receptive field rotation occurs.</p></list-item><list-item><p>It presents two experimental findings concerning the omega effect. First, observer response is irreproducible. Second, the time interval between spontaneous flips in perceived direction is lognormally distributed (mode&#x02248;2 s). These findings suggest the omega effect fits in the category of a typical bistable illusion, and therefore the processes that give rise to this illusion may be the same processes that underlie much of other bistable phenomenon.</p></list-item></list><sec id="s1a"><title>Previous Work</title><p>Visual motion perception has been a heavily researched topic and hence this paper will necessarily limit itself to a discussion of the most relevant work. Reviews reflecting the state-of-the-art in this area can be found in <xref ref-type="bibr" rid="pone.0004536-Krekelberg1">&#x0005b;13&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-Born1">&#x0005b;14&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-Derrington1">&#x0005b;15&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-Grzywacz1">&#x0005b;16&#x0005d;</xref>. Three seminal models of visual motion perception were proposed by Adelson and Bergen (1985), van Santen and Sperling (1985), and Watson and Ahumada (1985) <xref ref-type="bibr" rid="pone.0004536-Adelson1">&#x0005b;1&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-vanSanten1">&#x0005b;2&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-Watson1">&#x0005b;3&#x0005d;</xref>. Central to the Adelson Bergen &#x00026; Watson Ahumada models is the concept that the entire power spectrum of an image undergoing coherent translation lies on a plane in the spatiotemporal frequency domain <xref ref-type="bibr" rid="pone.0004536-Watson2">&#x0005b;17&#x0005d;</xref>. Determining this plane is therefore equivalent to determining the motion of the image. In its original form the Adelson Bergen motion detector is limited to detecting motion in 1D. Its extension to 2D was provided by Heeger (1987), Simoncelli and Heeger (1998) <xref ref-type="bibr" rid="pone.0004536-Heeger1">&#x0005b;18&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-Simoncelli1">&#x0005b;19&#x0005d;</xref>. The model has been refined further in Rust, Mante, Simoncelli, and Movshon (2006) where it is shown that it can capture the full range of pattern motion selectivity found in MT <xref ref-type="bibr" rid="pone.0004536-Rust1">&#x0005b;20&#x0005d;</xref>. Emerson, Bergen, and Adelson (1992) did a study in which it was shown that the responses of V1 complex cells from cat's striate cortex were well fitted by the Adelson Bergen model <xref ref-type="bibr" rid="pone.0004536-Emerson1">&#x0005b;21&#x0005d;</xref>. Moreover, cell responses were found to be inconsistent with the van Santen and Sperling model. Cells sensitive to rotary motion have been discovered in areas MST/MSTd of the brain <xref ref-type="bibr" rid="pone.0004536-Tanaka1">&#x0005b;22&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-Sakata1">&#x0005b;23&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-Graziano1">&#x0005b;9&#x0005d;</xref>. These cells have large receptive fields compared to cells in V1/MT. Also, they are not sensitive as to where in their receptive field rotation occurs, a phenomenon termed position invariance <xref ref-type="bibr" rid="pone.0004536-Graziano1">&#x0005b;9&#x0005d;</xref>.</p><p>Random dot kinematograms (RDKs) have been widely used in studies of visual motion perception <xref ref-type="bibr" rid="pone.0004536-Ullman1">&#x0005b;6&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-Dawson1">&#x0005b;7&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-Williams1">&#x0005b;8&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-Rose1">&#x0005b;10&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-Newsome1">&#x0005b;24&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-Newsome2">&#x0005b;25&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-Barlow1">&#x0005b;26&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-Scase1">&#x0005b;27&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-Watamaniuk1">&#x0005b;28&#x0005d;</xref>. Newsome &#x00026; Pare (1998) have remarked that random dot displays are useful because they stimulate primary motion sensing mechanisms while minimizing familiar positional cues <xref ref-type="bibr" rid="pone.0004536-Newsome1">&#x0005b;24&#x0005d;</xref>. Newsome, Britten, &#x00026; Movshon (1989) found that a dot correlation of at least six percent is required for monkeys to be able to detect motion in RDKs undergoing translational motion <xref ref-type="bibr" rid="pone.0004536-Newsome2">&#x0005b;25&#x0005d;</xref>. The present study gives a similar result for human observers. The effect of time-sampled displays on motion perception has been previously researched by Morgan (1980), Watson, Ahumada, &#x00026; Farrell (1986) <xref ref-type="bibr" rid="pone.0004536-Morgan1">&#x0005b;29&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-Watson3">&#x0005b;30&#x0005d;</xref>. Williams &#x00026; Sekuler (1984) had studied the effect of dot density on observer performance <xref ref-type="bibr" rid="pone.0004536-Williams1">&#x0005b;8&#x0005d;</xref>. They formulated the probability of mismatch formula according to which observer performance should decrease with increase in dot density, a view challenged by the present paper.</p><p>A special case of the racetrack is the omega effect, in which a display of dynamic uniformly distributed random dots in a circular annulus evokes perception of illusory rotary motion. This phenomenon was discovered by Rose &#x00026; Blake (1998) <xref ref-type="bibr" rid="pone.0004536-Rose1">&#x0005b;10&#x0005d;</xref> although they trace its origin to as far back as Mackay (1965) <xref ref-type="bibr" rid="pone.0004536-MacKay1">&#x0005b;31&#x0005d;</xref>. Recently several papers studying illusory motion from Glass patterns have appeared in the literature <xref ref-type="bibr" rid="pone.0004536-Ross1">&#x0005b;32&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-Krekelberg2">&#x0005b;33&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-Krekelberg3">&#x0005b;34&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-Viva1">&#x0005b;35&#x0005d;</xref>. Motion perception in such cases, where the spatial form of the stimulus is believed to guide motion perception, has generally been termed as implied motion in order to distinguish it from real motion, in which the display itself contains non-zero motion energy. Geisler (1999) had suggested motion streaks as providing a spatial cue that guides motion perception <xref ref-type="bibr" rid="pone.0004536-Geisler1">&#x0005b;36&#x0005d;</xref>. Barlow &#x00026; Olshausen (2004) have explained the phenomenon of motion streaks and flow seen in Glass patterns by pointing out that the power spectrum of a motion blurred image or a Glass pattern exhibits strong anisotropy, which is a characteristic property of a moving image, and therefore excites the mechanisms that normally detect the distortions of local power spectrum caused by motion <xref ref-type="bibr" rid="pone.0004536-Barlow2">&#x0005b;37&#x0005d;</xref>. It is to be noted that the omega display does not display the anisotropy in power spectrum associated with Glass patterns, yet rotary motion is seen in it.</p></sec></sec><sec sec-type="materials|methods" id="s2"><title>Materials and Methods</title><p>The experimental stimulus used in this study is termed racetrack. Three movies of the stimulus are included with this paper. A Java applet is also available online at <ext-link ext-link-type="uri" xlink:href="http://purl.oclc.org/NET/racetrack">http://purl.oclc.org/NET/racetrack</ext-link>. The racetrack stimulus consists of a random dot pattern displayed in a circular annulus. The dot pattern is refreshed periodically. A certain fraction <italic>c</italic> of the dots, referred to as correlated dots, are rotated by an angle <italic>&#x003b8;</italic> in the next frame. The remaining dots have their positions generated randomly and uniformly in Cartesian <italic>(x,y)</italic>, and are representative of noise. The algorithm for generating dots is such that if a dot is correlated in the present frame, it is guaranteed not to be correlated in the next frame. This eliminates the appearance of multiple dot trajectories, and thus the only motion cues in the stimulus are two dot apparent motion cues. Observers see a swarm of dots that appears to rotate clockwise (CW) or counter-clockwise (CCW). The direction of rotation changes randomly according to the polarity of a coin that flips every 3 s. They are instructed to click the left mouse button for CCW motion, and the right mouse button for CW motion. By cross correlating the observer response with the actual direction of rotation of the correlated dots, an estimate of observer performance and reaction time denoted by &#x003c7; and &#x003c4; respectively is obtained. This process is illustrated in <xref ref-type="fig" rid="pone-0004536-g001">Figure 1</xref>. &#x003c7; is defined as the maximum value of the normalized cross correlation function. &#x003c4; is the time delay at which &#x003c7; occurs. A &#x003c7; value of 1 indicates perfect detection of the embedded motion. At <italic>c&#x0200a;&#x0003d;&#x0200a;0</italic> the observer response can still be cross correlated with the input signal, which would have dictated the rotation of correlated dots if there were any in the stimulus. The &#x003c7; value obtained in this case reflects chance, or zero, detectability of embedded motion. Response reproducibility is quantified by cross correlating observer response curves in response to the same stimulus in multiple trials.</p><fig id="pone-0004536-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0004536.g001</object-id><label>Figure 1</label><caption><title>The dotted curve is the motion generated by the computer, and the solid curve is the motion reported by the observer.</title><p>&#x003c7; is the maximum value of the normalized cross correlation function and &#x003c4; is the time delay at which &#x003c7; occurs.</p></caption><graphic xlink:href="pone.0004536.g001"/></fig><p>Definitions and default values of some parameters are as follows: dot correlation <italic>c</italic>&#x0200a;&#x0003d;&#x0200a;number of correlated dots/total number of dots; frame duration <italic>fd</italic>&#x0200a;&#x0003d;&#x0200a;length of time for which a frame stays on screen, default&#x0200a;&#x0003d;&#x0200a;30 ms; dot density <italic>dd</italic>&#x0200a;&#x0003d;&#x0200a;dots per unit area, default&#x0200a;&#x0003d;&#x0200a;5 dots/degrees<sup>2</sup>; angle of rotation <italic>&#x003b8;</italic>&#x0200a;&#x0003d;&#x0200a;angle by which correlated dots are rotated, default&#x0200a;&#x0003d;&#x0200a;5&#x000b0;, the spatial hop size of a correlated dot&#x0200a;&#x0003d;&#x0200a;<italic>r&#x003b8;</italic> where <italic>r</italic> is distance of dot from center, <italic>&#x003b8;</italic> in radians; inner circle diameter <italic>ic</italic>&#x0200a;&#x0003d;&#x0200a;angle subtended by inner circle diameter at the eye, default&#x0200a;&#x0003d;&#x0200a;7&#x000b0;; outer circle diameter <italic>oc</italic>&#x0200a;&#x0003d;&#x0200a;angle subtended by inner circle diameter at the eye, fixed at 10&#x000b0; in all experiments; dot diameter&#x0200a;&#x0003d;&#x0200a;5&#x02032;, fixed in all experiments; duration of a trial&#x0200a;&#x0003d;&#x0200a;60 s. Stimuli were displayed on a NEC MultiSync FP1370 22&#x02033; (20&#x02033; viewable image size) CRT monitor with display resolution&#x0200a;&#x0003d;&#x0200a;640&#x000d7;480@100 Hz; black dots (luminance&#x02248;0) against a background luminance of 10.8 cd/m<sup>2</sup> were displayed; viewing distance&#x0200a;&#x0003d;&#x0200a;1.65 m. The range and default values of some parameters is summarised in <xref ref-type="table" rid="pone-0004536-t001">Table 1</xref>.</p><table-wrap id="pone-0004536-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0004536.t001</object-id><label>Table 1</label><caption><title>Default values and range of various parameters used in experiments.</title></caption><graphic id="pone-0004536-t001-1" xlink:href="pone.0004536.t001"/><table frame="hsides" rules="groups" alternate-form-of="pone-0004536-t001-1"><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup><thead><tr><td align="left" rowspan="1" colspan="1">Parameter</td><td align="left" rowspan="1" colspan="1">Range</td><td align="left" rowspan="1" colspan="1">Default value</td></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Dot correlation c</td><td align="left" rowspan="1" colspan="1">0&#x02013;0.5</td><td align="left" rowspan="1" colspan="1">-</td></tr><tr><td align="left" rowspan="1" colspan="1">Frame duration fd</td><td align="left" rowspan="1" colspan="1">10&#x02013;100 ms</td><td align="left" rowspan="1" colspan="1">30 ms</td></tr><tr><td align="left" rowspan="1" colspan="1">Dot density dd</td><td align="left" rowspan="1" colspan="1">1&#x02013;25 dots/degrees<sup>2</sup></td><td align="left" rowspan="1" colspan="1">5 dots/degrees<sup>2</sup></td></tr><tr><td align="left" rowspan="1" colspan="1">Angle of rotation &#x003b8;</td><td align="left" rowspan="1" colspan="1">1&#x02013;20&#x000b0;</td><td align="left" rowspan="1" colspan="1">5&#x000b0;</td></tr><tr><td align="left" rowspan="1" colspan="1">Inner circle diameter ic</td><td align="left" rowspan="1" colspan="1">1&#x02013;9.5&#x000b0;</td><td align="left" rowspan="1" colspan="1">7&#x000b0;</td></tr><tr><td align="left" rowspan="1" colspan="1">Outer circle diameter oc</td><td align="left" rowspan="1" colspan="1">-</td><td align="left" rowspan="1" colspan="1">10&#x000b0;</td></tr><tr><td align="left" rowspan="1" colspan="1">Dot diameter</td><td align="left" rowspan="1" colspan="1">-</td><td align="left" rowspan="1" colspan="1">5&#x02032;</td></tr><tr><td align="left" rowspan="1" colspan="1">Duration of a trial</td><td align="left" rowspan="1" colspan="1">-</td><td align="left" rowspan="1" colspan="1">60 s</td></tr><tr><td align="left" rowspan="1" colspan="1">Dot luminance</td><td align="left" rowspan="1" colspan="1">-</td><td align="left" rowspan="1" colspan="1">&#x02248;0</td></tr><tr><td align="left" rowspan="1" colspan="1">Background luminance</td><td align="left" rowspan="1" colspan="1">-</td><td align="left" rowspan="1" colspan="1">10.8 cd/m<sup>2</sup></td></tr><tr><td align="left" rowspan="1" colspan="1">Monitor resolution</td><td align="left" rowspan="1" colspan="1">-</td><td align="left" rowspan="1" colspan="1">640&#x000d7;480 pixels</td></tr><tr><td align="left" rowspan="1" colspan="1">Viewing distance</td><td align="left" rowspan="1" colspan="1">-</td><td align="left" rowspan="1" colspan="1">1.65 m</td></tr></tbody></table></table-wrap><p>The study was conducted over a period of several years, and new observers were recruited as old ones dropped out. In all experiments the number of observers is at least four, and number of trials &#x02265;20 for each data point shown in the figures. Error bars in the figures equal one standard deviation (s.d.), unless otherwise stated. Custom software was written by the author in C# to generate the stimuli. The study was approved by Committee for Protection of Human Subjects (CPHS), UC Berkeley. Written informed consent was obtained from subjects.</p><sec id="s2a"><title>Model Description</title><p>The following steps and <xref ref-type="fig" rid="pone-0004536-g002">Figure 2</xref> describe the complete pipeline used to model observer responses to the racetrack:</p><list list-type="bullet"><list-item><p>Step 1: Stimulus is input to the Watson Ahumada motion detector, which at time <italic>t</italic> gives the instantaneous optical flow.</p></list-item><list-item><p>Step 2: The optical flow is easily converted into a measure of rotary motion signal by taking cross products with radial vector, followed by weighted averaging. The weights are obtained in Step 1; for each velocity estimate the Watson Ahumada detector is able to provide a confidence/error measure which is used as the weight. Area MST(d) in the brain is believed to carry out this type of processing, where the local motion signals from stage MT are pooled to estimate global patterns of rotation and expansion that guide in heading estimation <xref ref-type="bibr" rid="pone.0004536-Graziano1">&#x0005b;9&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-Perrone2">&#x0005b;38&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-Duffy1">&#x0005b;39&#x0005d;</xref>. The output of this step is denoted by <italic>e(t)</italic>.</p></list-item><list-item><p>Step 3: The human visual system must integrate information over a certain interval of time to compute a reliable estimate of motion. This is achieved by passing <italic>e(t)</italic> through a moving averages filter, with window size of half a second. The output of this step is denoted by <italic>I(t)</italic>.</p></list-item><list-item><p>Step 4: While doing psychophysical experiments with human observers, the only information available is the direction in which the observer is perceiving motion. Therefore in order to compare model response with experimental psychophysics, <italic>I(t)</italic> is passed through a level crossing detector (LCD) with thresholds &#x000b1;B. B&#x0200a;&#x0003d;&#x0200a;2&#x003c3;(I) at <italic>c&#x0200a;&#x0003d;&#x0200a;0</italic> under default parameters. This choice of B makes the events when <italic>I(t)</italic> may cross detection threshold, given there is no rotary motion in the stimulus, unlikely. The behavior of level crossing detector is as follows: when input crosses &#x0002b;/&#x02212;B the detector signals CCW/CW motion respectively, and continues to do so until the input crosses threshold in the opposite direction. When that happens, the LCD flips to the opposite state.</p></list-item></list><fig id="pone-0004536-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0004536.g002</object-id><label>Figure 2</label><caption><title>(a) Block schematic of the model (b) Optical flow output by Watson Ahumada motion detector (c) Model response at various other stages in the pipeline.</title></caption><graphic xlink:href="pone.0004536.g002"/></fig><p>&#x003c7;, &#x003c4; can now be computed for the model, and values compared to experimental psychophysics. In its present form the model is strictly deterministic. However, the human visual system necessarily exhibits some variability, characteristic of any real world physical system. In fact as shown in the results section, it is found that at <italic>c&#x0200a;&#x0003d;&#x0200a;0</italic> observer responses are not reproducible. This variability in response is incorporated into the model by adding Gaussian White Noise (GWN) <italic>n(t)</italic> to <italic>e(t)</italic>, until the model response reproducibility also drops to zero at <italic>c&#x0200a;&#x0003d;&#x0200a;0</italic>. This occurs for <italic>k&#x0200a;&#x0003d;&#x0200a;&#x003c3;(n(t))/&#x003c3;<sub>0</sub></italic>&#x02265;approximately six, where <italic>&#x003c3;<sub>0</sub></italic> stands for <italic>&#x003c3;(e)</italic> at <italic>c&#x0200a;&#x0003d;&#x0200a;0</italic> under default parameters. Accordingly <italic>k</italic> was fixed at six. Model simulations were run at a resolution of 128&#x000d7;128 pixels, unless otherwise stated. Circular dots in psychophysical experiments were approximated as squares of equal area in model simulations. In all results, Watson Ahumada sensors are tuned to a center frequency of 0.64 cycles/degrees, unless otherwise stated. The reason for this setting is that it gave acceptable results. It may also be noted that most of the energy in power spectra of natural images is concentrated at relatively low spatial frequencies <xref ref-type="bibr" rid="pone.0004536-vanderSchaaf1">&#x0005b;40&#x0005d;</xref>. Default values of model parameters are summarised in <xref ref-type="table" rid="pone-0004536-t002">Table 2</xref>. My source code for the Watson Ahumada component of the model is publicly available <xref ref-type="bibr" rid="pone.0004536-Jain1">&#x0005b;41&#x0005d;</xref>.</p><table-wrap id="pone-0004536-t002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0004536.t002</object-id><label>Table 2</label><caption><title>Default values of model parameters used in simulations.</title></caption><graphic id="pone-0004536-t002-2" xlink:href="pone.0004536.t002"/><table frame="hsides" rules="groups" alternate-form-of="pone-0004536-t002-2"><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/></colgroup><thead><tr><td align="left" rowspan="1" colspan="1">Parameter</td><td align="left" rowspan="1" colspan="1">Default value</td></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Spatiotemporal filters</td><td align="left" rowspan="1" colspan="1">As in Watson &#x00026; Ahumada (1985) <xref ref-type="bibr" rid="pone.0004536-Watson1">&#x0005b;3&#x0005d;</xref></td></tr><tr><td align="left" rowspan="1" colspan="1">Center frequency</td><td align="left" rowspan="1" colspan="1">0.64 cycles/&#x000b0;</td></tr><tr><td align="left" rowspan="1" colspan="1">Noise</td><td align="left" rowspan="1" colspan="1">&#x003c3;(n(t))/&#x003c3;<sub>0</sub>&#x02248;6</td></tr><tr><td align="left" rowspan="1" colspan="1">LCD threshold B</td><td align="left" rowspan="1" colspan="1">2&#x003c3;(I) at c&#x0200a;&#x0003d;&#x0200a;0</td></tr><tr><td align="left" rowspan="1" colspan="1">Moving averages filter</td><td align="left" rowspan="1" colspan="1">Impulse Response <inline-formula><inline-graphic xlink:href="pone.0004536.e001.jpg" mimetype="image"/></inline-formula></td></tr><tr><td align="left" rowspan="1" colspan="1">Resolution</td><td align="left" rowspan="1" colspan="1">128&#x000d7;128 pixels</td></tr></tbody></table></table-wrap></sec></sec><sec id="s3"><title>Results</title><p>We begin with a discussion of the omega effect (<italic>c&#x0200a;&#x0003d;&#x0200a;0</italic> case of racetrack), and present two important results. First, although the display triggers perception of rotary motion, the direction of motion perceived is not dependent on what dot pattern is shown. Second, the time interval between spontaneous flips in direction exhibits a lognormal distribution.</p><sec id="s3a"><title>Omega effect: Response Reproducibility and distribution of spontaneous flips in perceived direction</title><p>As mentioned earlier, the omega effect is the <italic>c&#x0200a;&#x0003d;&#x0200a;0</italic> case of the racetrack. About two-thirds of observers report perception of rotary motion at <italic>c&#x0200a;&#x0003d;&#x0200a;0</italic>, even though there is no motion embedded in the stimulus <xref ref-type="bibr" rid="pone.0004536-Anonymous1">&#x0005b;42&#x0005d;</xref>. The perceived direction of motion changes randomly from time to time. After prolonged viewing most observers can usually choose the perceived direction of motion at will. For some observers the direction of motion switches when a sudden attention grabbing stimulus is given (such as a sudden tap on the back of the head). Some observers have even remarked that mere pressing of a mouse button causes the perceived direction of motion to reverse.</p><p>An important characteristic of the omega effect is that an observer gives different responses to the same stimulus in multiple trials. This is quantified in the following way. The observer response curves in response to the same stimulus in two separate trials are cross correlated. Let &#x003b6; denote the maximum value of the normalized cross correlation function. &#x003b6; is taken to be the measure of response reproducibility. It is found that the value of &#x003b6; when the same stimulus is shown in multiple trials is no different than the value of &#x003b6; when different stimuli are shown in multiple trials. Thus, the response reproducibility of the omega effect is zero. This may happen because the display is inherently ambiguous like most, if not all, bistable illusions. Both interpretations are equally likely and the brain randomly chooses a configuration at any time instant. It is found that &#x003b6;&#x0200a;&#x0003d;&#x0200a;&#x003bc;<sub>1</sub>&#x000b1;&#x003c3;<sub>1</sub>&#x0200a;&#x0003d;&#x0200a;0.145&#x000b1;0.1048 (mean&#x000b1;s.d.) based on 47 trials in which same stimulus is shown from trial to trial. Further, &#x003b6;&#x0200a;&#x0003d;&#x0200a;&#x003bc;<sub>2</sub>&#x000b1;&#x003c3;<sub>2</sub>&#x0200a;&#x0003d;&#x0200a;0.118&#x000b1;0.1359 based on 67 trials in which different stimuli are shown in multiple trials. One sided <italic>t</italic>-test to test the null hypothesis &#x003bc;<sub>1</sub>&#x0200a;&#x0003d;&#x0200a;&#x003bc;<sub>2</sub> against the alternate hypothesis &#x003bc;<sub>1</sub>&#x0003e;&#x003bc;<sub>2</sub> gives <italic>t</italic>&#x0200a;&#x0003d;&#x0200a;1.196. At &#x003b1;&#x0200a;&#x0003d;&#x0200a;0.05 level of significance the null hypothesis cannot be rejected (<italic>P</italic> value&#x0200a;&#x0003d;&#x0200a;0.1158).</p><p>The foregoing discussion has shown that the reproducibility of response is zero for the omega effect (<italic>c&#x0200a;&#x0003d;&#x0200a;0</italic>). However, intuitively we expect if c is not zero, i.e., some dots are deliberately correlated to undergo rotary motion, then observers should start responding in direction of motion of correlated dots. <xref ref-type="fig" rid="pone-0004536-g003">Figure 3</xref> shows the response reproducibility increases with c as expected (&#x003b6;&#x0200a;&#x0003d;&#x0200a;1 reflects perfect reproducibility).</p><fig id="pone-0004536-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0004536.g003</object-id><label>Figure 3</label><caption><title>Response reproducibility &#x003b6; vs. c.</title><p>Both model and humans show zero reproducibility at c&#x0200a;&#x0003d;&#x0200a;0, and the reproducibility steadily increases with c, because the motion signal gets stronger.</p></caption><graphic xlink:href="pone.0004536.g003"/></fig><p><xref ref-type="fig" rid="pone-0004536-g004">Figure 4(a)</xref> shows the histogram of the inter flip interval (IFI), which is the time interval between spontaneous reversals in perceived direction of motion, at c&#x0200a;&#x0003d;&#x0200a;0. The mode of the histogram occurs at IFI&#x02248;2 s. The histogram is well approximated by a lognormal distribution which is evident in <xref ref-type="fig" rid="pone-0004536-g004">Figure 4(b)</xref>, where the pdf (probability density function) of ln(IFI) is plotted together with a Gaussian fit. The IFI of many bistable illusions is lognormally distributed. Such distributions are common in biology, and one way to interpret them is in terms of the noise driven motion of a state point <xref ref-type="bibr" rid="pone.0004536-Riani1">&#x0005b;43&#x0005d;</xref>.</p><fig id="pone-0004536-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0004536.g004</object-id><label>Figure 4</label><caption><title>(a) histogram of Inter Flip Interval (IFI) at c&#x0200a;&#x0003d;&#x0200a;0 (mode&#x02248;2 s) (b) normalised histogram of ln(IFI) together with a Gaussian fit.</title><p>The pdf of ln(IFI) given by the model is also shown.</p></caption><graphic xlink:href="pone.0004536.g004"/></fig><p>The mechanisms underlying omega effect are not clear. When dots are displayed in a circular annulus their freedom of movement is restricted. The dots at the boundary cannot move in all 360&#x000b0; directions. In the limit when the annulus width tends to zero, the dots can only move tangentially. This suggests an increase in the omega effect with decrease in annulus width which is experimentally true <xref ref-type="bibr" rid="pone.0004536-Rose1">&#x0005b;10&#x0005d;</xref>. When the annulus has appreciable width the dots at boundary are more likely to bounce normal to the boundary. Some observers do report perception of a radial pulsating motion in the omega display <xref ref-type="bibr" rid="pone.0004536-Anonymous1">&#x0005b;42&#x0005d;</xref>. Rose&#x00026;Blake (1998) postulated that the omega effect arises because of interaction between cells that are sensitive to curvature in the display, and cells that are sensitive to motion <xref ref-type="bibr" rid="pone.0004536-Rose1">&#x0005b;10&#x0005d;</xref>. For its part, the Watson Ahumada model outputs a zero mean white noise like signal in response to the omega display, since there are dots bouncing off in all directions randomly. This signal combined with the intrinsic noise <italic>n(t)</italic> (which at <italic>c&#x0200a;&#x0003d;&#x0200a;0</italic> is six times stronger than the Watson Ahumada signal) results in rapid zero mean fluctuations. Because of their stochastic nature, these fluctuations become large enough at times to cross the LCD thresholds. The IFI distribution resulting from such stochastic fluctuations is also shown in <xref ref-type="fig" rid="pone-0004536-g004">Figure 4(b)</xref> for comparison.</p></sec><sec id="s3b"><title>Effect of dot correlation c</title><p><xref ref-type="fig" rid="pone-0004536-g005">Figure 5(a)</xref> shows variation of signal detectability &#x003c7; vs. the dot correlation <italic>c</italic>. A &#x003c7; value of 1 means perfect detection, and &#x003c7; at <italic>c&#x0200a;&#x0003d;&#x0200a;0</italic> reflects the baseline zero level of &#x003c7; corresponding to chance detectability. The increase in &#x003c7; with c is easy to understand, as the value of c directly controls the amount of motion embedded in the stimulus. As can be seen from the figure, the model fits the experimental data very closely. If the threshold for motion perception is defined as the value of <italic>c</italic> for which &#x003c7; is one standard deviation higher than the &#x003c7; value at <italic>c&#x0200a;&#x0003d;&#x0200a;0</italic>, then this gives a threshold of c in the range of 0.03 to 0.06. This is comparable to thresholds reported elsewhere <xref ref-type="bibr" rid="pone.0004536-Newsome1">&#x0005b;24&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-Newsome2">&#x0005b;25&#x0005d;</xref>. The experimental method described in this paper allows the measurement of the reaction time &#x003c4; of an observer. <xref ref-type="fig" rid="pone-0004536-g005">Figure 5(b)</xref> shows a graph of the reaction time &#x003c4; vs. <italic>c</italic>. For c&#x02248;0, &#x003c4; is about 1.5 s, and decreases steadily with increase in <italic>c</italic>. It takes less time to recognize the motion signal as the signal gets stronger. At high values of <italic>c</italic>, &#x003c4; is about half a second. The model is seen to fit the experimental data well. In general &#x003c7; and &#x003c4; are inversely correlated as shown in <xref ref-type="fig" rid="pone-0004536-g005">Figure 5(c)</xref>. Parameters that tend to increase &#x003c7; tend to decrease &#x003c4; and vice-versa.</p><fig id="pone-0004536-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0004536.g005</object-id><label>Figure 5</label><caption><title>(a) &#x003c7; vs. c (b) &#x003c4; vs. c (fd&#x0200a;&#x0003d;&#x0200a;30 ms, ic&#x0200a;&#x0003d;&#x0200a;7&#x000b0;, dd&#x0200a;&#x0003d;&#x0200a;5 dots/degrees<sup>2</sup>) (c) &#x003c4; vs. &#x003c7; scatter plot and piecewise linear fit for experimental data.</title></caption><graphic xlink:href="pone.0004536.g005"/></fig></sec><sec id="s3c"><title>Effect of frame duration fd</title><p><xref ref-type="fig" rid="pone-0004536-g006">Figure 6</xref> shows that fd&#x02248;30 ms is optimal for motion perception. The same sequence of frames that evoke perception of vivid motion at fd&#x02248;30 ms, fail to evoke any perception of motion at fd &#x0226b;30 ms. The explanation proposed for the fd effect seen here is as follows. The motion computed by local motion detectors at time t is based on the spatiotemporal signal from time t-T to time t, where T&#x02248;200 ms is the temporal size of receptive fields of simple/complex cells found in the primary visual cortex <xref ref-type="bibr" rid="pone.0004536-DeAngelis1">&#x0005b;44&#x0005d;</xref>. When fd is too large the input is mostly constant within a window of 200 ms and so motion sensitive cells will fail to detect any motion. On the other hand, if fd is too small the input may be changing at a rate that the cells cannot handle. The bandwidth of the stimulus, viewed as a continuous-time signal, is directly proportional to the rate at which the individual racetrack frames are played. When fd is too low, the correlated dot will stay in the receptive field (RF) of a motion sensitive cell for a very brief interval of time, and will not excite the spatiotemporal RF profile of the cell.</p><fig id="pone-0004536-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0004536.g006</object-id><label>Figure 6</label><caption><title>&#x003c7; vs. frame duration fd.</title><p>c&#x0200a;&#x0003d;&#x0200a;0.1, ic&#x0200a;&#x0003d;&#x0200a;7&#x000b0;, dd&#x0200a;&#x0003d;&#x0200a;5 dots/degrees<sup>2</sup>.</p></caption><graphic xlink:href="pone.0004536.g006"/></fig><p>The model results are close to that of experiment, except for the &#x003c7; values at fd&#x0200a;&#x0003d;&#x0200a;10 ms. This may be because of the high bandwidth of neurons used in the model. It is interesting to note that without noise, &#x003c7; at fd&#x0200a;&#x0003d;&#x0200a;100 ms is at the baseline zero level. If noise is added, &#x003c7; rises above zero level, and matches value given by human observers. This is reminiscent of the beneficial effect noise may sometimes play in a system, by stochastically boosting a subthreshold signal in the manner of stochastic resonance <xref ref-type="bibr" rid="pone.0004536-Benzi1">&#x0005b;45&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-Gammaitoni1">&#x0005b;46&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-Moss1">&#x0005b;47&#x0005d;</xref>.</p></sec><sec id="s3d"><title>Effect of dot density dd</title><p><xref ref-type="fig" rid="pone-0004536-g007">Figure 7</xref> shows the effect of varying the dot density dd in the display. Humans display a remarkable indifference to the dot density in the display. This shows that it is the relative proportion of the correlated dots that matters, not their absolute number. The experimentally observed independence of observer performance on dot density cannot be explained by models of motion perception based on matching dots or features to their nearest neighbors in the next frame <xref ref-type="bibr" rid="pone.0004536-Ullman1">&#x0005b;6&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-Dawson1">&#x0005b;7&#x0005d;</xref>. Such models display a marked dependence on dot density in the display according to the probability of mismatch formula <xref ref-type="bibr" rid="pone.0004536-Williams1">&#x0005b;8&#x0005d;</xref>. As the dot density increases there are more dots per unit area, and the chances that the nearest neighbor is not the correlated partner increase.</p><fig id="pone-0004536-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0004536.g007</object-id><label>Figure 7</label><caption><title>&#x003c7; vs. dot density dd.</title><p>c&#x0200a;&#x0003d;&#x0200a;0.2, ic&#x0200a;&#x0003d;&#x0200a;7&#x000b0;, fd&#x0200a;&#x0003d;&#x0200a;30 ms. Model simulations done at 256&#x000d7;256 pixel resolution for dd&#x0003e;10.</p></caption><graphic xlink:href="pone.0004536.g007"/></fig><p>A derivation of the probability of mismatch formula follows. A correlated dot is displaced by a distance <italic>h</italic> in the next frame. A nearest neighbor model operates by matching dots to their nearest neighbors in the next frame. The matching directly gives the local motion vectors, which is the output of the model. Therefore, for the correlated dot to be matched correctly to its partner, no dot should fall within a circle of radius <italic>h</italic> in the next frame. The probability of this happening, which is equal to the probability of no mismatch equals:<disp-formula><graphic xlink:href="pone.0004536.e002.jpg" mimetype="image" position="float"/></disp-formula>where A is the area of display, N is total number of dots in the display, N&#x0200a;&#x0003d;&#x0200a;A&#x000b7;dd, and we assume that dots are uniformly distributed.</p><p>Approximating 1&#x02212;x as exp(&#x02212;x) for x sufficiently small, and substituting A&#x000b7;dd for N,<disp-formula><graphic xlink:href="pone.0004536.e003.jpg" mimetype="image" position="float"/></disp-formula>therefore,<disp-formula><graphic xlink:href="pone.0004536.e004.jpg" mimetype="image" position="float"/><label>(1)</label></disp-formula>which the formula given in Williams &#x00026; Sekuler (1984) <xref ref-type="bibr" rid="pone.0004536-Williams1">&#x0005b;8&#x0005d;</xref>. The probability of mismatch values for the dot density range used in <xref ref-type="fig" rid="pone-0004536-g007">Figure 7</xref>, are tabulated in <xref ref-type="table" rid="pone-0004536-t003">Table 3</xref>. This formula makes it explicit that as the dot density increases, there would be more and more mismatches, and therefore observer performance should decrease with increase in dot density. In reality, however, observer performance is independent of dot density in the display. The Watson Ahumada motion detector is able to capture this independence as shown in <xref ref-type="fig" rid="pone-0004536-g007">Figure 7</xref>.</p><table-wrap id="pone-0004536-t003" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0004536.t003</object-id><label>Table 3</label><caption><title>Probability of mismatch values for dot densities in <xref ref-type="fig" rid="pone-0004536-g007">Figure 7</xref>.</title></caption><graphic id="pone-0004536-t003-3" xlink:href="pone.0004536.t003"/><table frame="hsides" rules="groups" alternate-form-of="pone-0004536-t003-3"><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/></colgroup><thead><tr><td align="left" rowspan="1" colspan="1">Dot density (dots/degrees<sup>2</sup>)</td><td align="left" rowspan="1" colspan="1">Probability of mismatch&#x0200a;&#x0003d;&#x0200a;1&#x02212;exp(&#x02212;&#x003c0;h<sup>2</sup>dd) (up to 4 decimal places) h&#x0200a;&#x0003d;&#x0200a;0.37&#x000b0;</td></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">1</td><td align="left" rowspan="1" colspan="1">0.3495</td></tr><tr><td align="left" rowspan="1" colspan="1">2</td><td align="left" rowspan="1" colspan="1">0.5769</td></tr><tr><td align="left" rowspan="1" colspan="1">4</td><td align="left" rowspan="1" colspan="1">0.8210</td></tr><tr><td align="left" rowspan="1" colspan="1">8</td><td align="left" rowspan="1" colspan="1">0.9680</td></tr><tr><td align="left" rowspan="1" colspan="1">16</td><td align="left" rowspan="1" colspan="1">0.9990</td></tr><tr><td align="left" rowspan="1" colspan="1">25</td><td align="left" rowspan="1" colspan="1">1.0000</td></tr></tbody></table></table-wrap><p>It may be noted that if some of the assumptions leading to the formula in equation (1) do not hold, the analytic form of P(mismatch) may no longer be given accurately by 1&#x02212;exp(&#x02212;&#x003c0;h<sup>2</sup>dd). However, the central thesis of the formula that observer performance should decrease with dot density will still remain true. This is because as the dot density increases, there are more dots per unit area, and therefore the expected separation between dots would decrease. When the expected dot separation becomes less than the hop size <italic>h</italic>, the matching would be dominated by mismatches, and performance would decline. It may be appropriate here to remark on the study of Grzywacz, Watamaniuk and McKee (1995) (<xref ref-type="fig" rid="pone-0004536-g001">figure 1</xref> in their paper) <xref ref-type="bibr" rid="pone.0004536-Grzywacz2">&#x0005b;48&#x0005d;</xref>. It appears to me that the authors correctly simulated the Adelson Bergen model and found that it is insensitive to dot density. However, they concluded incorrectly, misguided by the probability of mismatch formula, that psychophysical results should depend on dot density.</p></sec><sec id="s3e"><title>Effect of spatial hop size h</title><p>The hop size is the amount of displacement given to the correlated dots. By default the correlated dots are rotated by an angle of 5&#x000b0;. With ic&#x0200a;&#x0003d;&#x0200a;7&#x000b0;, and angle subtended by outer circle fixed at 10&#x000b0;, this translates to average displacement of  <inline-formula><inline-graphic xlink:href="pone.0004536.e005.jpg" mimetype="image"/></inline-formula> visual angle on the eye. <xref ref-type="fig" rid="pone-0004536-g008">Figure 8 </xref> shows  the effect of varying the hop size for the model and  humans, at different dot densities. The correlated dots were rotated by angles of {1,5,10,15,20} degrees, corresponding to average displacements of {0.074, 0.37, 0.74, 1.11, 1.48} degrees visual angle on the eye. The curves for the model and humans are approximately similar. Note in particular that changing dot density does not produce any change in &#x003c7;. The figures show that as the hop size is increased, motion disappears in the display even though the dot correlation is very high (c&#x0200a;&#x0003d;&#x0200a;0.4). This is because if the hop size becomes greater than the RF size, motion sensitive neurons will fail to register motion. Also important is the decrease in &#x003c7; if the hop size becomes too small. In this case, the spatiotemporal profile of the stimulus will not cross-correlate well with the spatiotemporal RF of motion sensitive cells.</p><fig id="pone-0004536-g008" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0004536.g008</object-id><label>Figure 8</label><caption><title>(a) &#x003c7; vs. hop size h for human observers (b) &#x003c7; vs. hop size for model.</title><p>c&#x0200a;&#x0003d;&#x0200a;0.4, fd&#x0200a;&#x0003d;&#x0200a;30 ms, ic&#x0200a;&#x0003d;&#x0200a;7&#x000b0;.</p></caption><graphic xlink:href="pone.0004536.g008"/></fig></sec><sec id="s3f"><title>Effect of inner circle diameter ic</title><p>The angle subtended by the outer circle diameter is fixed at 10&#x000b0; in all the experiments. <xref ref-type="fig" rid="pone-0004536-g009">Figure 9</xref> shows the effect of varying the angle subtended by the inner circle diameter ic (c&#x0200a;&#x0003d;&#x0200a;0.1). It is seen that observer performance falls off as the angle subtended by the inner circle diameter ic is changed from 7&#x000b0; to 9.5&#x000b0;. At ic&#x0200a;&#x0003d;&#x0200a;9.5&#x000b0; the annulus is very thin, and appears like a 1D ring rather than a 2D annulus. When ic is small, the noise in the display is uniformly distributed in the sense that if &#x003b8; is the angle made by the noise vector, then &#x003b8; is uniformly distributed from &#x02212;&#x003c0; to &#x0002b;&#x003c0;. Denote the cross product of noise vector with the radial vector by <italic>x</italic>&#x0200a;&#x0003d;&#x0200a;sin(<italic>&#x003b8;</italic>). Then <inline-formula><inline-graphic xlink:href="pone.0004536.e006.jpg" mimetype="image"/></inline-formula>, and the amount of noise is given by<disp-formula><graphic xlink:href="pone.0004536.e007.jpg" mimetype="image" position="float"/></disp-formula></p><fig id="pone-0004536-g009" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0004536.g009</object-id><label>Figure 9</label><caption><title>&#x003c7; vs. angle subtended by inner circle diameter ic.</title><p>Angle subtended by outer circle diameter is fixed at 10&#x000b0;. c&#x0200a;&#x0003d;&#x0200a;0.1, dd&#x0200a;&#x0003d;&#x0200a;5 dots/degrees<sup>2</sup>, fd&#x0200a;&#x0003d;&#x0200a;30 ms. Model simulations at 256&#x000d7;256 pixel resolution. f<sub>0</sub> denotes center frequency of Watson Ahumada sensors.</p></caption><graphic xlink:href="pone.0004536.g009"/></fig><p>On the other hand, when ic&#x02192;oc, &#x003b8; is either &#x02013;&#x003c0;/2 or &#x0002b;&#x003c0;/2 with equal probability. <inline-formula><inline-graphic xlink:href="pone.0004536.e008.jpg" mimetype="image"/></inline-formula> is still zero but<disp-formula><graphic xlink:href="pone.0004536.e009.jpg" mimetype="image" position="float"/></disp-formula>so the amount of noise has apparently doubled in this case. Model performance is seen to partially match psychophysical performance. The curve with center frequency equal to 1.28 cycles/&#x000b0; shows a better fit than the curve with center frequency equal to 0.64 cycles/&#x000b0;. Unfortunately I cannot say why the former curve shows a better fit.</p></sec><sec id="s3g"><title>Effect of reverse contrast</title><p>If the stimulus is modified such that the correlated dots flip their polarity as they rotate, meaning black dots change to white and vice-versa, then the reverse-phi motion <xref ref-type="bibr" rid="pone.0004536-Anstis1">&#x0005b;49&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-Anstis2">&#x0005b;50&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-Adelson1">&#x0005b;1&#x0005d;</xref> takes place. It is found that the motion perceived by an observer is opposite to the physical displacement of the correlated dots. If the correlated dots move CCW(CW), observer perceives motion in CW(CCW) direction respectively. The Watson Ahumada model is able to capture this phenomenon as shown in <xref ref-type="fig" rid="pone-0004536-g010">Figure 10</xref>. If the observer perceives motion in a direction opposite to rotation of the correlated dots, the observer response is negatively correlated with the embedded motion. For this reason &#x003c7; in <xref ref-type="fig" rid="pone-0004536-g010">Figure 10</xref> is defined as the minimum value of the normalized cross correlation function between the response and input function.</p><fig id="pone-0004536-g010" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0004536.g010</object-id><label>Figure 10</label><caption><title>&#x003c7; vs. c for contrast reversing dots.</title><p>fd&#x0200a;&#x0003d;&#x0200a;30 ms, ic&#x0200a;&#x0003d;&#x0200a;7&#x000b0;, dd&#x0200a;&#x0003d;&#x0200a;2.5 dots/degrees<sup>2</sup>.</p></caption><graphic xlink:href="pone.0004536.g010"/></fig><p>To understand why motion may be perceived in the opposite direction when dots reverse their contrast, consider the signal <inline-formula><inline-graphic xlink:href="pone.0004536.e010.jpg" mimetype="image"/></inline-formula>. It is well known <xref ref-type="bibr" rid="pone.0004536-Watson2">&#x0005b;17&#x0005d;</xref> that the Fourier Transform of an image undergoing coherent translational motion lies on a plane, i.e., if <inline-formula><inline-graphic xlink:href="pone.0004536.e011.jpg" mimetype="image"/></inline-formula> then <inline-formula><inline-graphic xlink:href="pone.0004536.e012.jpg" mimetype="image"/></inline-formula> where <inline-formula><inline-graphic xlink:href="pone.0004536.e013.jpg" mimetype="image"/></inline-formula> is the 2D Fourier Transform of <inline-formula><inline-graphic xlink:href="pone.0004536.e014.jpg" mimetype="image"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="pone.0004536.e015.jpg" mimetype="image"/></inline-formula> is velocity. The equation of plane is <inline-formula><inline-graphic xlink:href="pone.0004536.e016.jpg" mimetype="image"/></inline-formula>. This observation yields following algorithm to determine motion in a signal <inline-formula><inline-graphic xlink:href="pone.0004536.e017.jpg" mimetype="image"/></inline-formula>: find the best fitting plane to <inline-formula><inline-graphic xlink:href="pone.0004536.e018.jpg" mimetype="image"/></inline-formula> that passes through the origin. The velocity can be read off the equation of the plane. Now consider what happens when <inline-formula><inline-graphic xlink:href="pone.0004536.e019.jpg" mimetype="image"/></inline-formula> reverses its contrast every <inline-formula><inline-graphic xlink:href="pone.0004536.e020.jpg" mimetype="image"/></inline-formula>. The modified signal is given by <inline-formula><inline-graphic xlink:href="pone.0004536.e021.jpg" mimetype="image"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="pone.0004536.e022.jpg" mimetype="image"/></inline-formula> is a square wave alternating between &#x0002b;1 and &#x02212;1 every <inline-formula><inline-graphic xlink:href="pone.0004536.e023.jpg" mimetype="image"/></inline-formula>. The Fourier Series of <inline-formula><inline-graphic xlink:href="pone.0004536.e024.jpg" mimetype="image"/></inline-formula> is given by <inline-formula><inline-graphic xlink:href="pone.0004536.e025.jpg" mimetype="image"/></inline-formula>, with <inline-formula><inline-graphic xlink:href="pone.0004536.e026.jpg" mimetype="image"/></inline-formula>, <inline-formula><inline-graphic xlink:href="pone.0004536.e027.jpg" mimetype="image"/></inline-formula> being a constant, and <inline-formula><inline-graphic xlink:href="pone.0004536.e028.jpg" mimetype="image"/></inline-formula>. This gives <inline-formula><inline-graphic xlink:href="pone.0004536.e029.jpg" mimetype="image"/></inline-formula>. Note that <inline-formula><inline-graphic xlink:href="pone.0004536.e030.jpg" mimetype="image"/></inline-formula>. Thus, the Fourier Transform of <inline-formula><inline-graphic xlink:href="pone.0004536.e031.jpg" mimetype="image"/></inline-formula> does not lie on a plane passing through the origin. Instead, the Fourier Transform of <inline-formula><inline-graphic xlink:href="pone.0004536.e032.jpg" mimetype="image"/></inline-formula> consists of infinitely many planes given by <inline-formula><inline-graphic xlink:href="pone.0004536.e033.jpg" mimetype="image"/></inline-formula> as illustrated in <xref ref-type="fig" rid="pone-0004536-g011">Figure 11</xref>. Assuming <inline-formula><inline-graphic xlink:href="pone.0004536.e034.jpg" mimetype="image"/></inline-formula> is mostly constant, the best fitting plane to <inline-formula><inline-graphic xlink:href="pone.0004536.e035.jpg" mimetype="image"/></inline-formula> (that also passes through the origin) is &#x022a5; to <inline-formula><inline-graphic xlink:href="pone.0004536.e036.jpg" mimetype="image"/></inline-formula>. If <inline-formula><inline-graphic xlink:href="pone.0004536.e037.jpg" mimetype="image"/></inline-formula> is normal of the best fitting plane, then <inline-formula><inline-graphic xlink:href="pone.0004536.e038.jpg" mimetype="image"/></inline-formula>. <inline-formula><inline-graphic xlink:href="pone.0004536.e039.jpg" mimetype="image"/></inline-formula> is velocity of <inline-formula><inline-graphic xlink:href="pone.0004536.e040.jpg" mimetype="image"/></inline-formula> under reverse contrast. Letting <inline-formula><inline-graphic xlink:href="pone.0004536.e041.jpg" mimetype="image"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="pone.0004536.e042.jpg" mimetype="image"/></inline-formula> we have<disp-formula><graphic xlink:href="pone.0004536.e043.jpg" mimetype="image" position="float"/></disp-formula></p><fig id="pone-0004536-g011" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0004536.g011</object-id><label>Figure 11</label><caption><title>The Fourier Transform of an image undergoing coherent translational motion &#x0002b; periodic reverse contrast lies on infinitely many planes of the form <inline-formula><inline-graphic xlink:href="pone.0004536.e044.jpg" mimetype="image"/></inline-formula>, with <inline-formula><inline-graphic xlink:href="pone.0004536.e045.jpg" mimetype="image"/></inline-formula> being an odd number.</title><p>The dashed lines denote the window of visibility <xref ref-type="bibr" rid="pone.0004536-Watson3">&#x0005b;30&#x0005d;</xref>.</p></caption><graphic xlink:href="pone.0004536.g011"/></fig><p>This equation can be satisfied by many <inline-formula><inline-graphic xlink:href="pone.0004536.e046.jpg" mimetype="image"/></inline-formula>. In particular <inline-formula><inline-graphic xlink:href="pone.0004536.e047.jpg" mimetype="image"/></inline-formula> is a solution, which is motion in opposite direction to <inline-formula><inline-graphic xlink:href="pone.0004536.e048.jpg" mimetype="image"/></inline-formula>. Note that <inline-formula><inline-graphic xlink:href="pone.0004536.e049.jpg" mimetype="image"/></inline-formula> suggests that a faster moving particle should actually appear to move slower! This surprising prediction appears to be true within appropriate range. A display of alternating black and white stripes was made. The width of a stripe was 0.25&#x000b0;. The stripe pattern was translated to the right, and the stripes reversed their contrast after a time interval T. On viewing the display, motion was perceived in the leftward direction instead of right. With fd&#x0200a;&#x0003d;&#x0200a;T&#x0200a;&#x0003d;&#x0200a;30 ms and a hop size of 0.125&#x000b0;, the pattern appeared to be moving slower than with hop size of 0.0625&#x000b0;. Further experiments need to be done to gather numerical data to quantify the effect.</p></sec><sec id="s3h"><title>Model sensitivity to center position</title><p>By definition of rotation, any measure of rotary motion has to be specified with respect to some center of rotation (more accurately the axis of rotation has to be specified). In all the results presented up till now, the center position used in the simulations was the true center of rotation of the dots. What happens if the true center of rotation is not accurately known, as must be the case in reality? <xref ref-type="fig" rid="pone-0004536-g012">Figure 12</xref> shows a schematic in which point O is the true center relative to which the correlated dots are rotating, and point C is the center relative to which rotary motion is computed by the model. <inline-formula><inline-graphic xlink:href="pone.0004536.e050.jpg" mimetype="image"/></inline-formula> is a motion cue. The rotary motion relative to the true center O is given by <inline-formula><inline-graphic xlink:href="pone.0004536.e051.jpg" mimetype="image"/></inline-formula>, whereas the rotary motion relative to C is given by <inline-formula><inline-graphic xlink:href="pone.0004536.e052.jpg" mimetype="image"/></inline-formula>. We have<disp-formula><graphic xlink:href="pone.0004536.e053.jpg" mimetype="image" position="float"/></disp-formula></p><fig id="pone-0004536-g012" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0004536.g012</object-id><label>Figure 12</label><caption><title>Point O represents the true center of rotation, whereas point C is the center relative to which rotary motion is computed by the model.</title><p>The offset is given by <inline-formula><inline-graphic xlink:href="pone.0004536.e054.jpg" mimetype="image"/></inline-formula> where <inline-formula><inline-graphic xlink:href="pone.0004536.e055.jpg" mimetype="image"/></inline-formula> is radius of inner circle.</p></caption><graphic xlink:href="pone.0004536.g012"/></fig><p>The condition <inline-formula><inline-graphic xlink:href="pone.0004536.e056.jpg" mimetype="image"/></inline-formula> is true in case of the racetrack. The uncorrelated dots are uniformly distributed and generate motion cues in all directions with equal probability. The correlated dots generate motion cues in tangential direction, which when summed over the entire 360&#x000b0; annulus add up to zero. The expected value of <inline-formula><inline-graphic xlink:href="pone.0004536.e057.jpg" mimetype="image"/></inline-formula> is thus zero. Therefore it seems accurate knowledge of position of the true center relative to which rotation occurs is not needed. <xref ref-type="fig" rid="pone-0004536-g013">Figure 13(a)</xref> shows model sensitivity to knowledge of true center position. The rotary motion is computed by the model relative to a point C that is offset from the true center O. The offset is given by <inline-formula><inline-graphic xlink:href="pone.0004536.e058.jpg" mimetype="image"/></inline-formula> where R<sub>i</sub> is radius of inner circle. Two curves are shown: in one there is no noise added to the model, i.e., n(t)&#x0200a;&#x0003d;&#x0200a;0, and in the other GWN equal to the default value of &#x003c3;(GWN)/&#x003c3;<sub>0</sub>&#x0200a;&#x0003d;&#x0200a;6 is added to the model. It can be seen that the &#x003c7; values are not affected much by uncertainty in knowledge of true center position, and start to deteriorate only when the offset becomes very large. This may explain the experimentally observed position invariance of MST(d) cells, the fact that the cells are insensitive to where in their RF rotation occurs <xref ref-type="bibr" rid="pone.0004536-Graziano1">&#x0005b;9&#x0005d;</xref>.</p><fig id="pone-0004536-g013" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0004536.g013</object-id><label>Figure 13</label><caption><title>&#x003c7; vs. center relative to which rotary motion is computed (a) full 360&#x000b0; annulus is visible (b) only 90&#x000b0; of annulus is visible.</title><p>Type1 &#x02013; a single 90&#x000b0; sector is visible. Type 2 - two sectors located diametrically opposite to each other, and each 45&#x000b0; in size, are visible. Both curves are for the model.</p></caption><graphic xlink:href="pone.0004536.g013"/></fig><p>It seems that when only a sector of the racetrack is made visible, the condition <inline-formula><inline-graphic xlink:href="pone.0004536.e059.jpg" mimetype="image"/></inline-formula> may not hold true because of the correlated dots. However, if two sectors located diametrically opposite to each other are displayed then <inline-formula><inline-graphic xlink:href="pone.0004536.e060.jpg" mimetype="image"/></inline-formula>. <xref ref-type="fig" rid="pone-0004536-g013">Figure 13(b)</xref> shows &#x003c7; vs. offset for the two cases: type1 when only a single 90&#x000b0; sector is made visible, and type2 when two sectors located diametrically opposite to each other, and each 45&#x000b0; in size, are displayed. Interestingly the model is still robust enough to the offset even when only a sector of the racetrack is displayed, irrespective of whether it is type1 or type2.</p></sec><sec id="s3i"><title>Effect of displaying only a sector</title><p><xref ref-type="fig" rid="pone-0004536-g014">Figure 14(a)</xref> shows the effect of displaying only a sector of the complete annulus on human observers. Two cases are considered. In type1, a single sector is shown that is randomly positioned. In type2, two sectors located diametrically opposite to each other, and each half the size of the sector in type1, are displayed. It is seen that &#x003c7; increases monotonically as the sector size increases. It is interesting to note that there is a significant difference in &#x003c7; for the two cases, even though the total area displayed is the same in the two cases. The corresponding data for the model is shown in <xref ref-type="fig" rid="pone-0004536-g014">Figure 14(b)</xref>. The model shows an increase in &#x003c7; with sector size. However, there is no difference between type1 and type2 for the model.</p><fig id="pone-0004536-g014" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0004536.g014</object-id><label>Figure 14</label><caption><title>&#x003c7; vs. sector.</title><p>In case of type 1 only one sector is displayed, whereas in case of type 2 two sectors located diametrically opposite to each other, and each half the size of sector in type 1, are displayed. (a) human performance (b) model performance.</p></caption><graphic xlink:href="pone.0004536.g014"/></fig></sec><sec id="s3j"><title>Effect of inserting random frames</title><p><xref ref-type="fig" rid="pone-0004536-g015">Figure 15</xref> shows effect of inserting K random frames between every pair of correlated frames in the stimulus. It is seen that observer performance does not fall to zero abruptly, but decreases in a graceful manner showing that the human visual system takes multiples frames into consideration when estimating motion. The model performance also does not fall to zero abruptly, but degrades much more rapidly than human performance.</p><fig id="pone-0004536-g015" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0004536.g015</object-id><label>Figure 15</label><caption><title>Effect of inserting K random frames between correlated frames.</title><p>c&#x0200a;&#x0003d;&#x0200a;0.5, fd&#x0200a;&#x0003d;&#x0200a;30 ms, dd&#x0200a;&#x0003d;&#x0200a;5 dots/degrees<sup>2</sup>, ic&#x0200a;&#x0003d;&#x0200a;7&#x000b0;.</p></caption><graphic xlink:href="pone.0004536.g015"/></fig></sec><sec id="s3k"><title>Dipoles</title><p>Instead of displaying dots in an annulus, each dot can be split into two dots &#x02013; one black and one white forming a dipole. This results in what has been termed as the anti-Glass pattern <xref ref-type="bibr" rid="pone.0004536-Burr1">&#x0005b;51&#x0005d;</xref>. The <italic>c&#x0200a;&#x0003d;&#x0200a;0</italic> case creates a powerful motion illusion that has been previously investigated <xref ref-type="bibr" rid="pone.0004536-Viva1">&#x0005b;35&#x0005d;</xref>. The addition of dipoles introduces several new parameters:</p><list list-type="order"><list-item><p>the dipole spacing s,</p></list-item><list-item><p>the black to white intensity ratio bwir defined as <inline-formula><inline-graphic xlink:href="pone.0004536.e061.jpg" mimetype="image"/></inline-formula> where I<sub>0</sub>, I<sub>b</sub>, I<sub>w</sub> are luminance of background (fixed at 10.8 cd/m<sup>2</sup>), black and white dots respectively,</p></list-item><list-item><p>the dipole orientation: tangential or radial as in <xref ref-type="fig" rid="pone-0004536-g016">Figure 16</xref></p></list-item></list><fig id="pone-0004536-g016" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0004536.g016</object-id><label>Figure 16</label><caption><title>(a) tangential dipoles (b) radial dipoles.</title><p>Center-to-center spacing &#x0200a;&#x0003d;&#x0200a;17&#x02032; in both cases.</p></caption><graphic xlink:href="pone.0004536.g016"/></fig><p>Complex patterns of motion are perceived with dipoles in the display, e.g., if dipoles are oriented radially there is tendency to observe radial pulsating motion, even if dipoles are actually rotating with significant rotary motion. Depending upon the parameter settings, motion in opposite directions is also seen. It can become difficult to assign a single motion direction to the whole display, although there is no doubt that there is motion in it. Let RC (reverse contrast) ON denote the setting that if a dipole is correlated, then black changes to white and vice-versa in the next frame. With RC ON, the perception of motion can switch from normal phi to reverse phi depending upon dipole spacing. This section reports results of an experiment investigating &#x003c7; vs. bwir with center-to-center spacing equal to six minutes, <italic>c&#x0200a;&#x0003d;&#x0200a;0</italic>, and RC ON. The results are summarised in <xref ref-type="fig" rid="pone-0004536-g017">Figure 17</xref>. As can be seen the model is able to capture some aspects of psychophysical behavior, but not all of it. In <xref ref-type="fig" rid="pone-0004536-g017">Figure 17</xref>, the definition of &#x003c7; is modified as follows. Let &#x003c7;<sub>&#x0002b;</sub> denote maximum value of normalized cross correlation function, and &#x003c7;<sub>&#x02212;</sub> denote minimum value of normalized cross correlation function. If |&#x003c7;<sub>&#x0002b;</sub>|&#x0003e;|&#x003c7;<sub>&#x02212;</sub>|, &#x003c7;&#x0200a;&#x0003d;&#x0200a;&#x003c7;<sub>&#x0002b;</sub>, otherwise &#x003c7;&#x0200a;&#x0003d;&#x0200a;&#x003c7;<sub>&#x02212;</sub>. When |&#x003c7;<sub>&#x0002b;</sub>|&#x0003e;|&#x003c7;<sub>&#x02212;</sub>|, observer perceives motion in the direction of displacement of correlated dots and therefore &#x003c7; is defined to be equal to &#x003c7;<sub>&#x0002b;</sub> in this case. By similar reasoning, &#x003c7; is defined to be &#x003c7;<sub>&#x02212;</sub> for the other case.</p><fig id="pone-0004536-g017" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0004536.g017</object-id><label>Figure 17</label><caption><title>&#x003c7; vs. bwir (black to white intensity ratio).</title><p>Dipole spacing &#x0200a;&#x0003d;&#x0200a;6&#x02032;, c&#x0200a;&#x0003d;&#x0200a;0.5, dd&#x0200a;&#x0003d;&#x0200a;2.5 dots/degrees<sup>2</sup>, RC ON, (a) human observers (b) Watson Ahumada model with simulations at 256&#x000d7;256 pixel resolution.</p></caption><graphic xlink:href="pone.0004536.g017"/></fig></sec></sec><sec id="s4"><title>Discussion</title><p>Although this paper shows that the Watson Ahumada motion detector does a good job at detecting motion in random dot kinematograms (RDKs) consonant with human psychophysical performance, it remains to be seen how well it would perform on real world imagery. The challenge here is that although it is straightforward to run the model on real world test cases, how do we accurately measure the optical flow perceived by humans on these test cases? Computer vision papers characterise optical flow performance of a model by either using synthetic image sequences designed to mimic the real world, or using real world image sequences in which the motion of the camera is carefully calibrated <xref ref-type="bibr" rid="pone.0004536-McCane1">&#x0005b;52&#x0005d;</xref>. However, as we have already seen in this paper: 1. the same sequence of image frames can produce different perception depending on frame rate, 2. the human visual system takes multiple frames into consideration when determining motion. In the light of these remarks, it is not immediately obvious what the ground truth optical flow (ground truth being defined as the flow perceived by a human) would be for the test cases mentioned above. These caveats should be borne in mind while attempting a performance characterisation of the Watson Ahumada model using the computer vision paradigm. I have placed some preliminary work running the Watson Ahumada model on real world imagery online as a proof of concept <xref ref-type="bibr" rid="pone.0004536-Jain1">&#x0005b;41&#x0005d;</xref>.</p><p>The neurophysiological plausibility of a model is likely to attract heavy debate. Krekelberg (2008) has provided a comprehensive discussion on the biological plausibility of the Reichardt, Adelson Bergen, and gradient based motion detectors <xref ref-type="bibr" rid="pone.0004536-Krekelberg1">&#x0005b;13&#x0005d;</xref>. With respect to the Watson Ahumada model, DeAngelis et. al. (1995) and others have found that the Watson Ahumada filters provide an accurate model of simple cell receptive fields (RFs) <xref ref-type="bibr" rid="pone.0004536-DeAngelis1">&#x0005b;44&#x0005d;</xref>. Quoting DeAngelis et. al. <xref ref-type="bibr" rid="pone.0004536-DeAngelis2">&#x0005b;53&#x0005d;</xref>:</p><p>&#x0201c;Rather, simple cell RFs in the joint space-time domain appear to be fit well by a model first proposed by Watson and Ahumada &#x02026; Based on the Watson-Ahumada formulation, we have modelled space-time RFs of simple cells, as the weighted sum of two space-time separable subunits in a quadrature relationship. This model formulation provides a remarkably good fit to the data from most cells, regardless of their degree of space-time inseparability &#x02026; In conclusion, to account for space-time RFs of simple cells that differ widely in the degree of space-time inseparability, at least two separable subunits appear necessary as modelled by Watson and Ahumada.&#x0201d;</p><p>Although there are similarities between the Watson Ahumada motion detector and the Adelson Bergen motion detector, which is usually the <italic>de facto</italic> motion detection mechanism used in studies of visual motion perception, there are also some differences. The Adelson Bergen motion detector measures how much power the stimulus has within a spatiotemporal frequency band. Thus a detector tuned to (&#x003c9;<sub>x0</sub>,&#x003c9;<sub>y0</sub>,&#x003c9;<sub>t0</sub>) effectively samples the power spectrum of the stimulus within the vicinity of (&#x003c9;<sub>x0</sub>,&#x003c9;<sub>y0</sub>,&#x003c9;<sub>t0</sub>). Such detectors have been proposed as models of V1 complex cells <xref ref-type="bibr" rid="pone.0004536-Adelson1">&#x0005b;1&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-Emerson1">&#x0005b;21&#x0005d;</xref>. The responses of multiple such detectors tuned to different spatiotemporal frequencies are pooled to determine the best fitting plane in the frequency domain <xref ref-type="bibr" rid="pone.0004536-Heeger1">&#x0005b;18&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-Simoncelli1">&#x0005b;19&#x0005d;</xref>. The best fitting plane defines the motion of the stimulus <xref ref-type="bibr" rid="pone.0004536-Watson2">&#x0005b;17&#x0005d;</xref>. This processing, although still debatable, is believed to occur in MT. In contrast, with respect to the Watson Ahumada motion detector, information about the motion of the stimulus is encoded in the (most dominant) temporal frequency of oscillation of detector response as per the equation:<disp-formula><graphic xlink:href="pone.0004536.e062.jpg" mimetype="image" position="float"/></disp-formula></p><p>The temporal frequencies of oscillation of different detectors tuned to different (&#x003c9;<sub>x</sub>,&#x003c9;<sub>y</sub>) are measured, and then above relationship is used to determine the motion of the stimulus. The neural locus of the stages that perform this computation is unclear. Also unclear is the relationship of the model to what we do know about motion processing in the brain beyond the first stage of spatiotemporal filtering. For example, the model does not state how simple V1 neuron outputs could be combined to generate speed tuned V1 complex and MT cells <xref ref-type="bibr" rid="pone.0004536-Perrone3">&#x0005b;54&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004536-Priebe1">&#x0005b;55&#x0005d;</xref>. Perrone (2005) has put forward a model that explains how the magnitude of the Fourier transform of simple V1 neuron responses can be combined to generate the magnitude of the Fourier transform of a speed tuned neuron <xref ref-type="bibr" rid="pone.0004536-Perrone4">&#x0005b;56&#x0005d;</xref>. The input V1 neurons that Perrone's model uses are based on the Watson Ahumada filters.</p><p>It may be worthwhile to mention that the Watson Ahumada model has been proposed as a model of primary motion sensing mechanisms, what Cavanagh (1991) called passive motion detectors in his paper <xref ref-type="bibr" rid="pone.0004536-Cavanagh1">&#x0005b;57&#x0005d;</xref>. The human visual system is a complex parallel distributed system in which modules interact with each other and do not function in isolation, e.g., it is widely accepted now that motion perception interacts with form perception, a view that was not always held in this field. The interactions between modules can give rise to phenomenon that cannot be explained by either module alone. Benton, O'Brien, &#x00026; Curran (2007) have recently provided example of a fractal rotation stimulus in which rotation is perceived within any arbitrary window applied to the stimulus <xref ref-type="bibr" rid="pone.0004536-Benton1">&#x0005b;58&#x0005d;</xref>. The authors assert that the fact that observers can readily perceive fractal rotation is a clear example of a stimulus in which motion extraction is dependent upon the prior analysis of some spatial property (which happens to be the orientation in case of fractal rotation). The omega effect itself is believed to occur because of interactions between form and motion processing circuits in the brain. Although there are growing examples of such stimuli that point to interactions between form and motion, little is known about how these interactions occur. To my knowledge no quantitative model has been put forward to explain these interactions.</p><p>In conclusion, the contribution of this paper is to present a performance characterisation of the Watson Ahumada model of human visual motion sensing. The model performance is seen to match human performance with respect to most parameters. It is able to explain some key and important parts of the psychophysical data such as independence of observer performance to dot density in the display, and decrease of observer performance with frame duration of the display. The model insensitivity to the center position relative to which rotary motion is computed, together with the vector analysis presented in the paper, may explain the experimentally observed position invariance of MST(d) cells. In addition, this paper shows that the omega effect of Rose &#x00026; Blake (1998) is a truly bistable illusion. Although the display of random dots triggers perception of rotary motion, the direction of motion perceived is independent of what dot pattern is shown. The time interval between spontaneous reversals in perceived direction is lognormally distributed as is the case for most bistable illusions. Therefore the processes that give rise to this illusion may be the same processes that underlie much of other bistable phenomenon.</p></sec><sec sec-type="supplementary-material" id="s5"><title>Supporting Information</title><supplementary-material content-type="local-data" id="pone.0004536.s001"><label>Movie S1</label><caption><p>A movie of the racetrack for c&#x0200a;&#x0003d;&#x0200a;0.</p><p>(8.63 MB AVI)</p></caption><media xlink:href="pone.0004536.s001.avi" mimetype="video" mime-subtype="x-msvideo"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pone.0004536.s002"><label>Movie S2</label><caption><p>A movie of the racetrack for c&#x0200a;&#x0003d;&#x0200a;0.3.</p><p>(8.02 MB AVI)</p></caption><media xlink:href="pone.0004536.s002.avi" mimetype="video" mime-subtype="x-msvideo"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pone.0004536.s003"><label>Movie S3</label><caption><p>A movie of the racetrack for c&#x0200a;&#x0003d;&#x0200a;0.5.</p><p>(8.94 MB AVI)</p></caption><media xlink:href="pone.0004536.s003.avi" mimetype="video" mime-subtype="x-msvideo"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></sec></body><back><ack><p>This work was done when I was a graduate student in Donald A. Glaser's lab at UC Berkeley. I thank him and T. Kumar for the financial support and help which made this work possible. In particular Donald A. Glaser is credited with naming the stimulus described in this paper as the racetrack, and for introducing me to the <italic>c&#x0200a;&#x0003d;&#x0200a;0</italic> case, which he invented to model the illusory motion perceived in Leviant's Enigma <xref ref-type="bibr" rid="pone.0004536-Kumar1">&#x0005b;59&#x0005d;</xref>. T. Kumar provided guidance in various aspects of this research, especially the planning of the psychophysical experiments and recruitment of subjects. I thank my friend David Gelbart for proof-reading this paper.</p><p>This paper is dedicated to Pink Floyd &#x02192; The Division Bell &#x02192; High Hopes.</p></ack><ref-list><title>References</title><ref id="pone.0004536-Adelson1"><label>1</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Adelson</surname><given-names>EH</given-names></name><name><surname>Bergen</surname><given-names>JR</given-names></name></person-group><year>1985</year><article-title>Spatiotemporal energy models for the perception of motion.</article-title><source>J Opt Soc Am A</source><volume>2(2)</volume><fpage>284</fpage><lpage>299</lpage><pub-id pub-id-type="pmid">3973762</pub-id></citation></ref><ref id="pone.0004536-vanSanten1"><label>2</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>van Santen</surname><given-names>JPH</given-names></name><name><surname>Sperling</surname><given-names>G</given-names></name></person-group><year>1985</year><article-title>Elaborated Reichardt detectors.</article-title><source>J Opt Soc Am A</source><volume>2(2)</volume><fpage>300</fpage><lpage>321</lpage><pub-id pub-id-type="pmid">3973763</pub-id></citation></ref><ref id="pone.0004536-Watson1"><label>3</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Watson</surname><given-names>AB</given-names></name><name><surname>Ahumada</surname><given-names>A</given-names></name></person-group><year>1985</year><article-title>Model of human visual-motion sensing.</article-title><source>J Opt Soc Am A</source><volume>2(2)</volume><fpage>322</fpage><lpage>342</lpage><pub-id pub-id-type="pmid">3973764</pub-id></citation></ref><ref id="pone.0004536-Johnston1"><label>4</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Johnston</surname><given-names>A</given-names></name><name><surname>McOwan</surname><given-names>PW</given-names></name><name><surname>Buxton</surname><given-names>H</given-names></name></person-group><year>1992</year><article-title>A computational model of the analysis of some first-order and second-order motion patterns by simple and complex cells.</article-title><source>Proc Roy Soc B</source><volume>250</volume><fpage>297</fpage><lpage>306</lpage></citation></ref><ref id="pone.0004536-Perrone1"><label>5</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Perrone</surname><given-names>JA</given-names></name><name><surname>Thiele</surname><given-names>A</given-names></name></person-group><year>2002</year><article-title>A model of speed tuning in MT neurons.</article-title><source>Vis Res</source><volume>42(8)</volume><fpage>1035</fpage><lpage>51</lpage><pub-id pub-id-type="pmid">11934454</pub-id></citation></ref><ref id="pone.0004536-Ullman1"><label>6</label><citation citation-type="book"><person-group person-group-type="author"><name><surname>Ullman</surname><given-names>S</given-names></name></person-group><year>1979</year><source>The Interpretation of Visual Motion</source><publisher-name>MIT Press</publisher-name></citation></ref><ref id="pone.0004536-Dawson1"><label>7</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Dawson</surname><given-names>MRW</given-names></name></person-group><year>1991</year><article-title>The How and Why of What Went Where in Apparent Motion: Modeling Solutions to the Motion Correspondence Problem.</article-title><source>Psychological Review</source><volume>98(4)</volume><fpage>569</fpage><lpage>603</lpage><pub-id pub-id-type="pmid">1961774</pub-id></citation></ref><ref id="pone.0004536-Williams1"><label>8</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Williams</surname><given-names>DW</given-names></name><name><surname>Sekuler</surname><given-names>R</given-names></name></person-group><year>1984</year><article-title>Coherent Global Motion Percepts from Stochastic Local Motions.</article-title><source>Vis Res</source><volume>24(1)</volume><fpage>55</fpage><lpage>62</lpage><pub-id pub-id-type="pmid">6695508</pub-id></citation></ref><ref id="pone.0004536-Graziano1"><label>9</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Graziano</surname><given-names>MSA</given-names></name><name><surname>Andersen</surname><given-names>RA</given-names></name><name><surname>Snowden</surname><given-names>RJ</given-names></name></person-group><year>1994</year><article-title>Tuning of MST Neurons to Spiral Motions.</article-title><source>J Neurosci</source><volume>14(1)</volume><fpage>54</fpage><lpage>67</lpage><pub-id pub-id-type="pmid">8283251</pub-id></citation></ref><ref id="pone.0004536-Rose1"><label>10</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Rose</surname><given-names>D</given-names></name><name><surname>Blake</surname><given-names>R</given-names></name></person-group><year>1998</year><article-title>Motion Perception: From Phi to Omega.</article-title><source>Proc Roy Soc B</source><volume>353(1371)</volume><fpage>967</fpage><lpage>980</lpage></citation></ref><ref id="pone.0004536-Shermer1"><label>11</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Shermer</surname><given-names>M</given-names></name></person-group><year>2008</year><article-title>Patternicity.</article-title><source>Sci Am</source><volume>299(6)</volume><fpage>48</fpage><pub-id pub-id-type="pmid">19143444</pub-id></citation></ref><ref id="pone.0004536-Green1"><label>12</label><citation citation-type="book"><person-group person-group-type="author"><name><surname>Green</surname><given-names>DM</given-names></name><name><surname>Swets</surname><given-names>JA</given-names></name></person-group><year>1966</year><source>Signal detection theory and psychophysics</source><publisher-loc>New York</publisher-loc><publisher-name>Wiley</publisher-name></citation></ref><ref id="pone.0004536-Krekelberg1"><label>13</label><citation citation-type="book"><person-group person-group-type="author"><name><surname>Krekelberg</surname><given-names>B</given-names></name></person-group><year>2008</year><article-title>Motion detection mechanisms.</article-title><person-group person-group-type="editor"><name><surname>Allan</surname><given-names>Basbaum</given-names></name></person-group><source>The Senses: A Comprehensive Reference</source><publisher-loc>Oxford</publisher-loc><publisher-name>Elsevier Inc</publisher-name></citation></ref><ref id="pone.0004536-Born1"><label>14</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Born</surname><given-names>RT</given-names></name><name><surname>Bradley</surname><given-names>DC</given-names></name></person-group><year>2005</year><article-title>Structure and function of visual area MT.</article-title><source>Ann Rev Neurosci</source><volume>28</volume><fpage>157</fpage><lpage>189</lpage><pub-id pub-id-type="pmid">16022593</pub-id></citation></ref><ref id="pone.0004536-Derrington1"><label>15</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Derrington</surname><given-names>AM</given-names></name><name><surname>Allen</surname><given-names>HA</given-names></name><name><surname>Delicato</surname><given-names>DS</given-names></name></person-group><year>2004</year><article-title>Visual mechanisms of motion analysis and motion perception.</article-title><source>Ann Rev Psych</source><volume>55</volume><fpage>181</fpage><lpage>205</lpage></citation></ref><ref id="pone.0004536-Grzywacz1"><label>16</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Grzywacz</surname><given-names>NM</given-names></name><name><surname>Merwine</surname><given-names>DK</given-names></name></person-group><year>2003</year><article-title>Neural basis of motion perception.</article-title><source>Encyclopedia of Cognitive Science</source><volume>3</volume><fpage>86</fpage><lpage>98</lpage></citation></ref><ref id="pone.0004536-Watson2"><label>17</label><citation citation-type="other"><person-group person-group-type="author"><name><surname>Watson</surname><given-names>AB</given-names></name><name><surname>Ahumada</surname><given-names>A</given-names></name></person-group><year>1983</year><article-title>A look at motion in the frequency domain.</article-title><comment>Technical Report 84352, NASA Technical Memorandum</comment></citation></ref><ref id="pone.0004536-Heeger1"><label>18</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Heeger</surname><given-names>DJ</given-names></name></person-group><year>1987</year><article-title>Model for the extraction of image flow.</article-title><source>J Opt Soc Am A</source><volume>4(8)</volume><fpage>1455</fpage><lpage>1471</lpage><pub-id pub-id-type="pmid">3625326</pub-id></citation></ref><ref id="pone.0004536-Simoncelli1"><label>19</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Simoncelli</surname><given-names>EP</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name></person-group><year>1998</year><article-title>A model of neuronal responses in visual area MT.</article-title><source>Vis Res</source><volume>38(5)</volume><fpage>743</fpage><lpage>761</lpage><pub-id pub-id-type="pmid">9604103</pub-id></citation></ref><ref id="pone.0004536-Rust1"><label>20</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Rust</surname><given-names>NC</given-names></name><name><surname>Mante</surname><given-names>V</given-names></name><name><surname>Simoncelli</surname><given-names>EP</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><year>2006</year><article-title>How MT cells analyze the motion of visual patterns.</article-title><source>Nat Neurosci</source><volume>9(11)</volume><fpage>1421</fpage><lpage>1431</lpage><pub-id pub-id-type="pmid">17041595</pub-id></citation></ref><ref id="pone.0004536-Emerson1"><label>21</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Emerson</surname><given-names>RC</given-names></name><name><surname>Bergen</surname><given-names>JR</given-names></name><name><surname>Adelson</surname><given-names>EH</given-names></name></person-group><year>1992</year><article-title>Directionally selective complex cells and the computation of motion energy in cat visual cortex.</article-title><source>Vis Res</source><volume>32(2)</volume><fpage>203</fpage><lpage>218</lpage><pub-id pub-id-type="pmid">1574836</pub-id></citation></ref><ref id="pone.0004536-Tanaka1"><label>22</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Tanaka</surname><given-names>K</given-names></name><name><surname>Saito</surname><given-names>H</given-names></name></person-group><year>1989</year><article-title>Analysis of Motion of the Visual Field by Direction, Expansion/Contraction, and Rotation cells clustered in the Dorsal Part of the Medial Superior Temporal Area of the Macaque Monkey.</article-title><source>J Neurophysiol</source><volume>62(3)</volume><fpage>626</fpage><lpage>641</lpage><pub-id pub-id-type="pmid">2769351</pub-id></citation></ref><ref id="pone.0004536-Sakata1"><label>23</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Sakata</surname><given-names>H</given-names></name><name><surname>Shibutani</surname><given-names>H</given-names></name><name><surname>Ito</surname><given-names>Y</given-names></name><name><surname>Tsurugai</surname><given-names>K</given-names></name><name><surname>Mine</surname><given-names>S</given-names></name><name><surname>Kusunoki</surname><given-names>M</given-names></name></person-group><year>1994</year><article-title>Functional properties of rotation-sensitive neurons in the posterior parietal association cortex of the monkey.</article-title><source>Exp Brain Res</source><volume>101(2)</volume><fpage>183</fpage><lpage>202</lpage><pub-id pub-id-type="pmid">7843308</pub-id></citation></ref><ref id="pone.0004536-Newsome1"><label>24</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Newsome</surname><given-names>WT</given-names></name><name><surname>Pare</surname><given-names>EB</given-names></name></person-group><year>1988</year><article-title>A Selective Impairment of Motion Perception following lesions of the Middle Temporal Visual Area MT.</article-title><source>J Neurosci</source><volume>8(6)</volume><fpage>2201</fpage><lpage>2211</lpage><pub-id pub-id-type="pmid">3385495</pub-id></citation></ref><ref id="pone.0004536-Newsome2"><label>25</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Newsome</surname><given-names>WT</given-names></name><name><surname>Britten</surname><given-names>KH</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><year>1989</year><article-title>Neuronal Correlates of a perceptual decision.</article-title><source>Nature</source><volume>341(6237)</volume><fpage>52</fpage><lpage>54</lpage><pub-id pub-id-type="pmid">2770878</pub-id></citation></ref><ref id="pone.0004536-Barlow1"><label>26</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Barlow</surname><given-names>H</given-names></name><name><surname>Tripathy</surname><given-names>SP</given-names></name></person-group><year>1997</year><article-title>Correspondence Noise and Signal Pooling in the Detection of Coherent Visual Motion.</article-title><source>J Neurosci</source><volume>17(20)</volume><fpage>7954</fpage><lpage>7966</lpage><pub-id pub-id-type="pmid">9315913</pub-id></citation></ref><ref id="pone.0004536-Scase1"><label>27</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Scase</surname><given-names>MO</given-names></name><name><surname>Braddick</surname><given-names>OJ</given-names></name><name><surname>Raymond</surname><given-names>JE</given-names></name></person-group><year>1996</year><article-title>What is noise for the motion system?</article-title><source>Vis Res</source><volume>36(16)</volume><fpage>2579</fpage><lpage>2586</lpage><pub-id pub-id-type="pmid">8917818</pub-id></citation></ref><ref id="pone.0004536-Watamaniuk1"><label>28</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Watamaniuk</surname><given-names>SNJ</given-names></name><name><surname>McKee</surname><given-names>SP</given-names></name><name><surname>Grzywacz</surname><given-names>NM</given-names></name></person-group><year>1995</year><article-title>Detecting a Trajectory Embedded in Random-direction Motion Noise.</article-title><source>Vis Res</source><volume>35(1)</volume><fpage>65</fpage><lpage>77</lpage><pub-id pub-id-type="pmid">7839611</pub-id></citation></ref><ref id="pone.0004536-Morgan1"><label>29</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Morgan</surname><given-names>MJ</given-names></name></person-group><year>1980</year><article-title>Analogue models of motion perception.</article-title><source>Proc Roy Soc B</source><volume>290(1038)</volume><fpage>117</fpage><lpage>135</lpage></citation></ref><ref id="pone.0004536-Watson3"><label>30</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Watson</surname><given-names>AB</given-names></name><name><surname>Ahumada</surname><given-names>A</given-names></name><name><surname>Farrell</surname><given-names>JE</given-names></name></person-group><year>1986</year><article-title>Window of Visibility: a psychophysical theory of fidelity in time-sampled visual motion displays.</article-title><source>J Opt Soc Am A</source><volume>3(3)</volume><fpage>300</fpage><lpage>307</lpage></citation></ref><ref id="pone.0004536-MacKay1"><label>31</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>MacKay</surname><given-names>DM</given-names></name></person-group><year>1965</year><article-title>Visual Noise as a tool of Research.</article-title><source>J Gen Psychol</source><volume>72</volume><fpage>181</fpage><lpage>197</lpage><pub-id pub-id-type="pmid">14285614</pub-id></citation></ref><ref id="pone.0004536-Ross1"><label>32</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ross</surname><given-names>J</given-names></name><name><surname>Badcock</surname><given-names>DR</given-names></name><name><surname>Hayes</surname><given-names>A</given-names></name></person-group><year>2000</year><article-title>Coherent global motion in the absence of coherent velocity signals.</article-title><source>Curr Biol</source><volume>10</volume><fpage>679</fpage><lpage>682</lpage><pub-id pub-id-type="pmid">10837253</pub-id></citation></ref><ref id="pone.0004536-Krekelberg2"><label>33</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Krekelberg</surname><given-names>B</given-names></name><name><surname>Dannenberg</surname><given-names>S</given-names></name><name><surname>Hoffmann</surname><given-names>KP</given-names></name><name><surname>Bremmer</surname><given-names>F</given-names></name><name><surname>Ross</surname><given-names>J</given-names></name></person-group><year>2003</year><article-title>Neural correlates of implied motion.</article-title><source>Nature</source><volume>424</volume><fpage>674</fpage><lpage>677</lpage><pub-id pub-id-type="pmid">12904793</pub-id></citation></ref><ref id="pone.0004536-Krekelberg3"><label>34</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Krekelberg</surname><given-names>B</given-names></name><name><surname>Vatakis</surname><given-names>A</given-names></name><name><surname>Kourtzi</surname><given-names>Z</given-names></name></person-group><year>2005</year><article-title>Implied motion from form in the Human Visual Cortex.</article-title><source>J Neurophysiol</source><volume>94</volume><fpage>4373</fpage><lpage>4386</lpage><pub-id pub-id-type="pmid">16107528</pub-id></citation></ref><ref id="pone.0004536-Viva1"><label>35</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Viva</surname><given-names>MMD</given-names></name><name><surname>Gori</surname><given-names>M</given-names></name><name><surname>Burr</surname><given-names>DC</given-names></name></person-group><year>2006</year><article-title>Powerful Motion Illusion Caused by Temporal Asymmetries in ON and OFF Visual Pathways.</article-title><source>J Neurophysiol</source><volume>95</volume><fpage>3928</fpage><lpage>3932</lpage><pub-id pub-id-type="pmid">16709726</pub-id></citation></ref><ref id="pone.0004536-Geisler1"><label>36</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Geisler</surname><given-names>WS</given-names></name></person-group><year>1999</year><article-title>Motion streaks provide a spatial code for motion direction.</article-title><source>Nature</source><volume>400</volume><fpage>65</fpage><lpage>69</lpage><pub-id pub-id-type="pmid">10403249</pub-id></citation></ref><ref id="pone.0004536-Barlow2"><label>37</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Barlow</surname><given-names>H</given-names></name><name><surname>Olshausen</surname><given-names>B</given-names></name></person-group><year>2004</year><article-title>Convergent evidence for the visual analysis of optic flow through anisotropic attenuation of high spatial frequencies.</article-title><source>J Vis</source><volume>4</volume><fpage>415</fpage><lpage>426</lpage><pub-id pub-id-type="pmid">15330709</pub-id></citation></ref><ref id="pone.0004536-Perrone2"><label>38</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Perrone</surname><given-names>JA</given-names></name><name><surname>Stone</surname><given-names>LS</given-names></name></person-group><year>1994</year><article-title>A model of self-motion estimation within primate extrastriate visual cortex.</article-title><source>Vis Res</source><volume>34(21)</volume><fpage>2917</fpage><lpage>2938</lpage><pub-id pub-id-type="pmid">7975326</pub-id></citation></ref><ref id="pone.0004536-Duffy1"><label>39</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Duffy</surname><given-names>CJ</given-names></name><name><surname>Wurtz</surname><given-names>RH</given-names></name></person-group><year>1995</year><article-title>Response of Monkey MST Neurons to Optic Flow Stimuli with Shifted Centers of Motion.</article-title><source>J Neurosci</source><volume>15(7)</volume><fpage>5192</fpage><lpage>5208</lpage><pub-id pub-id-type="pmid">7623145</pub-id></citation></ref><ref id="pone.0004536-vanderSchaaf1"><label>40</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>van der Schaaf</surname><given-names>A</given-names></name><name><surname>van Hateren</surname><given-names>JH</given-names></name></person-group><year>1996</year><article-title>Modeling the Power Spectra of Natural Images: Statistics and Information.</article-title><source>Vis Res</source><volume>36(17)</volume><fpage>2759</fpage><lpage>2770</lpage><pub-id pub-id-type="pmid">8917763</pub-id></citation></ref><ref id="pone.0004536-Jain1"><label>41</label><citation citation-type="other"><person-group person-group-type="author"><name><surname>Jain</surname><given-names>S</given-names></name></person-group><year>2007</year><article-title>Optical Flow or Motion Estimation using the Watson Ahumada (WA) algorithm.</article-title><comment><ext-link ext-link-type="uri" xlink:href="http://www.codeproject.com/KB/audio-video/Optical_Flow_Estimation.aspx">http://www.codeproject.com/KB/audio-video/Optical_Flow_Estimation.aspx</ext-link></comment></citation></ref><ref id="pone.0004536-Anonymous1"><label>42</label><citation citation-type="other">Anonymous survey available at <ext-link ext-link-type="uri" xlink:href="http://purl.oclc.org/NET/survey">http://purl.oclc.org/NET/survey</ext-link></citation></ref><ref id="pone.0004536-Riani1"><label>43</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Riani</surname><given-names>M</given-names></name><name><surname>Simonotto</surname><given-names>E</given-names></name></person-group><year>1994</year><article-title>Stochastic Resonance in the Perceptual Interpretation of Ambiguous figures: A Neural Network Model.</article-title><source>Phys Rev Lett</source><volume>72(19)</volume><fpage>3120</fpage><lpage>3123</lpage><pub-id pub-id-type="pmid">10056072</pub-id></citation></ref><ref id="pone.0004536-DeAngelis1"><label>44</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>DeAngelis</surname><given-names>DC</given-names></name><name><surname>Ohzawa</surname><given-names>I</given-names></name><name><surname>Freeman</surname><given-names>RD</given-names></name></person-group><year>1995</year><article-title>Receptive-field dynamics in the central visual pathways.</article-title><source>Trends Neurosci</source><volume>18</volume><fpage>451</fpage><lpage>458</lpage><pub-id pub-id-type="pmid">8545912</pub-id></citation></ref><ref id="pone.0004536-Benzi1"><label>45</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Benzi</surname><given-names>R</given-names></name><name><surname>Sutera</surname><given-names>A</given-names></name><name><surname>Vulpani</surname><given-names>A</given-names></name></person-group><year>1981</year><article-title>The mechanism of stochastic resonance.</article-title><source>J Phys A</source><volume>14</volume><fpage>453</fpage><lpage>457</lpage></citation></ref><ref id="pone.0004536-Gammaitoni1"><label>46</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Gammaitoni</surname><given-names>L</given-names></name><name><surname>Hanggi</surname><given-names>P</given-names></name><name><surname>Jung</surname><given-names>P</given-names></name><name><surname>Marchesoni</surname><given-names>F</given-names></name></person-group><year>1998</year><article-title>Stochastic Resonance.</article-title><source>Rev Mod Phys</source><volume>70(1)</volume><fpage>223</fpage><lpage>287</lpage></citation></ref><ref id="pone.0004536-Moss1"><label>47</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Moss</surname><given-names>F</given-names></name><name><surname>Ward</surname><given-names>LM</given-names></name><name><surname>Sannita</surname><given-names>WG</given-names></name></person-group><year>2004</year><article-title>Stochastic Resonance and sensory information processing: a tutorial and review of application.</article-title><source>Clinical Neurophysiology</source><volume>115</volume><fpage>267</fpage><lpage>281</lpage><pub-id pub-id-type="pmid">14744566</pub-id></citation></ref><ref id="pone.0004536-Grzywacz2"><label>48</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Grzywacz</surname><given-names>NM</given-names></name><name><surname>Watamaniuk</surname><given-names>SNJ</given-names></name><name><surname>McKee</surname><given-names>SP</given-names></name></person-group><year>1995</year><article-title>Temporal Coherence Theory for the detection and measurement of Visual Motion.</article-title><source>Vis Res</source><volume>35(22)</volume><fpage>3183</fpage><lpage>3203</lpage><pub-id pub-id-type="pmid">8533352</pub-id></citation></ref><ref id="pone.0004536-Anstis1"><label>49</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Anstis</surname><given-names>SM</given-names></name></person-group><year>1970</year><article-title>Phi movement as a subtractive process.</article-title><source>Vis Res</source><volume>10</volume><fpage>1411</fpage><lpage>1430</lpage><pub-id pub-id-type="pmid">5516541</pub-id></citation></ref><ref id="pone.0004536-Anstis2"><label>50</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Anstis</surname><given-names>SM</given-names></name><name><surname>Rogers</surname><given-names>BJ</given-names></name></person-group><year>1975</year><article-title>Illusory reversal of visual depth and movement during changes of contrast.</article-title><source>Vis Res</source><volume>15</volume><fpage>957</fpage><lpage>961</lpage><pub-id pub-id-type="pmid">1166630</pub-id></citation></ref><ref id="pone.0004536-Burr1"><label>51</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Burr</surname><given-names>D</given-names></name><name><surname>Ross</surname><given-names>J</given-names></name></person-group><year>2006</year><article-title>The effects of opposite-polarity dipoles on the detection of Glass patterns.</article-title><source>Vis Res</source><volume>46</volume><fpage>1139</fpage><lpage>1144</lpage><pub-id pub-id-type="pmid">16256166</pub-id></citation></ref><ref id="pone.0004536-McCane1"><label>52</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>McCane</surname><given-names>B</given-names></name><name><surname>Novins</surname><given-names>K</given-names></name><name><surname>Crannitch</surname><given-names>D</given-names></name><name><surname>Galvin</surname><given-names>B</given-names></name></person-group><year>2001</year><article-title>On Benchmarking Optical Flow.</article-title><source>Computer Vision and Image Understanding</source><volume>84</volume><fpage>126</fpage><lpage>143</lpage></citation></ref><ref id="pone.0004536-DeAngelis2"><label>53</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>DeAngelis</surname><given-names>GC</given-names></name><name><surname>Ohzawa</surname><given-names>I</given-names></name><name><surname>Freeman</surname><given-names>RD</given-names></name></person-group><year>1996</year><article-title>Reply to TINS letter to the Editor by Wang et. al.</article-title><source>Trends in Neuroscience</source><volume>19</volume><fpage>386</fpage></citation></ref><ref id="pone.0004536-Perrone3"><label>54</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Perrone</surname><given-names>JA</given-names></name><name><surname>Thiele</surname><given-names>A</given-names></name></person-group><year>2001</year><article-title>Speed skills: measuring the visual speed analyzing properties of primate MT neurons.</article-title><source>Nat Neurosci</source><volume>4(5)</volume><fpage>526</fpage><lpage>532</lpage><pub-id pub-id-type="pmid">11319562</pub-id></citation></ref><ref id="pone.0004536-Priebe1"><label>55</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Priebe</surname><given-names>NJ</given-names></name><name><surname>Lisberger</surname><given-names>SG</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><year>2006</year><article-title>Tuning for Spatiotemporal Frequency and Speed in Directionally Selective Neurons of Macaque Striate Cortex.</article-title><source>J Neurosci</source><volume>26(11)</volume><fpage>2941</fpage><lpage>50</lpage><pub-id pub-id-type="pmid">16540571</pub-id></citation></ref><ref id="pone.0004536-Perrone4"><label>56</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Perrone</surname><given-names>JA</given-names></name></person-group><year>2005</year><article-title>Economy of scale: A motion sensor with variable speed tuning.</article-title><source>J Vis</source><volume>5(1)</volume><fpage>28</fpage><lpage>33</lpage><pub-id pub-id-type="pmid">15831064</pub-id></citation></ref><ref id="pone.0004536-Cavanagh1"><label>57</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Cavanagh</surname><given-names>P</given-names></name></person-group><year>1991</year><article-title>Short-range vs. long-range motion: Not a valid distinction.</article-title><source>Spatial Vision</source><volume>5</volume><fpage>303</fpage><lpage>309</lpage><pub-id pub-id-type="pmid">1751430</pub-id></citation></ref><ref id="pone.0004536-Benton1"><label>58</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Benton</surname><given-names>CP</given-names></name><name><surname>O'Brien</surname><given-names>JMD</given-names></name><name><surname>Curran</surname><given-names>W</given-names></name></person-group><year>2007</year><article-title>Fractal rotation isolates mechanisms for form-dependent motion in human vision.</article-title><source>Biol Lett</source><volume>3</volume><fpage>306</fpage><lpage>308</lpage><pub-id pub-id-type="pmid">17360252</pub-id></citation></ref><ref id="pone.0004536-Kumar1"><label>59</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kumar</surname><given-names>T</given-names></name><name><surname>Glaser</surname><given-names>DA</given-names></name></person-group><year>2006</year><article-title>Illusory motion in Enigma: A psychophysical investigation.</article-title><source>PNAS</source><volume>103(6)</volume><fpage>1947</fpage><lpage>1952</lpage><pub-id pub-id-type="pmid">16446435</pub-id></citation></ref></ref-list><fn-group><fn fn-type="conflict"><p><bold>Competing Interests: </bold>The author has declared that no competing interests exist.</p></fn><fn fn-type="financial-disclosure"><p><bold>Funding: </bold>The equipment used in the research belonged to Donald A Glaser, who also provided funding to pay human subjects used in this research. The author was supported in part by a GSR (Graduate Student Researcher) funded by Donald A Glaser and in part by a GSI (Graduate Student Instructor) provided by EECS Department UC Berkeley.</p></fn></fn-group></back></article>