<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN" "archivearticle.dtd"><article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article" xml:lang="EN"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id><journal-id journal-id-type="publisher-id">bioinformatics</journal-id><journal-id journal-id-type="hwp">bioinfo</journal-id><journal-title>Bioinformatics</journal-title><issn pub-type="ppub">1367-4803</issn><issn pub-type="epub">1460-2059</issn><publisher><publisher-name>Oxford University Press</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">19189978</article-id><article-id pub-id-type="pmc">2647838</article-id><article-id pub-id-type="doi">10.1093/bioinformatics/btp046</article-id><article-id pub-id-type="publisher-id">btp046</article-id><article-categories><subj-group subj-group-type="heading"><subject>Applications Note</subject><subj-group><subject>Databases and Ontologies</subject></subj-group></subj-group></article-categories><title-group><article-title>VANO: a volume-object image annotation system</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Peng</surname><given-names>Hanchuan</given-names></name><xref ref-type="corresp" rid="COR1">*</xref></contrib><contrib contrib-type="author"><name><surname>Long</surname><given-names>Fuhui</given-names></name></contrib><contrib contrib-type="author"><name><surname>Myers</surname><given-names>Eugene W.</given-names></name></contrib></contrib-group><aff>Janelia Farm Research Campus, Howard Hughes Medical Institute, Ashburn, Virginia, VA, USA</aff><author-notes><corresp id="COR1">*To whom correspondence should be addressed.</corresp><fn><p>Associate Editor: Jonathan Wren</p></fn></author-notes><pub-date pub-type="ppub"><day>1</day><month>3</month><year>2009</year></pub-date><pub-date pub-type="epub"><day>2</day><month>2</month><year>2009</year></pub-date><pub-date pub-type="pmc-release"><day>2</day><month>2</month><year>2009</year></pub-date><volume>25</volume><issue>5</issue><fpage>695</fpage><lpage>697</lpage><history><date date-type="received"><day>9</day><month>12</month><year>2008</year></date><date date-type="rev-recd"><day>14</day><month>1</month><year>2009</year></date><date date-type="accepted"><day>16</day><month>1</month><year>2009</year></date></history><permissions><copyright-statement>&#x000a9; 2009 The Author(s)</copyright-statement><copyright-year>2009</copyright-year><license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by-nc/2.0/uk/"><p><!--CREATIVE COMMONS-->This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/2.0/uk/">http://creativecommons.org/licenses/by-nc/2.0/uk/</ext-link>) which permits unrestricted non-commercial use, distribution, and reproduction in any medium, provided the original work is properly cited.</p></license></permissions><abstract><p>Volume-object annotation system (VANO) is a cross-platform image annotation system that enables one to conveniently visualize and annotate 3D volume objects including nuclei and cells. An application of VANO typically starts with an initial collection of objects produced by a segmentation computation. The objects can then be labeled, categorized, deleted, added, split, merged and redefined. VANO has been used to build high-resolution digital atlases of the nuclei of Caenorhabditis elegans at the L1 stage and the nuclei of Drosophila melanogaster's ventral nerve cord at the late embryonic stage.</p><p><bold>Availability</bold>: Platform independent executables of VANO, a sample dataset, and a detailed description of both its design and usage are available at research.janelia.org/peng/proj/vano. VANO is open-source for co-development.</p><p><bold>Contact:</bold> <email>pengh@janelia.hhmi.org</email></p><p><bold>Supplementary information:</bold> <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/cgi/content/full/btp046/DC1">Supplementary data</ext-link> are available at <italic>Bioinformatics</italic> online.</p></abstract></article-meta></front><body><sec sec-type="intro" id="SEC1"><title>1 INTRODUCTION</title><p>Image content annotation is a basic problem in the analysis of 3D high-resolution cellular and molecular images (Peng, <xref ref-type="bibr" rid="B4">2008</xref>). Many methods have been developed for determining annotations computationally such as categorizing gene expression patterns (e.g Zhou and Peng, <xref ref-type="bibr" rid="B7">2007</xref>) or predicting cell identities (e.g. Long <italic>et al.</italic>, <xref ref-type="bibr" rid="B2">2008a</xref>). Critical to their development is the availability of a corpus of curated training data, and since none of these methods is perfect, their application in the field is benefited by having the ability to manually curate the results they produce. VANO, short for volume-object annotation system, was developed specifically to allow one to produce annotations manually and to correct or refine the output of good, but not perfect, automated annotation methods. This tool has and continues to play a critical role in our recent work in building 3D digital atlases of the L1 stage of <italic>Caenorhabditis elegans</italic>, and the late embryo ventral nerve cord and adult brain of <italic>Drosophila melanogaster</italic>.</p><p>VANO is a cross-platform 3D annotator that provides a spreadsheet of all 3D image objects that is linked to both 3D view of the raw image and a segmentation &#x02018;mask&#x02019; that specifies the voxels that belong to each object (<xref ref-type="fig" rid="F1">Fig. 1</xref>). For a given object, one can label it and set any number of user-defined attributes either in the spreadsheet or from the 3D views. Moreover, objects can be created, deleted, split, merged or redefined by commands that directly manipulate the segmentation mask. In typical use scenarios, VANO is started (i) on just a raw image with no objects; (ii) with a segmentation mask produced by a computation (e.g. Long <italic>et al.</italic>, <xref ref-type="bibr" rid="B1">2007</xref>); or (iii) with both a segmentation mask and an initial annotation (i.e. label and attributes), produced again by an automated computation (e.g. Long <italic>et al.</italic>, <xref ref-type="bibr" rid="B2">2008a</xref>) or other means.<fig id="F1" position="float"><label>Fig. 1.</label><caption><p>GUI and applications of VANO in annotating 3D <italic>C.elegans</italic> and <italic>D.melanogaster</italic> image stacks. (<bold>a</bold>) The 3D image viewer: a tri-view for the subject image (true color, upper left), a tri-view for the mask image (in pseudo-color, lower left) and control panel (right). The displayed images are confocal stacks of a <italic>C.elegans</italic> larva (data by Xiao Liu and Stuart Kim). The worm in this stack was straightened using the algorithm of Peng <italic>et al.</italic> (<xref ref-type="bibr" rid="B4">2008</xref>). (<bold>b</bold>) The annotation table viewer: a spreadsheet where each row is an annotation entry for an image object and each column holds a particular attribute of an object. In this example each object is a nucleus. (<bold>c</bold>) Application of VANO to annotating neuronal patterns in the brain of <italic>D.melanogaster</italic>. Left: the subject image where NC82 (red) stains synaptic density and GFP (green) stains a target set of neurons (data by Julie Simpson). Right: the mask image where each object, in a distinct pseudo-color, is a glia-delineated compartment of the brain (mask by Arnim Jenett).</p></caption><graphic xlink:href="btp046f1"/></fig></p><p>Image visualization tools such as Amira (amiravis.com) provide for flexible painting or refinement of a segmentation mask but do not support the concept of text annotations thereof. Existing image-tagging tools such as the annotator of the Open Microscope Environment (<ext-link ext-link-type="uri" xlink:href="www.openmicroscopy.org">www.openmicroscopy.org</ext-link>) permit one to input text descriptions, but only for the entire stack and not for single objects. VANO allows one to define and annotate an arbitrary collection of 3D image objects in an interactive and efficient way.</p><p>Due to space limitations, we briefly describe the design, usage and some applications of VANO. The <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/cgi/content/full/btp046/DC1">Supplementary Material</ext-link>, downloadable at the VANO website, provides detailed documentation.</p></sec><sec id="SEC2"><title>2 DESIGN</title><p>VANO is designed to view, select, annotate and modify image objects with a simple and intuitive GUI which consists of two main panels&#x02014;a <italic>3D image viewer</italic> and an <italic>annotation table viewer</italic>&#x02014;and a number of auxiliary popup dialogs (see <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/cgi/content/full/btp046/DC1">Supplementary Material</ext-link>).</p><p>The image viewer consists of two <italic>tri-views</italic>, one for the raw image above and another for the segmentation mask, along with a control panel at right providing display options and widget-based control of these views (<xref ref-type="fig" rid="F1">Fig. 1</xref>a). The three images of a tri-view display the <italic>XY</italic>, <italic>ZY</italic> and <italic>XZ</italic> planes passing through a <italic>current focus point</italic> that is indicated by the intersection of dashed lines superimposed on each image. Both tri-views use the same focus point and thus always show the same planes and all views change in correspondence to the movement of this focus point whose location is adjusted by clicking in an image or moving a slider in the control panel.</p><p>The annotation table viewer is an editable spreadsheet (<xref ref-type="fig" rid="F1">Fig. 1</xref>b) where each row contains the annotation information for an object and each column contains a particular annotation attribute. A typical annotation entry has &#x02018;standard&#x02019; columns, including object order, label, standard name, user comment, 3D center coordinates, volume and the average, standard deviation, peak voxel intensity and mass (=average intensity &#x000d7; volume) of the object. The later attributes starting with the center are computed directly from the mask image. Note that mass in effect gives the level of gene expression or protein abundance in application that require it. In addition, customized annotation columns can be added via a schema file mechanism. Annotations can be entered directly in this spreadsheet or can be entered in dialogs that pop-up for the object under the current focus when an &#x02018;E&#x02019; is typed. VANO uses the model-view-controller paradigm (Reenskaug, <xref ref-type="bibr" rid="B6">1979</xref>) so changes made in one view are immediately reflected to all other views of the underlying data.</p><p>VANO is launched with either a subject image stack, in which case the mask and annotations are assumed to be empty, or a previously saved or manually prepared &#x02018;.ano&#x02019; linker file that contains (derived) names of files containing the subject image, the mask image, the annotation and optionally the attribute schema. The image files are stored in TIFF format, and the annotation is stored in simple comma separated values format so it can easily be parsed and used by other programs such as Excel.</p><p>VANO is coded in C++ and uses the platform-independent QT (trolltech.com) GUI library so that it runs under all major operating systems, e.g. OS X, Windows NT/XP and most variants of Unix.</p></sec><sec id="SEC3"><title>3 USAGE</title><p>VANO can be used to (i) create masks and annotations for objects from scratch; (ii) correct the segmentation of an existing mask; or (iii) enter, edit or correct the annotation of the set of objects in the current mask. The combination of a spreadsheet that lists all objects and pop-ups for individual objects in an image view makes it easy to survey annotation and yet keep track of hundreds of objects as one progresses with the markup of such a collection.</p><p>Editing or entering annotation is simply a matter of editing or entering within the spreadsheet or within a text dialog of a pop-up. Editing segmentation in the general case requires the ability to paint arbitrary sets of pixels. This is extremely tedious and not really scalable to our scenario. Fortunately, the objects of interest to us are always globular and sufficiently modeled by a sphere. So, while VANO supports an arbitrary mask produced by a segmentation program, the simple manual edits supported are (i) deleting an object; (ii) merging an object adjacent to another, (iii) adding a <italic>spherical</italic> object of some radius; (iv) splitting an object by replacing it with two or more spheres; and (v) redefining an object by replacing it with a sphere. The restriction to spheres has not been found to be limiting and if somewhat more tailored masks are desired we find combining 2&#x02013;4 spheres generally suffices to give a &#x02018;snug&#x02019; mask.</p></sec><sec id="SEC4"><title>4 APPLICATIONS</title><p>VANO allows one to conveniently create or efficiently edit a segmentation and annotation of a collection of globular objects. As such it played a critical support role in building a 3D digital nuclei atlas for <italic>C.elegans</italic> (<xref ref-type="fig" rid="F1">Fig. 1</xref>a and b; collaboration with Stuart Kim lab at Stanford) and a 3D digital atlas of the nuclei of the ventral nerve cord of late stage <italic>D.melanogaster</italic> embryos (collaboration with Chris Doe lab at Oregon). For these two applications, VANO was used to produce the training sets for our automated algorithms (Long <italic>et al.</italic>, <xref ref-type="bibr" rid="B1">2007</xref>, <xref ref-type="bibr" rid="B2">2008a</xref>), to assess the quality of the 3D segmentations and annotations of nuclei produced by these algorithms, and to correct errors wherever needed to produce near perfect reference results.</p><p>VANO can also be used to annotate images in contexts where the image objects have an irregular shape. For example, we have been using VANO to annotate the enervation pattern of target neurons in defined compartments of the adult brain of <italic>D.melanogaster</italic> (collaborations with Gerry Rubin and Julie Simpson laboratories at Janelia Farm Research Campus). In <xref ref-type="fig" rid="F1">Figure 1</xref>c, each glia-isolated compartment is defined as a separate object with a complicated 3D shape. VANO enables us to conveniently interact with these 3D objects and annotate the neuronal distribution pattern within each compartment. VANO can be used in many situations in biomedical imaging where the annotation of automatically segmented images is desired.</p><p>In addition, VANO can be used to collect the prior information (e.g. 3D location) and statistics (e.g. mean/peak intensity) of image objects. The information is useful for developing 3D segmentation methods of cells or intracellular organelles, or related applications.</p></sec><sec sec-type="supplementary-material"><title>Supplementary Material</title><supplementary-material id="PMC_1" content-type="local-data"><caption><title>[Supplementary Data]</title></caption><media mimetype="text" mime-subtype="html" xlink:href="btp046_index.html"/><media xlink:role="associated-file" mimetype="application" mime-subtype="pdf" xlink:href="btp046_1.pdf"/></supplementary-material></sec></body><back><ack><title>ACKNOWLEDGEMENTS</title><p>We thank Xiao Liu and Stuart Kim for feedback in annotating <italic>C.elegans</italic> data; Mike Layden, Ellie Heckscher and Chris Doe for feedback in annotating fruit fly embryo data; Arnim Jenett, Gerry Rubin and Julie Simpson for feedback on annotating fruit fly adult brain data; and Frank Midgley for feedback on the design of VANO. We thank Zongcai Ruan for assistance in writing batch-compiling scripts and Margaret Jefferies for editorial review of the manuscript.</p><p><italic>Conflict of Interest</italic>: none declared.</p></ack><ref-list><title>REFERENCES</title><ref id="B1"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Long</surname><given-names>F</given-names></name></person-group><article-title>Automatic segmentation of nuclei in 3D microscopy images of C. elegans</article-title><source>In Proceedings of the IEEE ISBI'2007</source><year>2007</year><fpage>536</fpage><lpage>539</lpage></citation></ref><ref id="B2"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Long</surname><given-names>F</given-names></name><etal/></person-group><article-title>Automatic recognition of cells (ARC) for 3D images of C. elegans. Lecture Notes in Computer Science:</article-title><source>Research in Comp. Mol. Biology.</source><year>2008a</year><volume>4955</volume><publisher-loc>Berlin, Heidelberg</publisher-loc><publisher-name>Springer</publisher-name><fpage>128</fpage><lpage>139</lpage></citation></ref><ref id="B3"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Long</surname><given-names>F</given-names></name></person-group><article-title>A 3D digital atlas of C. elegans and its application to single-cell expression analysis</article-title><source>HHMI JFRC Technical Report.</source><year>2008b</year></citation></ref><ref id="B4"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Peng</surname><given-names>H</given-names></name></person-group><article-title>Bioimage informatics: a new area of engineering biology</article-title><source>Bioinformatics</source><year>2008</year><volume>24</volume><fpage>1827</fpage><lpage>1836</lpage><pub-id pub-id-type="pmid">18603566</pub-id></citation></ref><ref id="B5"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Peng</surname><given-names>H</given-names></name><etal/></person-group><article-title>Straightening Caenorhabditis elegans images</article-title><source>Bioinformatics</source><year>2008</year><volume>24</volume><fpage>234</fpage><lpage>242</lpage><pub-id pub-id-type="pmid">18025002</pub-id></citation></ref><ref id="B6"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Reenskaug</surname><given-names>T</given-names></name></person-group><article-title>THING-MODEL-VIEW-EDITOR:</article-title><source>an Example from a planningsystem. Xerox Parc technical note.</source><year>1979</year><fpage>1978</fpage><lpage>1979</lpage></citation></ref><ref id="B7"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>J</given-names></name><name><surname>Peng</surname><given-names>H</given-names></name></person-group><article-title>Automatic recognition and annotation of gene expression patterns of fly embryos</article-title><source>Bioinformatics</source><year>2007</year><volume>23</volume><fpage>589</fpage><lpage>596</lpage><pub-id pub-id-type="pmid">17237064</pub-id></citation></ref></ref-list></back></article>