<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN" "archivearticle.dtd"><article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Genet Sel Evol</journal-id><journal-title>Genetics, Selection, Evolution. : GSE</journal-title><issn pub-type="ppub">0999-193X</issn><issn pub-type="epub">1297-9686</issn><publisher><publisher-name>BioMed Central</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">19284681</article-id><article-id pub-id-type="pmc">2637029</article-id><article-id pub-id-type="publisher-id">1297-9686-41-2</article-id><article-id pub-id-type="doi">10.1186/1297-9686-41-2</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research</subject></subj-group></article-categories><title-group><article-title>A fast algorithm for BayesB type of prediction of genome-wide estimates of genetic value</article-title></title-group><contrib-group><contrib id="A1" corresp="yes" contrib-type="author"><name><surname>Meuwissen</surname><given-names>Theo HE</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>theo.meuwissen@umb.no</email></contrib><contrib id="A2" contrib-type="author"><name><surname>Solberg</surname><given-names>Trygve R</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>Trygve.roger.solberg@geno.no</email></contrib><contrib id="A3" contrib-type="author"><name><surname>Shepherd</surname><given-names>Ross</given-names></name><xref ref-type="aff" rid="I3">3</xref><email>r.shepherd@cqu.edu.au</email></contrib><contrib id="A4" contrib-type="author"><name><surname>Woolliams</surname><given-names>John A</given-names></name><xref ref-type="aff" rid="I1">1</xref><xref ref-type="aff" rid="I2">2</xref><email>john.woolliams@roslin.ed.ac.uk</email></contrib></contrib-group><aff id="I1"><label>1</label>Institute Animal and Aquacultural Sciences, Norwegian University of Life Sciences, Box 5003, N1432 As, Norway</aff><aff id="I2"><label>2</label>The Roslin Institute, Royal (Dick) School of Veterinary Studies, University of Edinburgh, Roslin, Midlothian EH25 9PS, UK</aff><aff id="I3"><label>3</label>Faculty of Business and Informatics, Central Queensland University, Rockhampton 4702, Queensland, Australia</aff><pub-date pub-type="collection"><year>2009</year></pub-date><pub-date pub-type="epub"><day>5</day><month>1</month><year>2009</year></pub-date><volume>41</volume><issue>1</issue><fpage>2</fpage><lpage>2</lpage><ext-link ext-link-type="uri" xlink:href="http://www.gsejournal.org/content/41/1/2"/><history><date date-type="received"><day>16</day><month>12</month><year>2008</year></date><date date-type="accepted"><day>5</day><month>1</month><year>2009</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2009 Meuwissen et al; licensee BioMed Central Ltd.</copyright-statement><copyright-year>2009</copyright-year><copyright-holder>Meuwissen et al; licensee BioMed Central Ltd.</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.0"><p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/2.0"/>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</p><!--<rdf xmlns="http://web.resource.org/cc/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:dc="http://purl.org/dc/elements/1.1" xmlns:dcterms="http://purl.org/dc/terms"><Work xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:dcterms="http://purl.org/dc/terms/" rdf:about=""><license rdf:resource="http://creativecommons.org/licenses/by/2.0"/><dc:type rdf:resource="http://purl.org/dc/dcmitype/Text"/><dc:author>               Meuwissen               HE               Theo                              theo.meuwissen@umb.no            </dc:author><dc:title>            A fast algorithm for BayesB type of prediction of genome-wide estimates of genetic value         </dc:title><dc:date>2009</dc:date><dcterms:bibliographicCitation>Genetics Selection Evolution 41(1): 2-. (2009)</dcterms:bibliographicCitation><dc:identifier type="sici">1297-9686(2009)41:1&#x0003c;2&#x0003e;</dc:identifier><dcterms:isPartOf>urn:ISSN:1297-9686</dcterms:isPartOf><License rdf:about="http://creativecommons.org/licenses/by/2.0"><permits rdf:resource="http://web.resource.org/cc/Reproduction" xmlns=""/><permits rdf:resource="http://web.resource.org/cc/Distribution" xmlns=""/><requires rdf:resource="http://web.resource.org/cc/Notice" xmlns=""/><requires rdf:resource="http://web.resource.org/cc/Attribution" xmlns=""/><permits rdf:resource="http://web.resource.org/cc/DerivativeWorks" xmlns=""/></License></Work></rdf>--></license></permissions><abstract><p>Genomic selection uses genome-wide dense SNP marker genotyping for the prediction of genetic values, and consists of two steps: (1) estimation of SNP effects, and (2) prediction of genetic value based on SNP genotypes and estimates of their effects. For the former step, BayesB type of estimators have been proposed, which assume <italic>a priori </italic>that many markers have no effects, and some have an effect coming from a gamma or exponential distribution, <italic>i.e</italic>. a fat-tailed distribution. Whilst such estimators have been developed using Monte Carlo Markov chain (MCMC), here we derive a much faster non-MCMC based estimator by analytically performing the required integrations. The accuracy of the genome-wide breeding value estimates was 0.011 (s.e. 0.005) lower than that of the MCMC based BayesB predictor, which may be because the integrations were performed one-by-one instead of for all SNPs simultaneously. The bias of the new method was opposite to that of the MCMC based BayesB, in that the new method underestimates the breeding values of the best selection candidates, whereas MCMC-BayesB overestimated their breeding values. The new method was computationally several orders of magnitude faster than MCMC based BayesB, which will mainly be advantageous in computer simulations of entire breeding schemes, in cross-validation testing, and practical schemes with frequent re-estimation of breeding values.</p></abstract></article-meta></front><body><sec><title>Introduction</title><p>The recent detection of thousands to millions of SNP markers and the dramatic improvements in high-throughput, cost effective genotyping technology have made it possible to apply marker assisted selection at a genome wide scale, which is termed genomic selection [<xref ref-type="bibr" rid="B1">1</xref>]. These authors suggested three methods for the estimation of genetic value from dense SNP marker data, namely GS-BLUP, BayesA, and BayesB. GS-BLUP applies the BLUP approach to the estimation of the effects of the marker alleles, which assumes a normal prior distribution for the marker effects, where the variance of the prior distribution was assumed equal for all the markers. Since an equal variance for each of the marker effects seems unrealistic, the BayesA method extended the GS-BLUP method by estimating the variance of every marker separately, and an inverse chi-square prior was used for the estimation of these variances. In the BayesB method it was assumed that many of the markers will actually have no effect, and the prior distribution of the variances was a mixture of a distribution with zero variance and an inverse chi-squared distribution. In a simulation study where the genetic model included a finite number of loci with exponentially distributed effects, BayesB provided more accurate prediction of genetic value than BayesA, which in turn was more accurate than GS-BLUP.</p><p>Although BayesB has the potential for the development of more faithful genetic models, and so seems the method of choice for estimating genome wide breeding values (GW-EBV), its calculation requires the use of computer intensive MCMC techniques. For practical applications and for computer simulations of genomic selection breeding schemes, where many selection rounds and replications are required, it would be advantageous if a much faster algorithm for the calculation of BayesB GW-EBV would be available. Thus, our aim here is to present a fast non-MCMC based algorithm for the calculation of BayesB type estimates of GW-EBV. By using a mixture of a distribution with zero effects and an exponential distribution as a prior for the marker effects, the integration involved in calculating the expectation of the breeding values given the data can be solved analytically, which makes non-MCMC estimation of GW-EBV possible.</p></sec><sec sec-type="methods"><title>Methods</title><sec><title>The model</title><p>We will first develop a model for the estimation of the effect of one SNP. The model will be extended to m SNPs in the fourth section of Methods, where m will be assumed to be much larger than the number of records n. When estimating one SNP effect, we generally do not need to use prior information, since the prior will usually be overwhelmed by the information from the data. However, since we will be extending the model to the estimation of many SNP effects, we will use prior information here. Also, in order to facilitate expansion to multi-SNP models we assume that the SNP considered is a randomly chosen SNP with a random effect, instead of a particular SNP with some particular effect. We will assume that a SNP marker has two alleles, 0 and 1, with allele 1 the reference allele having frequency p. For the purpose of estimating gene effects, the SNP genotypes were standardised to form an n &#x000d7; 1 vector of covariates, <bold>b</bold>, defined for animal i as: (1) b<sub>i </sub>= -2p/SD, if i has homozygous genotype '0_0'; (2) b<sub>i </sub>= (1&#x02013;2p)/SD if i has heterozygote genotype '0_1'; (3) b<sub>i </sub>= 2(1-p)/SD if i has homozygous genotype '1_1'; where SD = &#x0221a;[2p(1-p)]. Thus, the b<sub>i </sub>are standardised such that their mean is 0 and their variance is 1 in a random mating population. If g is the effect of the SNP in the population, and we assume that it is drawn from a distribution of marker effects with mean 0, then the variance due to the marker is Var(b<sub>i</sub>g) = Var(b<sub>i</sub>)Var(g) = Var(g). Therefore by modelling the variance of the effect of the SNP, we also model the variance directly due to the SNP, irrespective of its frequency. This way of modelling the variance due to the SNP will be discussed in detail in Discussion. It may be noted however that the standardisation of the variance of the b<sub>i </sub>is not essential to our derivations below, <italic>i.e</italic>. when considered more appropriate we could choose the b<sub>i </sub>as -2p, (1&#x02013;2p), and 2(1-p), respectively. The model for the records denoted by the n &#x000d7; 1 vector <bold>y </bold>is:</p><p><disp-formula id="bmcM1"><label>(1)</label><bold>y </bold>= <bold>b</bold><italic>g </italic>+ <bold>e</bold></disp-formula></p><p>where g is the effect of the SNP; and <bold>e </bold>is an n &#x000d7; 1 vector of residuals which are assumed normally distributed with variance <italic>&#x003c3;</italic><sub>e</sub><sup>2</sup>. We will ignore the estimation of an overall mean for now since, even if it were included in the model, its estimate would not affect the equation for the estimation of g since <bold>1</bold><sup>'</sup><bold>b </bold>= 0, following from the standardisation of <bold>b</bold>.</p></sec><sec><title>Prior distribution of g</title><p>The prior distribution of the SNP effect g, <italic>&#x003c0;</italic>(<italic>g</italic>), is assumed to be a mixture of a distribution with a discrete probability mass of zero and an exponential distribution reflected about g = 0 (see [<xref ref-type="bibr" rid="B2">2</xref>]):</p><p><disp-formula id="bmcM2"><label>(2)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M1" name="1297-9686-41-2-i1" overflow="scroll"><mml:semantics><mml:mrow><mml:mi>&#x003c0;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mstyle scriptlevel="+1"><mml:mfrac bevelled="true"><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mi>&#x003b3;</mml:mi><mml:mi>&#x003bb;</mml:mi><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:mo>|</mml:mo><mml:mi>g</mml:mi><mml:mo>|</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>for&#x000a0;</mml:mtext><mml:mi>g</mml:mi><mml:mo>&#x02260;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003b3;</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>for&#x000a0;</mml:mtext><mml:mi>g</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:semantics></mml:math></disp-formula></p><p>where <italic>&#x003b3; </italic>is the fraction of the SNPs that are in linkage disequilibrium (LD) with a quantitative trait locus (QTL) and may consequently have a non-zero effect; and <italic>&#x003bb; </italic>is the parameter of the exponential distribution. As described in the Appendix 1 this may be re-expressed as <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M2" name="1297-9686-41-2-i2" overflow="scroll"><mml:semantics><mml:mrow><mml:mi>&#x003c0;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac bevelled="true"><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mi>&#x003b3;</mml:mi><mml:mi>&#x003bb;</mml:mi><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:mo>|</mml:mo><mml:mi>g</mml:mi><mml:mo>|</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003b3;</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x003b4;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math></inline-formula> where <italic>&#x003b4;</italic>(<italic>g</italic>) is the Dirac delta function. Therefore since the variance of the zero-reflected exponential distribution is 2<italic>&#x003bb;</italic><sup>-2</sup>, for m markers the total genetic variance is <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M3" name="1297-9686-41-2-i3" overflow="scroll"><mml:semantics><mml:mrow><mml:msubsup><mml:mi>&#x003c3;</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:semantics></mml:math></inline-formula> = 2<italic>m&#x003b3;&#x003bb;</italic><sup>-2</sup>. Covariances between marker effects are expected to be zero, because any non-zero covariance will depend on the coding of the marker alleles which is arbitrary, <italic>i.e</italic>. a positive covariance can be changed in a negative one by recoding the marker alleles. The hyper-parameters of the prior distribution (<italic>&#x003b3; </italic>and <italic>&#x003bb;</italic>) are assumed known here. If one is willing to assume that a fraction <italic>&#x003b3; </italic>of the markers are in LD with QTL, the variance per marker in LD with a QTL is <italic>&#x003c3;</italic><sub>a</sub><sup>2</sup>/(m<italic>&#x003b3;</italic>), and an estimate of the <italic>&#x003bb; </italic>hyper-parameter is &#x0221a;(2 m<italic>&#x003b3;</italic>/<italic>&#x003c3;</italic><sub>a</sub><sup>2</sup>).</p></sec><sec><title>The posterior distribution and the expectation of g | y</title><p>For the likelihood of the data <bold>y </bold>given the genetic effect g a multi-variate normal distribution is assumed with mean <bold>b</bold>g and variance <bold>I</bold><italic>&#x003c3;</italic><sub>e</sub><sup>2 </sup>from (2), where <bold>I </bold>is the n &#x000d7; n identity matrix. Thus, the likelihood function is <italic>&#x003c6;</italic>(<bold>y</bold>; <bold>b</bold><italic>g</italic>, <bold>I</bold><inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M4" name="1297-9686-41-2-i4" overflow="scroll"><mml:semantics><mml:mrow><mml:msubsup><mml:mi>&#x003c3;</mml:mi><mml:mi>e</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:semantics></mml:math></inline-formula>), where <italic>&#x003c6;</italic>(<bold>y</bold>; <italic>&#x003bc;</italic>, <bold>V</bold>) is the multi-variate normal density function with mean <bold><italic>&#x003bc; </italic></bold>and (co)variance matrix <bold>V</bold>. In what follows the dimensionality of the multi-variate <italic>&#x003c6;</italic>(.;.,.) will be left implicit from the parameters and will include the univariate density. The summary statistic for g is Y = (<bold>b</bold><sup>'</sup><bold>b</bold>)<sup>-1</sup><bold>b</bold><sup>'</sup><bold>y </bold>= <bold>b</bold><sup>'</sup><bold>y/</bold>n and, consequently, all information on g contained in <bold>y </bold>is also contained in Y. The variance of Y is <italic>&#x003c3;</italic><sup>2 </sup>= (<bold>b</bold><sup>'</sup><bold>b</bold>)<sup>-1</sup><italic>&#x003c3;</italic><sub>e</sub><sup>2 </sup>= <italic>&#x003c3;</italic><sub>e</sub><sup>2</sup>/n since <bold>b'b </bold>= n. Therefore, the likelihood function <italic>&#x003c6;</italic>(<bold>y</bold>; <bold>b</bold><italic>g</italic>, <bold>I</bold><inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M5" name="1297-9686-41-2-i4" overflow="scroll"><mml:semantics><mml:mrow><mml:msubsup><mml:mi>&#x003c3;</mml:mi><mml:mi>e</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:semantics></mml:math></inline-formula>) is proportional to the univariate density <italic>&#x003c6;</italic>(<italic>Y</italic>; <italic>g</italic>, <italic>&#x003c3;</italic><sup>2</sup>), as shown in Appendix 2, and so we will use the univariate version of the likelihood function for simplicity. The posterior distribution of g|<bold>y </bold>now becomes:</p><p><disp-formula id="bmcM3"><label>(3)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M6" name="1297-9686-41-2-i5" overflow="scroll"><mml:semantics><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>g</mml:mi><mml:mo>|</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>&#x003d5;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>;</mml:mo><mml:mi>g</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x003c0;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>&#x0222b;</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>&#x0221e;</mml:mi></mml:mrow><mml:mi>&#x0221e;</mml:mi></mml:msubsup><mml:mrow><mml:mi>&#x003d5;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>;</mml:mo><mml:mi>g</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x003c0;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:semantics></mml:math></disp-formula></p><p>The posterior distribution is not affected by the use of either <italic>&#x003c6;</italic>(<bold>y</bold>; <bold>b</bold><italic>g</italic>, <bold>I</bold><inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M7" name="1297-9686-41-2-i4" overflow="scroll"><mml:semantics><mml:mrow><mml:msubsup><mml:mi>&#x003c3;</mml:mi><mml:mi>e</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:semantics></mml:math></inline-formula>) or <italic>&#x003c6;</italic>(<italic>Y</italic>; <italic>g</italic>, <italic>&#x003c3;</italic><sup>2</sup>) since they are proportional to each other, <italic>i.e</italic>. <italic>&#x003c6;</italic>(<bold>y</bold>; <bold>b</bold><italic>g</italic>, <bold>I</bold><inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M8" name="1297-9686-41-2-i4" overflow="scroll"><mml:semantics><mml:mrow><mml:msubsup><mml:mi>&#x003c3;</mml:mi><mml:mi>e</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:semantics></mml:math></inline-formula>)/<italic>&#x003c6;</italic>(<italic>Y</italic>; <italic>g</italic>, <italic>&#x003c3;</italic><sup>2</sup>) = constant, and this constant is a factor of both the numerator and the denominator. The expectation of g given <bold>y </bold>is (<italic>e.g</italic>. [<xref ref-type="bibr" rid="B2">2</xref>]) as <italic>E </italic>[<italic>g</italic>|<bold>y</bold>] = &#x0222b; <italic>gp</italic>(<italic>g</italic>|<bold>y</bold>)<italic>dg </italic>and thus:</p><p><disp-formula id="bmcM4"><label>(4)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M9" name="1297-9686-41-2-i6" overflow="scroll"><mml:semantics><mml:mrow><mml:mi>E</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mi>g</mml:mi><mml:mo>|</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>&#x0222b;</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>&#x0221e;</mml:mi></mml:mrow><mml:mi>&#x0221e;</mml:mi></mml:msubsup><mml:mrow><mml:mi>g</mml:mi><mml:mi>&#x003d5;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>;</mml:mo><mml:mi>g</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x003c0;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>&#x0222b;</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>&#x0221e;</mml:mi></mml:mrow><mml:mi>&#x0221e;</mml:mi></mml:msubsup><mml:mrow><mml:mi>&#x003d5;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>;</mml:mo><mml:mi>g</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x003c0;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:semantics></mml:math></disp-formula></p><p>Both the integral in the numerator and that in the denominator are analytically derived in full in Appendix 1. This results in a closed form for E [g|<bold>y</bold>], which is presented in the Appendix 1 in Equation (B3).</p></sec><sec><title>Extension to m SNPs</title><p>The extension to the estimation of the effects of m SNPs is obtained by the use of a modification of the Iterative Conditional Mode (ICM) algorithm [<xref ref-type="bibr" rid="B3">3</xref>], which we will call the Iterative Conditional Expectation (ICE) algorithm. The ICE algorithm uses the expectation/mean instead of the mode of the posterior, because (1) the mean of g maximises the correlation between <italic>g </italic>and <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M10" name="1297-9686-41-2-i7" overflow="scroll"><mml:semantics><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:semantics></mml:math></inline-formula>[<xref ref-type="bibr" rid="B2">2</xref>]; and (2) due to the spike at zero the posterior may be bi-modal (see Results), in which case the mode may be quite far away from the mean. The ICE algorithm iteratively calculates E(g|Y) for each SNP in turn, using the current solutions of all the other SNPs as if they were true effects, which is known to only approximately converge to the correct solution. We will first describe the algorithm and next its approximate nature. The effects of the SNPs are denoted g<sub>i </sub>(i = 1, .., m), and in vector notation by <bold>g</bold>. When estimating the effect of the i<sup>th </sup>SNP, the current estimates of all other SNPs are used to calculate Y<sub>i </sub>and <italic>&#x003c3;</italic><sup>2</sup>. Iterating from a starting solution, <italic>e.g</italic>. <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M11" name="1297-9686-41-2-i8" overflow="scroll"><mml:semantics><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mstyle></mml:semantics></mml:math></inline-formula> = 0, the algorithm performs within each iteration the following steps:</p><p>For all SNPs i = 1, .., m,</p><p>Step 1: calculate 'adjusted' records, <italic>y</italic><sub>-<italic>i</italic></sub>, which are corrected for all the other SNPs so <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M12" name="1297-9686-41-2-i9" overflow="scroll"><mml:semantics><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mo>&#x02212;</mml:mo><mml:mstyle displaystyle="true"><mml:msub><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>&#x02260;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>b</mml:mi></mml:mstyle><mml:mi>j</mml:mi></mml:msub><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:semantics></mml:math></inline-formula>. Estimate the sufficient statistics <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M13" name="1297-9686-41-2-i10" overflow="scroll"><mml:semantics><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:msup><mml:mi>b</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula>, and <italic>&#x003c3;</italic><sup>2 </sup>= <italic>&#x003c3;</italic><sub>e</sub><sup>2</sup>/n.</p><p>Step 2: Equation B3 of Appendix 1 is used to calculate <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M14" name="1297-9686-41-2-i11" overflow="scroll"><mml:semantics><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula> = <italic>E </italic>[<italic>g</italic><sub><italic>i</italic></sub>|<italic>Y</italic><sub><italic>i</italic></sub>], which is used to update the solution for marker i.</p><p>The iteration is stopped when the changes in the solutions become small, <italic>i.e</italic>. <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M15" name="1297-9686-41-2-i12" overflow="scroll"><mml:semantics><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mstyle><mml:mi>q</mml:mi></mml:msup><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mstyle><mml:mrow><mml:mi>q</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mstyle><mml:mi>q</mml:mi></mml:msup><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mstyle><mml:mrow><mml:mi>q</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mstyle><mml:mi>q</mml:mi></mml:msup><mml:mo>'</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mstyle><mml:mi>q</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x0003c;</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math></inline-formula>, where subscript q denotes the q<sup>th </sup>iteration. In the Step 1, it is computationally more efficient to calculate Y<sub>i </sub>directly as <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M16" name="1297-9686-41-2-i13" overflow="scroll"><mml:semantics><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:msup><mml:mi>b</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mo>&#x02212;</mml:mo><mml:mstyle displaystyle="true"><mml:msub><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>&#x02260;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:msup><mml:mi>b</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>b</mml:mi></mml:mstyle><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle><mml:mo>/</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula>. The advantage being that the elements of the normal equations matrix <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M17" name="1297-9686-41-2-i14" overflow="scroll"><mml:semantics><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:msup><mml:mi>b</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>b</mml:mi></mml:mstyle><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula> may be stored, which speeds up the calculation of Y<sub>i</sub>.</p><p>As mentioned before, if the only fixed effect is the overall mean, no correction for fixed effects is needed. If it is required to estimate fixed effects <italic>&#x003b2; </italic>with design matrix <bold>X</bold>, the calculation of <bold>y</bold><sub>-i </sub>in the Step 1 becomes <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M18" name="1297-9686-41-2-i15" overflow="scroll"><mml:semantics><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mo>&#x02212;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>X</mml:mi></mml:mstyle><mml:mi>&#x003b2;</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mstyle displaystyle="true"><mml:msub><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>&#x02260;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>b</mml:mi></mml:mstyle><mml:mi>j</mml:mi></mml:msub><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:semantics></mml:math></inline-formula> and each iteration also updates the solutions for the fixed effects <italic>e.g</italic>. by <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M19" name="1297-9686-41-2-i16" overflow="scroll"><mml:semantics><mml:mrow><mml:mi>&#x003b2;</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:msup><mml:mi>X</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mi>X</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:msup><mml:mi>X</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mo>&#x02212;</mml:mo><mml:mstyle displaystyle="true"><mml:msub><mml:mo>&#x02211;</mml:mo><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>b</mml:mi></mml:mstyle><mml:mi>j</mml:mi></mml:msub><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math></inline-formula>.</p><p>The approximate nature of the ICE algorithm is due to <italic>y</italic><sub>-<italic>i </italic></sub>and thus Y<sub>i </sub>not being known, but being estimated. For ease of notation, this was not denoted by a hat elsewhere in this paper, but in this paragraph it is necessary to make the distinction between the true values of <bold>y</bold><sub>-<italic>i </italic></sub>= <bold>y </bold>- &#x003a3;<sub><italic>j </italic>&#x02260; <italic>i</italic></sub><bold>b</bold><sub><italic>j</italic></sub><italic>g</italic><sub><italic>j </italic></sub>and <italic>Y</italic><sub><italic>i </italic></sub>and their estimates: <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M20" name="1297-9686-41-2-i17" overflow="scroll"><mml:semantics><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula> and <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M21" name="1297-9686-41-2-i18" overflow="scroll"><mml:semantics><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula>, which are calculated as indicated above. Estimation errors in <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M22" name="1297-9686-41-2-i17" overflow="scroll"><mml:semantics><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula> and <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M23" name="1297-9686-41-2-i18" overflow="scroll"><mml:semantics><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula> occur due to the estimation errors of the other SNP effects <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M24" name="1297-9686-41-2-i19" overflow="scroll"><mml:semantics><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula> (<italic>j </italic>&#x02260; <italic>i</italic>), which is reflected by their Prediction Error Variance, PEV(<italic>g</italic><sub><italic>j</italic></sub>). From a second order Taylor series expansion of E(g<sub>i</sub>|Y<sub>i</sub>) around its mean <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M25" name="1297-9686-41-2-i18" overflow="scroll"><mml:semantics><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula>, it follows that:</p><p><disp-formula id="bmcM5"><label>(5)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M26" name="1297-9686-41-2-i20" overflow="scroll"><mml:semantics><mml:mrow><mml:mi>E</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mn>0.5</mml:mn><mml:mfrac><mml:mrow><mml:msup><mml:mi>&#x003b4;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mi>E</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>&#x003b4;</mml:mi><mml:msubsup><mml:mi>Y</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math></disp-formula></p><p>where <italic>Var</italic>(<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M27" name="1297-9686-41-2-i18" overflow="scroll"><mml:semantics><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula>) is due to prediction error variances and covariances of the g<sub>j</sub>. It follows that <italic>E</italic>(<italic>g</italic><sub><italic>i</italic></sub>|<italic>Y</italic><sub><italic>i</italic></sub>) &#x02248; <italic>E</italic>(<italic>g</italic><sub><italic>i</italic></sub>|<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M28" name="1297-9686-41-2-i18" overflow="scroll"><mml:semantics><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula>), as is implicitly assumed in step 2 of the ICE algorithm, if the second derivative of E(g<sub>i</sub>|Y<sub>i</sub>) is small or <italic>Var</italic>(<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M29" name="1297-9686-41-2-i18" overflow="scroll"><mml:semantics><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula>) is small. The latter is probably only the case if there are few markers <italic>j </italic>&#x02260; <italic>i</italic>. The first section of Results investigates the non-linearity, <italic>i.e</italic>. second and higher order derivatives, of the E(g<sub>i</sub>|Y<sub>i</sub>) function.</p></sec><sec><title>Comparison of non- and MCMC based BayesB</title><p>The BayesB algorithm developed here will be denoted by fBayesB (for 'fast BayesB') and the BayesB algorithm using MCMC (as described in [<xref ref-type="bibr" rid="B1">1</xref>]) will be denoted by MBayesB. fBayesB and MBayesB were compared in twenty simulated populations. The simulation of the population and analysis by MBayesB was conducted by Solberg <italic>et al</italic>. [<xref ref-type="bibr" rid="B4">4</xref>] and their paper gives a detailed description of the simulation procedures. In brief, the populations were simulated for 1000 generations at an effective size of 100 in order to create mutation drift balance and LD between the markers and the genes. The genome consisted of 10 chromosomes of 100 cM with a total of 8010 equidistant marker loci including markers at each end of the chromosome. The mutation rate per marker locus per meiosis was high (2.5*10<sup>-3</sup>) to ensure that virtually all the loci were segregating. If more than one mutation occurred at a marker locus, the mutation that resulted in the highest Minor Allele Frequency (MAF) was considered as 'visible', whereas the others were considered 'unvisible' and were thus ignored. With these parameters, the visibility procedure turned 99% of markers into biallelic markers, even if several mutations had occurred, with the remaining 1% being monoallelic. There were 1000 equidistant putative QTL positions, which were chosen such that a QTL position was always in the middle between two marker loci. Whether or not a putative QTL position had an effect on the trait depended on the existence of a mutation during the simulated generations, which occurred with a mutation rate of 2.5*10<sup>-5</sup>. The effects of QTL alleles were sampled from a gamma distribution with scale parameter 1.4 and shape parameter 4.2, and were considered with equal probabilities of being positive or negative.</p><p>The scale parameter of the gamma distribution was chosen such that the expected genetic variance was 1 (as in [<xref ref-type="bibr" rid="B1">1</xref>]). In generation 1001 and 1002 the population size was increased to 1000, and the animals were genotyped for the 8010 markers. In generation 1001, the animals also had phenotypic records, <italic>i.e</italic>. the phenotype of animal i was:</p><p><disp-formula><bold>y</bold><sub><italic>i </italic></sub>= &#x003a3;<sub><italic>j</italic></sub>(<italic>a</italic><sub><italic>ij</italic>(<italic>p</italic>) </sub>+ <italic>a</italic><sub><italic>ij</italic>(<italic>m</italic>)</sub>) + <italic>e</italic><sub><italic>i</italic></sub></disp-formula></p><p>where a<sub>ij(p) </sub>is the effect of the paternal (m, maternal) allele that animal i inherited at QTL locus j; e<sub>i</sub>~N(0, <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M30" name="1297-9686-41-2-i4" overflow="scroll"><mml:semantics><mml:mrow><mml:msubsup><mml:mi>&#x003c3;</mml:mi><mml:mi>e</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:semantics></mml:math></inline-formula>), where <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M31" name="1297-9686-41-2-i4" overflow="scroll"><mml:semantics><mml:mrow><mml:msubsup><mml:mi>&#x003c3;</mml:mi><mml:mi>e</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:semantics></mml:math></inline-formula> was set equal to the realised genetic variance in the replicate, such that the heritability was 0.5 in each replicate. Marker effects were estimated using the phenotypes and genotypes obtained from generation 1001. The total genetic values for the animals of generation 1002 were predicted (GW-EBV) from their marker genotypes and the estimates of the marker effects. The accuracy of these estimates was calculated as the correlation between the GW-EBV and the true breeding value, which is known in this simulation study. The coefficient of the regression of the true genetic value on the GW-EBV was used as a measure of the bias of the EBV, and a regression coefficient of 1 implies no bias.</p></sec></sec><sec><title>Results</title><sec><title>The non-linear regression curve</title><p>In Figure <xref ref-type="fig" rid="F1">1</xref>, E [g|Y] is plotted against the value of Y with <italic>&#x003c3;</italic><sup>2 </sup>= 1; since Y is the sufficient statistic for g given the data <bold>y</bold>, E [g|<bold>y</bold>] = E [g|Y]. Figure <xref ref-type="fig" rid="F1">1</xref> shows also the regression curve when the integrals in Equation (4) were numerically evaluated, as was done by Goddard [<xref ref-type="bibr" rid="B2">2</xref>]. The empirical curve of Goddard has similar characteristics, which is relatively flat at Y = 0, but approaches a derivative of 1 for extreme values of Y. However as a result of the closed expression in Appendix 1 (B3) it is possible to explore the full solution space and Figure <xref ref-type="fig" rid="F2">2</xref> shows some examples from this space. The examples demonstrate several features. Firstly E [g|Y] is an odd function (in a mathematical sense) satisfying E [g| -Y] = -E [g|Y]. Secondly, <italic>d E </italic>[<italic>g</italic>|<italic>Y</italic>]/<italic>dY </italic>is non-zero at Y = 0 but decreases towards 0 as <italic>&#x003b3; </italic>tends to 0. Furthermore <italic>d E </italic>[<italic>g</italic>|<italic>Y</italic>]/<italic>dY </italic>is not necessarily monotonic, for example see <italic>&#x003b3; </italic>= 0.05 in Figure <xref ref-type="fig" rid="F2">2</xref>. In the example with <italic>&#x003b3; </italic>= 0.05 it is clear that <italic>d E </italic>[<italic>g</italic>|<italic>Y</italic>]/<italic>dY </italic>exceeds 1 for Y &#x02248; 3.5 <italic>i.e</italic>. an increment in Y results in a greater increment in E [g|Y]. Heuristically this occurs because for small <italic>&#x003b3; </italic>there are only few non zero marker effects, but those present are large; therefore E [g|Y] is close to 0, since Y is expected to have occurred by chance, until Y becomes large and statistically unusual in magnitude, but once considered unusual, E [g|Y] is large. Asymptotically, for Y of large magnitude <italic>d E </italic>[<italic>g</italic>|<italic>Y</italic>]/<italic>dY </italic>tends to 1. The asymptotic behaviour of E(g|Y) is:</p><fig position="float" id="F1"><label>Figure 1</label><caption><p><bold>The expectation of the genetic value given the summary statistic of the data Y, E(g|Y), as a function of Y</bold>. The parameter of the exponential distribution is <italic>&#x003bb; </italic>= 1, <italic>&#x003c3;</italic><sup>2 </sup>= 1, and the probability of a marker having a true effect is <italic>&#x003b3; </italic>= 0.05; E(g|Y) calculated by numerical integration is represented by black dots and the analytical solution is shown as white dots.</p></caption><graphic xlink:href="1297-9686-41-2-1"/></fig><fig position="float" id="F2"><label>Figure 2</label><caption><p><bold>The expectation of the genetic value given the summary statistic of the data Y, E(g|Y) as a function of Y</bold>. The parameter of the exponential distribution is <italic>&#x003bb; </italic>= 1, <italic>&#x003c3;</italic><sup>2 </sup>= 1, and the probability of a marker having a true effect is <italic>&#x003b3; </italic>= 0.05 (<bold>bold curve</bold>), 0.5 (dotted curve), and 1.0 (regular line).</p></caption><graphic xlink:href="1297-9686-41-2-2"/></fig><p><disp-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M32" name="1297-9686-41-2-i21" overflow="scroll"><mml:semantics><mml:mrow><mml:mtext>E</mml:mtext><mml:mo stretchy="false">[</mml:mo><mml:mtext>g</mml:mtext><mml:mo>|</mml:mo><mml:mi>Y</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mi>Y</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>for&#x000a0;</mml:mtext><mml:mi>Y</mml:mi><mml:mo>&#x02192;</mml:mo><mml:mo>+</mml:mo><mml:mi>&#x0221e;</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mi>Y</mml:mi><mml:mo>+</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>for&#x000a0;</mml:mtext><mml:mi>Y</mml:mi><mml:mo>&#x02192;</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>&#x0221e;</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:semantics></mml:math></disp-formula></p><p>This is nominally independent of <italic>&#x003b3;</italic>, but for a given <italic>&#x003c3;</italic><sup>2 </sup>the value of <italic>&#x003bb; </italic>will increase as <italic>&#x003b3; </italic>increases. Assuming that all the genetic variance can be explained by markers, and the trait has a phenotypic variance of 1 and heritability h<sup>2</sup>, <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M33" name="1297-9686-41-2-i22" overflow="scroll"><mml:semantics><mml:mrow><mml:mi>&#x003bb;</mml:mi><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mi>n</mml:mi><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msqrt><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>m</mml:mi><mml:mi>&#x003b3;</mml:mi><mml:mo>/</mml:mo><mml:msup><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msqrt></mml:mrow></mml:semantics></mml:math></inline-formula>. In summary, the effect is that for small Y values the estimates of g are regressed back substantially, whereas the regression back for large values of Y is diminishing and small.</p><p>The non-linearity of E [g|Y] is especially pronounced for small <italic>&#x003b3;</italic>, and the second derivative seems positive (negative) for positive (negative) values of Y that are approximately between -4 &#x0003c; Y &#x0003c; 4. Since most Y values (expressed in <italic>&#x003c3; </italic>units) will be between these boundaries, the regression E [g|Y] is quite non-linear. For multiple SNPs, Equation (5) suggests that the estimates of g will be conservative in the sense that they will show a bias towards zero. This bias will be increased for smaller <italic>&#x003b3;</italic>, <italic>i.e</italic>. for a smaller number of QTL over number of markers ratio.</p><p>Figure <xref ref-type="fig" rid="F3">3</xref> depicts the prior, likelihood and posterior distribution of g, in a situation where the posterior is bimodal. For smaller values of Y, the likelihood curve moves to the left and the two peaks of the posterior merge into one. For larger values of Y, the likelihood moves to the right, hence its value at 0 reduces, and the peak of the posterior at zero disappears. In the latter case, the posterior becomes approximately a symmetric distribution, and the use of the mode (ICM) instead of the mean (ICE) would not make much difference.</p><fig position="float" id="F3"><label>Figure 3</label><caption><p><bold>The probability density function (PDF) of the prior (...), likelihood (_ _ _), and posterior (___) of g</bold>. The parameter from the exponential distribution <italic>&#x003bb; </italic>= 1.67, <italic>&#x003b3; </italic>= 0.1, and Y = 0.2 (s.d. units); the spike of the prior distribution at zero is depicted by an exponential distribution, that is reflected around zero, with a very large <italic>&#x003bb; </italic>of 200.</p></caption><graphic xlink:href="1297-9686-41-2-3"/></fig></sec><sec><title>The accuracy and bias of GW-EBV using BLUP, fBayesB and MBayesB</title><p>MBayesB is slightly more accurate than fBayesB (Table <xref ref-type="table" rid="T1">1</xref>). The difference in accuracy is 0.011 with s.e. of difference of 0.005, which is statistically significant. For comparison, the accuracy of BLUP GW-EBV is also shown, calculated with a prior that each marker contributes an equal amount of variance, namely 1/m, <italic>i.e</italic>. the infinitesimal model is assumed to hold, at least approximately. The accuracy of the BLUP GW-EBV is considerably lower than that of MBayesB and fBayesB, which is probably because the genetic model underlying the simulations is quite far from the infinitesimal model.</p><table-wrap position="float" id="T1"><label>Table 1</label><caption><p>The accuracy of MBayesB, fBayesB and BLUP, defined by the correlation between true and estimated breeding values in generation 1002.</p></caption><table frame="hsides" rules="groups"><thead><tr><td align="left"><bold><underline>Method</underline></bold></td><td align="left"><bold>Accuracy + se</bold></td><td align="left"><bold>Regression + se</bold></td></tr></thead><tbody><tr><td align="left">fBayesB</td><td align="left">0.849 &#x000b1; 0.011</td><td align="left">1.145 &#x000b1; 0.025</td></tr><tr><td align="left">MBayesB</td><td align="left">0.860 &#x000b1; 0.010</td><td align="left">0.923 &#x000b1; 0.011</td></tr><tr><td align="left">BLUP</td><td align="left">0.694 + 0.006</td><td align="left">0.990 + 0.009</td></tr></tbody></table><table-wrap-foot><p>Together with the regression of true on estimated breeding value.</p><p>MBayesB and fBayesB incorporate BayesB assumption calculated using MCMC or by the methods described here, and BLUP denotes estimation assuming equal variances due to each of the markers</p></table-wrap-foot></table-wrap><p>Both MBayesB and fBayesB yielded biased EBV, but, interestingly, the biases are opposite in direction. MBayesB yields EBV that are too variable, so the EBV require to be shrunk in order to predict the TBV without bias, hence the regression of the TBV on the EBV is &#x0003c;1. In contrast, fBayesB yields EBV with too little variance, so the EBV require to be scaled up in order to predict the TBV without bias, <italic>i.e</italic>. the regression is &#x0003e;1. This conservative behaviour of <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M34" name="1297-9686-41-2-i7" overflow="scroll"><mml:semantics><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:semantics></mml:math></inline-formula>, <italic>i.e</italic>. differences between the estimates are smaller than the real life differences, is expected based on the non-linearity observed in Figure <xref ref-type="fig" rid="F2">2</xref> and Equation (5) (see first section of Results). Especially, the bias of the fBayesB is considerable, and should be corrected for by rescaling the EBV when used in a breeding scheme where EBVs based on different amounts of information are to be compared.</p><p>In order to investigate any systematic deviations of fBayesB-EBV from the MBayesB-EBV, which is considered the golden standard, Figure <xref ref-type="fig" rid="F4">4</xref> plots both types of EBV against each other. The regression of the EBV from both types of non-linear regression methods against each other seems pretty linear, which indicates that both methods seem to non-linearly regress the phenotypic data in a very similar way.</p><fig position="float" id="F4"><label>Figure 4</label><caption><p><bold>Scatter plot of fBayesB-EBV against MBayesB-EBV and their linear regression line</bold>.</p></caption><graphic xlink:href="1297-9686-41-2-4"/></fig></sec><sec><title>Computer time</title><p>The difference in computer time is large: whereas fBayesB takes 2 to 5 minutes MBayesB takes 47 h to compute. No attempt was made to implement parallel computing with MBayesB, although it is readily amenable to parallel procedures through running multiple shorter MCMC chains (each chain should be longer than the burn-in period), which reduces the required wall-time for the calculations. The impact of parallel computing procedures of fBayesB is less clear, but there also appears to be no need for this.</p></sec></sec><sec><title>Discussion</title><p>A fast, non-MCMC based algorithm, called Iterative Conditional Expectation (ICE), was derived for the calculation of GW-EBV using dense SNP genotype and phenotypic data. The speed of improvement is due to the analytical integration of the integrals involved in the calculation of E [g|Y]. The Bayesian estimation model used here has very similar characteristics to BayesB as described by [<xref ref-type="bibr" rid="B1">1</xref>] and denoted MBayesB here: the prior distribution is a mixture of a heavy-tailed distribution (fBayesB: exponential distribution; MBayesB: a normal distribution whose variance is sampled from an inverse chi-squared) and a distribution with zero effects. The latter mixture distribution is also called a 'spike and slab' mixture [<xref ref-type="bibr" rid="B5">5</xref>]. The QTL effects had a Gamma distribution, and thus differed from both that of fBayesB and MBayesB. It may be noted that the prior distribution of fBayesB and MBayesB does not apply to the QTL effects but to the marker effects, for which the true prior distribution will be hard to derive. Although we cannot rule out that the slightly better accuracy of MBayesB compared to fBayesB (Table <xref ref-type="table" rid="T1">1</xref>) is due to the prior distribution of MBayesB being better than that of fBayesB, the non-linear regressions of MBayesB and fBayesB seemed very similar since they resulted in a linear regression of the fBayesB-EBV on the MBayesB-EBV (Figure <xref ref-type="fig" rid="F4">4</xref>). The difference in accuracy seems to be due to that the ICE algorithm ignores higher order derivatives of E(g|Y) function to Y (Eqn. 5). Relaxing this assumption requires (1) taking second order derivatives of the E(g|Y) function, (2) calculation of prediction error variances of <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M35" name="1297-9686-41-2-i23" overflow="scroll"><mml:semantics><mml:mrow><mml:mi>&#x003a3;</mml:mi><mml:msub><mml:mi>b</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula>, and more research is needed to perform these calculations computationally efficiently.</p><p>The justification for the 'spike and slab' prior distribution is that many of the SNPs will not be in LD with a QTL and thus have no effect, whereas the SNPs that are in LD with a QTL have a distribution of effects that is similar to that of the QTL, albeit smaller in magnitude due to the need for several markers to predict the effect of the true QTL genotypes. The true distribution of QTL is often reported to be exponential or gamma [<xref ref-type="bibr" rid="B6">6</xref>]. Hayes and Goddard [<xref ref-type="bibr" rid="B6">6</xref>] found a shape parameter for the gamma distribution of 0.4, <italic>i.e</italic>. a leptokurtic shape similar to that of the exponential distribution. Where the marker is not in perfect LD with the gene, it will pick up only a fraction of the gene effect and the impact of this on the distribution of marker effects is included within the assumptions concerning their prior distribution.</p><p>The non-linear regression curve, resulting from the choice of the prior distribution, is rather flat for values of Y close to 0, but approaches a ratio of E [g|Y]/Y = 1 for Y of large magnitude, so E [g|Y] &#x02248; Y albeit for very large, and hence rare, deviations. Thus large values of Y are assumed to represent true marker effects, whereas small values are regressed back substantially, <italic>i.e</italic>. are unlikely to represent a true effect. In contrast, if Best Linear Unbiased Prediction (BLUP) of marker effects is used, <italic>i.e</italic>. a normal prior distribution of the marker effects, the regression does not depend on Y and is a constant equal to <italic>&#x003c3;</italic><sup>2</sup>/(<italic>&#x003c3;</italic><sup>2 </sup>+ <italic>&#x003c3;</italic><sub>m</sub><sup>2</sup>), <italic>i.e</italic>. E(g|Y) = Y* <italic>&#x003c3;</italic><sup>2</sup>/(<italic>&#x003c3;</italic><sup>2 </sup>+ <italic>&#x003c3;</italic><sub>m</sub><sup>2</sup>), where <italic>&#x003c3;</italic><sub>m</sub><sup>2 </sup>is the variance of the marker effects, which will be <italic>&#x003c3;</italic><sub>a</sub><sup>2</sup>/m. This distinction is due to the use of the normal prior instead of the exponential and, as a consequence, the heavier tails giving credence to large marker effects. Nevertheless the high value of E [g|Y]/Y when using the exponential prior may not be a desirable effect, if outlier data points are encountered.</p><p>The variance due to a marker is Var("Marker") = Var(b<sub>i</sub>)Var(g). Here we standardised the variance of the genotypes to Var(b<sub>i</sub>) = 1, <italic>i.e</italic>. the prior variance assumed for the marker effects, g, applies directly for the variance due to the marker, and thus does not depend on marker frequency. We prefer this parameterisation, assuming that the variance of the marker effects is frequency dependent, because (1) QTL with large effects are expected to be at rare frequencies, which implies that the variance of the QTL is roughly constant (at least considerably more constant than when QTL effects were not frequency dependent); (2) if we assume that the QTL variance needs to be above a certain threshold before the markers pick up its effect, these QTL will have a much more constant variance than randomly picked QTL. The algorithm is equally capable of handling the coding of b<sub>i </sub>as 0, 1, and 2, (or after subtracting the mean -2p, (1&#x02013;2p), and 2(1-p)) for the genotypes mm, Mm, and MM, respectively. The accuracies of the GW-EBV were virtually the same as those in Table <xref ref-type="table" rid="T1">1</xref> when the latter parameterisation of the b<sub>i </sub>was used (result not shown).</p><p>The computational advantage of our fast algorithm for the BayesB approach to GW-EBV will not outweigh the reduced accuracy observed, if confirmed for typical trait architecture, when used in practical breeding schemes and the computational time and effort can be afforded. If, in practice, breeding schemes wish to select upon GW-EBV that require frequent updating, then a more appropriate comparison is between frequently updated fBayesB estimates of marker effects and the use of 'old' MCMC based estimates of marker effects, where the GW-EBV of animals are calculated without updating the estimates of marker effects, because of computational constraints. In the latter case there will be a loss of accuracy. It will depend on the amount of new information coming into the breeding value evaluation system, which of these alternatives should be favoured. In simulations of breeding schemes and in cross-validation testing of GW-EBV, the large number of EBV evaluations required may make our fast algorithm the only means to implement BayesB type genome-wide breeding value estimation.</p></sec><sec><title>Competing interests</title><p>The authors declare that they have no competing interests.</p></sec><sec><title>Authors' contributions</title><p>THEM analysed the data and drafted the manuscript; TRS simulated the data; RS performed literature search on EM type of algorithms and came up with the ICE algorithm; JAW derived the analytical integrations and helped drafting the manuscript. All authors approved the final version of the paper.</p></sec><sec><title>Appendix 1</title><sec><title>Analytical derivation of E [g|Y]</title><p>Here we will analytically derive the integrals in (4) in the main text. The prior <italic>&#x003c0;</italic>(<italic>g</italic>) as described in the text is:</p><p><disp-formula id="bmcMB1"><label>(B1)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M36" name="1297-9686-41-2-i24" overflow="scroll"><mml:semantics><mml:mrow><mml:mi>&#x003c0;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac bevelled="true"><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mi>&#x003b3;</mml:mi><mml:mi>&#x003bb;</mml:mi><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:mo>|</mml:mo><mml:mi>g</mml:mi><mml:mo>|</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003b3;</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x003b4;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math></disp-formula></p><p>where <italic>&#x003b4;</italic>(<italic>g</italic>) is the Dirac delta function <ext-link ext-link-type="uri" xlink:href="http://mathworld.wolfram.com/DeltaFunction.html"/>. The Delta function has the property that <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M37" name="1297-9686-41-2-i25" overflow="scroll"><mml:semantics><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>&#x0222b;</mml:mo><mml:mi>a</mml:mi><mml:mi>b</mml:mi></mml:msubsup><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x003b4;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:semantics></mml:math></inline-formula> if a &#x0003c; 0 &#x0003c; b and 0 otherwise, consequently <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M38" name="1297-9686-41-2-i26" overflow="scroll"><mml:semantics><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>&#x0222b;</mml:mo><mml:mi>a</mml:mi><mml:mi>b</mml:mi></mml:msubsup><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x003b4;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:semantics></mml:math></inline-formula> if a &#x0003c; c &#x0003c; b and 0 otherwise. The numerator of (4) involves an integration from -&#x0221e; to +&#x0221e;, which for the first term in (B1) is here split into:</p><p><disp-formula id="bmcMB2"><label>(B2)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M39" name="1297-9686-41-2-i27" overflow="scroll"><mml:semantics><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>&#x0222b;</mml:mo><mml:mn>0</mml:mn><mml:mrow><mml:mo>+</mml:mo><mml:mi>&#x0221e;</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mi>g</mml:mi><mml:mi>&#x003b3;</mml:mi><mml:mfrac><mml:mi>&#x003bb;</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mi>&#x003c3;</mml:mi><mml:msqrt><mml:mrow><mml:mn>2</mml:mn><mml:mi>&#x003c0;</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:mi>g</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>g</mml:mi><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>&#x0222b;</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>&#x0221e;</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup><mml:mrow><mml:mi>g</mml:mi><mml:mi>&#x003b3;</mml:mi><mml:mfrac><mml:mi>&#x003b3;</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mi>&#x003c3;</mml:mi><mml:msqrt><mml:mrow><mml:mn>2</mml:mn><mml:mi>&#x003c0;</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:mi>g</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:semantics></mml:math></disp-formula></p><p>The first term in (B2) involves <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M40" name="1297-9686-41-2-i28" overflow="scroll"><mml:semantics><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac bevelled="true"><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>/</mml:mo><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:mi>g</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math></inline-formula> and the exponent can be re-expressed as:</p><p><disp-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M41" name="1297-9686-41-2-i29" overflow="scroll"><mml:semantics><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac bevelled="true"><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>/</mml:mo><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:mi>g</mml:mi><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac bevelled="true"><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>g</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>/</mml:mo><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac bevelled="true"><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msup><mml:mi>&#x003bb;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:semantics></mml:math></disp-formula></p><p>The term <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M42" name="1297-9686-41-2-i30" overflow="scroll"><mml:semantics><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac bevelled="true"><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msup><mml:mi>&#x003bb;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:mi>Y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math></inline-formula> does not involve g and is a constant in the integration, whilst the remaining part, <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M43" name="1297-9686-41-2-i31" overflow="scroll"><mml:semantics><mml:mrow><mml:mi>exp</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac bevelled="true"><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>g</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>/</mml:mo><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math></inline-formula>, is proportional to a normal density with mean (<italic>Y </italic>&#x02013; <italic>&#x003bb;&#x003c3;</italic><sup>2</sup>) and variance <italic>&#x003c3;</italic><sup>2</sup>. Now collecting terms, the first term of (B2) becomes:</p><p><disp-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M44" name="1297-9686-41-2-i32" overflow="scroll"><mml:semantics><mml:mrow><mml:mstyle scriptlevel="+1"><mml:mfrac bevelled="true"><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mi>&#x003b3;</mml:mi><mml:mi>&#x003bb;</mml:mi><mml:mi>exp</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac bevelled="true"><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msup><mml:mi>&#x003bb;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi>exp</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:mi>Y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>&#x0222b;</mml:mo><mml:mn>0</mml:mn><mml:mrow><mml:mo>+</mml:mo><mml:mi>&#x0221e;</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mi>g</mml:mi><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>&#x003c3;</mml:mi><mml:msqrt><mml:mrow><mml:mn>2</mml:mn><mml:mi>&#x003c0;</mml:mi></mml:mrow></mml:msqrt><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mstyle><mml:mi>exp</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac bevelled="true"><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>g</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>/</mml:mo><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:semantics></mml:math></disp-formula></p><p>The integrand may be recognised as being proportional to the mean of a truncated normal distribution, where the truncation point is 0, and truncated normal distributed has mean (<italic>Y </italic>&#x02013; <italic>&#x003bb;&#x003c3;</italic><sup>2</sup>) and variance <italic>&#x003c3;</italic><sup>2</sup>. The constant of proportionality is the further normalising required for the true truncated density, which is [1 &#x02013; &#x003a6;(0; (<italic>Y </italic>&#x02013; <italic>&#x003bb;&#x003c3;</italic><sup>2</sup>), <italic>&#x003c3;</italic><sup>2</sup>)], where &#x003a6;(<italic>x</italic>; <italic>&#x003bc;</italic>, <italic>&#x003c3;</italic><sup>2</sup>) is the cumulative normal distribution function with mean <italic>&#x003bc; </italic>and variance <italic>&#x003c3;</italic><sup>2</sup>. Calculating the mean of a truncated normal distribution belongs to the standard tools used in animal breeding (involving the standardisation of the distribution and calculating the intensity of selection; <italic>e.g</italic>. [<xref ref-type="bibr" rid="B7">7</xref>]). For brevity, we define here the function &#x00398;<sub><italic>U</italic></sub>(<italic>x</italic>; <italic>&#x003bc;</italic>, <italic>&#x003c3;</italic><sup>2</sup>), which represents the mean of an upper truncated normal distribution with mean <italic>&#x003bc; </italic>and variance <italic>&#x003c3;</italic><sup>2 </sup>truncated at x. After accounting for the scaling the first term of (B2) is seen to be:</p><p><disp-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M45" name="1297-9686-41-2-i33" overflow="scroll"><mml:semantics><mml:mrow><mml:mstyle scriptlevel="+1"><mml:mfrac bevelled="true"><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mi>&#x003b3;</mml:mi><mml:mi>&#x003bb;</mml:mi><mml:mi>exp</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac bevelled="true"><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msup><mml:mi>&#x003bb;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi>exp</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:mi>Y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003a6;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:msub><mml:mi>&#x00398;</mml:mi><mml:mi>U</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math></disp-formula></p><p>Using a very similar derivation, the second term of (B2) becomes:</p><p><disp-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M46" name="1297-9686-41-2-i34" overflow="scroll"><mml:semantics><mml:mrow><mml:mstyle scriptlevel="+1"><mml:mfrac bevelled="true"><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mi>&#x003b3;</mml:mi><mml:mi>&#x003bb;</mml:mi><mml:mi>exp</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac bevelled="true"><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msup><mml:mi>&#x003bb;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi>exp</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:mi>Y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x003a6;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>+</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>&#x00398;</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>+</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math></disp-formula></p><p>where &#x00398;<sub><italic>L</italic></sub>(<italic>x</italic>; <italic>&#x003bc;</italic>, <italic>&#x003c3;</italic><sup>2</sup>) represents the mean of a lower truncated normal distribution with mean <italic>&#x003bc; </italic>and variance <italic>&#x003c3;</italic><sup>2 </sup>truncated at x. From (B1) the final term of the numerator of equation (4) is <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M47" name="1297-9686-41-2-i35" overflow="scroll"><mml:semantics><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>&#x0222b;</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>&#x0221e;</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mi>&#x0221e;</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003b3;</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>&#x003c3;</mml:mi><mml:msqrt><mml:mrow><mml:mn>2</mml:mn><mml:mi>&#x003c0;</mml:mi></mml:mrow></mml:msqrt><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mstyle><mml:mi>exp</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac bevelled="true"><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>/</mml:mo><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x003b4;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula> which enumerates to 0 following the rules of the Dirac delta-function.</p><p>The integral in the denominator of equation (4), follows similar arguments to the numerator but there is no g in the integrand so that the integrals now calculate the probability masses associated with the truncated distributions of their means. The term with the Dirac delta function integrates to:</p><p><disp-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M48" name="1297-9686-41-2-i36" overflow="scroll"><mml:semantics><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>&#x0222b;</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>&#x0221e;</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mi>&#x0221e;</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003b3;</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>&#x003c3;</mml:mi><mml:msqrt><mml:mrow><mml:mn>2</mml:mn><mml:mi>&#x003c0;</mml:mi></mml:mrow></mml:msqrt><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mstyle><mml:mi>exp</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac bevelled="true"><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>/</mml:mo><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x003b4;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>g</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003b3;</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>&#x003c3;</mml:mi><mml:msqrt><mml:mrow><mml:mn>2</mml:mn><mml:mi>&#x003c0;</mml:mi></mml:mrow></mml:msqrt><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>exp</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac bevelled="true"><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msup><mml:mi>Y</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>/</mml:mo><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math></disp-formula></p><p>After carrying out these calculations and some simplification, and denoting <italic>Y</italic><sup>- </sup>= <italic>Y </italic>&#x02013; <italic>&#x003bb;&#x003c3;</italic><sup>2 </sup>and <italic>Y</italic><sup>+ </sup>= <italic>Y </italic>+ <italic>&#x003bb;&#x003c3;</italic><sup>2 </sup>the equation (4) in the main text becomes:</p><p><disp-formula id="bmcMB3"><label>(B3)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M49" name="1297-9686-41-2-i37" overflow="scroll"><mml:semantics><mml:mrow><mml:mfrac><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:mi>Y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003a6;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>;</mml:mo><mml:msup><mml:mi>Y</mml:mi><mml:mo>&#x02212;</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>&#x00398;</mml:mi><mml:mi>U</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>;</mml:mo><mml:msup><mml:mi>Y</mml:mi><mml:mo>&#x02212;</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:mi>Y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x003a6;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>;</mml:mo><mml:msup><mml:mi>Y</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>&#x00398;</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>;</mml:mo><mml:msup><mml:mi>Y</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:mi>Y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003a6;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>;</mml:mo><mml:msup><mml:mi>Y</mml:mi><mml:mo>&#x02212;</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:mi>Y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x003a6;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>;</mml:mo><mml:msup><mml:mi>Y</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003b3;</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>&#x003b3;</mml:mi><mml:mi>&#x003bb;</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac bevelled="true"><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msup><mml:mi>&#x003bb;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x003d5;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>;</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:semantics></mml:math></disp-formula></p></sec></sec><sec><title>Appendix 2</title><sec><title>The likelihood of multivariate data can be described by a univariate likelihood function involving the sufficient statistics of the data</title><p>The multivariate likelihood of the data, <bold>y</bold>, as described by model (1) is:</p><p><disp-formula id="bmcMA1"><label>(A1)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M50" name="1297-9686-41-2-i38" overflow="scroll"><mml:semantics><mml:mrow><mml:msub><mml:mi>&#x003d5;</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mo>;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>g</mml:mi><mml:mi>b</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>I</mml:mi></mml:mstyle><mml:msubsup><mml:mi>&#x003c3;</mml:mi><mml:mi>e</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x0221d;</mml:mo><mml:mi>exp</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>0.5</mml:mn><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mo>&#x02212;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>g</mml:mi><mml:mi>b</mml:mi></mml:mstyle><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mo>&#x02212;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>g</mml:mi><mml:mi>b</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msubsup><mml:mi>&#x003c3;</mml:mi><mml:mi>e</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math></disp-formula></p><p>where &#x0221d; means equal up to a proportionality constant; g = the effect of the SNP, and <bold>b </bold>is a nx1 vector of covariates obtained from the SNP genotyping. We re-express the term (<bold>y </bold>&#x02013; gb)'(<bold>y </bold>&#x02013; <bold>gb</bold>)) as:</p><p><disp-formula id="bmcMA2"><label>(A2)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M51" name="1297-9686-41-2-i39" overflow="scroll"><mml:semantics><mml:mrow><mml:mtable columnalign="right"><mml:mtr columnalign="right"><mml:mtd columnalign="right"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:msup><mml:mi>y</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mi>y</mml:mi></mml:mstyle><mml:mo>&#x02212;</mml:mo><mml:mn>2</mml:mn><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>g</mml:mi><mml:msup><mml:mi>b</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mi>y</mml:mi></mml:mstyle><mml:mo>+</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>g</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mn>2</mml:mn></mml:mstyle></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:msup><mml:mi>b</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mi>b</mml:mi></mml:mstyle></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="right"><mml:mtd columnalign="right"><mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>g</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mn>2</mml:mn></mml:mstyle></mml:msup><mml:mo>&#x02212;</mml:mo><mml:mn>2</mml:mn><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>g</mml:mi></mml:mstyle><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:msup><mml:mi>b</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mi>b</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mn>1</mml:mn></mml:mstyle></mml:mrow></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:msup><mml:mi>b</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mi>y</mml:mi></mml:mstyle></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:msup><mml:mi>b</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mi>b</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:msup><mml:mi>y</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mi>y</mml:mi></mml:mstyle></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="right"><mml:mtd columnalign="right"><mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>g</mml:mi></mml:mstyle><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:msup><mml:mi>b</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mi>b</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mn>1</mml:mn></mml:mstyle></mml:mrow></mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:msup><mml:mi>b</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mi>y</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mn>2</mml:mn></mml:mstyle></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:msup><mml:mi>b</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mi>b</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>&#x02212;</mml:mo><mml:mfrac><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:msup><mml:mi>y</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mi>b</mml:mi><mml:msup><mml:mi>b</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mi>y</mml:mi></mml:mstyle></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:msup><mml:mi>b</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mi>b</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:msup><mml:mi>y</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mi>y</mml:mi></mml:mstyle></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:semantics></mml:math></disp-formula></p><p>If we use the likelihood (A1) for the estimation of the SNP effect g, than the last two terms in Equation (A2) are constant and thus do not affect the maximisation of the likelihood. Hence, for the estimation of g, (A1) could be expressed as a single-variate density:</p><p><disp-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M52" name="1297-9686-41-2-i40" overflow="scroll"><mml:semantics><mml:mrow><mml:mi>&#x003d5;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>g</mml:mi></mml:mstyle><mml:mo>;</mml:mo><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x0221d;</mml:mo><mml:mi>exp</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>0.5</mml:mn><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>g</mml:mi></mml:mstyle><mml:mo>&#x02212;</mml:mo><mml:mi>Y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math></disp-formula></p><p>where <italic>Y </italic>= (<bold>b'b</bold>)<sup>-1</sup><bold>b'y </bold>and <italic>&#x003c3;</italic><sup>2 </sup>= (<bold>b'b</bold>)<sup>-1</sup><inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M53" name="1297-9686-41-2-i4" overflow="scroll"><mml:semantics><mml:mrow><mml:msubsup><mml:mi>&#x003c3;</mml:mi><mml:mi>e</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:semantics></mml:math></inline-formula> are the sufficient statistics of the data.</p></sec></sec></body><back><ack><sec><title>Acknowledgements</title><p>Helpful comments from two anonymous reviewers are gratefully acknowledged.</p></sec></ack><ref-list><ref id="B1"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Meuwissen</surname><given-names>THE</given-names></name><name><surname>Hayes</surname><given-names>BJ</given-names></name><name><surname>Goddard</surname><given-names>ME</given-names></name></person-group><article-title>Prediction of total genetic value using genome wide dense marker maps</article-title><source>Genetics</source><year>2001</year><volume>157</volume><fpage>1819</fpage><lpage>1829</lpage><pub-id pub-id-type="pmid">11290733</pub-id></citation></ref><ref id="B2"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Goddard</surname><given-names>ME</given-names></name></person-group><article-title>Genomic selection: prediction of accuracy and maximisation of long term response</article-title><source>Genetica</source><year>2008</year><comment>DOI 10.1007/s10709-008-9308-0</comment><pub-id pub-id-type="pmid">18704696</pub-id></citation></ref><ref id="B3"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Besag</surname><given-names>J</given-names></name></person-group><article-title>On the Statistical Analysis of Dirty Pictures</article-title><source>J R Stat Soc [Ser B]</source><year>1986</year><volume>48</volume><fpage>259</fpage><lpage>302</lpage></citation></ref><ref id="B4"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Solberg</surname><given-names>TR</given-names></name><name><surname>Sonesson</surname><given-names>AK</given-names></name><name><surname>Woolliams</surname><given-names>JA</given-names></name><name><surname>Meuwissen</surname><given-names>THE</given-names></name></person-group><article-title>Genomic selection using different marker types and densities</article-title><source>J Anim Sci</source><year>2008</year><comment></comment><pub-id pub-id-type="pmid">18407980</pub-id></citation></ref><ref id="B5"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>George</surname><given-names>EI</given-names></name><name><surname>McCulloch</surname><given-names>RE</given-names></name></person-group><article-title>Variable selection via Gibbs sampling</article-title><source>J Am Statist Assoc</source><year>1993</year><volume>88</volume><fpage>881</fpage><lpage>889</lpage><pub-id pub-id-type="doi">10.2307/2290777</pub-id></citation></ref><ref id="B6"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Hayes</surname><given-names>BJ</given-names></name><name><surname>Goddard</surname><given-names>ME</given-names></name></person-group><article-title>The distribution of the effects of genes affecting quantitative traits in livestock</article-title><source>Genet Sel Evol</source><year>2001</year><volume>33</volume><fpage>209</fpage><lpage>229</lpage><pub-id pub-id-type="pmid">11403745</pub-id><pub-id pub-id-type="doi">10.1051/gse:2001117</pub-id></citation></ref><ref id="B7"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Falconer</surname><given-names>DS</given-names></name><name><surname>Mackay</surname><given-names>TFS</given-names></name></person-group><source>An introduction to quantitative genetics</source><year>1996</year><publisher-name>Essex: Longman Group</publisher-name></citation></ref></ref-list></back></article>