<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN" "archivearticle.dtd"><article xml:lang="EN" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">J Comput Neurosci</journal-id><journal-title>Journal of Computational Neuroscience</journal-title><issn pub-type="ppub">0929-5313</issn><issn pub-type="epub">1573-6873</issn><publisher><publisher-name>Springer US</publisher-name><publisher-loc>Boston</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">18214662</article-id><article-id pub-id-type="pmc">2633940</article-id><article-id pub-id-type="publisher-id">73</article-id><article-id pub-id-type="doi">10.1007/s10827-007-0073-3</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Neuron splitting in compute-bound parallel network simulations enables runtime scaling with twice as many processors</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name name-style="western"><surname>Hines</surname><given-names>Michael L.</given-names></name><address><email>michael.hines@yale.edu</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name name-style="western"><surname>Eichner</surname><given-names>Hubert</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name name-style="western"><surname>Sch&#x000fc;rmann</surname><given-names>Felix</given-names></name><xref ref-type="aff" rid="Aff3">3</xref></contrib><aff id="Aff1"><label>1</label>Computer Science, Yale University, New Haven, CT USA </aff><aff id="Aff2"><label>2</label>Max-Planck-Institute of Neurobiology, Martinsried, Germany </aff><aff id="Aff3"><label>3</label>Brain Mind Institute, EPFL, Lausanne, Switzerland </aff></contrib-group><author-notes><fn fn-type="com"><p><bold>Action Editor: Terrence Sejnowski</bold></p></fn></author-notes><pub-date pub-type="epub"><day>23</day><month>1</month><year>2008</year></pub-date><pub-date pub-type="ppub"><month>8</month><year>2008</year></pub-date><volume>25</volume><issue>1</issue><fpage>203</fpage><lpage>210</lpage><history><date date-type="received"><day>4</day><month>10</month><year>2007</year></date><date date-type="rev-recd"><day>7</day><month>12</month><year>2007</year></date><date date-type="accepted"><day>26</day><month>12</month><year>2007</year></date></history><permissions><copyright-statement>&#x000a9; Springer Science+Business Media, LLC 2007</copyright-statement></permissions><abstract xml:lang="EN"><p>Neuron tree topology equations can be split into two subtrees and solved on different processors with no change in accuracy, stability, or computational effort; communication costs involve only sending and receiving two double precision values by each subtree at each time step. Splitting cells is useful in attaining load balance in neural network simulations, especially when there is a wide range of cell sizes and the number of cells is about the same as the number of processors. For compute-bound simulations load balance results in almost ideal runtime scaling. Application of the cell splitting method to two published network models exhibits good runtime scaling on twice as many processors as could be effectively used with whole-cell balancing.</p></abstract><kwd-group><title>Keywords</title><kwd>Computer simulation</kwd><kwd>Computer modeling</kwd><kwd>Neuronal networks</kwd><kwd>Load balance</kwd><kwd>Parallel simulation</kwd></kwd-group><custom-meta-wrap><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; Springer Science+Business Media, LLC 2008</meta-value></custom-meta></custom-meta-wrap></article-meta></front><body><sec id="Sec1" sec-type="introduction"><title>Introduction</title><p>Load balance is a necessary condition for efficient parallel simulation of networks of neurons. That is, since the overall speed of the simulation is rate limited by the processor which has the most work to do, greatest efficiency is achieved when the maximum workload is as close as possible to the average workload.</p><p>Neuronal network simulations are often perfectly balanced by choosing the number of each cell type to be an integer multiple of the number of processors. If individual cell processing time does not vary too widely, or the number of cells is much greater than the number of processors, a simple round robin distribution algorithm analogous to card dealing is usually good enough to divide the load reasonably uniformly among the available processors (cf Migliore et al. <xref ref-type="bibr" rid="CR9">2006</xref>). When the number of processors is such that only a small number of cells can be on each processor, it is often sufficient to iteratively choose the cell with the longest processing time and put it on the least used processor. More sophisticated algorithms such as the Complete Karmarkar&#x02013;Karp algorithm (Korf <xref ref-type="bibr" rid="CR6">1998</xref>) can also be employed.</p><p>Although investigators often choose to scale the network size with the number of available processors to keep runtime more or less constant (weak scaling), on occasion it is desirable to keep the problem size the same and reduce runtime through the use of as many processors as is consistent with strong scaling. Strong scaling is obviously impossible via whole-cell load balancing when the number of processors is greater than the number of cells. With heterogeneous size cells, strong scaling fails even earlier. Clearly, the strong scaling regime can be extended to larger numbers of processors only by splitting cells into smaller pieces.</p><p>Very strong coupling between adjacent compartment voltages demands implicit methods for numerical stability with reasonable time steps and therefore a matrix equation must be solved every time step. Though the matrix setup can obviously be parallelized down to the individual compartment level, optimal solution of the tree matrix via Gaussian elimination is normally accomplished by a recursive, and therefore serial, algorithm, e.g. Mascagni and Sherman (<xref ref-type="bibr" rid="CR8">1996</xref>) or Hines (<xref ref-type="bibr" rid="CR1">1984</xref>). This paper describes a method for splitting cells into two subtrees simulated on different processors with no change in accuracy, stability, and computational effort, and with a communication cost consisting of only two double precision values sent and received by each subtree at each time step. The method is closely related to one discussed in Hines (<xref ref-type="bibr" rid="CR2">1994</xref>) in the context of Cray YMP vectorization. Since a cell can be split at one of many locations, satisfactory load balance is routinely obtained by filling a processor with cells to just below the average workload and topping off with a split piece.</p><p>We compare the runtime scaling behavior vs number of processors for two whole-cell load balance methods and the cell splitting method using two published network models: a thalamocortical model by Traub et&#x000a0;al. (<xref ref-type="bibr" rid="CR11">2005</xref>) and a dentate gyrus model by Santhakumar et&#x000a0;al. (<xref ref-type="bibr" rid="CR10">2005</xref>).</p></sec><sec id="Sec2" sec-type="methods"><title>Methods</title><p>All simulations were carried out with the NEURON v6.1 simulation program (Hines and Carnevale <xref ref-type="bibr" rid="CR4">2007</xref>). The &#x0201c;splitcell&#x0201d; functionality is available when NEURON is configured with the <preformat>--with-paranrn</preformat> option which requires pre-installation of an implementation of the message passing interface (MPI). Performance tests were carried out on the EPFL IBM Blue Gene/L.</p><p>Load balance and cell splitting algorithms were tested by modifying two published network models from the ModelDB section of the Senselab database (<ext-link ext-link-type="uri" xlink:href="http://senselab.med.yale.edu">http://senselab.med.yale.edu</ext-link>): Traub et al. (<xref ref-type="bibr" rid="CR11">2005</xref>), and Santhakumar et al. (<xref ref-type="bibr" rid="CR10">2005</xref>). In order to focus on load balance with reduced use of computer resources we scaled down the Traub model tenfold and turned off gap junction interactions. This left a minimal model of 356 cells of 14 types with all type ratios preserved. In all cases the parallel models produce quantitatively identical spike times as their original serial counterparts. Complete model code with modifications used in this paper is available from ModelDB with accession number 97917.</p><sec id="Sec3"><title>Numerical methods for cell splitting</title><p>The most important efficiency attribute of spatially discretized neuron equations is that the number of arithmetic operations required to solve the tree topology matrix equations is exactly the same as for a tridiagonal matrix representing an unbranched cable with the same number of compartments (cf Hines and Carnevale <xref ref-type="bibr" rid="CR3">1997</xref>). Optimal Gaussian elimination triangularizes the matrix proceeding from leaves to the root of the tree and back substitutes in reverse order from root to leaves. At a branch point, one cannot continue the triangularization process till the subtrees at the branch have been triangularized. Conversely, one cannot start on the back substitution of the subtrees of a branch point until after the parent cable has been back substituted. Any compartment can serve as the root of the tree. In the simplest case of an unbranched single cable, it takes exactly the same number of operations to triangularize simultaneously from the two ends to some middle point and back substitute from there as it does in the normal sequence of triangularization from one end to the other.</p><p>The current balance equation of the <italic>i</italic><sup><italic>th</italic></sup> compartment has the form <disp-formula id="Equ1"><label>1</label><tex-math id="M1">\documentclass[12pt]{minimal}\usepackage{amsmath}\usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy}\usepackage{mathrsfs}\usepackage{upgreek}\setlength{\oddsidemargin}{-69pt}\begin{document}$$ a_{\!p} V_{\!\!p} + d_i V_{\!i} + \sum_c a_c V_{\!c} ~=~ b_{\!i} $$\end{document}</tex-math></disp-formula>where the <italic>V</italic><sub><italic>i</italic></sub>, <italic>V</italic><sub><italic>p</italic></sub>, and <italic>V</italic><sub><italic>c</italic></sub> refer to the voltages of this, the unique parent, and all the child compartments respectively. The <italic>a</italic> coefficients are constants depending only on the shape of the compartments, capacitance, and axial resistance. The <italic>d</italic> and <italic>b</italic> are evaluated using only parameters and variables known at the beginning of the time step in the <italic>i</italic><sup><italic>th</italic></sup> compartment. After triangularization has eliminated the effect of child voltages on the current balance equations, each compartment equation contains only two terms, one involving this compartment voltage and one involving the parent voltage, with changed values for <italic>d</italic><sub><italic>i</italic></sub> and <italic>b</italic><sub><italic>i</italic></sub><disp-formula id="Equa"><tex-math id="M2">\documentclass[12pt]{minimal}\usepackage{amsmath}\usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy}\usepackage{mathrsfs}\usepackage{upgreek}\setlength{\oddsidemargin}{-69pt}\begin{document}$$ a_{\!p} V_{\!\!p} + d'_i V_{\!i} ~=~ b'_i $$\end{document}</tex-math></disp-formula> and, since the root compartment has no parent <disp-formula id="Equb"><tex-math id="M3">\documentclass[12pt]{minimal}\usepackage{amsmath}\usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy}\usepackage{mathrsfs}\usepackage{upgreek}\setlength{\oddsidemargin}{-69pt}\begin{document}$$ V_{\!r} ~=~ b_{\!r} / d_{r} $$\end{document}</tex-math></disp-formula> which can then be substituted into each of the root&#x02019;s child equations.</p><p>It is clear that there is no impediment to simultaneous triangularization of each subtree of the root compartment. The only question is precisely how to handle the arithmetic operations that modify the root compartment equations since one of the child compartments is on a different processor. One possibility is to split a cell at the boundary between two compartments. In this case, there are really two root compartments and after triangularization on each processor, the problem is to solve the two root equations which are coupled by the conductance between the centers of those compartments. I.e. <disp-formula id="Equc"><tex-math id="M4">\documentclass[12pt]{minimal}\usepackage{amsmath}\usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy}\usepackage{mathrsfs}\usepackage{upgreek}\setlength{\oddsidemargin}{-69pt}\begin{document}$$\begin{gathered}d_{r1} V_{r1}  + a_{12} V_{r2}  = b_{r1}  \hfill \\  a_{21} V_{r1}  + d_{r2} V_{r2}  = b_{r2}  \hfill \\ \end{gathered} $$\end{document}</tex-math></disp-formula>Here, to complete the triangularization, the processor handling root 1 needs <italic>d</italic><sub><italic>r</italic>2</sub> and <italic>b</italic><sub><italic>r</italic>2</sub> from the processor handling root 2 and vice versa.</p><p>The other possibility is more in keeping with  NEURON&#x02019;s semantics of the &#x0201c;connect&#x0201d; statement. That is, imagine that two trees, simulatable in isolation have their roots connected by a zero resistance wire. This is tantamount to dividing the root compartment itself into two pieces and full triangularization ends up with two equations of the form <disp-formula id="Equd"><tex-math id="M5">\documentclass[12pt]{minimal}\usepackage{amsmath}\usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy}\usepackage{mathrsfs}\usepackage{upgreek}\setlength{\oddsidemargin}{-69pt}\begin{document}$$\begin{gathered}  d_{r1} V_r  + i_r  = b_{r1}  \hfill \\  d_{r2} V_r  - i_r  = b_{r2}  \hfill \\ \end{gathered} $$\end{document}</tex-math></disp-formula>where <italic>i</italic><sub><italic>r</italic></sub> is the current flowing in the (virtual) wire connecting the roots. In practice, <italic>i</italic><sub><italic>r</italic></sub> is not computed and uses no memory location. Instead, the two equations are added together by each machine exchanging its triangularized d and b and adding them to their corresponding quantities so that each machine redundantly solves <disp-formula id="Eque"><tex-math id="M6">\documentclass[12pt]{minimal}\usepackage{amsmath}\usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy}\usepackage{mathrsfs}\usepackage{upgreek}\setlength{\oddsidemargin}{-69pt}\begin{document}$$ (d_{r1} + d_{r2}) V_{\!r} ~=~ (b_{\!r1} + b_{\!r2}) $$\end{document}</tex-math></disp-formula> Considering Gaussian elimination only, the number of operations required for the two methods is almost identical. However, for several reasons we prefer splitting the root node itself despite the apparent redundancy of both processes computing the same value for <italic>V</italic><sub><italic>r</italic></sub>. First, as already mentioned, the second method corresponds to the semantics of the NEURON connect statement <preformat>connect child(0or1), parent(x)</preformat> which represents the connection of either end of a child cable to any location of the parent cable without introducing any extra conductance at the connection point. The concept of connecting two trees together by a wire is somewhat simpler than requiring both processes to compute the constant coupling coefficient which depends on length and diameter of both compartments. Second, and more substantively, splitting at the boundary between compartments requires, in addition to the exchange of the triangularized d and b, an exchange of the values of <italic>V</italic><sub><italic>r</italic>1</sub> and <italic>V</italic><sub><italic>r</italic>2</sub> at the beginning of the time step since evaluation of <italic>b</italic><sub><italic>r</italic>1</sub> during the setup phase depends on the previous step&#x02019;s value for <italic>V</italic><sub><italic>r</italic>2</sub> and vice versa. It should also be mentioned that, although NEURON does not currently support splitcell (or gap junction) simulation using the variable step methods, because synchronization of the event queues on different processors has not yet been implemented, the variable step method setup phase which involves evaluation of the right hand side of <disp-formula id="Equf"><tex-math id="M7">\documentclass[12pt]{minimal}\usepackage{amsmath}\usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy}\usepackage{mathrsfs}\usepackage{upgreek}\setlength{\oddsidemargin}{-69pt}\begin{document}$$ c y' ~=~ f(y, t) $$\end{document}</tex-math></disp-formula> does require an estimate of the value of the <italic>i</italic><sub><italic>r</italic></sub> current and so it is not clear at present whether the strategy of splitting the root node will retain its setup advantage over splitting at a compartment boundary. The answer depends on details of the way NEURON handles evaluation of the voltage at the zero area nodes at the ends of sections.</p></sec><sec id="Sec4"><title>NEURON support for splitcell computation</title><p>In most cases the parent location in a connect statement is also the 0 or 1 end of the parent and that is the situation captured by an extension to the <preformat>ParallelContext</preformat> class that NEURON uses to manage interprocessor communication. Assuming the object reference, <preformat>pc</preformat>, references an instance of the <preformat>ParallelContext</preformat> class, then a virtual interprocessor connection is made between two trees by a pair of corresponding <preformat>rootsection {pc.splitcell(otherhost)}</preformat> Here, it is an error if the <preformat>rootsection</preformat> is connected to a parent section, i.e. is not the root of its tree. The argument, <preformat>otherhost</preformat>, must be <preformat>pc.id</preformat> plus or minus 1 and the <preformat>splitcell</preformat> method call makes the connection to the location identified by the corresponding call to <preformat>splitcell</preformat> on the other host. It can be seen that we purposely limit a cell to be split between hosts i and i+1. Thus, a host can deal with at most two split cells, one part of one cell on host i-1 and one part of the other cell on host i+1. This allows MPI_Send and MPI_Recv to take advantage of the Blue Gene torus topology to minimize communication time. It sacrifices the obvious possibilities inherent in choosing a branch point as the root node and dividing a cell into three pieces. It also disallows the possibility of splitting a cell and simulating the two pieces in a single process. But the latter is more or less pointless and the same result can be obtained with the connect statement.</p><p>Splitcell is well suited to the practical issues of specifying cells in the NEURON environment. That is, most models define cell types that are instantiated as a whole and it is desirable to split different instances of the same type at different locations. Thus it is proper to separate the code that defines a cell from the code that disconnects the two subtrees, destroys the portion of the cell not needed on a host, re-roots the remaining subtree so that the disconnect point is the root node, and calls the splitcell method on the root of the remaining subtree. A wrapper method has been provided in NEURON&#x02019;s tool library to carry out these subsidiary operations so that the cell is split properly if the same statement is executed on the two processes that have instantiated a cell. Clearly, there is a good deal of wasted effort in setting up an entire cell and then throwing away half of it. But in a network context, splitting is a small portion of the total network setup time, which in turn is very small compared to runtime. Also, if administrative issues can be overcome in regard to processes creating only the subtrees they need, there is no reason one cannot connect those subtrees with the <preformat>ParallelContext.splitcell</preformat> method.</p></sec></sec><sec id="Sec5" sec-type="results"><title>Results</title><sec id="Sec6"><title>Load balance</title><p>Cells differ in the amount of processing time they add to network simulation runtime due to differences in number of cell compartments, types of channels in a compartment, the number and complexity of synapses, and the number of spikes handled by the synapses  on a cell.</p><p>The simplest whole cell load balance strategy ignores differences in individual cell processing time and distributes cells (each one identified by a global unique identifier, gid) according to the round robin or card dealing algorithm</p><p><preformat>for (gid = pc.id; gid &#x0003c; ncell;</preformat></p><p><preformat>&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;gid += pc.nhost) {</preformat></p><p><preformat>&#x000a0;&#x000a0;&#x000a0;&#x000a0;// create cell associated with gid</preformat></p><p><preformat>}</preformat></p><p>where <preformat>pc.id</preformat> and <preformat>pc.nhost</preformat> refers to the MPI rank and total number of MPI processes respectively. This is the recommended default method for parallel NEURON simulations and, based on the measured computation time on each processor, provides an initial measure of load balance to assess whether it is worthwhile to try methods that are more complicated but might yield superior performance.</p><p>The simplest load balance algorithm which takes into account differences in cell processing time is the &#x0201c;longest processing time&#x0201d; (LPT) algorithm in which one iteratively chooses the largest cell and puts it on the currently least used processor (cf Korf <xref ref-type="bibr" rid="CR6">1998</xref>). The use of LPT, as well as our splitcell load balance method described below, requires a weight assignment as close as possible to the actual computation time required by a cell during a simulation. Unfortunately, such fine grain measurement even at the whole cell level during a trial simulation introduces significant measurement artifacts and we have found it useful to use more easily measured proxies to estimate the relative computation time that would result from a given partition.</p><p>We have tested several proxies, e.g. number of NEURON sections, number of compartments, and number of equations. But the proxy or complexity measure that corresponds most closely to actual computation time is to measure the computation time of a 100 compartment cable with each membrane channel or mechanism inserted separately and normalize to the computation time of the cable with no channels present. We do this also for synapses by instantiating one per compartment with the caveat that since no spikes are handled, it may underestimate the computation time added by a synapse in the actual simulation.</p><p>With a complexity measure for each mechanism type and each elementary compartment (an empty compartment has complexity 1) it is straightforward to assign a total complexity value to each compartment, each cell as a whole, <italic>C</italic><sub><italic>i</italic></sub>, and the whole network, <italic>C</italic><sub><italic>n</italic></sub>. The load balance problem can then be expressed as partitioning the network so that the maximum complexity on any processor is as close as possible to <inline-formula id="IEq1"><!-- Alternate image not processed: 10827_2007_73_Article_IEq1.gif --><tex-math id="M8">\documentclass[12pt]{minimal}\usepackage{amsmath}\usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy}\usepackage{mathrsfs}\usepackage{upgreek}\setlength{\oddsidemargin}{-69pt}\begin{document}$C_n/{\tt nhost}$\end{document}</tex-math></inline-formula>.</p><p>Figure&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref> shows the number and complexity range of the cells which are to be distributed among the processors for the Santhakumar and Traub models. In order to obtain the complexity data for each cell, we perform a complete setup of the entire network, including synapses, using the default round robin distribution. Each host appends to a file the complexity of each cell on that host. There are 5 distinct cell sizes for the Santhakumar model. The single cell with complexity 0 is an artificial cell used for stimulation. The 15 largest are 17 compartment Mossy cells and the most common are 9 compartment Granule cells. The location and number of synapses does not vary within a type. The Mossy cell complexity of 1,487 means that we predict it will take 1,487 times longer to solve the equations for one of those cells than to solve a single empty compartment. The Traub model has 14 cell types. Within a type, number and locations of synapses are chosen randomly from type-to-type projection dependent distributions. For the particular instance shown here, there were 137 distinct complexity values and the 356 instances of those values are displayed in a histogram with bin size 50. Tufted deep IB cells with 61 compartments are the most common cell type, 80 of them. The 10 largest are thalamocortical relay cells with 137 compartments. The complexity information in the &#x0201c;whole-cell&#x0201d; file is used by the LPT algorithm to determine the distribution of cells on processors.<fig id="Fig1"><label>Fig.&#x000a0;1</label><caption><p>Cell complexity variation for the Santhakumar and reduced Traub model. For the Santhakumar model there are 500 cells with complexity 731</p></caption><graphic position="anchor" xlink:href="10827_2007_73_Fig1_HTML" id="MO1"/></fig></p><p>In addition to whole-cell complexity, each host also determines for each cell the set of complexity pairs for each possible split point. A branch point with a parent and two children adds three distinct subtree pairs, (parent alone, child1 + child2), (parent + child1, child2), and (parent + child2, child1) or 6 distinct complexity values to the set of possible split cell complexities. At branch points with more than three connected sections, typically at the soma which may have a dozen branches, <italic>nb</italic>, the <italic>nb</italic>*(<italic>nb</italic>&#x02009;&#x02212;&#x02009;1)/2 possible complexity pairs were arbitrarily reduced to 2*<italic>nb</italic> examples consisting of successive addition of the least or greatest remaining complexity subtree to the parent subtree.</p><p>The left side of Fig. <xref rid="Fig2" ref-type="fig">2</xref> shows the distinct split piece sizes for the cell types of the Santhakumar model. <fig id="Fig2"><label>Fig.&#x000a0;2</label><caption><p><italic>Left</italic> distinct split piece sizes for the cell types of the Santhakumar model. The number of cells for each type is indicated below the type label. <italic>Right</italic> example of filling 256 processors with 528 cells with 3% balance tolerance. The <italic>vertical lines</italic> with marks indicate the cell and piece sizes that add up to the load on selected (labeled by processor id) and adjacent processors. The <italic>horizontal line</italic> with complexity 1,572 indicates average proces sor load</p></caption><graphic position="anchor" xlink:href="10827_2007_73_Fig2_HTML" id="MO2"/></fig></p><p>The total complexity of each cell along with their sets of split piece complexity data was used to decide upon a distribution of cells and split cells on <preformat>nhost</preformat> processors where the maximum complexity on a processor was as close as feasible to the average complexity and with the constraint that only one cell can be split between processors <italic>i</italic> and <italic>i</italic>&#x02009;+&#x02009;1. Because of this constraint as well as the ability to split a cell at one of many locations, LPT is not directly applicable and we instead attempted to find accurately balanced partitions using simplistic heuristics which, nevertheless, were reasonably successful on our present networks.</p><p>The principle heuristic is to fill one processor at a time with the largest remaining whole cells. When a whole cell would cause the processor to exceed its maximum complexity, top off the processor by choosing the optimum split piece of that whole cell such that the processor has less than its maximum complexity. Then begin filling the next processor with the left over piece.</p><p>The result of the heuristic is illustrated on the right side of Fig. <xref rid="Fig2" ref-type="fig">2</xref> where the maximum complexity per processor was chosen to be 3% larger than the average complexity, <italic>C</italic><sub><italic>n</italic></sub>/256 (<italic>C</italic><sub><italic>n</italic></sub>&#x02009;=&#x02009;402,493), for the 528 cell Santhakumar network. In this case, the fill algorithm succeeded in that less than 256 processors were needed. The last piece (along with the 0 size stimulus) is placed on processor 252 and the last 3 processors are empty. Apart from those, processor 15 has the least load with a complexity of 1,325. Processor 28 has the greatest load with a complexity of 1,626. Notice that processor 0 is filled with a whole Mossy cell and topped off with the smallest piece of a second Mossy cell. Processor 1 is filled with the remaining (largest) piece of the second and the next to smallest piece of the third Mossy cell. If more than <preformat>nhost</preformat> processors are required by the fill algorithm, then the maximum complexity per processor has to be increased and we try again. For a 2% maximum above average complexity, the algorithm happens to need 262 processors, hence the acceptance of a 3% load imbalance for a 256 processor allocation.</p><p>The distribution information is written to an <preformat>nhost</preformat> specific file with a format such that it is a straightforward matter for each processor to quickly find the relevant section of the file and read only the information for processors <italic>i</italic>&#x02009;&#x02212;&#x02009;1 and <italic>i</italic> to determine which cells are to be instantiated on processor <italic>i</italic> and, if split, which portion is to be retained.</p></sec><sec id="Sec7"><title>Performance</title><p>Figure <xref rid="Fig3" ref-type="fig">3</xref> shows the runtime performance of the 528 cell Santhakumar and 356 cell Traub models as a function of number of processors using the three load balance algorithms described above. <fig id="Fig3"><label>Fig.&#x000a0;3</label><caption><p>Run time performance in seconds vs number of processors for the Santhakumar and Traub models and for three load balance algorithms. <italic>RR</italic> is round robin, <italic>LPT</italic> is longest processing time, and <italic>Split</italic> is for some cells split into two pieces and simulated on different processors. Because the Traub model has 356 cells, RR and LPT methods have the same runtime for 512 processors. <italic>Open circles</italic> show the average computation time (same for all balance methods). <italic>Dashed line</italic> shows ideal speedup (slope is &#x02212;&#x02009;1 on the log<sub>2</sub> vs log<sub>2</sub> plots) relative to average computation time with 32 processors</p></caption><graphic position="anchor" xlink:href="10827_2007_73_Fig3_HTML" id="MO3"/></fig></p><p>Table <xref rid="Tab1" ref-type="table">1</xref> shows the load imbalance of the distributions chosen by the round robin, least processing time, and split cell algorithms. The last two columns in Table <xref rid="Tab1" ref-type="table">1</xref> compare the predicted balance of the split cell method and the balance measured during a simulation and demonstrate that the complexity values derived from the processing time for individual channel and synapse types are reasonable proxies for total computation time. Of course, for 512 processors there are more processors than Traub model cells and so the round robin and longest processing time algorithms yield identical run times. <table-wrap id="Tab1"><label>Table&#x000a0;1</label><caption><p>Percentage load imbalance for Traub and Santhakumar models</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Model</th><th>#CPU</th><th>RR</th><th>LPT</th><th>Split CX</th><th>Split CT</th></tr></thead><tbody><tr><td rowspan="5">Traub</td><td char="." align="char">32</td><td char="." align="char">6</td><td char="." align="char">5</td><td char="." align="char">0</td><td char="." align="char">1</td></tr><tr><td char="." align="char">64</td><td char="." align="char">15</td><td char="." align="char">6</td><td char="." align="char">1</td><td char="." align="char">2</td></tr><tr><td char="." align="char">128</td><td char="." align="char">31</td><td char="." align="char">8</td><td char="." align="char">2</td><td char="." align="char">4</td></tr><tr><td char="." align="char">256</td><td char="." align="char">88</td><td char="." align="char">37</td><td char="." align="char">3</td><td char="." align="char">6</td></tr><tr><td char="." align="char">512</td><td char="." align="char">120</td><td char="." align="char">115</td><td char="." align="char">11</td><td char="." align="char">13</td></tr><tr><td rowspan="5">Santhakumar</td><td char="." align="char">32</td><td char="." align="char">5</td><td char="." align="char">4</td><td char="." align="char">0</td><td char="." align="char">2</td></tr><tr><td char="." align="char">64</td><td char="." align="char">16</td><td char="." align="char">5</td><td char="." align="char">1</td><td char="." align="char">2</td></tr><tr><td char="." align="char">128</td><td char="." align="char">37</td><td char="." align="char">16</td><td char="." align="char">1</td><td char="." align="char">2</td></tr><tr><td char="." align="char">256</td><td char="." align="char">78</td><td char="." align="char">39</td><td char="." align="char">3</td><td char="." align="char">5</td></tr><tr><td char="." align="char">512</td><td char="." align="char">158</td><td char="." align="char">89</td><td char="." align="char">4</td><td char="." align="char">6</td></tr></tbody></table><table-wrap-foot><p>Imbalance for the Round Robin (RR) and &#x0201c;Split CT&#x0201d; column is derived from the maximum and average processor computation time of a simulation. LPT and &#x0201c;Split CX&#x0201d; columns show the predicted imbalance derived from the complexity proxy</p></table-wrap-foot></table-wrap></p><p>On up to 128 processors, the LPT and Splitcell algorithms generate distributions that are very well load balanced. The total complexity and maximum cell complexity for Santhakumar are 402,493 and 1,487 respectively so that whole cell load balance is impossible with more than 270 processors. For Traub, total complexity is 1.13e6 with maximum cell complexity 4,740 so that the whole cell balance limit is below 238 processors. Given these total complexities along with the 300 and 1,000&#x000a0;ms simulation times with time steps of 0.1 and 0.025&#x000a0;ms, one expects the Traub model to have a runtime 38 times longer than the Santhakumar model. That is consistent with the observed computation time ratio of 37. Although the spiking patterns of the two models are very different they have a similar network spiking rate, approximately 12 spikes/ms and 9 spikes/ms for the Traub and Santhakumar models respectively. Thus we expect spike exchange overhead to be similar for the two models and this, along with our complexity measure indicating the almost threefold greater complexity of the Traub model, explains the threefold greater (runtime/computation - 1) value for the splitcell balanced Santhakumar model for 256 and 512 processors. That is, for a balanced model, computation time is proportional to complexity, spike exchange time is proportional to spike rate, and splitcell matrix communication time is proportional to number of time steps per millisecond. The more complex Traub model is thus performance limited by its complexity at least up to 512 processors whereas Santhakumar spike exchange overhead is becoming noticeable at 256 processors.</p></sec></sec><sec id="Sec8" sec-type="discussion"><title>Discussion</title><p>We have shown that splitting a cell into two pieces on separate processors nevertheless allows Gaussian elimination to be carried out with almost no increase in computational effort and no change in accuracy or stability. Splitting cells into two pieces and doubling the number of processors can reduce runtime by a factor of two. This performance doubling is realized when computation time is much greater than spike exchange time and the overhead of per time step exchange of the triangularized diagonal and right hand side elements of subtree roots. In this regime, when load balance is achieved, runtime performance displays nearly ideal scaling behavior.</p><p>It is worth discussing similarities and dissimilarities of the presented split cell method with how gap junctions are treated in a simulation. Most importantly, gap junctions couple pairs of compartments so that the equations no longer have a tree topology. Yet, gap junctions have a relatively large resistance compared to the resistance between the centers of adjacent cable compartments so that the extra off diagonal Jacobian elements tend to be very small relative to the diagonal and, for reasonable time steps, can be ignored during Gaussian elimination without significantly affecting stability or accuracy. Thus, gap junction currents affect only the right hand side and diagonal of the current balance equation 1 and cells can continue to be split at any compartment. Interprocessor gap junctions require an exchange of voltages on either side of the gap at the beginning of each time step. However, strongly coupled split cells cannot be reconnected using the gap junction method without introducing serious stability and accuracy problems that can only be overcome through the use of much smaller time steps. Fortunately, the message payload doubling from one to two double precision values does not increase MPI Send/Recv time so the split cell method makes it possible to maintain accuracy and stability with no increase in communication time over that of a gap junction.</p><p>Longitudinal ionic diffusion presents a case of even weaker coupling than that of gap junctions and an exchange of ion concentration state variables is certainly sufficient without causing numerical instability. On the other hand, simulations involving extracellular fields involve very tightly coupled equations with a grid topology and are therefore outside the scope of the presented method. Mechanisms such as radial diffusion, most second messenger cascades, and channel gating states, do not exhibit inter compartmental coupling except indirectly through membrane potential and therefore simulations involving such methods are not affected by cell splitting.</p><p>Because of per time step communication overhead, practical use of the split cell method (as well as gap junctions) requires hardware with a high speed interconnect. Performance is likely to be poor on Beowulf clusters with Ethernet connections slower than 1 gigabit/sec.</p><p>A significant benefit of the double precision quantitative identity (modulo round off error due to different ordering for Gaussian elimination) between split and whole cell method compartment voltages during a simulation is the ease in diagnosing errors that result in non-identity of network spike patterns. Such errors typically occur during the setup of connections between source cell and target synapse because of the extra user logic involved in determining which source cell split piece contains the source location and which target cell split piece contains the synapse location.</p><p>Minor differences between predicted load balance via the complexity proxy and measured load balance during a simulation (last two columns in Table <xref rid="Tab1" ref-type="table">1</xref> and the RR, LPT 512 processor Traub items) can be attributed in part to several additional factors that contribute to computation time such as spike queue management, and the synapse calculations that occur on delivery of a spike. Computation time is also sensitive to high speed cache misses that depend on the problem size and memory usage patterns but this may be less of a factor for the higher number of processors since in that case each processor&#x02019;s portion of the problem fits entirely into the cache.</p><p>The limitation of splitting into two pieces essentially limits the method&#x02019;s benefits to at most a doubling of the number of processors on which a given simulation can be usefully performed. In simulations with identical numbers of cells and processors, the most complex cell is the rate limiting step. Therefore, two-fold speed-up with the split cell method can only be achieved if the most complex cell indeed can be split into two equal pieces. Particularly, in the context of very detailed simulations, such as the neocortical simulations of the Blue Brain Project (Markram <xref ref-type="bibr" rid="CR7">2006</xref>), certain cell types can be more than twice as complex as the average cell (e.g. detailed layer five thick tufted pyramidal cells exhibit substantially more complex dendrites than layer 2/3 cells). Thus, being able to split cells into more than two pieces is strongly desirable and motivated the extension of the presented method. Fortunately, Gaussian elimination is generally a small portion of the overall computation time so that an extension of the method to split a tree at many nodes into many pieces, even though it implies a significant Gaussian elimination complexity increase, means one can usefully increase the number of processors by up to a factor of 8&#x02014;even for large single cell models. A subsequent paper presents the extended method (Hines et al. <xref ref-type="bibr" rid="CR5">2008</xref>).</p></sec></body><back><ack><title>Acknowledgements</title><p>Research supported by NIH grant NS11613 and the Blue Brain Project.</p></ack><ref-list id="Bib1"><title>References</title><ref id="CR1"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Hines</surname><given-names>M.</given-names></name></person-group><article-title>Efficient computation of branched nerve equations</article-title><source>International Journal of Biomedical Computations</source><year>1984</year><volume>15</volume><fpage>69</fpage><lpage>76</lpage><pub-id pub-id-type="doi">10.1016/0020-7101(84)90008-4</pub-id></citation><citation citation-type="display-unstructured">Hines, M. (1984). Efficient computation of branched nerve equations. International Journal of Biomedical Computations, 15, 69&#x02013;76. </citation></ref><ref id="CR2"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Hines</surname><given-names>M.</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Skrzypek</surname><given-names>J.</given-names></name></person-group><article-title>The NEURON simulation program</article-title><source>Neural Network Simulation Environments</source><year>1994</year><publisher-loc>Norwell, MA</publisher-loc><publisher-name>Kluwer</publisher-name><fpage>147</fpage><lpage>163</lpage></citation><citation citation-type="display-unstructured">Hines, M. (1994). The NEURON simulation program. In  J. Skrzypek (Ed.), Neural Network Simulation Environments (pp. 147&#x02013;163). Norwell, MA: Kluwer. </citation></ref><ref id="CR3"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Hines</surname><given-names>M. L.</given-names></name><name><surname>Carnevale</surname><given-names>N. T.</given-names></name></person-group><article-title>The NEURON simulation environment</article-title><source>Neural Computation</source><year>1997</year><volume>9</volume><fpage>1179</fpage><lpage>1209</lpage><pub-id pub-id-type="doi">10.1162/neco.1997.9.6.1179</pub-id></citation><citation citation-type="display-unstructured">Hines, M. L., &#x00026; Carnevale, N. T. (1997). The NEURON simulation environment. Neural Computation, 9, 1179&#x02013;1209. <pub-id pub-id-type="pmid">9248061</pub-id></citation></ref><ref id="CR4"><citation citation-type="other">Hines, M. L., &#x00026; Carnevale, N. T. (2007). Translating network models to parallel hardware in NEURON. <italic>Journal of  Neuroscience Methods</italic>, Sep 16 (epub ahead of print).</citation></ref><ref id="CR5"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Hines</surname><given-names>M. L.</given-names></name><name><surname>Markram</surname><given-names>H.</given-names></name><name><surname>Sch&#x000fc;rmann</surname><given-names>F.</given-names></name></person-group><article-title>Fully implicit parallel simulation of single neurons</article-title><source>Journal of Computational Neuroscience</source><year>2008</year><volume>8</volume><issue>Suppl 2</issue><fpage>P6</fpage></citation><citation citation-type="display-unstructured">Hines, M. L., Markram, H., &#x00026; Sch&#x000fc;rmann, F. (2008). Fully  implicit parallel simulation of single neurons. Journal of Computational Neuroscience, 8(Suppl 2), P6. </citation></ref><ref id="CR6"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Korf</surname><given-names>R. E.</given-names></name></person-group><article-title>A complete anytime algorithm for number partitioning</article-title><source>Artificial Intelligence</source><year>1998</year><volume>106</volume><fpage>181</fpage><lpage>203</lpage><pub-id pub-id-type="doi">10.1016/S0004-3702(98)00086-1</pub-id></citation><citation citation-type="display-unstructured">Korf, R. E. (1998). A complete anytime algorithm for number partitioning. Artificial Intelligence, 106, 181&#x02013;203. </citation></ref><ref id="CR7"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Markram</surname><given-names>H.</given-names></name></person-group><article-title>The blue brain project</article-title><source>Nature Reviews. Neuroscience</source><year>2006</year><volume>7</volume><fpage>153</fpage><lpage>160</lpage><pub-id pub-id-type="doi">10.1038/nrn1848</pub-id></citation><citation citation-type="display-unstructured">Markram, H. (2006). The blue brain project. Nature Reviews. Neuroscience, 7, 153&#x02013;160. <pub-id pub-id-type="pmid">16429124</pub-id></citation></ref><ref id="CR8"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Mascagni</surname><given-names>M.</given-names></name><name><surname>Sherman</surname><given-names>A.</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Koch</surname><given-names>C.</given-names></name><name><surname>Segev</surname><given-names>I.</given-names></name></person-group><article-title>Numerical methods for neuronal modeling</article-title><source>Methods of neuronal modeling: From ions to networks</source><year>1996</year><publisher-loc>Cambridge, MA</publisher-loc><publisher-name>MIT Press</publisher-name></citation><citation citation-type="display-unstructured">Mascagni, M., &#x00026; Sherman, A. (1996). Numerical methods for neuronal modeling. In C. Koch &#x00026; I. Segev (Eds.), Methods of neuronal modeling: From ions to networks. Cambridge, MA: MIT Press. </citation></ref><ref id="CR9"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Migliore</surname><given-names>M.</given-names></name><name><surname>Cannia</surname><given-names>C.</given-names></name><name><surname>Lytton</surname><given-names>W. W.</given-names></name><name><surname>Markram</surname><given-names>H.</given-names></name><name><surname>Hines</surname><given-names>M. L.</given-names></name></person-group><article-title>Parallel network simulations with NEURON</article-title><source>Journal of Computational Neuroscience</source><year>2006</year><volume>21</volume><fpage>119</fpage><lpage>129</lpage><pub-id pub-id-type="doi">10.1007/s10827-006-7949-5</pub-id></citation><citation citation-type="display-unstructured">Migliore, M., Cannia, C., Lytton, W. W., Markram, H., &#x00026; Hines, M. L. (2006). Parallel network simulations with NEURON. Journal of Computational Neuroscience, 21, 119&#x02013;129. <pub-id pub-id-type="pmid">16732488</pub-id></citation></ref><ref id="CR10"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Santhakumar</surname><given-names>V.</given-names></name><name><surname>Aradi</surname><given-names>I.</given-names></name><name><surname>Soltesz</surname><given-names>I.</given-names></name></person-group><article-title>Role of mossy fiber sprouting and mossy cell loss in hyperexcitability: A network model of the dentate gyrus incorporating cell types and axonal topography</article-title><source>Journal of Neurophysiology</source><year>2005</year><volume>93</volume><fpage>437</fpage><lpage>453</lpage><pub-id pub-id-type="doi">10.1152/jn.00777.2004</pub-id></citation><citation citation-type="display-unstructured">Santhakumar, V., Aradi, I., &#x00026; Soltesz, I. (2005). Role of mossy fiber sprouting and mossy cell loss in hyperexcitability: A network model of the dentate gyrus incorporating cell types and axonal topography. Journal of Neurophysiology, 93, 437&#x02013;453. <pub-id pub-id-type="pmid">15342722</pub-id></citation></ref><ref id="CR11"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Traub</surname><given-names>R. D.</given-names></name><name><surname>Contreras</surname><given-names>D.</given-names></name><name><surname>Cunningham</surname><given-names>M. O.</given-names></name><name><surname>Murray</surname><given-names>H.</given-names></name><name><surname>LeBeau</surname><given-names>F. E.</given-names></name><name><surname>Roopun</surname><given-names>A.</given-names></name><etal/></person-group><article-title>Single-column thalamocortical network model exhibiting gamma oscillations, sleep spindles, and epileptogenic bursts</article-title><source>Journal of Neurophysiology</source><year>2005</year><volume>93</volume><fpage>2194</fpage><lpage>2232</lpage><pub-id pub-id-type="doi">10.1152/jn.00983.2004</pub-id></citation><citation citation-type="display-unstructured">Traub, R. D., Contreras, D., Cunningham, M. O., Murray, H., LeBeau, F. E., Roopun, A., et al. (2005). Single-column thalamocortical network model exhibiting gamma oscillations, sleep spindles, and epileptogenic bursts. Journal of Neurophysiology, 93, 2194&#x02013;2232. <pub-id pub-id-type="pmid">15525801</pub-id></citation></ref></ref-list></back></article>