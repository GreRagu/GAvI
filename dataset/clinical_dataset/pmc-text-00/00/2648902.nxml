<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN" "archivearticle.dtd"><article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article" xml:lang="EN"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Biostatistics</journal-id><journal-id journal-id-type="hwp">biosts</journal-id><journal-id journal-id-type="publisher-id">biosts</journal-id><journal-title>Biostatistics (Oxford, England)</journal-title><issn pub-type="ppub">1465-4644</issn><issn pub-type="epub">1468-4357</issn><publisher><publisher-name>Oxford University Press</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">19068485</article-id><article-id pub-id-type="pmc">2648902</article-id><article-id pub-id-type="doi">10.1093/biostatistics/kxn042</article-id><article-categories><subj-group subj-group-type="heading"><subject>Articles</subject></subj-group></article-categories><title-group><article-title>Microarray background correction: maximum likelihood estimation for the normal&#x02013;exponential convolution</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Silver</surname><given-names>Jeremy D.</given-names></name></contrib></contrib-group><aff>Bioinformatics Division, Walter and Eliza Hall Institute, Parkville 3050, Victoria, Australia and Department of Biostatistics, University of Copenhagen, &#x000d8;ster Farimagsgade 5, Entrance B, PO Box 2099, DK-1014 Copenhagen K, Denmark <email>j.silver@biostat.ku.dk</email></aff><contrib-group><contrib contrib-type="author"><name><surname>Ritchie</surname><given-names>Matthew E.</given-names></name></contrib></contrib-group><aff>Department of Oncology, University of Cambridge, Cambridge CB2 0RE, UK</aff><contrib-group><contrib contrib-type="author"><name><surname>Smyth</surname><given-names>Gordon K.</given-names></name><xref ref-type="corresp" rid="cor1">*</xref></contrib></contrib-group><aff>Bioinformatics Division, Walter and Eliza Hall Institute, Parkville 3050, Victoria, Australia <email>smyth@wehi.edu.au</email></aff><author-notes><corresp id="cor1"><label>*</label>To whom correspondence should be addressed.</corresp></author-notes><!--Fake ppub date generated  by PMC from publisher pub-date/@pub-type='epub-ppub' --><pub-date pub-type="ppub"><month>4</month><year>2009</year></pub-date><pub-date pub-type="epub"><day>8</day><month>12</month><year>2008</year></pub-date><pub-date pub-type="pmc-release"><day>8</day><month>12</month><year>2008</year></pub-date><volume>10</volume><issue>2</issue><fpage>352</fpage><lpage>363</lpage><history><date date-type="received"><day>21</day><month>12</month><year>2007</year></date><date date-type="rev-recd"><day>28</day><month>7</month><year>2008</year></date><date date-type="rev-recd"><day>1</day><month>10</month><year>2008</year></date><date date-type="accepted"><day>17</day><month>10</month><year>2008</year></date></history><permissions><copyright-statement>&#x000a9; 2008 The Author(s)</copyright-statement><copyright-year>2009</copyright-year><license license-type="open-access"><p><!--CREATIVE COMMONS-->This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/2.0/uk/">http://creativecommons.org/licenses/by-nc/2.0/uk/</ext-link>) which permits unrestricted non-commercial use, distribution, and reproduction in any medium, provided the original work is properly cited.</p></license></permissions><abstract><p>Background correction is an important preprocessing step for microarray data that attempts to adjust the data for the ambient intensity surrounding each feature. The &#x0201c;normexp&#x0201d; method models the observed pixel intensities as the sum of 2 random variables, one normally distributed and the other exponentially distributed, representing background noise and signal, respectively. Using a saddle-point approximation, Ritchie <italic>and others</italic> (2007) found normexp to be the best background correction method for 2-color microarray data. This article develops the normexp method further by improving the estimation of the parameters. A complete mathematical development is given of the normexp model and the associated saddle-point approximation. Some subtle numerical programming issues are solved which caused the original normexp method to fail occasionally when applied to unusual data sets. A practical and reliable algorithm is developed for exact maximum likelihood estimation (MLE) using high-quality optimization software and using the saddle-point estimates as starting values. &#x0201c;MLE&#x0201d; is shown to outperform heuristic estimators proposed by other authors, both in terms of estimation accuracy and in terms of performance on real data. The saddle-point approximation is an adequate replacement in most practical situations. The performance of normexp for assessing differential expression is improved by adding a small offset to the corrected intensities.</p></abstract><kwd-group><kwd>2-color microarray</kwd><kwd>Background correction</kwd><kwd>Maximum likelihood</kwd><kwd>Nelder-Mead algorithm</kwd><kwd>Newton- Raphson algorithm</kwd><kwd>Normal-exponential convolution</kwd></kwd-group></article-meta></front><body><sec sec-type="intro"><label>1.</label><title>I<sc>NTRODUCTION</sc></title><p>Fluorescence intensities measured by microarrays are subject to a range of different sources of noise, both between and within arrays. Background correction aims to adjust for these effects by taking account of ambient fluorescence in the neighborhood of each microarray feature.</p><p>Ritchie <italic>and others</italic> (2007) compared a range of background correction methods for 2-color microarrays. A method normexp was introduced which models the observed intensities as the sum of exponentially distributed signals and normally distributed background values. The corrected intensities are obtained as the conditional expectations of the signals given the observations. The normexp method is an adaptation of the background correction method proposed by Irizarry <italic>and others</italic> (2003) for Affymetrix single-channel arrays, as the first step of the popular &#x0201c;robust multi-array average (RMA)&#x0201d; algorithm for preprocessing Affymetrix expression data. Ritchie <italic>and others</italic> (2007) showed that normexp, followed by a started-log transformation (i.e. log(<italic>x</italic> + <italic>c</italic>), for constant <italic>c</italic>), gave the lowest false-discovery rate of any commonly available background correction method for 2-color microarrays.</p><p>The convolution model underlying the normexp method involves 3 unknown parameters, all of which must be estimated before the method can be applied. In the 2-color context, the parameters must be estimated for each channel on each array, by fitting the convolution model to the observed intensities for that channel. Ritchie <italic>and others</italic> (2007) suggested an approximate likelihood method for estimating the parameters, based on a saddle-point approximation, but did not give mathematical details.</p><p>This article develops the normexp method further by improving the estimation of the parameters. First, a complete mathematical development is given of the normexp model and the associated saddle-point approximation. Second, some subtle numerical programming issues are solved which caused the original normexp method to fail occasionally when applied to unusual data sets. Third, we show how exact maximum likelihood estimation (MLE) of the parameters can be made practical and reliable. Fourth, we compare exact and approximate MLE with estimators proposed by other authors.</p><p>MLE has previously proved difficult because of numerical sensitivity of the likelihood function (Irizarry <italic>and others</italic>, 2003), (<xref ref-type="bibr" rid="bib2">Bolstad, 2004</xref>), (<xref ref-type="bibr" rid="bib11">McGee and Chen, 2006</xref>). Instead of MLE, the RMA algorithm, implemented in the affy software package for R (Gautier <italic>and others</italic>, 2004), uses simple heuristic estimators obtained by smoothing the histogram of observed intensities and partitioning the distribution about its mode (<xref ref-type="bibr" rid="bib2">Bolstad, 2004</xref>), (Irizarry <italic>and others</italic>, 2003). <xref ref-type="bibr" rid="bib11">McGee and Chen (2006)</xref> observed that the RMA estimators are highly biased and proposed 2 new estimators. These methods are based on the RMA kernel smoothing approach but partition the distribution about its mean (the &#x0201c;RMA-mean&#x0201d; method) or 75th percentile (the &#x0201c;RMA-75&#x0201d; method) and then apply a 1-step correction. The RMA-mean and RMA-75 estimators are far less biased than those of RMA but apparently do not improve the performance of the RMA algorithm on real data (<xref ref-type="bibr" rid="bib11">McGee and Chen, 2006</xref>).</p><p>The saddle-point approximation avoids the sensitivity of the likelihood function by providing a closed-form expression for the probability density on the log-scale, ensuring good relative accuracy. However, the saddle point itself must first be found for each data value. This article provides a globally convergent iterative scheme that locates the saddle point to full accuracy in floating-point arithmetic in all cases.</p><p>The accuracy of the different estimators are compared in a simulation study. The estimators are also compared using the extensive battery of calibration data sets assembled by Ritchie <italic>and others</italic> (2007). This allows the estimators to be compared according to their ability to estimate fold changes and to detect differential expression on real data. As in Ritchie <italic>and others</italic> (2007), the assumed context is that of a small microarray experiment in which popular differential expression methods are to be applied. MLE is shown to have markedly better performance than the heuristic estimators.</p><p>Section 2 describes the normexp convolution model, presents the MLE and &#x0201c;saddle&#x0201d; procedures, and addresses some challenges in their implementation. Section 3 briefly describes the 3 test data sets with known levels of differential expression. Section 4 compares the 4 estimation schemes both by simulation and by performance on the test data sets.</p></sec><sec><label>2.</label><title>C<sc>ORRECTION METHODS</sc></title><sec><label>2.1</label><title>The normal&#x02013;exponential convolution model</title><p>Image analysis software for 2-color microarrays produces red foreground and background intensities <italic>R</italic><sub>f</sub> and <italic>R</italic><sub>b</sub> and green foreground and background intensities <italic>G</italic><sub>f</sub> and <italic>G</italic><sub>b</sub> for each spot on each array. Our aim is to adjust the foreground intensities <italic>R</italic><sub>f</sub> and <italic>G</italic><sub>f</sub> for the ambient intensities represented by <italic>R</italic><sub>b</sub> and <italic>G</italic><sub>b</sub>.</p><p>The normexp model for the red channel assumes <italic>R</italic><sub>f</sub> = <italic>R</italic><sub>b</sub> + <italic>B</italic> + <italic>S</italic>, where <italic>S</italic> is the true expression intensity signal and <italic>B</italic> is the residual background not captured by <italic>R</italic><sub>b</sub>. The model for the green channel is similar. The signal <italic>S</italic> is assumed exponentially distributed with mean <italic>&#x003b1;</italic>, while <italic>B</italic> is normally distributed with mean <italic>&#x003bc;</italic> and variance <italic>&#x003c3;</italic><sup>2</sup>. The parameters <italic>&#x003bc;</italic>, <italic>&#x003c3;</italic><sup>2</sup>, and <italic>&#x003b1;</italic> are assumed different for each channel on each array. All variables are assumed independent.</p><p>Write <italic>X</italic> = <italic>R</italic><sub>f</sub> &#x02212; <italic>R</italic><sub>b</sub> for the background-subtracted observed intensity. The normexp model becomes<disp-formula id="fd2.1"><label>(2.1)</label><inline-graphic xlink:href="biostskxn042fx1_ht.jpg"/></disp-formula>The joint density of <italic>B</italic> and <italic>S</italic> is just the product of densities<disp-formula id="fd2.2"><label>(2.2)</label><inline-graphic xlink:href="biostskxn042fx2_ht.jpg"/></disp-formula>where <italic>s</italic>&#x02009;&#x0003e;&#x02009;0 and <italic>&#x003c6;</italic>(&#x000b7;) is the Gaussian density function. A simple transformation gives the joint density of <italic>X</italic> and <italic>S</italic> as<disp-formula><inline-graphic xlink:href="biostskxn042fx3_ht.jpg"/></disp-formula>where <italic>&#x003bc;</italic><sub><italic>S</italic>&#x000b7;<italic>X</italic></sub> = <italic>x</italic> &#x02212; <italic>&#x003bc;</italic> &#x02212; <italic>&#x003c3;</italic><sup>2</sup>/<italic>&#x003b1;</italic>. Integrating over <italic>s</italic> gives the marginal density of <italic>X</italic>:<disp-formula id="fd2.3"><label>(2.3)</label><inline-graphic xlink:href="biostskxn042fx4_ht.jpg"/></disp-formula>where &#x003a6;(&#x000b7;) is the Gaussian distribution function. Dividing the joint by the marginal gives the conditional density of <italic>S</italic> given <italic>X</italic> as<disp-formula><inline-graphic xlink:href="biostskxn042fx5_ht.jpg"/></disp-formula>for <italic>s</italic>&#x02009;&#x0003e;&#x02009;0, which is a truncated Gaussian distribution. Our estimate of the signal given the observed intensities is the conditional expectation<disp-formula id="fd2.4"><label>(2.4)</label><inline-graphic xlink:href="biostskxn042fx6_ht.jpg"/></disp-formula></p></sec><sec><label>2.2</label><title>Saddle-point approximation</title><p>MLE requires the marginal density (2.3), which turns out to be difficult to compute with full relative accuracy in floating-point arithmetic, due to subtractive cancelation affecting both factors in the expression. As an alternative, the saddle-point approximation, or tilted Edgeworth expansion, provides a means of approximating the density of any random variable from its cumulant generating function (<xref ref-type="bibr" rid="bib1">Barndorff-Nielsen and Cox, 1981</xref>, p. 104). The approximation is attractive because it typically remains accurate far into the tails of the distribution.</p><p>The cumulant generating function of <italic>X</italic> is immediately available as the sum of those for <italic>B</italic> and <italic>S</italic>,<disp-formula><inline-graphic xlink:href="biostskxn042fx7_ht.jpg"/></disp-formula>where <italic>&#x003b8;</italic>&#x02009;&#x0003c;&#x02009;1/<italic>&#x003b1;</italic>. The definition of the cumulant generating function implies that <italic>g</italic>(<italic>x</italic>;<italic>&#x003b8;</italic>) = <italic>f</italic><sub><italic>X</italic></sub>(<italic>x</italic>)exp[<italic>y</italic><italic>&#x003b8;</italic> &#x02212; <italic>K</italic><sub><italic>X</italic></sub>(<italic>&#x003b8;</italic>)] integrates to unity for all <italic>&#x003b8;</italic>. Here, we suppress the dependence of <italic>f</italic><sub><italic>X</italic></sub> on <italic>&#x003bc;</italic>, <italic>&#x003c3;</italic>, and <italic>&#x003b1;</italic> for notational simplicity. The density <italic>g</italic>(<italic>x</italic>;<italic>&#x003b8;</italic>) defines a linear exponential family with canonical parameter <italic>&#x003b8;</italic> and <italic>r</italic>th cumulant <italic>&#x003ba;</italic><sub><italic>r</italic></sub> = <italic>K</italic><sub><italic>X</italic></sub><sup>(<italic>r</italic>)</sup>(<italic>&#x003b8;</italic>).</p><p>The second-order Edgeworth expansion for <italic>g</italic> (<xref ref-type="bibr" rid="bib1">Barndorff-Nielsen and Cox, 1981</xref>, p. 106) is log <inline-formula><inline-graphic xlink:href="biostskxn042fx8_ht.jpg"/></inline-formula> yielding the approximation <inline-formula><inline-graphic xlink:href="biostskxn042fx9_ht.jpg"/></inline-formula>. The key feature which makes the saddle-point approximation so effective is its ability to choose <italic>&#x003b8;</italic> to make the Edgeworth expansion as accurate as possible for each <italic>x</italic>, by choosing <italic>&#x003b8;</italic> so that <italic>x</italic> is the mean of the distribution, that is <italic>&#x003b8;</italic> is chosen to solve the saddle-point equation<disp-formula id="fd2.5"><label>(2.5)</label><inline-graphic xlink:href="biostskxn042fx10_ht.jpg"/></disp-formula>for <italic>&#x003b8;</italic>&#x02009;&#x0003c;&#x02009;1/<italic>&#x003b1;</italic>. Although this equation has a simple analytic solution, computing the solution is subject to catastrophic subtractive cancelation for certain values of <italic>&#x003c3;</italic> and <italic>&#x003b1;</italic>. Details of how we avert this numerical issue are provided in Section A of the <ext-link ext-link-type="uri" xlink:href="http://biostatistics.oxfordjournals.org/cgi/content/full/kxn042/DC1">supplementary material</ext-link> available at <italic>Biostatistics</italic> online (<ext-link ext-link-type="uri" xlink:href="http://www.biostatistics.oxfordjournals.org">http://www.biostatistics.oxfordjournals.org</ext-link>).</p></sec><sec><label>2.3</label><title>Optimization</title><p>Given a set of observed intensities <italic>x</italic><sub><italic>i</italic></sub>, <italic>i</italic> = 1,&#x02026;,<italic>n</italic>, the unknown parameters <italic>&#x003bc;</italic>, <italic>&#x003c3;</italic>, and <italic>&#x003b1;</italic> must be estimated before the correction formula (2.4) can be applied. Starting values are obtained as follows. The initial estimate <inline-formula><inline-graphic xlink:href="biostskxn042fx11_ht.jpg"/></inline-formula><sub>0</sub> of <italic>&#x003bc;</italic> is the 5% quantile of the <italic>x</italic><sub><italic>i</italic></sub>. The initial variance <inline-formula><inline-graphic xlink:href="biostskxn042fx13_ht.jpg"/></inline-formula> is the mean of (<italic>x<sub>i</sub></italic>&#x02212;<inline-formula><inline-graphic xlink:href="biostskxn042fx11_ht.jpg"/></inline-formula><sub>0</sub>)<sup>2</sup> for <italic>x<sub>i</sub></italic>&#x0003c;<inline-formula><inline-graphic xlink:href="biostskxn042fx11_ht.jpg"/></inline-formula><sub>0</sub>. The initial <inline-formula><inline-graphic xlink:href="biostskxn042fx12_ht.jpg"/></inline-formula> is <inline-formula><inline-graphic xlink:href="biostskxn042fx14_ht.jpg"/></inline-formula>.</p><p>Next, the saddle-point approximation to the likelihood is maximized using the Nelder&#x02013;Mead (1965) simplex algorithm. Finally, using the saddle-point estimates as starting values, the exact likelihood is maximized using the nlminb function of R, which performs unconstrained minimization using PORT routines (<xref ref-type="bibr" rid="bib6">Gay, 1981</xref>), (<xref ref-type="bibr" rid="bib7">Gay, 1983</xref>), (<xref ref-type="bibr" rid="bib8">Gay, 1990</xref>). First and second derivatives of <italic>f</italic><sub><italic>X</italic></sub> with respect to <italic>&#x003bc;</italic>, log<italic>&#x003b1;</italic>, and log<italic>&#x003c3;</italic><sup>2</sup> are supplied. Optimizing the likelihood with respect to log<italic>&#x003b1;</italic> and log<italic>&#x003c3;</italic><sup>2</sup>, rather than <italic>&#x003b1;</italic> and <italic>&#x003c3;</italic><sup>2</sup>, avoids parameter constraints and improves convergence.</p><p>The algorithm is implemented in the limma software package for R (<xref ref-type="bibr" rid="bib17">Smyth, 2005</xref>). Saddle-point parameter estimation takes about 1 s per channel with 20 000 probe arrays on a 2 GHz Windows PC. Exact MLE takes about 50% longer. Time taken is roughly linear with the number of probes.</p></sec><sec><label>2.4</label><title>Transformation and offset</title><p>The normexp background correction (2.4) is performed for each channel on each array, yielding adjusted strictly positive red and green intensities <italic>R</italic> and <italic>G</italic> for each spot on each array. These are then converted to log-ratios, <italic>M</italic> = log<sub>2</sub>(<italic>R</italic>/<italic>G</italic>), and log-averages, <inline-formula><inline-graphic xlink:href="biostskxn042fx15_ht.jpg"/></inline-formula> (Yang <italic>and others</italic>, 2001).</p><p>It also proves useful to offset the intensities by a small positive value <italic>k</italic>, giving offset log-ratios <italic>M</italic> = log<sub>2</sub>[(<italic>R</italic> + <italic>k</italic>)/(<italic>G</italic> + <italic>k</italic>)]. This simple transformation shifts the intensities away from 0 and serves to stabilize the variance of the log-ratios at low intensities (<xref ref-type="bibr" rid="bib15">Rocke and Durbin, 2003</xref>), (Ritchie <italic>and others</italic>, 2007). The value <italic>k</italic> = 50 was chosen for this study on the basis of our previous experience with cDNA microarray experiments (Ritchie <italic>and others</italic>, 2007).</p></sec></sec><sec><label>3.</label><title>T<sc>EST DATA</sc></title><sec><label>3.1</label><title>Spike-in experiment</title><p>We use the same 3 calibration data sets as Ritchie <italic>and others</italic> (2007). The first uses Lucidea Universal ScoreCard controls (Amersham Biosciences) to assess bias. Twelve copies of the control probe set were printed in duplicate on 9 cDNA microarrays, along with a 13K clone library. Only the control probes are analyzed here. Prior to labeling, test and reference control RNA were spiked into RNA samples to produce known fold changes (<ext-link ext-link-type="uri" xlink:href="http://biostatistics.oxfordjournals.org/cgi/content/full/kxn042/DC1">Supplementary Table 1</ext-link> available at <italic>Biostatistics</italic> online). All 8 background correction methods (RMA, RMA-75, saddle, and MLE, with and without the offset) were applied. The resulting log-ratios were normalized and duplicate spots were combined to give an estimate of the log<sub>2</sub>-fold change as described by Ritchie <italic>and others</italic> (2007).</p></sec><sec><label>3.2</label><title>Mixture experiment</title><p>The second data set is from Holloway <italic>and others</italic> (2006). Six RNA mixtures consisting of mRNA from MCF7 and Jurkat cell lines in known relative concentrations (100%:0%, 94%:6%, 88%:12%, 76%:24%, 50%:50% and 0%:100%) were compared to pure Jurkat reference mRNA on 12 cDNA microarrays printed with a Human 10.5K clone set. Dye-swap pairs were performed for each of the 6 mixtures. All 8 background correction methods were applied and the data were normalized using print-tip loess (Yang <italic>and others</italic>, 2001). Probe-wise nonlinear regression equations were fitted to the normalized log-ratios (Holloway <italic>and others</italic>, 2006). This produced for each probe a reliable consensus estimate of the MCF7 to Jurkat fold change and a standard deviation that estimates the between-array measurement error.</p></sec><sec><label>3.3</label><title>Quality control study</title><p>The final data set is from Ritchie <italic>and others</italic> (2006) and comprises 111 replicate arrays printed with the same 10.5k clone set as in the mixture study and hybridized with MCF7 (Cy3) and Jurkat mRNA (Cy5). Spot image data were morph background corrected and print-tip loess normalized. This very large data set enables genes truly differentially expressed (DE) between MCF7 and Jurkat to be identified with a high degree of confidence.</p></sec></sec><sec sec-type="results"><label>4.</label><title>R<sc>ESULTS</sc></title><sec><label>4.1</label><title>Reliability</title><p>The estimation scheme outlined in Section 2.3 has proved to be extremely reliable. It has converged successfully for all data sets the authors have encountered so far, including thousands of simulated and real microarrays. This contrasts with earlier experiences reported by <xref ref-type="bibr" rid="bib11">McGee and Chen (2006)</xref>, whose optimization algorithm, using Newton's method, converged in only 15% of cases, even when initial estimates were equal to the true parameter values.</p><p>RMA estimation also returned useable values for all data sets. The RMA-mean and RMA-75 methods each failed for some simulated data sets, the former slightly more often than the latter. Since the two are otherwise similar in performance, results will be presented here only for RMA-75. RMA-75 returned NaNs for 32% of simulated data sets with <italic>&#x003c3;</italic> = 5 and <italic>&#x003b1;</italic> = 10<sup>4</sup> and for 0.3% of data sets with <italic>&#x003c3;</italic> = 20 and <italic>&#x003b1;</italic> = 10<sup>4</sup>.</p></sec><sec><label>4.2</label><title>Estimation accuracy</title><p>Data were simulated for all combinations of <italic>&#x003bc;</italic>&#x02208;{30,100,500}, <italic>&#x003c3;</italic>&#x02208;{5,20,100}, and <italic>&#x003b1;</italic>&#x02208;{10<sup>2</sup>,10<sup>3</sup>,10<sup>4</sup>}. These values represent a very wide range of scenarios in terms of the distribution of foreground values typically observed in microarray data. For each combination of parameter values, 1000 replicate samples of 20 000 observed intensities <italic>X</italic> were generated. Results are presented only for <italic>&#x003bc;</italic> = 100 as the other results are almost identical.</p><p>The MLE bias and standard deviation were the smallest, followed closely by those of saddle (<xref ref-type="table" rid="tbl1">Tables 1</xref>&#x02013;<xref ref-type="table" rid="tbl2"/><xref ref-type="table" rid="tbl3">3</xref>). RMA-75 is much more biased and RMA is by far the worst. Parameter estimates for individual data sets for the representative parameter values <italic>&#x003c3;</italic> = 20 and <italic>&#x003b1;</italic> = 1000 are plotted in <xref ref-type="fig" rid="fig1">Figure 1</xref>; the estimates from RMA fall outside the range of this plot. MLE is the most precise with almost no bias. Saddle is equally precise but with some bias, tending to underestimate <italic>&#x003c3;</italic>. RMA-75 and RMA on the other hand overestimate <italic>&#x003c3;</italic>.</p><table-wrap id="tbl1" position="float"><label>Table 1.</label><caption><p>Bias and standard deviation (shown in brackets) in estimating &#x003bc; for the 4 estimation methods in 9 different scenarios. The true values of &#x003b1; and &#x003c3; in each scenario are shown in the first 2 columns, and &#x003bc;&#x02009;=&#x02009;100 for all scenarios. All values are given to 2 significant figures</p></caption><table frame="hsides" rules="groups"><thead><tr><td rowspan="1" colspan="1">&#x003c3;</td><td align="center" rowspan="1" colspan="1">&#x003b1;</td><td align="center" rowspan="1" colspan="1">MLE</td><td align="center" rowspan="1" colspan="1">Saddle</td><td align="center" rowspan="1" colspan="1">RMA-75</td><td align="center" rowspan="1" colspan="1">RMA</td></tr></thead><tbody><tr><td rowspan="1" colspan="1">5</td><td align="char" char="." rowspan="1" colspan="1">10<sup>2</sup></td><td align="char" char="." rowspan="1" colspan="1">0.0079 (0.22)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 0.25 (0.22)</td><td align="char" char="." rowspan="1" colspan="1">1.7 (1.6)</td><td align="char" char="." rowspan="1" colspan="1">12 (2.7)</td></tr><tr><td rowspan="1" colspan="1">20</td><td align="char" char="." rowspan="1" colspan="1">10<sup>2</sup></td><td align="char" char="." rowspan="1" colspan="1">0.0024 (0.47)</td><td align="char" char="." rowspan="1" colspan="1">0.013 (0.50)</td><td align="char" char="." rowspan="1" colspan="1">5.4 (2.3)</td><td align="char" char="." rowspan="1" colspan="1">25 (2.6)</td></tr><tr><td rowspan="1" colspan="1">100</td><td align="char" char="." rowspan="1" colspan="1">10<sup>2</sup></td><td align="char" char="." rowspan="1" colspan="1">0.013 (1.6)</td><td align="char" char="." rowspan="1" colspan="1">11.0 (1.5)</td><td align="char" char="." rowspan="1" colspan="1">4.8 (11)</td><td align="char" char="." rowspan="1" colspan="1">47 (9.0)</td></tr><tr><td rowspan="1" colspan="1">5</td><td align="char" char="." rowspan="1" colspan="1">10<sup>3</sup></td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 0.023 (0.67)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 0.37 (0.65)</td><td align="char" char="." rowspan="1" colspan="1">4.2 (7.5)</td><td align="char" char="." rowspan="1" colspan="1">44 (23)</td></tr><tr><td rowspan="1" colspan="1">20</td><td align="char" char="." rowspan="1" colspan="1">10<sup>3</sup></td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 0.025 (1.4)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 1.3 (1.4)</td><td align="char" char="." rowspan="1" colspan="1">6.6 (11)</td><td align="char" char="." rowspan="1" colspan="1">69 (24)</td></tr><tr><td rowspan="1" colspan="1">100</td><td align="char" char="." rowspan="1" colspan="1">10<sup>3</sup></td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 0.098 (3.1)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 3.4 (3.1)</td><td align="char" char="." rowspan="1" colspan="1">26.0 (18)</td><td align="char" char="." rowspan="1" colspan="1">170 (24)</td></tr><tr><td rowspan="1" colspan="1">5</td><td align="char" char="." rowspan="1" colspan="1">10<sup>4</sup></td><td align="char" char="." rowspan="1" colspan="1">0.022 (2.3)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 0.36 (2.2)</td><td align="char" char="." rowspan="1" colspan="1">32.0 (64)</td><td align="char" char="." rowspan="1" colspan="1">380 (230)</td></tr><tr><td rowspan="1" colspan="1">20</td><td align="char" char="." rowspan="1" colspan="1">10<sup>4</sup></td><td align="char" char="." rowspan="1" colspan="1">0.20 (4.2)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 1.3 (4.0)</td><td align="char" char="." rowspan="1" colspan="1">32.0 (66)</td><td align="char" char="." rowspan="1" colspan="1">390 (220)</td></tr><tr><td rowspan="1" colspan="1">100</td><td align="char" char="." rowspan="1" colspan="1">10<sup>4</sup></td><td align="char" char="." rowspan="1" colspan="1">0.069 (9.2)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 6.5 (9.0)</td><td align="char" char="." rowspan="1" colspan="1">41.0 (85)</td><td align="char" char="." rowspan="1" colspan="1">520 (240)</td></tr></tbody></table></table-wrap><table-wrap id="tbl2" position="float"><label>Table 2.</label><caption><p>Bias and standard deviation (shown in brackets) in estimating &#x003c3; for the 4 estimation methods in 9 different scenarios. The true values of &#x003b1; and &#x003c3; in each scenario are shown in the first 2 columns, and &#x003bc;&#x02009;=&#x02009;100 for all scenarios. All values are given to 2 significant figures. &#x0221e;<sup>a</sup> and &#x0221e;<sup>b</sup> indicate, respectively, where 32.4% and 0.3% of replicates yielded infinite estimates</p></caption><table frame="hsides" rules="groups"><thead><tr><td rowspan="1" colspan="1">&#x003c3;</td><td align="center" rowspan="1" colspan="1">&#x003b1;</td><td align="center" rowspan="1" colspan="1">MLE</td><td align="center" rowspan="1" colspan="1">Saddle</td><td align="center" rowspan="1" colspan="1">RMA-75</td><td align="center" rowspan="1" colspan="1">RMA</td></tr></thead><tbody><tr><td rowspan="1" colspan="1">5</td><td align="char" char="." rowspan="1" colspan="1">10<sup>2</sup></td><td align="char" char="." rowspan="1" colspan="1">0.00059 (0.20)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 0.40 (0.19)</td><td align="char" char="." rowspan="1" colspan="1">1.5 (0.71)</td><td align="char" char="." rowspan="1" colspan="1">7.0 (1.9)</td></tr><tr><td rowspan="1" colspan="1">20</td><td align="char" char="." rowspan="1" colspan="1">10<sup>2</sup></td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 0.0069 (0.40)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 0.46 (0.43)</td><td align="char" char="." rowspan="1" colspan="1">5.6 (1.0)</td><td align="char" char="." rowspan="1" colspan="1">15.0 (1.6)</td></tr><tr><td rowspan="1" colspan="1">100</td><td align="char" char="." rowspan="1" colspan="1">10<sup>2</sup></td><td align="char" char="." rowspan="1" colspan="1">0.003 (1.0)</td><td align="char" char="." rowspan="1" colspan="1">7.3 (0.99)</td><td align="char" char="." rowspan="1" colspan="1">25.0 (5.0)</td><td align="char" char="." rowspan="1" colspan="1">45.0 (5.1)</td></tr><tr><td rowspan="1" colspan="1">5</td><td align="char" char="." rowspan="1" colspan="1">10<sup>3</sup></td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 0.067 (0.62)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 0.56 (0.56)</td><td align="char" char="." rowspan="1" colspan="1">3.2 (4.7)</td><td align="char" char="." rowspan="1" colspan="1">32.0 (19)</td></tr><tr><td rowspan="1" colspan="1">20</td><td align="char" char="." rowspan="1" colspan="1">10<sup>3</sup></td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 0.11 (1.2)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 1.9 (1.1)</td><td align="char" char="." rowspan="1" colspan="1">6.0 (5.3)</td><td align="char" char="." rowspan="1" colspan="1">44.0 (19)</td></tr><tr><td rowspan="1" colspan="1">100</td><td align="char" char="." rowspan="1" colspan="1">10<sup>3</sup></td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 0.00048 (2.8)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 5.9 (2.7)</td><td align="char" char="." rowspan="1" colspan="1">27.0 (7.8)</td><td align="char" char="." rowspan="1" colspan="1">100.0 (16)</td></tr><tr><td rowspan="1" colspan="1">5</td><td align="char" char="." rowspan="1" colspan="1">10<sup>4</sup></td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 0.72 (2.4)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 1.2 (2.1)</td><td rowspan="1" colspan="1">&#x0221e;a (&#x0221e;a)</td><td align="char" char="." rowspan="1" colspan="1">310.0 (190)</td></tr><tr><td rowspan="1" colspan="1">20</td><td align="char" char="." rowspan="1" colspan="1">10<sup>4</sup></td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 0.40 (4.0)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 2.5 (3.6)</td><td rowspan="1" colspan="1">&#x0221e;b (&#x0221e;b)</td><td align="char" char="." rowspan="1" colspan="1">300.0 (180)</td></tr><tr><td rowspan="1" colspan="1">100</td><td align="char" char="." rowspan="1" colspan="1">10<sup>4</sup></td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 0.52 (8.5)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 10.0 (7.8)</td><td align="char" char="." rowspan="1" colspan="1">36.0 (46)</td><td align="char" char="." rowspan="1" colspan="1">360.0 (190)</td></tr></tbody></table></table-wrap><table-wrap id="tbl3" position="float"><label>Table 3.</label><caption><p>Bias and standard deviation (shown in brackets) in estimating &#x003b1; for the 4 estimation methods in 9 different scenarios. The true values of &#x003b1; and &#x003c3; in each scenario are shown in the first 2 columns, and &#x003bc;&#x02009;=&#x02009;100 for all scenarios. All values are given to 2 significant figures</p></caption><table frame="hsides" rules="groups"><thead><tr><td rowspan="1" colspan="1">&#x003c3;</td><td align="center" rowspan="1" colspan="1">&#x003b1;</td><td align="center" rowspan="1" colspan="1">MLE</td><td align="center" rowspan="1" colspan="1">Saddle</td><td align="center" rowspan="1" colspan="1">RMA-75</td><td align="center" rowspan="1" colspan="1">RMA</td></tr></thead><tbody><tr><td rowspan="1" colspan="1">5</td><td align="char" char="." rowspan="1" colspan="1">10<sup>2</sup></td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 0.00013 (0.75)</td><td align="char" char="." rowspan="1" colspan="1">0.25 (0.75)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 1.1 (1.5)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 80 (0.31)</td></tr><tr><td rowspan="1" colspan="1">20</td><td align="char" char="." rowspan="1" colspan="1">10<sup>2</sup></td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 0.013 (0.82)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 0.023 (0.84)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 2.5 (1.9)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 79 (0.40)</td></tr><tr><td rowspan="1" colspan="1">100</td><td align="char" char="." rowspan="1" colspan="1">10<sup>2</sup></td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 0.046 (1.6)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 11.0 (1.5)</td><td align="char" char="." rowspan="1" colspan="1">27.0 (8.1)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 69 (4.4)</td></tr><tr><td rowspan="1" colspan="1">5</td><td align="char" char="." rowspan="1" colspan="1">10<sup>3</sup></td><td align="char" char="." rowspan="1" colspan="1">0.021 (6.8)</td><td align="char" char="." rowspan="1" colspan="1">0.37 (6.8)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 2.8 (10)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 800 (2.9)</td></tr><tr><td rowspan="1" colspan="1">20</td><td align="char" char="." rowspan="1" colspan="1">10<sup>3</sup></td><td align="char" char="." rowspan="1" colspan="1">0.11 (6.8)</td><td align="char" char="." rowspan="1" colspan="1">1.4 (6.8)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 4.6 (12)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 800 (2.9)</td></tr><tr><td rowspan="1" colspan="1">100</td><td align="char" char="." rowspan="1" colspan="1">10<sup>3</sup></td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 0.16 (7.5)</td><td align="char" char="." rowspan="1" colspan="1">3.2 (7.5)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 15.0 (16)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 790 (3.2)</td></tr><tr><td rowspan="1" colspan="1">5</td><td align="char" char="." rowspan="1" colspan="1">10<sup>4</sup></td><td align="char" char="." rowspan="1" colspan="1">0.50 (72)</td><td align="char" char="." rowspan="1" colspan="1">1.0 (72)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 28.0 (100)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 8000 (28)</td></tr><tr><td rowspan="1" colspan="1">20</td><td align="char" char="." rowspan="1" colspan="1">10<sup>4</sup></td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 3.2 (69)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 1.6 (69)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 29.0 (100)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 8000 (28)</td></tr><tr><td rowspan="1" colspan="1">100</td><td align="char" char="." rowspan="1" colspan="1">10<sup>4</sup></td><td align="char" char="." rowspan="1" colspan="1">3.1 (71)</td><td align="char" char="." rowspan="1" colspan="1">9.5 (71)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 23.0 (110)</td><td align="char" char="." rowspan="1" colspan="1">&#x02013; 8000 (30)</td></tr></tbody></table></table-wrap><fig id="fig1" position="float"><label>Fig. 1.</label><caption><p>Box plots of parameter estimates for the 3 best-performing methods. The true values of the parameters are indicated by dashed vertical lines. Estimates of RMA were so far from those of the other methods that do not appear when plotted on this scale (see Tables 1&#x02013;3).</p></caption><graphic xlink:href="biostskxn042f01_ht"/></fig><p>Another way to view accuracy is in terms of ability to return the correct signal values. The left panel of <xref ref-type="fig" rid="fig2">Figure 2</xref> shows the bias with which <italic>E</italic>(<italic>S</italic>|<italic>X</italic>) estimates <italic>S</italic> on the log<sub>2</sub>-scale, for <italic>&#x003bc;</italic> = 0, <italic>&#x003c3;</italic> = 20, and <italic>&#x003b1;</italic> = 1000. Here, RMA-75 and especially RMA yield far more biased estimates of the signal than MLE or saddle, which are relatively accurate. Although MLE and saddle do tend to overestimate the true signal at lower intensities, this is indistinguishable from the bias that arises from inserting the true parameter values into <italic>E</italic>(<italic>S</italic>|<italic>X</italic>).</p><fig id="fig2" position="float"><label>Fig. 2.</label><caption><p>Left panel: smoothed log<sub>2</sub>-ratio of the true to the estimated signal versus the true signal. The black line shows this relationship if the true parameter values are used instead of estimates. The data used for this figure include 100 000 observations simulated with <italic>&#x003bc;</italic> = 0, <italic>&#x003c3;</italic> = 20, and <italic>&#x003b1;</italic> = 1000. Quantiles for the signal distribution are marked. The curves were smoothed using the lowess function in R (<xref ref-type="bibr" rid="bib3">Cleveland, 1979</xref>). Right panel: smoothed <inline-formula><inline-graphic xlink:href="biostskxn042fx16_ht.jpg"/></inline-formula><sup>2</sup> from the nonlinear fits versus intensity for the mixture experiment. The <italic>A</italic>-values have been standardized between methods and plotted from the 5th to the 95th percentiles. The quantiles of the <italic>A</italic>-values are marked.</p></caption><graphic xlink:href="biostskxn042f02_4c"/></fig></sec><sec><label>4.3</label><title>Implicit offsets</title><p>The normalized <italic>M</italic>- and <italic>A</italic>-values for one array from the mixture experiment are shown in <xref ref-type="fig" rid="fig3">Figure 3</xref>. This array has 100% Jurkat on both channels, so there is no true differential expression.</p><fig id="fig3" position="float"><label>Fig. 3.</label><caption><p>MA-plots obtained using different background correction methods for a self&#x02013;self hybridization from the mixture experiment.</p></caption><graphic xlink:href="biostskxn042f03_ht"/></fig><p>Some fanning of <italic>M</italic>-values is apparent at low <italic>A</italic>-values in the MLE and saddle panels. This fanning is essentially eliminated in the corresponding offset panels at the cost of compressing the range of <italic>A</italic>-values. Compared with MLE, RMA-75 and especially RMA show a somewhat compressed range of <italic>A</italic>- and <italic>M</italic>-values even before the offset is applied. Our interpretation is that these estimation schemes implicitly incorporate offsets, which arise from the fact that they tend to overestimate the quantity <italic>&#x003bc;</italic><sub><italic>S</italic>&#x000b7;<italic>X</italic></sub>. Adding an offset to RMA is therefore in effect a double offset.</p><p>For this array, high offset and low <italic>M</italic>-value variability is desirable because the true <italic>M</italic>-values are zero. For arrays with genuine differential expression, compression of the <italic>M</italic>-values might appear as bias. We examine this in Section 4.5.</p></sec><sec><label>4.4</label><title>Precision of expression values</title><p>We now examine the precision of the background-corrected intensities, using results from the mixture experiment. The residual standard deviation for each probe, <inline-formula><inline-graphic xlink:href="biostskxn042fx16_ht.jpg"/></inline-formula><sub><italic>i</italic></sub>, is a measure of the precision with which the <italic>M</italic>-values returned by the microarrays follow the pattern of the mixing proportions. The right panel of <xref ref-type="fig" rid="fig2">Figure 2</xref> shows the trend in variability for each background method as a function of intensity. The vertical scale is log<sub>2</sub>-variance, so each unit on the vertical axis corresponds to a 2-fold change in variance.</p><p>As expected, precision improves with intensity for all the background correction methods prior to applying an offset. MLE and saddle have the best precision of the 4 methods for most of the intensity range. RMA-75 is relatively poor at higher intensities. After adding an offset, MLE and saddle have roughly constant variance across the intensity range, whereas the offset seems overdone for RMA and RMA-75, which now show a reversed trend in precision.</p></sec><sec><label>4.5</label><title>Bias of expression values</title><p>It is to be expected that higher precision, purchased by compressing the intensity range, will also result in attenuated signal. This is confirmed by examining the MCF7&#x02013;Jurkat log-fold changes estimated from the mixture experiment. <ext-link ext-link-type="uri" xlink:href="http://biostatistics.oxfordjournals.org/cgi/content/full/kxn042/DC1">Supplementary Figure 1</ext-link> available at <italic>Biostatistics</italic> online shows box plots of the log-fold changes arising from each method. The spread of fold changes narrows when offsets are added, although the largest fold changes remain nearly as great.</p><p>To confirm whether attenuated fold changes can be interpreted as bias, we turn to the spike-in experiment data. <ext-link ext-link-type="uri" xlink:href="http://biostatistics.oxfordjournals.org/cgi/content/full/kxn042/DC1">Supplementary Figure 2</ext-link> available at <italic>Biostatistics</italic> online shows the <italic>M</italic>-values for a typical slide for the non-DE calibration controls and for the DE D03Med ratio controls, theoretically having 3-fold change down ( &#x02212; log<sub>2</sub>3 = &#x02212; 1.58). All methods give log-ratios which are slightly biased towards 0, and the bias increases when offsets are added. There is surprisingly little difference between the 4 estimation algorithms, all leading to broadly similar bias.</p></sec><sec><label>4.6</label><title>Assessing differential expression</title><p>We now assess the ability of background corrected expression values to identify DE genes correctly. Apart from the self&#x02013;self hybridizations, the mixture experiment consists of 5 dye-swap pairs of arrays. We assessed differential expression between MCF7 and Jurkat using each pair of arrays separately. The RNA mixtures vary from 100% to 50% MCF7, so the magnitude of the fold changes will vary from one pair of the arrays to another, but the set of DE genes should be the same in each case.</p><p>Using only 2 arrays to find DE genes presents a challenging problem because there is only one degree of freedom available to estimate gene-wise standard deviations. The level of difficulty further increases with the concentration of Jurkat in the MCF7:Jurkat RNA mixture. The use of ordinary <italic>t</italic>-tests or other traditional univariate statistics to assess differential expression would be disastrous (<xref ref-type="bibr" rid="bib16">Smyth, 2004</xref>). Instead, we use two of the most popular algorithms for microarray differential expression which have the characteristic of &#x0201c;borrowing&#x0201d; information between genes and so enable statistical inferences with some confidence even for small numbers of replicate arrays. Genes were ranked in terms of evidence for differential expression using significance analysis of microarrays (SAM) regularized <italic>t</italic>-statistics (Tusher <italic>and others</italic>, 2001) and using empirical Bayes moderated <italic>t</italic>-statistics (<xref ref-type="bibr" rid="bib16">Smyth, 2004</xref>). The statistics were calculated using the samr (<ext-link ext-link-type="uri" xlink:href="http://www-stat.stanford.edu/display=&#x02019;block'~tibs/SAM/">http://www-stat.stanford.edu/display=&#x02019;block'&#x0223c;tibs/SAM/</ext-link>) and limma (<xref ref-type="bibr" rid="bib17">Smyth, 2005</xref>) software packages, respectively.</p><p>To assess the success of the differential expression analyses, an independent determination of which genes are truly DE is required. The top 30% of genes, as ranked by moderated <italic>t</italic>-statistics, from the quality control study were selected as unambiguously DE and the bottom 40% as unambiguously non-DE. This gave 3098 DE and 4130 non-DE genes. The remaining 30% of genes were treated as indeterminate and are not used in the analysis.</p><p><xref ref-type="fig" rid="fig4">Figure 4</xref> shows the number of false discoveries for each method versus the number of genes selected by ranking the genes using absolute <italic>t</italic>-statistics, from largest to smallest for (a) limma and (b) SAM. The curves have been averaged over the 5 dye-swap pairs. The limma curves show that adding an offset reduces the false-discovery rate, with the best performance achieved by MLE and saddle, followed by RMA-75 and then RMA. For SAM, the advantage of &#x0201c;MLE + offset&#x0201d; and &#x0201c;saddle + offset&#x0201d; over the methods is even more marked. SAM appears to penalize the methods which do not stabilize the variance.</p><fig id="fig4" position="float"><label>Fig. 4.</label><caption><p>Number of false discoveries from the mixture data set using moderated <italic>t</italic>-statistics from (a) limma and (b) SAM. Each curve is an average over the 5 mixtures.</p></caption><graphic xlink:href="biostskxn042f04_4c"/></fig></sec></sec><sec sec-type="discussion"><label>5.</label><title>D<sc>ISCUSSION</sc></title><p>In this article, we have shown that exact MLE gives the most accurate estimation of the normexp parameters, which translates into higher precision for the computed log-ratios of expression. The saddle-point approximation is a very close competitor. The heuristic normexp estimators are markedly poorer in estimation accuracy. Furthermore, RMA-mean and RMA-75 fail occasionally and even frequently for some simulated scenarios. However, MLE and saddle converged successfully in all of our tests.</p><p>The performance of normexp for assessing differential expression on real data is improved when combined with an offset, as a result of stabilizing the variance as a function of intensity. MLE + offset and saddle + offset gave the lowest false-discovery rates. Although exact MLE does slightly better, the saddle-point approximation could be considered an adequate replacement in most practical situations.</p><p>Estimation accuracy did not directly translate to practical performance in all cases. RMA gives easily the most biased parameter estimates. Yet when we turned to the real data examples, RMA yielded higher precision and fewer false positives than RMA-75. Prior to offset, RMA is the best of all the methods when used with SAM significance analysis. This can be understood in terms of noise&#x02013;bias trade-off. It appears that the biased RMA estimators have the fortuitous effect of introducing an implicit offset into the corrected intensities, and this has a variance stabilizing effect. This partly explains why the RMA algorithm has been so successful for Affymetrix data. RMA also tends to return roughly similar parameter estimates regardless of the data, producing more consistent parameter estimates between arrays than the other methods. We speculate that this consistency may also help its performance on real data.</p><p>Since our study was completed, Ding <italic>and others</italic> (2008) developed a normexp-type background correction method for Illumina microarray data. They proposed a Markov chain Monte Carlo (MCMC) simulation method to approximate the maximum likelihood parameter estimates. Their method is not directly applicable to non-Illumina data because it requires Illumina negative controls. MCMC is far more computationally intensive than our Newton&#x02013;Raphson MLE and returns estimates which vary stochastically from run to run.</p><p>Our algorithm is the first to return reliable, exact maximum likelihood estimates for the normexp model. This was only achieved after careful attention to a number of numerical analysis issues. In initial attempts, numerical issues including subtractive cancelation prevented us from computing the likelihood for some data sets. Several ingredients were required before reliable success was achieved including: (1) good initial estimates provided by the saddle procedure, (2) optimizing with respect to log<italic>&#x003b1;</italic> and log<italic>&#x003c3;</italic> instead of <italic>&#x003b1;</italic> and <italic>&#x003c3;</italic> (to enforce <italic>&#x003b1;</italic> &#x0003e; 0 and <italic>&#x003c3;</italic>&#x02009;&#x0003e;&#x02009;0), and (3) optimizing using both first and second derivatives. Note that the Nelder&#x02013;Mead algorithm was used first with the saddle-point likelihood, then a pseudo-Newton&#x02013;Raphson algorithm was used on the exact likelihood once a focused parameter range was established. The Nelder&#x02013;Mead algorithm could not have been used directly on the exact likelihood because of the much wider range of parameter values under which the likelihood would need to be evaluated. Nor could the Newton&#x02013;Raphson have been applied to the saddle-point approximation because of the lack of good starting values.</p><p>Although we have focused exclusively here on 2-color microarrays, our algorithmic development has obvious applications to other micoarray platforms as well.</p></sec><sec><title>F<sc>UNDING</sc></title><p><grant-sponsor>Allan Harris memorial scholarship (J.D.S.)</grant-sponsor>; <grant-sponsor>Isaac Newton Trust (M.E.R.)</grant-sponsor>; <grant-sponsor>National Health and Medical Research Council Program</grant-sponsor> Grant (<grant-num>406657</grant-num> to G.K.S.). <grant-sponsor>Funding for open access charge: NHMRC Program Grant (G. K. S.)</grant-sponsor>.</p></sec><sec sec-type="supplementary-material"><title>Supplementary Material</title><supplementary-material id="PMC_1" content-type="local-data"><caption><title>[Supplementary Material]</title></caption><media mimetype="text" mime-subtype="html" xlink:href="kxn042_index.html"/><media xlink:role="associated-file" mimetype="application" mime-subtype="pdf" xlink:href="kxn042_1.pdf"/></supplementary-material></sec></body><back><ack><p>We are grateful to Terry Speed and Ben Bolstad for valuable discussions and to a coeditor, an associate editor, and an anonymous reviewer for useful suggestions. <italic>Conflict of Interest:</italic> None declared.</p></ack><ref-list><ref id="bib1"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Barndorff-Nielsen</surname><given-names>OE</given-names></name><name><surname>Cox</surname><given-names>DR</given-names></name></person-group><source>Asymptotic Techniques for Use in Statistics</source><year>1981</year><publisher-loc>London, UK</publisher-loc><publisher-name>Chapman and Hall</publisher-name></citation></ref><ref id="bib2"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Bolstad</surname><given-names>BM</given-names></name></person-group><article-title>background, normalization and summarization, [PhD. Thesis]</article-title><source>Low-level analysis of high-density oligonucleotide array data</source><year>2004</year><publisher-loc>Berkeley, CA</publisher-loc><publisher-name>University of California</publisher-name></citation></ref><ref id="bib3"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Cleveland</surname><given-names>WS</given-names></name></person-group><article-title>Robust locally weighted regression and smoothing scatterplots</article-title><source>Journal of the American Statistical Association</source><year>1979</year><volume>74</volume><fpage>829</fpage><lpage>836</lpage></citation></ref><ref id="bib4"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ding</surname><given-names>L-H</given-names></name><name><surname>Xie</surname><given-names>Y</given-names></name><name><surname>Park</surname><given-names>S</given-names></name><name><surname>Xiao</surname><given-names>G</given-names></name><name><surname>Story</surname><given-names>MD</given-names></name></person-group><article-title>Enhanced identification and biological validation of differential gene expression via Illumina whole-genome expression arrays through the use of the model-based background correction methodology</article-title><source>Nucleic Acids Research</source><year>2008</year><comment>36, e58</comment></citation></ref><ref id="bib5"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Gautier</surname><given-names>L</given-names></name><name><surname>Cope</surname><given-names>L</given-names></name><name><surname>Bolstad</surname><given-names>BM</given-names></name><name><surname>Irizarry</surname><given-names>RA</given-names></name></person-group><article-title>affy&#x02014;analysis of Affymetrix GeneChip data at the probe level</article-title><source>Bioinformatics</source><year>2004</year><volume>20</volume><fpage>307</fpage><lpage>315</lpage><pub-id pub-id-type="pmid">14960456</pub-id></citation></ref><ref id="bib6"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Gay</surname><given-names>DM</given-names></name></person-group><article-title>Computing optimal locally constrained steps</article-title><source>SIAM Journal on Scientific and Statistical Computing</source><year>1981</year><volume>2</volume><fpage>186</fpage><lpage>197</lpage></citation></ref><ref id="bib7"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Gay</surname><given-names>DM</given-names></name></person-group><article-title>Algorithm 611&#x02014;subroutines for unconstrained minimization using a model/trust-region approach</article-title><source>ACM Transactions on Mathematical Software</source><year>1983</year><volume>9</volume><fpage>503</fpage><lpage>524</lpage></citation></ref><ref id="bib8"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Gay</surname><given-names>DM</given-names></name></person-group><source>Computing science technical report no. 153: usage summary for selected optimization routines. Technical Report</source><year>1990</year><publisher-loc>Murray Hill, NJ</publisher-loc><publisher-name>AT and T Bell Laboratories</publisher-name></citation></ref><ref id="bib9"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Holloway</surname><given-names>AJ</given-names></name><name><surname>Oshlack</surname><given-names>A</given-names></name><name><surname>Diyagama</surname><given-names>DS</given-names></name><name><surname>Bowtell</surname><given-names>DD</given-names></name><name><surname>Smyth</surname><given-names>GK</given-names></name></person-group><article-title>Statistical analysis of an RNA titration series evaluates microarray precision and sensitivity on a whole-array basis</article-title><source>BMC Bioinformatics</source><year>2006</year><volume>7</volume><fpage>511</fpage><pub-id pub-id-type="pmid">17118209</pub-id></citation></ref><ref id="bib10"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Irizarry</surname><given-names>RA</given-names></name><name><surname>Hobbs</surname><given-names>B</given-names></name><name><surname>Collin</surname><given-names>F</given-names></name><name><surname>Beazer-Barclay</surname><given-names>YD</given-names></name><name><surname>Antonellis</surname><given-names>KJ</given-names></name><name><surname>Scherf</surname><given-names>U</given-names></name><name><surname>Speed</surname><given-names>TP</given-names></name></person-group><article-title>Exploration, normalization and summaries of high density oligonucleotide array probe level data</article-title><source>Biostatistics</source><year>2003</year><volume>4</volume><fpage>249</fpage><lpage>264</lpage><pub-id pub-id-type="pmid">12925520</pub-id></citation></ref><ref id="bib11"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>McGee</surname><given-names>M</given-names></name><name><surname>Chen</surname><given-names>Z</given-names></name></person-group><article-title>Parameter estimation for the exponential-normal convolution model for background correction of Affymetrix GeneChip data</article-title><source>Statistical Applications in Genetics and Molecular Biology</source><year>2006</year><comment>5, Article 24</comment></citation></ref><ref id="bib12"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Nelder</surname><given-names>JA</given-names></name><name><surname>Mead</surname><given-names>R</given-names></name></person-group><article-title>A simplex algorithm for function minimization</article-title><source>Computer Journal</source><year>1965</year><volume>7</volume><fpage>308</fpage><lpage>313</lpage></citation></ref><ref id="bib13"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ritchie</surname><given-names>ME</given-names></name><name><surname>Diyagama</surname><given-names>D</given-names></name><name><surname>Neilson</surname><given-names>J</given-names></name><name><surname>van Laar</surname><given-names>R</given-names></name><name><surname>Dobrovic</surname><given-names>A</given-names></name><name><surname>Holloway</surname><given-names>A</given-names></name><name><surname>Smyth</surname><given-names>GK</given-names></name></person-group><article-title>Empirical array quality weights for microarray data</article-title><source>BMC Bioinformatics</source><year>2006</year><comment>7, Article 261</comment></citation></ref><ref id="bib14"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ritchie</surname><given-names>ME</given-names></name><name><surname>Silver</surname><given-names>JD</given-names></name><name><surname>Oshlack</surname><given-names>A</given-names></name><name><surname>Holmes</surname><given-names>M</given-names></name><name><surname>Diyagama</surname><given-names>D</given-names></name><name><surname>Holloway</surname><given-names>A</given-names></name><name><surname>Smyth</surname><given-names>GK</given-names></name></person-group><article-title>A comparison of background correction methods for two-colour microarrays</article-title><source>Bioinformatics</source><year>2007</year><volume>23</volume><fpage>2700</fpage><lpage>2707</lpage><pub-id pub-id-type="pmid">17720982</pub-id></citation></ref><ref id="bib15"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Rocke</surname><given-names>DM</given-names></name><name><surname>Durbin</surname><given-names>B</given-names></name></person-group><article-title>Approximate variance-stabilizing transformations for gene-expression microarray data</article-title><source>Bioinformatics</source><year>2003</year><volume>19</volume><fpage>966</fpage><lpage>972</lpage><pub-id pub-id-type="pmid">12761059</pub-id></citation></ref><ref id="bib16"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Smyth</surname><given-names>GK</given-names></name></person-group><article-title>Linear models and empirical Bayes methods for assessing differential expression in microarray experiments</article-title><source>Statistical Applications in Genetics and Molecular Biology</source><year>2004</year><comment>3, Article 3</comment></citation></ref><ref id="bib17"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Smyth</surname><given-names>GK</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Gentleman</surname><given-names>R</given-names></name><name><surname>Carey</surname><given-names>V</given-names></name><name><surname>Dudoit</surname><given-names>S</given-names></name><name><surname>Irizarry</surname><given-names>R</given-names></name><name><surname>Huber</surname><given-names>W</given-names></name></person-group><article-title>Limma: linear models for microarray data</article-title><source>Bioinformatics and Computational Biology Solutions using R and Bioconductor</source><year>2005</year><publisher-loc>New York</publisher-loc><publisher-name>Springer</publisher-name><fpage>397</fpage><lpage>420</lpage></citation></ref><ref id="bib18"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Tusher</surname><given-names>VG</given-names></name><name><surname>Tibshirani</surname><given-names>R</given-names></name><name><surname>Chu</surname><given-names>G</given-names></name></person-group><article-title>Significance analysis of microarrays applied to the ionizing radiation response</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><year>2001</year><volume>98</volume><fpage>5116</fpage><lpage>5121</lpage><pub-id pub-id-type="pmid">11309499</pub-id></citation></ref><ref id="bib19"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>YH</given-names></name><name><surname>Dudoit</surname><given-names>S</given-names></name><name><surname>Luu</surname><given-names>P</given-names></name><name><surname>Speed</surname><given-names>T</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Bittner</surname><given-names>ML</given-names></name><name><surname>Chen</surname><given-names>Y</given-names></name><name><surname>Dorsel</surname><given-names>AN</given-names></name><name><surname>Dougherty</surname><given-names>ER</given-names></name></person-group><article-title>Normalization for cDNA microarray data</article-title><source>Microarrays: Optical Technologies and Informatics. Proceedings of SPIE. Bellingham, WA: International Society for Optical Engineering</source><year>2001</year><volume>4266</volume><fpage>141</fpage><lpage>152</lpage></citation></ref></ref-list></back></article>