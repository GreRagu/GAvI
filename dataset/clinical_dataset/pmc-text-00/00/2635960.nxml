<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN" "archivearticle.dtd"><article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article" xml:lang="EN"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><journal-title>PLoS ONE</journal-title><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">19209225</article-id><article-id pub-id-type="pmc">2635960</article-id><article-id pub-id-type="publisher-id">08-PONE-RA-06081R1</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0004452</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline"><subject>Neuroscience/Cognitive Neuroscience</subject><subject>Neuroscience/Sensory Systems</subject><subject>Neuroscience/Psychology</subject></subj-group></article-categories><title-group><article-title>Effects of Place of Articulation Changes on Auditory Neural Activity: A Magnetoencephalography Study</article-title><alt-title alt-title-type="running-head">Place Feature Processing</alt-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Tavabi</surname><given-names>Kambiz</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author"><name><surname>Elling</surname><given-names>Ludger</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Dobel</surname><given-names>Christian</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Pantev</surname><given-names>Christo</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Zwitserlood</surname><given-names>Pienie</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="corresp" rid="cor1"><sup>&#x0002a;</sup></xref></contrib></contrib-group><aff id="aff1"><label>1</label><addr-line>Institute for Biomagnetism and Biosignalanalysis, Malmedyweg, M&#x000fc;nster, Germany</addr-line></aff><aff id="aff2"><label>2</label><addr-line>Department of Radiology, The Children's Hospital of Philadelphia, Philadelphia, Pennsylvania, United States of America</addr-line></aff><aff id="aff3"><label>3</label><addr-line>Department of Psychology, University of M&#x000fc;nster, M&#x000fc;nster, Germany</addr-line></aff><contrib-group><contrib contrib-type="editor"><name><surname>Warrant</surname><given-names>Eric</given-names></name><role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1">Lund University, Sweden</aff><author-notes><corresp id="cor1">&#x0002a; E-mail: <email>zwitser@psy.uni-muenster.de</email></corresp><fn fn-type="con"><p>Conceived and designed the experiments: PZ. Performed the experiments: LE. Analyzed the data: KT LE. Wrote the paper: KT PZ. Valuable contributions to data analysis: PZ. Contributions to design of experiments: KT. Valuable contributions to conception and design of experiments, as well as analysis of data: CD. Helpful comments concerning data analysis: CP.</p></fn></author-notes><pub-date pub-type="collection"><year>2009</year></pub-date><pub-date pub-type="epub"><day>11</day><month>2</month><year>2009</year></pub-date><volume>4</volume><issue>2</issue><elocation-id>e4452</elocation-id><history><date date-type="received"><day>23</day><month>8</month><year>2008</year></date><date date-type="accepted"><day>7</day><month>1</month><year>2009</year></date></history><copyright-statement>Tavabi et al. This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</copyright-statement><copyright-year>2009</copyright-year><abstract><p>In casual speech, phonemic segments often assimilate such that they adopt features from adjacent segments, a typical feature being their place of articulation within the vocal tract (e.g., labial, coronal, velar). Place assimilation (e.g., from coronal /n/ to labial /m/: rainbow&#x02192;&#x0002a;<italic>raimbow</italic>) alters the surface form of words. Listeners' ability to perceptually compensate for such changes seems to depend on the phonemic context, on whether the adjacent segment (e.g., the /b/ in &#x0201c;rainbow&#x0201d;) invites the particular change. Also, some assimilations occur frequently (e.g., /n/&#x02192;/m/), others are rare (e.g., /m/&#x02192;/n/). We investigated the effects of place assimilation, its contextual dependency, and its frequency on the strength of auditory evoked mismatch negativity (MMN) responses, using pseudowords. Results from magnetoencephalography (MEG) revealed that the MMN was modulated both by the frequency and contextual appropriateness of assimilations.</p></abstract><counts><page-count count="7"/></counts></article-meta></front><body><sec id="s1"><title>Introduction</title><p>Understanding speech involves the mapping of sound onto meaning, a process which presents quite a challenge because of the tremendous variability of the speech signal. This variability is in part due to changes caused by coarticulation of adjacent speech segments. One such process is assimilation, the adoption, by a particular phonemic segment, of features of an adjacent segment. Although it is unclear whether assimilation completely erases the original features, it certainly changes the shape of words. The question is how the speech-processing system deals with such variability.</p><p>There is ample evidence that listeners are able to deal with assimilation of adjacent segments <xref ref-type="bibr" rid="pone.0004452-Darcy1">&#x0005b;1&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004452-Gaskell1">&#x0005b;2&#x0005d;</xref>. How this is accomplished, and which representations are involved, is still under debate. Therefore, event-related responses revealed by MEG may help elucidate the timing and brain activity underlying compensation for this type of variation in speech. We concentrated on regressive place assimilation, which involves consonants adopting the place of articulation of following consonants. An example is the change from /n/ to /m/, where the coronal phoneme /n/ adopts the labial place of articulation of a following labial (e.g., /green boat/&#x02192;/greem boat/). For effective comprehension, the resulting change must be compensated for, by perceptual mechanisms <xref ref-type="bibr" rid="pone.0004452-Mitterer1">&#x0005b;3&#x0005d;</xref> and/or by means of flexible representations.</p><p>We focus on three issues relevant to compensation for assimilation. The first question, still under debate, concerns the level(s) at which compensation arises. There is evidence for a contribution of early, nonlinguistic auditory processing to compensation for assimilation <xref ref-type="bibr" rid="pone.0004452-Mitterer1">&#x0005b;3&#x0005d;</xref>, but which subsequent level is involved: the feature, segmental, lexical level, or multiple levels? Given that segments adopt features from other segments, there is agreement that features must in some way be involved. From there, the proposals diverge. Some argue for a lexical locus of compensation for assimilation <xref ref-type="bibr" rid="pone.0004452-Lahiri1">&#x0005b;4&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004452-Ranbom1">&#x0005b;5&#x0005d;</xref>, while others assume that (abstract) phonemic representations intervene in the process of matching information present in the acoustic-phonetic signal onto abstract word-form representations in the lexicon <xref ref-type="bibr" rid="pone.0004452-Frauenfelder1">&#x0005b;6&#x0005d;</xref>.</p><p>The second issue concerns the influence of the phonemic context surrounding assimilated segments. In speaking, assimilation of one segment is elicited by an adjacent context segment whose place of articulation is likely to be adopted. Thus, successful perceptual compensation for place assimilation may well depend on the presence of adjacent segments that elicit and thus license the change (see <xref ref-type="bibr" rid="pone.0004452-Darcy1">&#x0005b;1&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004452-Mitterer1">&#x0005b;3&#x0005d;</xref>, for overviews). A third issue concerns well-established asymmetries in the frequency with which place features change. While coronal segments often assimilate and adopt a labial or velar place of assimilation, labials and velars almost never surface with a coronal place of articulation <xref ref-type="bibr" rid="pone.0004452-Gaskell1">&#x0005b;2&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004452-Jun1">&#x0005b;7&#x0005d;</xref>.</p><p>These issues are dealt with differently by the major approaches to compensation for coarticulation (see <xref ref-type="bibr" rid="pone.0004452-Darcy1">&#x0005b;1&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004452-Gaskell1">&#x0005b;2&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004452-Ranbom1">&#x0005b;5&#x0005d;</xref>, for overviews). The first assumes a pre-lexical mechanism of <italic>feature parsing</italic> <xref ref-type="bibr" rid="pone.0004452-Gow1">&#x0005b;8&#x0005d;</xref>, in which feature cues are grouped and assigned to segments. Feature parsing is inherently context-dependent, since it re-aligns parsed features with the adjacent segments they originated from. The mechanism is supposed to be language-independent, and indifferent to the frequency of a particular assimilation. Feature parsing implements compensation at the mapping between features and phonemic segments, not at a lexical level. Note that it runs into trouble with complete assimilation &#x02013; when all traces of the original feature are lost.</p><p>The second position assumes a language-specific mechanism of <italic>phonological inference</italic>, that countermands the effects of assimilation either by rule-application <xref ref-type="bibr" rid="pone.0004452-MarslenWilson1">&#x0005b;9&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004452-Gaskell2">&#x0005b;10&#x0005d;</xref>, or implemented as compensation learned in a probabilistic connectionist network <xref ref-type="bibr" rid="pone.0004452-Gaskell3">&#x0005b;11&#x0005d;</xref>. This mechanism is context-sensitive, operates at the level of segments (and beyond), and can explain partial and complete assimilation. Because compensation is learned, the mechanism is sensitive to assimilation frequency. It also predicts language-specific effects, for which the evidence is mixed <xref ref-type="bibr" rid="pone.0004452-Darcy1">&#x0005b;1&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004452-Mitterer2">&#x0005b;12&#x0005d;</xref>.</p><p>The third position, the <italic>Featurally Underspecified Lexicon</italic> (FUL), holds that all features are extracted, but not all features are specified in the lexicon <xref ref-type="bibr" rid="pone.0004452-Mitterer1">&#x0005b;3&#x0005d;</xref>. Features are mapped directly onto abstract lexical representations, resulting in either: (i) <italic>match</italic> if both signal and lexicon share the same features (ii) <italic>mismatch</italic> if a feature in the signal contradicts the lexical representation or (iii) <italic>no-mismatch</italic> when an extracted feature is not specified in the lexical representation. Place assimilation of a coronal segment (e.g., /n/, /t/, /d/) results in a no-mismatch, because coronal segments are underspecified for their place of articulation. FUL locates compensation for assimilation at the level of the lexicon, can explain partial and complete assimilation, but is indifferent to context. Given that &#x0005b;coronal&#x0005d; is underspecified but &#x0005b;labial&#x0005d; and &#x0005b;velar&#x0005d; are specified, FUL regards the frequent place assimilation of coronals as legal, and the infrequent velar and labial assimilation as illegal. The model thus predicts clear effects of the frequency asymmetry. Finally, the <italic>tolerance-based account</italic> also locates compensation at the lexical level <xref ref-type="bibr" rid="pone.0004452-Lahiri1">&#x0005b;4&#x0005d;</xref>. While all features are represented with the lexical word-forms, the word-recognition system is more tolerant to minimal than to maximal deviations, and to frequent deviations &#x02013; for nasal place assimilation, these would be the /n/ to /m/ changes.</p><p>To distinguish between these positions, we investigated the consequences and neural correlates of mismatch (and, in terms of FUL, no-mismatch) between features in the signal and phonemic representations, concentrating on nasal consonants. A first question concerns the lowest linguistic level at which compensation for assimilation comes about: At the lexicon, or below? In our understanding, FUL implements compensation for assimilation at the lexical level, assuming underspecified word forms. The same holds for the tolerance-based account. Thus, the input /greem/ can map onto the representation of the word &#x0201c;green&#x0201d;, but what happens when the input is not a word &#x02013; can /freem/ be &#x0201c;understood&#x0201d; as &#x0201c;freen&#x0201d;? In the feature parsing and inference models, this is possible because compensation is implemented at the level of &#x02013; adjacent - segments. The use of pseudowords is thus decisive for the level at which compensation comes about.</p><p>The second question concerns the phonemic context. In FUL, coronal segments are always underspecified, independent of their position in the word, and of adjacent context (cf. <xref ref-type="bibr" rid="pone.0004452-Friedrich1">&#x0005b;13&#x0005d;</xref>). The contextual appropriateness of the change is thus irrelevant. However, convergent behavioral and electrophysiological evidence suggest that successful compensation relies on the context in which assimilation occurs <xref ref-type="bibr" rid="pone.0004452-Frauenfelder1">&#x0005b;cf. 6&#x0005d;</xref>&#x02013;<xref ref-type="bibr" rid="pone.0004452-Mitterer3">&#x0005b;15&#x0005d;</xref>. The third issue concerns the frequency of place assimilation. The only account that predicts no asymmetrical effects is feature parsing (cf. <xref ref-type="bibr" rid="pone.0004452-Gow2">&#x0005b;16&#x0005d;</xref>). <xref ref-type="table" rid="pone-0004452-t001">Table 1</xref> summarizes the predictions made by the main models concerning the three issues addressed here.</p><table-wrap id="pone-0004452-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0004452.t001</object-id><label>Table 1</label><caption><title>Predictions of the three main approaches with respect to the issues under investigation.</title></caption><graphic id="pone-0004452-t001-1" xlink:href="pone.0004452.t001"/><table frame="hsides" rules="groups" alternate-form-of="pone-0004452-t001-1"><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup><thead><tr><td align="left" rowspan="1" colspan="1">Locus of compensation</td><td align="left" rowspan="1" colspan="1">FUL</td><td align="left" rowspan="1" colspan="1">Feature Parsing</td><td align="left" rowspan="1" colspan="1">Phonological inference</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">lexical</td><td align="left" rowspan="1" colspan="1">pre-lexical</td><td align="left" rowspan="1" colspan="1">both</td></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Effects of phonetic context</td><td align="left" rowspan="1" colspan="1">&#x02212;</td><td align="left" rowspan="1" colspan="1">&#x0002b;</td><td align="left" rowspan="1" colspan="1">&#x0002b;</td></tr><tr><td align="left" rowspan="1" colspan="1">Effects of assimilation frequency</td><td align="left" rowspan="1" colspan="1">&#x0002b;</td><td align="left" rowspan="1" colspan="1">&#x02212;</td><td align="left" rowspan="1" colspan="1">&#x0002b;</td></tr></tbody></table></table-wrap><p>We used MEG to assess phonological variation due to nasal regressive place assimilation, its frequency and contextual appropriateness by means of effects on auditory evoked MMN, whose time course is taken as an electrophysiological index for early speech-comprehension processes <xref ref-type="bibr" rid="pone.0004452-Pulvermuller1">&#x0005b;17&#x0005d;</xref>. MMN is a neurophysiological index of the detection of a change in the acoustic input that can be elicited in the absence of focused attention <xref ref-type="bibr" rid="pone.0004452-Ntnen1">&#x0005b;18&#x0005d;</xref>). It arises in the oddball paradigm, when listeners are confronted with series of stimuli, some of which are frequently presented (standards) and some infrequently (deviants). Relative to the response evoked by standards, around 200 ms after stimulus onset, deviants evoke a more pronounced response &#x02013; negative in EEG. This is labelled Mismatch Negativity, MMN.</p><p>To address our first question &#x02013; the locus of perceptual compensation for assimilation &#x02013; we presented pseudowords in an auditory oddball paradigm. To investigate the frequency asymmetry, we compared two basic conditions. In the first, we presented standards (e.g, <italic>onbo</italic>) with the coronal nasal /n/ and deviants (e.g., <italic>ombo</italic>) with the labial nasal /m/. This deviant constitutes a frequent assimilation of the standard (from /n/ to /m/). If frequency plays a role, we expected this deviant to cause little mismatch. In condition 2, the standard contained the labial nasal (e.g., /m/ in <italic>omdo</italic>), and the deviant contained the coronal nasal (e.g., /n/ in <italic>ondo</italic>). As a consequence of the frequency asymmetry &#x02013; in line with phonological inference and with underspecification, if it were to apply to a pre-lexical level -, we expected the deviant to cause a clear mismatch to the underlying representation established by the standard. Feature parsing predicts no impact of assimilation frequency.</p><p>In conditions 1 and 2, the frequent (n&#x02192;m) and infrequent (m&#x02192;n) place assimilations are both followed by a segment that establishes a phonemic context for the change. With two additional conditions, we orthogonally manipulated contextual appropriateness, by contrasting conditions in which the segment following the change from standard to deviant promotes this change (e.g., <italic>onbo</italic>&#x02192;<italic>ombo</italic>; <italic>omdo</italic>&#x02192;<italic>ondo</italic>) with conditions in which the context segment is inappropriate for the assimilation (<italic>ondo</italic>&#x02192;<italic>omdo</italic>; <italic>ombo</italic>&#x02192;<italic>onbo</italic>). In line with feature-parsing and inference models, and with the bulk of empirical data, we expected an impact of the appropriateness of the phonemic context.</p><p>To control for effects due to mere differences between the acoustic properties of standards and deviants, we calculated the &#x0201c;identity&#x0201d; mismatch negativity (iMMN). For this, we subtracted the response to the exact same stimulus presented as deviant and standard across different conditions, thus exploiting the stimulus-status inversion in the oddball paradigm <xref ref-type="bibr" rid="pone.0004452-Pulvermuller1">&#x0005b;17&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004452-Eulitz1">&#x0005b;19&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004452-Bonte1">&#x0005b;20&#x0005d;</xref>.</p></sec><sec id="s2"><title>Results</title><p>The grand average standard and deviant waveforms from each experimental condition are shown in <xref ref-type="fig" rid="pone-0004452-g001">figure 1</xref>. With respect to the &#x0201c;traditional&#x0201d; Mismatch, calculated by subtracting standard and deviant from the same condition, the following pattern emerged. In the interval 170&#x02013;410 ms following stimulus onset, a significant main effect of Assimilation Frequency on mean amplitude (F<sub>(1,15)</sub>&#x0200a;&#x0003d;&#x0200a;8.8, &#x003b7;p<sup>2</sup>&#x0200a;&#x0003d;&#x0200a;0.4, <italic>p</italic>&#x0003c;0.05) was observed. Infrequent (/m/&#x02192;/n/) changes resulted in an attenuated MMN response as compared to the frequent (/n/&#x02192;/m/) changes, the difference between infrequent (&#x02212;4.0&#x000b1;1.6 nAm) and frequent (&#x02212;8.3&#x000b1;1.4 nAm) changes amounting to 4.3&#x000b1;1.4 nAm (M&#x000b1;S.E.M). No other effects on MMN activity were observed in this time interval.</p><fig id="pone-0004452-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0004452.g001</object-id><label>Figure 1</label><caption><title>Grand-averaged source waveforms for the experimental odd-ball sequences contrasting frequent/infrequent nasal place feature assimilations embedded in appropriate/inappropriate phonemic context.</title><p>Robust mismatch activity was present in both hemispheres in all conditions in the interval 170&#x02013;410 ms following stimulus (shown below the left panel) onset.</p></caption><graphic xlink:href="pone.0004452.g001"/></fig><p>Given that the Frequency effect on this MMN activity could be due to physical differences between the standard and deviant stimuli, we computed the identity mismatch, for the same stimulus presented as standard and as deviant. In the post-stimulus interval 170&#x02013;410 ms, no main effects of Frequency (F&#x0003c;4) and Phonemic Context (F&#x0003c;1) were observed. However, a significant interaction between Frequency and Context (F<sub>(1,15)</sub>&#x0200a;&#x0003d;&#x0200a;13.8, &#x003b7;p<sup>2</sup>&#x0200a;&#x0003d;&#x0200a;0.5, <italic>p</italic>&#x0003c;0.05) modulated mean iMMN amplitude. Post-hoc examination of the cell means revealed an overall attenuated response to the frequent, contextually appropriate change (&#x02212;1.6&#x000b1;1.2 nAm), as compared to the frequent-inappropriate (&#x02212;7.5&#x000b1;2.5 nAm), infrequent-appropriate (&#x02212;10.2&#x000b1;2.2 nAm), and infrequent-inappropriate (&#x02212;6.3&#x000b1;1.2 nAm) conditions. The frequent-appropriate condition differed from all other conditions at <italic>p</italic>&#x0003c;0.05 (|t<sub>15</sub>|&#x0003e;2.0), which in turn did not differ amongst each other. It should be noted that the identity of the nasal (/n/ or /m/) can be identified with high levels of confidence some 100&#x02013;130 ms after stimulus onset &#x02013;this is based on a separate gating test of the material. Early identification of nasal segments occurs because the initial vowels were not &#x0201c;neutralized&#x0201d; and thus carry information as to the identity of the following nasal. Consequently, information about assimilation frequency, as reflected in the n&#x02192;m vs. m&#x02192;n change between standard and deviant, is available quite early (certainly earlier than reflected by the conservative nasal-recognition measure from gating). Thus, when the nasals can be distinguished, the two stimulus types in any given oddball block become uniquely specified, and effects of context (the /d/ or /b/ following the nasal) can come about at the same point in time.</p></sec><sec id="s3"><title>Discussion</title><p>The current study assessed the consequences of variation due to place assimilation on evoked mismatch activity in auditory cortex. With pseudoword stimuli, we investigated the frequency of assimilations along with their licensing by the adjacent segmental context. The data revealed effects of frequency modulated by contextual appropriateness on the mismatch response, as represented here by the iMMN. For the latter, oddball effects are on the exact same speech token, depending on whether it served as standard or as deviant across different stimulation blocks (see <xref ref-type="table" rid="pone-0004452-t001">Table 1</xref>). It was demonstrated earlier that the inversion method of standard/deviant stimuli is sensitive to the feature specification of segments <xref ref-type="bibr" rid="pone.0004452-Eulitz1">&#x0005b;19&#x0005d;</xref>, statistical regularities of phoneme clusters <xref ref-type="bibr" rid="pone.0004452-Bonte1">&#x0005b;20&#x0005d;</xref>, as well as lexical items <xref ref-type="bibr" rid="pone.0004452-Pulvermuller2">&#x0005b;21&#x0005d;</xref>.</p><p>Our first aim concerned the locus of compensatory mechanisms. Because the results were obtained using pseudowords with no lexical status and no close lexical representations, we argue that our effects reflect auditory processes operating on pre-lexical representations, most probably phonemic segments. This does not fit well with FUL and the tolerance-based account, both of which rely on stored lexical representations to compensate for assimilation. Our data conform to results by Mitterer and colleagues, who observed that the MMN reflects compensation for assimilation even for language material that was foreign to their listeners <xref ref-type="bibr" rid="pone.0004452-Mitterer2">&#x0005b;12&#x0005d;</xref>. Given the pre-lexical locus of the implemented compensatory mechanisms, the feature-parsing and inference approaches can easily accommodate our results. Note that we showed that compensation for assimilation can start early, before lexical access, but this early effect need not be the only compensatory process involved.</p><p>Our second aim concerned the impact of contextual appropriateness on the processing of assimilated speech. Underspecification theories such as FUL maintain that the phonemic context which elicits and thus licenses the assimilation is irrelevant, and there is some support for this claim <xref ref-type="bibr" rid="pone.0004452-Gumnior1">&#x0005b;22&#x0005d;</xref>. Context effects that are observed on reaction time are sometimes explained in terms of a frustrated anticipation of appropriate context phonemes <xref ref-type="bibr" rid="pone.0004452-Lahiri2">&#x0005b;23&#x0005d;</xref>. Our present data revealed a clear interaction between context and frequency of change. The differences in iMMN amplitude revealed an asymmetry in neural activity between frequent and infrequent changes &#x02013; but only if the phonemic context invites the assimilation.</p><p>Mitterer &#x00026; Blomert <xref ref-type="bibr" rid="pone.0004452-Mitterer3">&#x0005b;15&#x0005d;</xref> also reported MMN effects as a function of contextual appropriateness of assimilations, using real-word stimuli. In our iMMN data displayed in <xref ref-type="fig" rid="pone-0004452-g002">figure 2</xref>, we observed a clear context effect for frequent changes (/n/&#x02192;/m/), with an attenuated response to contextually appropriate changes relative to inappropriate ones. This corroborates and extends the Mitterer and Blomert findings to show that the lexical level is not relevant for compensation for nasal assimilation. Keep in mind that unlike Mitterer and Blomert, our iMMN analysis is based on a comparison of identical stimuli, in their roles as deviant and standard. As the comparison of our own data from the MMN and iMMN indicate (see <xref ref-type="sec" rid="s2">results</xref>), a direct comparison of our iMMN results to the MMN data by Mitterer and colleagues might be problematic.</p><fig id="pone-0004452-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0004452.g002</object-id><label>Figure 2</label><caption><title>Mean amplitude of the identity mismatch (iMMN) in 170&#x02013;410 ms post-stimulus interval.</title><p>The iMMN reflects oddball effects on the same speech token presented as deviant and standard across stimulation blocks. As predicted, an asymmetry in mismatch activity was observed between specified and underspecified segments only for contextually appropriate cases. Compared to the frequent (/n/ to /m/) change from the appropriate context, all other conditions showed significant enhancements in mismatch amplitude. Error bars represent 95&#x00025; confidence intervals.</p></caption><graphic xlink:href="pone.0004452.g002"/></fig><p>With respect to our third question concerning the asymmetry in assimilation frequency (with /n/ to /m/ being frequent and /m/ to /n/ being rare), we indeed observed effects of frequency. This effect was quite pronounced in appropriate contexts, where infrequent changes generated a much larger mismatch response potential than frequent changes. In inappropriate contexts, frequency had no significant impact. Whereas a main effect of assimilation frequency would be in line with the FUL model, the observed interaction between frequency and context is not. Interestingly, iMMN amplitude was enhanced in all cases that implement one or more types of violation, compared to the case that conforms to the subject's knowledge of the patterns governing speech-sound assimilations (the frequent, contextually appropriate condition). Our data are better understood in terms of models that assign a role to both factors. Contextual appropriateness is an inherent feature in the feature parsing and inference models, which can also easily deal with a pre-lexical locus of compensation for assimilation. There is one aspect of our material that is problematic for feature parsing: Given that our speaker pronounced the stimuli as they were written (<italic>ombo</italic>, <italic>onbo</italic>, <italic>omdo</italic>, <italic>ondo</italic>), all changes were complete. This may tip the scale in favour of inference mechanisms, in which early effects of compensation for assimilation are located at the level of adjacent segments.</p><p>Although our data provide evidence for early and pre-attentive mechanisms involved in compensation for assimilation, we in no way wish to deny a role for (subsequent) lexical, and even semantic, involvement <xref ref-type="bibr" rid="pone.0004452-Gaskell1">&#x0005b;2&#x0005d;</xref>. Clearly, more research is needed on the timing and neural correlates of all processes underlying the compensatory mechanisms for resolving variability in speech.</p><p>In conclusion, the current study provides electrophysiological evidence for early auditory processes involved in speech perception. Auditory evoked mismatch negativity activity was modulated by the frequency and contextual appropriateness of assimilations conveyed by pseudowords. The evidence suggests that early feature extraction from the incoming sensory input provides bottom-up excitation of features, which in turn facilitates phonemic recognition by pattern-matching and automatic change-detection mechanisms in auditory cortex. Assimilation frequency and contextual appropriateness play a role at a phonemic (and thus pre-lexical) level of representation, and beyond, in order to constrain how elements combine into higher-level units such as word forms. Our results provide some backup for underspecification theories, &#x02013; given that we do observe effects of frequency &#x02013; and quite some more support for models that envisage a dynamic process of feature extraction, pattern matching and mapping onto segmental representations in a context-dependent way.</p></sec><sec sec-type="materials|methods" id="s4"><title>Materials and Methods</title><p>Sixteen right-handed German speakers (mean age 24, 11 female) participated in experimental procedures. The subjects gave written informed consent to their participation after they were completely informed about the nature of the study. The Ethics Commission of the University of M&#x000fc;nster approved all experimental procedures, which were in accordance with the Declaration of Helsinki.</p><p>Disyllabic vowel-consonant-consonant-vowel (VC<sub>1</sub>C<sub>2</sub>V) pseudowords (<italic>ombo</italic>, <italic>omdo</italic>, <italic>onbo</italic>, <italic>ondo</italic>) were quasi-synthesized from digitized recordings by a male native German speaker. Two initial vowels, one from a /m/ context, one from a /n/ context, nasal segments, and second syllables (C<sub>2</sub>V) were edited out and matched for duration. The Pitch Synchronous Overlap Addition algorithm in Praat <xref ref-type="bibr" rid="pone.0004452-Boersma1">&#x0005b;24&#x0005d;</xref> was used to calculate time windows from the glottal pulses in the original signal. Segment durations were matched by omitting, or appending, overlapping windows using a Gaussian function precisely centred on each glottal pulse. Each nasal segment was neutralized for coarticulatory cues to the identity of the following consonants, by mixing its two realizations in different contexts (/b/ or /d/). Next, the neutralized nasals were recombined with initial corresponding vowels. Finally, the C<sub>2</sub>V (i.e. /bo/ and /do/) were appended at zero crossings, with rising slopes to form 1039 ms long stimuli (see <xref ref-type="fig" rid="pone-0004452-g003">Figure 3</xref>). Four different tokens of each pseudoword were created by scaling their pitch contours. The resulting 16 sound files were faded in and out with 50 and 35 ms linear ramps, and the intensity was normalized to mean RMS amplitude across all stimuli.</p><fig id="pone-0004452-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0004452.g003</object-id><label>Figure 3</label><caption><title>Stimulus material.</title><p>Disyllabic VC<sub>1</sub>C<sub>2</sub>V pseudowords created by cross-splicing, mixing, and rejoining segments edited from recorded speech.</p></caption><graphic xlink:href="pone.0004452.g003"/></fig><p><xref ref-type="table" rid="pone-0004452-t002">Table 2</xref> describes the pseudo-random arrangement of stimuli into four odd-ball sequences, with equal numbers of the four tokens per stimulus, separated by a 2.4&#x000b1;0.2 s onset asynchrony, and a 25&#x00025; probability of deviants occurring. Mismatch always concerned a change in a single place feature of the nasal, embedded in a context that either promoted the assimilation or not (see <xref ref-type="table" rid="pone-0004452-t001">Table 1</xref>). The stimulus-status inversion in the paradigm guaranteed that standard and deviant stimuli were physically identical across conditions. The four different experimental sessions were counterbalanced across participants to counteract order effects.</p><table-wrap id="pone-0004452-t002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0004452.t002</object-id><label>Table 2</label><caption><title>Odd-ball paradigm.</title></caption><graphic id="pone-0004452-t002-2" xlink:href="pone.0004452.t002"/><table frame="hsides" rules="groups" alternate-form-of="pone-0004452-t002-2"><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup><thead><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">MMNm Condition</td><td align="left" rowspan="1" colspan="1">Standard</td><td align="left" rowspan="1" colspan="1">Deviant</td><td align="left" rowspan="1" colspan="1">Standard</td><td align="left" rowspan="1" colspan="1">Deviant</td><td align="left" rowspan="1" colspan="1">iMMNm Condition</td></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">1</td><td align="left" rowspan="1" colspan="1">frequent &#x02013;appropriate</td><td align="left" rowspan="1" colspan="1">&#x0005b;onbo&#x0005d;</td><td align="left" rowspan="1" colspan="1">&#x0005b;ombo&#x0005d;</td><td align="left" rowspan="1" colspan="1"><italic>(1)</italic> &#x0005b;onbo&#x0005d;</td><td align="left" rowspan="1" colspan="1"><italic>(4)</italic> &#x0005b;onbo&#x0005d;</td><td align="left" rowspan="1" colspan="1">infrequent - inappropriate</td></tr><tr><td align="left" rowspan="1" colspan="1">2</td><td align="left" rowspan="1" colspan="1">frequent &#x02013;inappropriate</td><td align="left" rowspan="1" colspan="1">&#x0005b;ondo&#x0005d;</td><td align="left" rowspan="1" colspan="1">&#x0005b;omdo&#x0005d;</td><td align="left" rowspan="1" colspan="1"><italic>(2)</italic> &#x0005b;ondo&#x0005d;</td><td align="left" rowspan="1" colspan="1"><italic>(3)</italic> &#x0005b;ondo&#x0005d;</td><td align="left" rowspan="1" colspan="1">infrequent - appropriate</td></tr><tr><td align="left" rowspan="1" colspan="1">3</td><td align="left" rowspan="1" colspan="1">infrequent &#x02013;appropriate</td><td align="left" rowspan="1" colspan="1">&#x0005b;omdo&#x0005d;</td><td align="left" rowspan="1" colspan="1">&#x0005b;ondo&#x0005d;</td><td align="left" rowspan="1" colspan="1"><italic>(3)</italic> &#x0005b;omdo&#x0005d;</td><td align="left" rowspan="1" colspan="1"><italic>(2)</italic> &#x0005b;omdo&#x0005d;</td><td align="left" rowspan="1" colspan="1">frequent - inappropriate</td></tr><tr><td align="left" rowspan="1" colspan="1">4</td><td align="left" rowspan="1" colspan="1">infrequent &#x02013;inappropriate</td><td align="left" rowspan="1" colspan="1">&#x0005b;ombo&#x0005d;</td><td align="left" rowspan="1" colspan="1">&#x0005b;onbo&#x0005d;</td><td align="left" rowspan="1" colspan="1"><italic>(4)</italic> &#x0005b;ombo&#x0005d;</td><td align="left" rowspan="1" colspan="1"><italic>(1)</italic> &#x0005b;ombo&#x0005d;</td><td align="left" rowspan="1" colspan="1">frequent - appropriate</td></tr></tbody></table><table-wrap-foot><fn id="nt101"><p>Odd-ball stimulus pairings used to elicit the auditory mismatch response to assimilation of nasal segments in different phonemic contexts. Mismatch always concerned a change in a single place feature of the nasal, frequent (n&#x02192;m) and infrequent (m&#x02192;n), embedded in a context that either promoted the change or not. The identity mismatch (iMMN) was computed by subtracting the evoked response to each pseudoword presented as standard from the response to the same stimulus presented as deviant. The iMMN conditions were defined on the basis of deviants at the time of data acquisition.</p></fn></table-wrap-foot></table-wrap><p>Auditory evoked fields were recorded using MEG (275 channel whole-head gradiometer; CTF system Inc., Vancouver, Canada) in a quiet, magnetically shielded room (600 Hz sampling rate, 150-Hz low-pass and 50-Hz notch filters online). For each pseudoword, 1140 ms (100 ms pre- stimulus) epochs were averaged off-line after artefact rejection (threshold 3.0 pT) and off-line noise correction. A DC-offset correction was applied based on the mean value obtained from the pre-stimulus interval.</p><p>To estimate the activity in auditory cortex, the method of signal space projection (SSP) <xref ref-type="bibr" rid="pone.0004452-Tesche1">&#x0005b;25&#x0005d;</xref> was applied to the MEG data, resulting in a virtual sensor maximally sensitive to P50 activity in our subjects. We chose to base the source localization in this study on P50 for the following reasons. First, P50 responses were larger and more reliably detected than the N100 and MMN, thus reducing localization error and affording the best signal-to-noise ratio. Second, it is generally accepted that the MMN is mainly generated in the auditory cortex <xref ref-type="bibr" rid="pone.0004452-Kujala1">&#x0005b;26&#x0005d;</xref>, with overlapping sources for processing complex stimuli <xref ref-type="bibr" rid="pone.0004452-Takegata1">&#x0005b;27&#x0005d;</xref>. Third, mean P50m and N100m localizations for subjects reliably displaying both components did not differ significantly. For these N&#x0200a;&#x0003d;&#x0200a;7 subjects, with bilateral dipole models for both components, localizations did not differ along any of the major axes in 3D space (all |t<sub>6</sub>|&#x0003c;2). Averaged data for each pseudoword stimulus, irrespective of odd-ball status (i.e., standard or deviant) were filtered using 3&#x02013;150 Hz band-pass for estimating the location of P50m generators. An equivalent single dipole (spatiotemporal model in common stereotaxic space based on individual anatomy) in each hemisphere was approximated to the magnetic field distribution around the maximum (the rising slope) of the global field power between 30 to 80 ms after stimulus onset. Individual models localized within volumes containing Heschl's Gyrus and Planum Temporale <xref ref-type="bibr" rid="pone.0004452-Penhune1">&#x0005b;28&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004452-Westbury1">&#x0005b;29&#x0005d;</xref>, and accounting for greater than 90&#x00025; of residual variance in the measured field were subjected to further analysis. An analysis of variance (ANOVA), with condition as a fixed factor, and with coordinates of acceptable P50m source models for each pseudoword stimulus (irrespective of odd-ball status) as dependent measure, revealed no significant localization differences between conditions (all Fs&#x0003c;2). Individual models meeting the fitting criteria were grand averaged and used as a source model, or SSP &#x0201c;virtual sensor&#x0201d;, used to derive the time course of auditory activity following odd-ball stimuli for each subject.</p><p>The resulting source waveforms derived from the SSP &#x0201c;virtual sensor&#x0201d; were band-pass filtered between 0&#x02013;25 Hz. The &#x0201c;traditional&#x0201d; MMN was obtained by subtracting the response to the standards from that elicited by deviants. The &#x0201c;identity&#x0201d; mismatch negativity (iMMN) was calculated by stimulus-status inversion, by subtracting the response to the same stimulus presented as deviant and standard across different conditions.</p></sec></body><back><ack><p>We are grateful to Markus Junghoefer for his helpful comments and assistance in data evaluation, and to Heidrun Bien for valuable discussions.</p></ack><ref-list><title>References</title><ref id="pone.0004452-Darcy1"><label>1</label><citation citation-type="book"><person-group person-group-type="author"><name><surname>Darcy</surname><given-names>I</given-names></name><name><surname>Ramus</surname><given-names>F</given-names></name><name><surname>Christophe</surname><given-names>A</given-names></name><name><surname>Kinzler</surname><given-names>K</given-names></name><name><surname>Dupoux</surname><given-names>E</given-names></name></person-group><article-title>Phonological knowledge in compensation for native and non-native assimilation.</article-title><person-group person-group-type="editor"><name><surname>K&#x000fc;gler</surname><given-names>F</given-names></name><name><surname>Fery</surname><given-names>C</given-names></name><name><surname>de Vijver</surname><given-names>R</given-names></name></person-group><source>Variation and gradience in phonetics and phonology</source><publisher-loc>Berlin</publisher-loc><publisher-name>Mouton</publisher-name><comment>In press</comment></citation></ref><ref id="pone.0004452-Gaskell1"><label>2</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Gaskell</surname><given-names>G</given-names></name><name><surname>Snoeren</surname><given-names>ND</given-names></name></person-group><year>2008</year><article-title>The impact of strong assimilation on the perception of connected speech.</article-title><source>Journal of Experimental Psychology: Human perception and Performance</source><volume>34</volume><fpage>1632</fpage><lpage>1647</lpage><pub-id pub-id-type="pmid">19045997</pub-id></citation></ref><ref id="pone.0004452-Mitterer1"><label>3</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Mitterer</surname><given-names>H</given-names></name><name><surname>Cs&#x000e9;pe</surname><given-names>V</given-names></name><name><surname>Blomert</surname><given-names>L</given-names></name></person-group><year>2006</year><article-title>The role of perceptual integration in the recognition of assimilated word forms.</article-title><source>The Quarterly Journal of Experimental Psychology</source><volume>59</volume><fpage>1395</fpage><lpage>1424</lpage><pub-id pub-id-type="pmid">16846968</pub-id></citation></ref><ref id="pone.0004452-Lahiri1"><label>4</label><citation citation-type="book"><person-group person-group-type="author"><name><surname>Lahiri</surname><given-names>A</given-names></name><name><surname>Reetz</surname><given-names>H</given-names></name></person-group><year>2002</year><article-title>Underspecified recognition.</article-title><person-group person-group-type="editor"><name><surname>Gussenhoven</surname><given-names>G</given-names></name><name><surname>Warner</surname><given-names>E</given-names></name></person-group><source>Laboratory Phonology</source><publisher-loc>Berlin</publisher-loc><publisher-name>Mouton</publisher-name><fpage>637</fpage><lpage>676</lpage></citation></ref><ref id="pone.0004452-Ranbom1"><label>5</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ranbom</surname><given-names>L</given-names></name><name><surname>Connine</surname><given-names>CM</given-names></name></person-group><year>2007</year><article-title>Lexical representation of phonological variation in spoken word recognition.</article-title><source>Journal of Memory and Language</source><volume>57</volume><fpage>273</fpage><lpage>298</lpage></citation></ref><ref id="pone.0004452-Frauenfelder1"><label>6</label><citation citation-type="book"><person-group person-group-type="author"><name><surname>Frauenfelder</surname><given-names>UH</given-names></name><name><surname>Floccia</surname><given-names>C</given-names></name></person-group><year>1999</year><article-title>The Recognition of Spoken Words.</article-title><person-group person-group-type="editor"><name><surname>Friederici</surname><given-names>AD</given-names></name></person-group><source>Language Comprehension: A Biological Perspective</source><publisher-loc>Heidelberg</publisher-loc><publisher-name>Springer-Verlag Berlin</publisher-name><fpage>1</fpage><lpage>41</lpage></citation></ref><ref id="pone.0004452-Jun1"><label>7</label><citation citation-type="book"><person-group person-group-type="author"><name><surname>Jun</surname><given-names>J</given-names></name></person-group><year>2004</year><article-title>Place assimilation.</article-title><person-group person-group-type="editor"><name><surname>Hayes</surname><given-names>B</given-names></name><name><surname>Kirchner</surname><given-names>R</given-names></name><name><surname>Steriade</surname><given-names>D</given-names></name></person-group><source>Phonetically based phonology</source><publisher-loc>Cambridge</publisher-loc><publisher-name>Cambridge University Press</publisher-name><fpage>58</fpage><lpage>86</lpage></citation></ref><ref id="pone.0004452-Gow1"><label>8</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Gow</surname><given-names>DW</given-names></name></person-group><year>2003</year><article-title>Feature parsing: Feature cue mapping in spoken word recognition.</article-title><source>Perception &#x00026; Psychophysics</source><volume>65</volume><fpage>575</fpage><lpage>590</lpage><pub-id pub-id-type="pmid">12812280</pub-id></citation></ref><ref id="pone.0004452-MarslenWilson1"><label>9</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Marslen-Wilson</surname><given-names>WD</given-names></name><name><surname>Nix</surname><given-names>A</given-names></name><name><surname>Gaskell</surname><given-names>G</given-names></name></person-group><year>1995</year><article-title>Phonological variation in lexical access: Abstractness, inference and English place assimilation.</article-title><source>Language and Cognitive Processes</source><volume>10</volume><fpage>285</fpage><lpage>308</lpage></citation></ref><ref id="pone.0004452-Gaskell2"><label>10</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Gaskell</surname><given-names>G</given-names></name><name><surname>Marslen-Wilson</surname><given-names>WD</given-names></name></person-group><year>1998</year><article-title>Mechanisms of phonological inference in speech perception.</article-title><source>Journal of Experimental Psychology: Human Perception and Performance</source><volume>24</volume><fpage>380</fpage><lpage>396</lpage><pub-id pub-id-type="pmid">9554092</pub-id></citation></ref><ref id="pone.0004452-Gaskell3"><label>11</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Gaskell</surname><given-names>G</given-names></name></person-group><year>2003</year><article-title>Modelling regressive and progressive effects of assimilation in speech perception.</article-title><source>Journal of Phonetics</source><volume>31</volume><fpage>447</fpage><lpage>463</lpage></citation></ref><ref id="pone.0004452-Mitterer2"><label>12</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Mitterer</surname><given-names>H</given-names></name><name><surname>Csepe</surname><given-names>V</given-names></name><name><surname>Honbolygo</surname><given-names>F</given-names></name><name><surname>Blomert</surname><given-names>L</given-names></name></person-group><year>2006</year><article-title>The recognition of phonologically assimilated words does not depend on specific language experience.</article-title><source>Cognitive Science</source><volume>30</volume><fpage>451</fpage><lpage>479</lpage></citation></ref><ref id="pone.0004452-Friedrich1"><label>13</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Friedrich</surname><given-names>C</given-names></name><name><surname>Eulitz</surname><given-names>C</given-names></name><name><surname>Lahiri</surname><given-names>A</given-names></name></person-group><year>2006</year><article-title>Not every pseudoword disrupts word recognition: an ERP study.</article-title><source>Behavioral and Brain Functions</source><volume>2</volume><fpage>36</fpage><pub-id pub-id-type="pmid">17062152</pub-id></citation></ref><ref id="pone.0004452-Coenen1"><label>14</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Coenen</surname><given-names>E</given-names></name><name><surname>Zwitserlood</surname><given-names>P</given-names></name><name><surname>Bolte</surname><given-names>J</given-names></name></person-group><year>2001</year><article-title>Variation and assimilation in German: Consequences for lexical access and representation.</article-title><source>Language and Cognitive Processes</source><volume>16</volume><fpage>535</fpage><lpage>564</lpage></citation></ref><ref id="pone.0004452-Mitterer3"><label>15</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Mitterer</surname><given-names>H</given-names></name><name><surname>Blomert</surname><given-names>L</given-names></name></person-group><year>2003</year><article-title>Coping with phonological assimilation in speech perception: Evidence for early compensation.</article-title><source>Perception &#x00026; Psychophysics</source><volume>65</volume><fpage>956</fpage><lpage>969</lpage><pub-id pub-id-type="pmid">14528902</pub-id></citation></ref><ref id="pone.0004452-Gow2"><label>16</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Gow</surname><given-names>D</given-names></name></person-group><year>2001</year><article-title>Assimilation and anticipation in continuous spoken word recognition.</article-title><source>Journal of Memory and Language</source><volume>45</volume><fpage>133</fpage><lpage>159</lpage></citation></ref><ref id="pone.0004452-Pulvermuller1"><label>17</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Pulvermuller</surname><given-names>F</given-names></name><name><surname>Shtyrov</surname><given-names>Y</given-names></name></person-group><year>2006</year><article-title>Language outside the focus of attention: The mismatch negativity as a tool for studying higher cognitive processes.</article-title><source>Progress in Neurobiology</source><volume>79</volume><fpage>49</fpage><lpage>71</lpage><pub-id pub-id-type="pmid">16814448</pub-id></citation></ref><ref id="pone.0004452-Ntnen1"><label>18</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>N&#x000e4;&#x000e4;t&#x000e4;nen</surname><given-names>R</given-names></name></person-group><year>2001</year><article-title>The perception of speech sounds by the human brain as reflected by the mismatch negativity (MMN) and its magnetic equivalent (MMNm).</article-title><source>Psychophysiology</source><volume>38</volume><fpage>1</fpage><lpage>21</lpage><pub-id pub-id-type="pmid">11321610</pub-id></citation></ref><ref id="pone.0004452-Eulitz1"><label>19</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Eulitz</surname><given-names>C</given-names></name><name><surname>Lahiri</surname><given-names>A</given-names></name></person-group><year>2004</year><article-title>Neurobiological Evidence for Abstract Phonological Representations in the Mental Lexicon during Speech Recognition.</article-title><source>J Cogn Neurosci</source><volume>16</volume><fpage>577</fpage><lpage>583</lpage><pub-id pub-id-type="pmid">15185677</pub-id></citation></ref><ref id="pone.0004452-Bonte1"><label>20</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Bonte</surname><given-names>ML</given-names></name><name><surname>Mitterer</surname><given-names>H</given-names></name><name><surname>Zellagui</surname><given-names>N</given-names></name><name><surname>Poelmans</surname><given-names>H</given-names></name><name><surname>Blomert</surname><given-names>L</given-names></name></person-group><year>2005</year><article-title>Auditory cortical tuning to statistical regularities in phonology.</article-title><source>Clinical Neurophysiology</source><volume>116</volume><fpage>2765</fpage><lpage>2774</lpage><pub-id pub-id-type="pmid">16256430</pub-id></citation></ref><ref id="pone.0004452-Pulvermuller2"><label>21</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Pulvermuller</surname><given-names>F</given-names></name><name><surname>Shtyrov</surname><given-names>Y</given-names></name><name><surname>Ilmoniemi</surname><given-names>RJ</given-names></name><name><surname>Marslen-Wilson</surname><given-names>WD</given-names></name></person-group><year>2006</year><article-title>Tracking speech comprehension in space and time.</article-title><source>NeuroImage</source><volume>31</volume><fpage>1297</fpage><lpage>1305</lpage><pub-id pub-id-type="pmid">16556504</pub-id></citation></ref><ref id="pone.0004452-Gumnior1"><label>22</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Gumnior</surname><given-names>H</given-names></name><name><surname>Zwitserlood</surname><given-names>P</given-names></name><name><surname>B&#x000f6;lte</surname><given-names>J</given-names></name></person-group><year>2005</year><article-title>Assimilation in existing and novel German compounds.</article-title><source>Language and Cognitive Processes</source><volume>20</volume><fpage>465</fpage><lpage>488</lpage></citation></ref><ref id="pone.0004452-Lahiri2"><label>23</label><citation citation-type="book"><person-group person-group-type="author"><name><surname>Lahiri</surname><given-names>A</given-names></name></person-group><year>2000</year><article-title>Phonology: Structure, representation, and process.</article-title><person-group person-group-type="editor"><name><surname>Wheeldon</surname><given-names>L</given-names></name></person-group><source>Aspects of language production: Studies in cognition series</source><publisher-loc>Philadelphia, PA</publisher-loc><publisher-name>Psychology Press</publisher-name><fpage>165</fpage><lpage>225</lpage></citation></ref><ref id="pone.0004452-Boersma1"><label>24</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Boersma</surname><given-names>P</given-names></name><name><surname>Weenink</surname><given-names>D</given-names></name></person-group><year>2001</year><article-title>PRAAT, a system for doing phonetics by computer.</article-title><source>Glot International</source><volume>5</volume><fpage>341</fpage><lpage>345</lpage></citation></ref><ref id="pone.0004452-Tesche1"><label>25</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Tesche</surname><given-names>CD</given-names></name><name><surname>Uusitalo</surname><given-names>MA</given-names></name><name><surname>Ilmoniemi</surname><given-names>RJ</given-names></name><name><surname>Huotilainen</surname><given-names>M</given-names></name><name><surname>Kajola</surname><given-names>M</given-names></name><etal/></person-group><year>1995</year><article-title>Signal-space projections of MEG data characterize both distributed and well-localized neuronal sources.</article-title><source>Electroencephalography and Clinical Neurophysiology</source><volume>95</volume><fpage>189</fpage><lpage>200</lpage><pub-id pub-id-type="pmid">7555909</pub-id></citation></ref><ref id="pone.0004452-Kujala1"><label>26</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kujala</surname><given-names>T</given-names></name><name><surname>Tervaniemi</surname><given-names>M</given-names></name><name><surname>Schroger</surname><given-names>E</given-names></name></person-group><year>2007</year><article-title>The mismatch negativity in cognitive and clinical neuroscience: Theoretical and methodological considerations.</article-title><source>Biological Psychology</source><volume>74</volume><fpage>1</fpage><lpage>19</lpage><pub-id pub-id-type="pmid">16844278</pub-id></citation></ref><ref id="pone.0004452-Takegata1"><label>27</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Takegata</surname><given-names>R</given-names></name><name><surname>Paavilainen</surname><given-names>P</given-names></name><name><surname>Naatanen</surname><given-names>R</given-names></name><name><surname>Winkler</surname><given-names>I</given-names></name></person-group><year>2001</year><article-title>Preattentive processing of spectral, temporal, and structural characteristics of acoustic regularities: A mismatch negativity study.</article-title><source>Psychophysiology</source><volume>38</volume><fpage>92</fpage><lpage>98</lpage><pub-id pub-id-type="pmid">11321624</pub-id></citation></ref><ref id="pone.0004452-Penhune1"><label>28</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Penhune</surname><given-names>VB</given-names></name><name><surname>Zatorre</surname><given-names>RJ</given-names></name><name><surname>MacDonald</surname><given-names>JD</given-names></name><name><surname>Evans</surname><given-names>AC</given-names></name></person-group><year>1996</year><article-title>Interhemispheric Anatomical Differences in Human Primary Auditory Cortex: Probabilistic Mapping and Volume Measurement from magentic Resonance Scans.</article-title><source>Cereb Cortex</source><volume>6</volume><fpage>661</fpage><lpage>672</lpage><pub-id pub-id-type="pmid">8921202</pub-id></citation></ref><ref id="pone.0004452-Westbury1"><label>29</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Westbury</surname><given-names>CF</given-names></name><name><surname>Zatorre</surname><given-names>RJ</given-names></name><name><surname>Evans</surname><given-names>AC</given-names></name></person-group><year>1999</year><article-title>Quantifying Variability in the Planum Temporale: A Probability Map.</article-title><source>Cereb Cortex</source><volume>9</volume><fpage>392</fpage><lpage>405</lpage><pub-id pub-id-type="pmid">10426418</pub-id></citation></ref></ref-list><fn-group><fn fn-type="conflict"><p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p></fn><fn fn-type="financial-disclosure"><p><bold>Funding: </bold>The Deutsche Forschungsgemeinschaft as part of SPP 1234: Phonological and phonetic competence: between grammar, signal processing, and neural activity (Project ZW-65-65/5-1 Neural and psychological correlates of phonological categories). For his involvement in this project C.D. was supported by the German Volkswagen Foundation (Volkswagen Stiftung, I/80709). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</p></fn></fn-group></back></article>