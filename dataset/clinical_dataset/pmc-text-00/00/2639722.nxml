<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN" "archivearticle.dtd"><article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article" xml:lang="EN"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><journal-title>PLoS Computational Biology</journal-title><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">19266015</article-id><article-id pub-id-type="pmc">2639722</article-id><article-id pub-id-type="publisher-id">08-PLCB-RA-0720R3</article-id><article-id pub-id-type="doi">10.1371/journal.pcbi.1000301</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline"><subject>Computational Biology/Computational Neuroscience</subject><subject>Otolaryngology/Audiology</subject></subj-group></article-categories><title-group><article-title>Understanding Pitch Perception as a Hierarchical Process with Top-Down Modulation</article-title><alt-title alt-title-type="running-head">Top-Down Model of Pitch Perception</alt-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Balaguer-Ballester</surname><given-names>Emili</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="corresp" rid="cor1"><sup>&#x0002a;</sup></xref></contrib><contrib contrib-type="author"><name><surname>Clark</surname><given-names>Nicholas R.</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref></contrib><contrib contrib-type="author"><name><surname>Coath</surname><given-names>Martin</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Krumbholz</surname><given-names>Katrin</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref></contrib><contrib contrib-type="author"><name><surname>Denham</surname><given-names>Susan L.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff1"><label>1</label><addr-line>Centre for Theoretical and Computational Neuroscience, University of Plymouth, Plymouth, United Kingdom</addr-line></aff><aff id="aff2"><label>2</label><addr-line>Computational Neuroscience Group, Central Institute for Mental Health (ZI), Ruprecht-Karls University of Heidelberg, Mannheim, Germany</addr-line></aff><aff id="aff3"><label>3</label><addr-line>MRC Institute of Hearing Research, Nottingham, United Kingdom</addr-line></aff><contrib-group><contrib contrib-type="editor"><name><surname>Friston</surname><given-names>Karl J.</given-names></name><role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1">University College London, United Kingdom</aff><author-notes><corresp id="cor1">&#x0002a; E-mail: <email>emili.balaguer@zi-mannheim.de</email></corresp><fn fn-type="con"><p>Conceived and designed the experiments: NRC KK. Performed the experiments: NRC. Analyzed the data: EB-B. Contributed reagents/materials/analysis tools: EB-B NRC MC KK SLD. Wrote the paper: EB-B NRC MC KK SLD. Conceived and implemented the model and evaluations: EB-B.</p></fn></author-notes><pub-date pub-type="collection"><month>3</month><year>2009</year></pub-date><!-- Fake ppub added to accomodate plos workflow change from 03/2008 --><pub-date pub-type="ppub"><month>3</month><year>2009</year></pub-date><pub-date pub-type="epub"><day>6</day><month>3</month><year>2009</year></pub-date><volume>5</volume><issue>3</issue><elocation-id>e1000301</elocation-id><history><date date-type="received"><day>26</day><month>8</month><year>2008</year></date><date date-type="accepted"><day>23</day><month>1</month><year>2009</year></date></history><copyright-statement>Balaguer-Ballester et al. This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</copyright-statement><copyright-year>2009</copyright-year><abstract><p>Pitch is one of the most important features of natural sounds, underlying the perception of melody in music and prosody in speech. However, the temporal dynamics of pitch processing are still poorly understood. Previous studies suggest that the auditory system uses a wide range of time scales to integrate pitch-related information and that the effective integration time is both task- and stimulus-dependent. None of the existing models of pitch processing can account for such task- and stimulus-dependent variations in processing time scales. This study presents an idealized neurocomputational model, which provides a unified account of the multiple time scales observed in pitch perception. The model is evaluated using a range of perceptual studies, which have not previously been accounted for by a single model, and new results from a neurophysiological experiment. In contrast to other approaches, the current model contains a hierarchy of integration stages and uses feedback to adapt the effective time scales of processing at each stage in response to changes in the input stimulus. The model has features in common with a <italic>hierarchical generative</italic> process and suggests a key role for efferent connections from central to sub-cortical areas in controlling the temporal dynamics of pitch processing.</p></abstract><abstract abstract-type="summary"><title>Author Summary</title><p>Pitch is one of the most important features of natural sounds. The pitch sensation depends strongly on its temporal context, as happens, for example, in the perception of melody in music and prosody in speech. However, the temporal dynamics of pitch processing are poorly understood. Perceptual studies have shown that there is apparently a wide range of time scales over which pitch-related information is integrated. This multiplicity in perceptual time scales requires a trade-off between temporal resolution and temporal integration, which is not exclusive to pitch perception but applies to auditory perception in general. As far as we are aware, no existing model can account simultaneously for the wide range and stimulus-dependent nature of the perceptual phenomenology. This article presents a neurocomputational model, which explains the temporal resolution&#x02013;integration trade-off observed in pitch perception in a unified fashion. The main contribution of this work is to propose that top-down, efferent mechanisms are crucial for pitch processing. The model replicates perceptual responses in a wide range of perceptual experiments not simultaneously accounted for by previous approaches. Moreover, it accounts quantitatively for the stimulus-dependent latency of the pitch onset response measured in the auditory cortex.</p></abstract><counts><page-count count="15"/></counts></article-meta></front><body><sec id="s1"><title>Introduction</title><p>Modelling the neural processing of pitch is essential for understanding the perceptual phenomenology of music and speech. Pitch, one of the most important features of auditory perception, is usually associated with periodicities in sounds <xref ref-type="bibr" rid="pcbi.1000301-Moore1">&#x0005b;1&#x0005d;</xref>. Hence, a number of models of pitch perception are based upon a temporal analysis of the neural activity evoked by the stimulus <xref ref-type="bibr" rid="pcbi.1000301-Licklider1">&#x0005b;2&#x0005d;</xref>&#x02013;<xref ref-type="bibr" rid="pcbi.1000301-Cariani2">&#x0005b;5&#x0005d;</xref>. Most of these models compute a form of short-term autocorrelation of the simulated auditory nerve activity using an exponentially weighted integration time window <xref ref-type="bibr" rid="pcbi.1000301-Meddis1">&#x0005b;6&#x0005d;</xref>&#x02013;<xref ref-type="bibr" rid="pcbi.1000301-BalaguerBallester3">&#x0005b;13&#x0005d;</xref>. Autocorrelation models have been able to predict the reported pitches of a wide range of complex stimuli. However, choosing an appropriate integration time window has been problematic, and none of the previous models has been able to explain the wide range of time scales encountered in perceptual data in a unified fashion. These data show that, in certain conditions, the auditory system is capable of integrating pitch-related information over time scales of several hundred milliseconds <xref ref-type="bibr" rid="pcbi.1000301-Hall1">&#x0005b;14&#x0005d;</xref>&#x02013;<xref ref-type="bibr" rid="pcbi.1000301-Bregman2">&#x0005b;22&#x0005d;</xref>, while at the same time being able to follow changes in pitch or pitch strength with a resolution of only a few milliseconds <xref ref-type="bibr" rid="pcbi.1000301-Hall1">&#x0005b;14&#x0005d;</xref>, <xref ref-type="bibr" rid="pcbi.1000301-Grose1">&#x0005b;15&#x0005d;</xref>, <xref ref-type="bibr" rid="pcbi.1000301-Bregman1">&#x0005b;21&#x0005d;</xref>&#x02013;<xref ref-type="bibr" rid="pcbi.1000301-Denham1">&#x0005b;24&#x0005d;</xref>. Limits on the temporal resolution of pitch perception have also been explored by determining pitch detection and discrimination performance as a function of frequency modulation rate <xref ref-type="bibr" rid="pcbi.1000301-Moore3">&#x0005b;25&#x0005d;</xref>&#x02013;<xref ref-type="bibr" rid="pcbi.1000301-Carlyon3">&#x0005b;27&#x0005d;</xref>, the main conclusion being that the auditory system has a limited ability to process rapid variations in pitch.</p><p>The trade-off between temporal integration and resolution is not exclusive to pitch perception, but is a general characteristic of auditory temporal processing. For instance, a long integration time of several hundred milliseconds is required to explain the way in which the detectability and perceived loudness of sounds increases with increasing sound duration <xref ref-type="bibr" rid="pcbi.1000301-deBoer1">&#x0005b;28&#x0005d;</xref>,<xref ref-type="bibr" rid="pcbi.1000301-Krumbholz1">&#x0005b;29&#x0005d;</xref>. In contrast, much shorter integration times are necessary to explain the fact that the auditory system can resolve sound events separated by only a few milliseconds <xref ref-type="bibr" rid="pcbi.1000301-deBoer1">&#x0005b;28&#x0005d;</xref>&#x02013;<xref ref-type="bibr" rid="pcbi.1000301-Shailer1">&#x0005b;30&#x0005d;</xref>. Therefore, it appears that the integration time of auditory processing varies with the stimulus and task. Previously it was proposed that integration and resolution reflect processing in separate, parallel streams with different stimulus-independent integration times <xref ref-type="bibr" rid="pcbi.1000301-deBoer1">&#x0005b;28&#x0005d;</xref>. More recently, in order to reconcile perceptual data pertaining to temporal integration and resolution tasks, it was suggested that the auditory system makes its decisions based on &#x0201c;multiple looks&#x0201d; at the stimulus <xref ref-type="bibr" rid="pcbi.1000301-Viemeister1">&#x0005b;31&#x0005d;</xref>, using relatively short time windows. However, to our knowledge no model has yet quantitatively explained the stimulus- and task-dependency of integration time constants.</p><p>Another major challenge for pitch modelling is to relate perceptual phenomena to neurophysiological data. Functional brain-imaging studies strongly suggest that pitch is processed in a hierarchical manner <xref ref-type="bibr" rid="pcbi.1000301-Kumar1">&#x0005b;32&#x0005d;</xref>, starting in sub-cortical structures <xref ref-type="bibr" rid="pcbi.1000301-Griffiths1">&#x0005b;33&#x0005d;</xref> and continuing up through Heschl's Gyrus on to the <italic>planum polare</italic> and <italic>planum temporale</italic> <xref ref-type="bibr" rid="pcbi.1000301-Griffiths2">&#x0005b;34&#x0005d;</xref>&#x02013;<xref ref-type="bibr" rid="pcbi.1000301-Gutschalk1">&#x0005b;36&#x0005d;</xref>. Within this processing hierarchy, there is an increasing dispersion in response latency, with lower pitches eliciting longer response latencies than higher pitches <xref ref-type="bibr" rid="pcbi.1000301-Krumbholz2">&#x0005b;37&#x0005d;</xref>. This suggests that the time window over which the auditory system integrates pitch-related information depends on the pitch itself. However, no attempt has yet been made to explain this latency dispersion.</p><p>In this study, we present a unified account of the multiple time scales involved in pitch processing. We suggest that top-down modulation within a hierarchical processing structure is important for explaining the stimulus-dependency of the effective integration time for extracting pitch information. A highly idealized model, formulated in terms of interacting neural ensembles, is presented. The model represents a natural extension of previous autocorrelation models of pitch in a form resembling a <italic>hierarchical generative</italic> process <xref ref-type="bibr" rid="pcbi.1000301-Friston1">&#x0005b;38&#x0005d;</xref>,<xref ref-type="bibr" rid="pcbi.1000301-Friston2">&#x0005b;39&#x0005d;</xref>, in which higher (e.g., cortical) levels modulate the responses in lower (e.g., sub-cortical) levels via feedback connections. Without modification, the model can account not only for a wide range of perceptual data, but also for novel neurophysiological data on pitch processing.</p></sec><sec sec-type="methods" id="s2"><title>Methods</title><p>The model consists of a feed-forward process, as well as a feedback process, which modifies the parameters of feed-forward processing. Both components are explained in detail below and schematic diagram of the model is shown in <xref ref-type="fig" rid="pcbi-1000301-g001">Figure 1</xref>.</p><fig id="pcbi-1000301-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000301.g001</object-id><label>Figure 1</label><caption><title>Schematic outline of the model.</title><p>The model consists of: 1) a simulation of auditory nerve spiking probabilities, <italic>p</italic>(<italic>t,k</italic>) (blue), in response to a sound for each cochlear frequency channel, <italic>k</italic>; 2) a cross-product of the auditory nerve activity with a time-delayed version of itself for a range of different time lags, <italic>l</italic> (in the diagram, processing relating to different lags is represented by stacked boxes); 3) two integration stages, <italic>A<sub>2</sub> and A<sub>3</sub></italic>, shown by green and red ellipses, which represent highly idealized models of collective neuronal responses using a shorter (&#x003c4;<sub>2</sub>) and a longer (&#x003c4;<sub>3</sub>) time constant, respectively. <italic>L<sub>2</sub></italic>(<italic>t</italic>) is the lag yielding the maximum response at the second processing stage, <italic>A<sub>2</sub></italic>(<italic>t,l</italic>); its inverse, <italic>1/L<sub>2</sub></italic>(<italic>t</italic>) represents an intermediate pitch prediction of the model. Similarly, <italic>1/L<sub>3</sub></italic>(<italic>t</italic>) represents the ultimate pitch estimate predicted by the model. When the pitch estimate changes over time, a mismatch between the previous pitch estimate at level 3 (labelled &#x0201c;expected pitch&#x0201d; or 1/<italic>L<sup>E</sup></italic>) and the current prediction at the first integration stage, <italic>1/L<sub>2</sub></italic>, feeds back to modulate the recurrent processes (curved lines) at both integration stages. See text for details.</p></caption><graphic xlink:href="pcbi.1000301.g001"/></fig><sec id="s2a"><title>Feed-Forward Processing</title><p>The role of the feed-forward process (solid lines in <xref ref-type="fig" rid="pcbi-1000301-g001">Figure 1</xref>) is to predict the pitch of the incoming stimulus. The perceived pitch of periodic sounds corresponds approximately to the reciprocal of the repetition period of the sound waveform. This is why temporal models of pitch perception, such as autocorrelation models, usually analyze the periodicities of the signal within the auditory-nerve channels, and then use these periodicities to derive a pitch estimate by computing the reciprocal of the periodicity that is most prevalent across frequency channels <xref ref-type="bibr" rid="pcbi.1000301-Licklider1">&#x0005b;2&#x0005d;</xref>.</p><p>The cochlea in the inner ear acts as a frequency analyzer, in that different sound frequencies activate different places along the cochlea, which are in turn innervated by different auditory nerve fibres <xref ref-type="bibr" rid="pcbi.1000301-Moore1">&#x0005b;1&#x0005d;</xref>. Thus, the cochlea can be modelled as a bank of band-pass filters. In the current model, each cochlear filter was implemented as a <italic>dual resonant nonlinear gammatone filter</italic>, which accounts for the sound level-dependent non-linear properties of cochlear processing <xref ref-type="bibr" rid="pcbi.1000301-LopezPoveda1">&#x0005b;40&#x0005d;</xref>. The filter output was then passed through a hair cell transduction model <xref ref-type="bibr" rid="pcbi.1000301-Sumner1">&#x0005b;41&#x0005d;</xref> to simulate the conversion of the mechanical cochlear response into auditory-nerve spiking activity. The model was implemented using DSAM (Development System for Auditory Modelling <ext-link ext-link-type="uri" xlink:href="http://www.pdn.cam.ac.uk/groups/dsam/">http://www.pdn.cam.ac.uk/groups/dsam/</ext-link>). It contained a total of 30 frequency channels with centre frequencies ranging from 100 to 10000 Hz on a logarithmic scale.</p><p>The hair cell transduction model generates auditory-nerve spike probabilities, <italic>p</italic>(<italic>t,k</italic>), as a function of time, <italic>t</italic>, in each frequency channel, <italic>k</italic>. The first processing stage (open boxes in <xref ref-type="fig" rid="pcbi-1000301-g001">Figure 1</xref>) computes the joint probability that a given auditory nerve fibre produces two spikes, one at time <italic>t</italic> and another at <italic>t-l</italic>, where <italic>l</italic> is a time delay or lag <xref ref-type="bibr" rid="pcbi.1000301-deCheveign2">&#x0005b;10&#x0005d;</xref>. These joint probabilities are generated by computing the cross-product of the auditory-nerve firing probability, p(t,<italic>k</italic>), with time-delayed versions of itself for a range of time delays. The cross-products are then summed across all frequency channels, <italic>k</italic>, to generate the output of the first stage of the model <italic>A<sub>1</sub></italic>(<italic>t,l</italic>):<disp-formula><graphic xlink:href="pcbi.1000301.e001.jpg" mimetype="image" position="float"/><label>(1)</label></disp-formula></p><p>The activity at the second processing stage, <italic>A<sub>2</sub></italic>(<italic>t,l</italic>) (green circles in <xref ref-type="fig" rid="pcbi-1000301-g001">Figure 1</xref>), is computed as a leaky integration, (i.e., a low-pass filter using an exponentially decaying function <xref ref-type="bibr" rid="pcbi.1000301-Dayan1">&#x0005b;42&#x0005d;</xref>) of the input activity, <italic>A<sub>1</sub></italic>(<italic>t,l</italic>), using relatively short time constants, &#x003c4;<sub>2</sub>. It may therefore be assumed to represent sub-thalamic neural populations <xref ref-type="bibr" rid="pcbi.1000301-Meddis3">&#x0005b;43&#x0005d;</xref>&#x02013;<xref ref-type="bibr" rid="pcbi.1000301-Winter1">&#x0005b;46&#x0005d;</xref>. The time constants at the second stage are lag-dependent (&#x003c4;<sub>2</sub>&#x0200a;&#x0003d;&#x0200a;&#x003c4;<sub>2</sub>(<italic>l</italic>)), as suggested by recent psychoacoustic studies <xref ref-type="bibr" rid="pcbi.1000301-Wiegrebe1">&#x0005b;23&#x0005d;</xref>,<xref ref-type="bibr" rid="pcbi.1000301-Krumbholz2">&#x0005b;37&#x0005d;</xref>. However, for clarity, the lag dependency will not be explicitly stated in the following equations. In the third stage, <italic>A<sub>3</sub></italic>(<italic>t,l</italic>) (red circles in <xref ref-type="fig" rid="pcbi-1000301-g001">Figure 1</xref>), the output of the second stage is integrated over a longer time scale, &#x003c4;<italic><sub>3</sub></italic>, as suggested by neuroimaging studies of pitch in the cortex <xref ref-type="bibr" rid="pcbi.1000301-Krumbholz2">&#x0005b;37&#x0005d;</xref>,<xref ref-type="bibr" rid="pcbi.1000301-Winkler1">&#x0005b;47&#x0005d;</xref>. This stage is assumed to be located more centrally. Both integration stages can be simply described as time-varying exponential averages,<disp-formula><graphic xlink:href="pcbi.1000301.e002.jpg" mimetype="image" position="float"/><label>(2)</label></disp-formula></p><p>In equation (2), &#x00394;<italic>t</italic> is the time step of the integration and <italic>E<sub>n</sub></italic>(<italic>t</italic>) is the instantaneous exponential decay rate of the response at each integration stage (<italic>E<sub>n</sub></italic>(<italic>t</italic>)&#x02264;&#x003c4;<italic><sub>n</sub></italic>), which will henceforth be referred to as the <italic>effective integration window</italic>. Establishing an appropriate time constant is as has been mentioned one of the major difficulties in formulating a general model of pitch perception. Hence, the value of <italic>E<sub>n</sub></italic>(<italic>t</italic>) in the model proposed here is not constant but is controlled by changes in the properties of the stimulus. The control of <italic>E<sub>n</sub></italic>(<italic>t</italic>) will be explained below.</p><p>The factors <italic>g<sub>n</sub></italic>(<italic>t</italic>) normalize the input to each stage by the corresponding integration window (<italic>g<sub>2</sub></italic>&#x02261;<italic>1</italic>; <italic>g<sub>3</sub></italic>(<italic>t</italic>)<italic>&#x0200a;&#x0003d;&#x0200a;E<sub>2</sub></italic>(<italic>t</italic>)<italic>/</italic>&#x003c4;<italic><sub>2</sub></italic>).</p><p>At each time step <italic>A<sub>n</sub></italic>(<italic>t,l</italic>) will have a maximum at some value of <italic>l</italic> which we will write as <italic>L<sub>n</sub></italic>. The inverse of this lag for the output of stage 2, <italic>1/L<sub>2</sub></italic>(<italic>t</italic>), represents the intermediate pitch prediction of the model (see <xref ref-type="fig" rid="pcbi-1000301-g001">Figure 1</xref>). Similarly, the inverse of the lag corresponding to the maximum response in stage 3, <italic>1/L<sub>3</sub></italic>(<italic>t</italic>) is the final pitch prediction. For convenience, we refer to the final pitch prediction from the preceding time step <italic>1/L<sub>3</sub></italic>(<italic>t</italic>-&#x00394;t) as the pitch <italic>expectation</italic>, <italic>1/L<sup>E</sup></italic>. In all simulations presented in the current study, we used 200 lags, with reciprocals logarithmically distributed, representing pitches between 50 to 2000 Hz <xref ref-type="bibr" rid="pcbi.1000301-Moore4">&#x0005b;48&#x0005d;</xref>.</p><p>As an example, <xref ref-type="fig" rid="pcbi-1000301-g002">Figure 2</xref> shows the model response to a sequence of pure tones (<xref ref-type="fig" rid="pcbi-1000301-g002">Figure 2A</xref>) with random frequencies and durations. <xref ref-type="fig" rid="pcbi-1000301-g002">Figure 2B</xref> shows the first stage of the model <italic>A<sub>1</sub></italic>(<italic>t,l</italic>) and <xref ref-type="fig" rid="pcbi-1000301-g002">Figure 2C</xref> the effective integration windows. <xref ref-type="fig" rid="pcbi-1000301-g002">Figure 2D</xref> shows the final model output; the red colour highlights the lag-channels with strong responses. The lag of the channel with the maximum response at a given time corresponds to the reciprocal of the pitch predicted by the model. Note that the response <italic>A<sub>3</sub></italic>(<italic>t,l</italic>) in <xref ref-type="fig" rid="pcbi-1000301-g002">Figure 2D</xref> was normalized to a maximum of unity after each time step and mapped exponentially onto the colour scale to make the plot clearer. However, this transformation is monotonic and thus does not affect the model predictions.</p><fig id="pcbi-1000301-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000301.g002</object-id><label>Figure 2</label><caption><title>Example of the model output in response to an arbitrary sequence of pure tones with random frequencies and durations.</title><p>(A) Spectrogram of the stimulus as a function of time. (B) Response of the second processing stage, <italic>A<sub>1</sub></italic>(<italic>t,l</italic>), plotted as a function of time, <italic>t</italic> (abscissa), and time lag, <italic>l</italic> (ordinate). (C) Effective integration window of the second and third processing stages, <italic>A<sub>2</sub></italic>(<italic>t,l</italic>) (<italic>E<sub>2</sub></italic>(<italic>t</italic>), green solid line) and <italic>A<sub>3</sub></italic>(<italic>t,l</italic>) (<italic>E<sub>3</sub></italic>(<italic>t</italic>), red dotted line). <italic>E<sub>2</sub></italic>(<italic>t</italic>) represents the integration time at the lag corresponding to the maximum response in the second stage. (D) Response of the third processing stage, <italic>A<sub>3</sub></italic>(<italic>t,l</italic>). <italic>A<sub>3</sub></italic>(<italic>t,l</italic>) was normalized to a maximum response of unity and exponentially enhanced after each time step for illustrative purposes. The colours in plots (B) and (D) represent the activation strength as a percentage of the maximum response at that time (blue: low response or 0&#x00025;; red: maximal response or 100&#x00025;). Thus, the lag channel corresponding to the current pitch estimate appears red.</p></caption><graphic xlink:href="pcbi.1000301.g002"/></fig><p>The necessity for stimulus-driven modulation of the effective integration time, <italic>E<sub>n</sub></italic>(<italic>t</italic>), becomes clear from a consideration of existing autocorrelation models. If <italic>E<sub>2</sub></italic>(<italic>t</italic>) were constant over time, i.e., <italic>E<sub>2</sub></italic>(<italic>t</italic>) &#x02261; &#x003c4;<italic><sub>2</sub></italic> , then <italic>A<sub>2</sub></italic>(<italic>t,l</italic>) would correspond to the <italic>summary autocorrelation function</italic> (SACF) proposed by Meddis and colleagues <xref ref-type="bibr" rid="pcbi.1000301-Meddis1">&#x0005b;6&#x0005d;</xref>,<xref ref-type="bibr" rid="pcbi.1000301-Meddis2">&#x0005b;7&#x0005d;</xref>. If, in addition, <italic>E<sub>3</sub></italic>(<italic>t</italic>) &#x02261; &#x003c4;<italic><sub>3</sub></italic> then <italic>A<sub>3</sub></italic>(<italic>t,l</italic>) would represent an additional leaky integrator with a longer time constant. This is equivalent to the <italic>cascade autocorrelation model</italic> proposed by Balaguer-Ballester et al. <xref ref-type="bibr" rid="pcbi.1000301-BalaguerBallester3">&#x0005b;13&#x0005d;</xref>. The right panel in <xref ref-type="fig" rid="pcbi-1000301-g003">Figure 3A</xref> illustrates the success of the purely feed-forward model in response to a click train stimulus with alternating inter-click intervals <xref ref-type="bibr" rid="pcbi.1000301-Carlyon4">&#x0005b;49&#x0005d;</xref>,<xref ref-type="bibr" rid="pcbi.1000301-Carlyon5">&#x0005b;50&#x0005d;</xref>. The arrow indicates the average pitch reported by listeners. The pitch of such alternating click train stimuli has been difficult to predict with autocorrelation models consisting of only one integration stage with a short time constant (see right panel in <xref ref-type="fig" rid="pcbi-1000301-g003">Figure 3B</xref>).</p><fig id="pcbi-1000301-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000301.g003</object-id><label>Figure 3</label><caption><title>Responses of autocorrelation models with fixed time constants.</title><p>(A) Response of the cascade autocorrelation model <xref ref-type="bibr" rid="pcbi.1000301-BalaguerBallester3">&#x0005b;13&#x0005d;</xref>; left plot: to the sequence of random tones shown in <xref ref-type="fig" rid="pcbi-1000301-g002">Figure 2A</xref>, and right plot: to the alternating click train shown in <xref ref-type="fig" rid="pcbi-1000301-g008">Figure 8A</xref>. (B) Response of short-term integration stage of the cascaded model (corresponding to the second stage of the current model, <italic>A<sub>2</sub></italic>(<italic>t,l</italic>), when the feedback modulation of the integration times, equation 8, is switched off); see text for further explanation. As in panel A, the left panel shows the response to the tone sequence and the right panel shows the response to the click train (arrows mark the reported pitches). Different colours show activation strength as a percentage of the maximum response, as in <xref ref-type="fig" rid="pcbi-1000301-g002">Figure 2</xref>.</p></caption><graphic xlink:href="pcbi.1000301.g003"/></fig><p>However, the longer time scale used in the second stage of the cascade autocorrelation model prevents the detection of rapid pitch changes such as in the sequence of pure tones shown in <xref ref-type="fig" rid="pcbi-1000301-g002">Figure 2</xref>. The left panel in <xref ref-type="fig" rid="pcbi-1000301-g003">Figure 3A</xref> clearly shows that the cascade autocorrelation model fails to distinguish the pitches of individual tones in the tone sequence used in <xref ref-type="fig" rid="pcbi-1000301-g002">Figure 2</xref>, while the left panel in <xref ref-type="fig" rid="pcbi-1000301-g003">Figure 3B</xref> shows that the SACF model does so fairly well. Therefore, stimulus-dependent changes in the effective integration windows are required.</p></sec><sec id="s2b"><title>Parallels with Population Models</title><p>Autocorrelation is usually considered to be a simplified phenomenological model of pitch perception, which is not straightforward to implement in a biologically plausible way <xref ref-type="bibr" rid="pcbi.1000301-deCheveign1">&#x0005b;8&#x0005d;</xref>,<xref ref-type="bibr" rid="pcbi.1000301-Meddis3">&#x0005b;43&#x0005d;</xref>. This is also the case for the proposed model. Nevertheless, an alternative, more formal way to express the second and third model stages (equation 2) is shown in equation (3), below. This is equivalent to an expression for the response of a neural population which integrates activity from the previous stage <xref ref-type="bibr" rid="pcbi.1000301-Dayan1">&#x0005b;42&#x0005d;</xref>:<disp-formula><graphic xlink:href="pcbi.1000301.e003.jpg" mimetype="image" position="float"/><label>(3)</label></disp-formula></p><p>The dot indicates a partial temporal derivative and &#x003c4;<italic><sub>n</sub></italic> is defined as the processing time constant of an idealized homogeneous population of neurons at stage <italic>n</italic>. The &#x0201c;activation&#x0201d; functions,&#x003a8;<italic><sub>n</sub></italic>, in equation (3), which typically use a fixed sigmoid function in standard models of neural assembles <xref ref-type="bibr" rid="pcbi.1000301-Gerstner1">&#x0005b;51&#x0005d;</xref>, are in the model proposed here time-dependent multiplicative gains:<disp-formula><graphic xlink:href="pcbi.1000301.e004.jpg" mimetype="image" position="float"/><label>(4)</label></disp-formula>where &#x003c9;<italic><sub>1</sub>/</italic>&#x003bb;<italic><sub>1</sub></italic>&#x02261;<italic>0</italic>; and &#x003c9;<italic><sub>n,</sub></italic> &#x003bb;<italic><sub>n</sub></italic> are defined in the next section.</p><p>Substituting equation (4) into equation (3) and integrating, allows us to obtain the effective integration windows, <italic>E<sub>n</sub></italic>(<italic>t</italic>), used in equation (2):<disp-formula><graphic xlink:href="pcbi.1000301.e005.jpg" mimetype="image" position="float"/><label>(5)</label></disp-formula></p></sec><sec id="s2c"><title>Detecting Changes in the Stimulus</title><p>In contrast with the feed-forward model, the goal of the feedback processing (dotted lines in <xref ref-type="fig" rid="pcbi-1000301-g001">Figure 1</xref>) is to detect unexpected changes in the input stimulus, such as the offset of a tone in a sequence, and to modulate the integration times involved in the feed-forward processing when such changes occur.</p><p>In the case where the stimulus is constant the pitch predictions at successive time steps will not differ. However, if the stimulus changes then the height of the peak corresponding to the current pitch prediction <italic>1/L<sub>n</sub></italic>(<italic>t</italic>) will change from one time step to the next. A mismatch between the pitch predictions at each level and the pitch expectation therefore indicates a change in the input stimulus.</p><p>A stimulus change typically requires a fast system response, so that information occurring around the time of the change can be updated quickly; this corresponds to using small <italic>E<sub>n</sub></italic>(<italic>t</italic>) values. Thus, during periods when there is a significant discrepancy between the current and expected pitch estimates, the effective integration time windows at both integration stages should become very short, so that the &#x0201c;memory&#x0201d; component of the model response is reduced to near zero and essentially reset. Similar rapid changes of activity in response to variations in the input have been previously reported in neural ensemble models <xref ref-type="bibr" rid="pcbi.1000301-Gerstner1">&#x0005b;51&#x0005d;</xref>,<xref ref-type="bibr" rid="pcbi.1000301-vanRossum1">&#x0005b;52&#x0005d;</xref>.</p><p><xref ref-type="fig" rid="pcbi-1000301-g002">Figure 2C</xref> illustrates the dynamics of <italic>E<sub>2</sub></italic>(<italic>t</italic>) (solid green line) and <italic>E<sub>3</sub></italic>(<italic>t</italic>) (dotted red line) in response to a random tone sequence, the spectrogram of which is shown in <xref ref-type="fig" rid="pcbi-1000301-g002">Figure 2A</xref>. After the end of each tone, both time constants, <italic>E<sub>2</sub></italic> and <italic>E<sub>3</sub></italic>, decrease for a brief period of time and then recover back to their maximum values (<italic>E<sub>n</sub></italic>(<italic>t</italic>)&#x02248;&#x003c4;<italic><sub>n</sub></italic>) when the next tone begins. As <italic>E<sub>2</sub></italic> is lag-dependent, the values plotted in <xref ref-type="fig" rid="pcbi-1000301-g002">Figure 2C</xref> represent the integration time constant at the lag, <italic>L<sub>2</sub></italic>(<italic>t</italic>), corresponding to the current maximum of <italic>A<sub>2</sub></italic>(<italic>t,l</italic>). The small overshoots after the initial dips in <italic>E<sub>2</sub></italic> reflect transient variations in <italic>L<sub>2</sub></italic> before a new stable prediction is achieved.</p><p>The effective integration windows, <italic>E<sub>n</sub></italic>(<italic>t</italic>), can vary over a large range of values, far exceeding the range of plausible neural time constants. However, it should be noted that the neural processing time constants used in the model, <italic>&#x003c4;<sub>n</sub></italic> (see equation 3), only take on biologically plausible values (shown in <xref ref-type="table" rid="pcbi-1000301-t001">Table 1</xref>). The effective integration windows, derived from the activation functions (equation 5), do not represent neural processing time constants. This aspect will be further addressed in the <xref ref-type="sec" rid="s4">Discussion</xref> section.</p><table-wrap id="pcbi-1000301-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000301.t001</object-id><label>Table 1</label><caption><title>Model parameters used in the simulations.</title></caption><graphic id="pcbi-1000301-t001-1" xlink:href="pcbi.1000301.t001"/><table frame="hsides" rules="groups" alternate-form-of="pcbi-1000301-t001-1"><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup><thead><tr><td align="left" rowspan="1" colspan="1">Parameter</td><td align="left" rowspan="1" colspan="1">&#x003b8;<italic><sub>2</sub></italic></td><td align="left" rowspan="1" colspan="1">&#x003b8;<italic><sub>3</sub></italic></td><td align="left" rowspan="1" colspan="1">&#x003c4;<italic><sub>2</sub></italic>(<italic>l</italic>) (ms)</td><td align="left" rowspan="1" colspan="1">&#x003c4;<italic><sub>3</sub></italic> (ms)</td><td align="left" rowspan="1" colspan="1">&#x003b7;<italic><sub>2</sub></italic> (kHz)</td><td align="left" rowspan="1" colspan="1">&#x003b7;<italic><sub>3</sub></italic> (kHz)</td><td align="left" rowspan="1" colspan="1">&#x003bc;<italic><sub>2</sub></italic> (kHz)</td><td align="left" rowspan="1" colspan="1">&#x003bc;<italic><sub>3</sub></italic> (kHz)</td></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Value</td><td align="left" rowspan="1" colspan="1">0.04</td><td align="left" rowspan="1" colspan="1">0.07</td><td align="left" rowspan="1" colspan="1">2&#x02013;80</td><td align="left" rowspan="1" colspan="1">2000</td><td align="left" rowspan="1" colspan="1">3.55</td><td align="left" rowspan="1" colspan="1">1.15</td><td align="left" rowspan="1" colspan="1">0.18</td><td align="left" rowspan="1" colspan="1">1.15</td></tr></tbody></table><table-wrap-foot><fn id="nt101"><p>Thresholds &#x003b8;<italic><sub>n</sub></italic> are dimensionless. Sampling frequency of the sounds (1<italic>/&#x00394;t</italic>) was 176 kHz; integration period in level three was 2 ms. &#x003c4;<sub>n</sub>&#x0003e;&#x003bb;<sub>n</sub>(t)&#x0003e;10<sup>&#x02212;9</sup> ms.</p></fn></table-wrap-foot></table-wrap><p>During the steady-state portions of each tone, the model essentially behaves like the cascade autocorrelation model <xref ref-type="bibr" rid="pcbi.1000301-BalaguerBallester3">&#x0005b;13&#x0005d;</xref>. The feedback mechanism simply allows the model to adapt quickly to changes in the stimulus.</p><p>A natural measure of the mismatch between pitch expectations and pitch predictions is the <italic>relative error gradient</italic> of the maximum response in <italic>A<sub>n</sub></italic>(<italic>t,L<sub>n</sub></italic>),<disp-formula><graphic xlink:href="pcbi.1000301.e006.jpg" mimetype="image" position="float"/><label>(6)</label></disp-formula>where the expected lag, <italic>L<sup>E</sup></italic>, is fixed in the temporal derivative; and <italic>L<sub>n</sub></italic>(<italic>t</italic>) is the lag corresponding to the maximum response at each time step as defined earlier.</p><p>The gradient at stage three in the model, <inline-formula><inline-graphic xlink:href="pcbi.1000301.e007.jpg" mimetype="image"/></inline-formula> is an &#x0201c;error&#x0201d; measure: if there is mismatch between the expected pitch estimate and the current prediction, i.e., <italic>L<sup>E</sup> &#x02260; L<sub>3</sub></italic>(<italic>t</italic>), then &#x003c1;<italic><sub>3</sub>&#x0003c;0</italic>. Similarly, at the second stage, &#x003c1;<italic><sub>2</sub>&#x0003c;0</italic> represents a mismatch, or error, between the expected pitch and the current intermediate prediction at stage two, 1/<italic>L<sub>2</sub></italic>(<italic>t</italic>).</p></sec><sec id="s2d"><title>Feedback Modulation</title><p>The goal of the feedback modulation triggered by changes in the stimulus is to adjust the effective time constants <italic>E<sub>n</sub></italic>(<italic>t</italic>). The error gradients &#x003c1;<italic><sub>n</sub></italic> give us a measure of stimulus change therefore, when &#x003c1;<italic><sub>n</sub></italic> is negative <italic>enough</italic> (compared to a threshold value &#x003b8;<italic><sub>n</sub></italic>) there is a discrepancy between the pitch prediction and the pitch expectation which requires that the time constants be adjusted. This is achieved by temporarily activating the recurrent term in equation 4, i.e., by defining<disp-formula><graphic xlink:href="pcbi.1000301.e008.jpg" mimetype="image" position="float"/><label>(7)</label></disp-formula>where &#x00398;(<italic>x</italic>) is the Heaviside function (equal to unity if <italic>x&#x0003e;0</italic> and zero otherwise) and &#x003b8;<italic><sub>n</sub></italic> are small positive thresholds for the error terms, &#x003c1;<italic><sub>n</sub></italic>. For example, during the gaps between tones in a sequence of tones, &#x003c1;<italic><sub>n</sub>&#x0003c;</italic>&#x02212;&#x003b8;<italic><sub>n</sub></italic> and the gains &#x003c9;<italic><sub>n</sub></italic>(<italic>t</italic>)<italic>/</italic>&#x003bb;<italic><sub>n</sub></italic>(<italic>t</italic>) temporarily become nonzero, thereby modulating the effective temporal integration windows, <italic>E<sub>n</sub></italic>(<italic>t</italic>).</p><p>This approach leads to a problem with the model as described so far in that the response to stimuli where there is a continuous discrepancy between expectations and predictions, very short effective time windows (<italic>E<sub>n</sub></italic>(<italic>t</italic>)&#x0226a;&#x003c4;<italic><sub>n</sub></italic>) produce oscillatory responses which do not correspond to the stable pitch perceived by listeners (see, for example, <xref ref-type="fig" rid="pcbi-1000301-g003">Figure 3B, right panel</xref>). The dynamics of the &#x02018;adaptation&#x02019; variable, &#x003bb;<italic><sub>n</sub></italic>(<italic>t</italic>), defined in equation 8 below, serve to modulate uncontrolled corrections to the effective integration windows.</p><p>Initially the value of &#x003bb;<italic><sub>n</sub></italic>(<italic>t</italic>) is small (&#x003bb;<italic><sub>n</sub></italic>(<italic>0</italic>)&#x0226a;&#x003c4;<italic><sub>n</sub></italic>) so that when change is first detected <italic>E<sub>n</sub></italic>(<italic>t</italic>) also becomes small (equation 5). However, in situations where there is a continuous mismatch between the predicted and the expected pitch, &#x003bb;<italic><sub>n</sub></italic>(<italic>t</italic>) grows and <italic>E<sub>n</sub></italic>(<italic>t</italic>) recovers to a value closer to &#x003c4;<sub>n</sub>.</p><p>Then, when there is no longer any discrepancy between expectation and prediction, &#x003bb;<italic><sub>n</sub></italic>(<italic>t</italic>) recovers to a small value again but without affecting <italic>E<sub>n</sub></italic>(<italic>t</italic>) because, in the absence of a mismatch, &#x003c9;<sub>n</sub><italic>&#x0200a;&#x0003d;&#x0200a;0</italic>. Therefore, the dynamics of &#x003bb; are described in general by:<disp-formula><graphic xlink:href="pcbi.1000301.e009.jpg" mimetype="image" position="float"/><label>(8)</label></disp-formula></p><p>Where &#x003b7; and &#x003bc; are the constants that control the rate of increase in &#x003bb; during periods of mismatch and the rate of decay in &#x003bb; during periods where no mismatch occurs.</p><p><xref ref-type="fig" rid="pcbi-1000301-g002">Figures 2C</xref> and <xref ref-type="fig" rid="pcbi-1000301-g008">8B</xref> illustrate two opposite instances of the effect of this top-down processing. In response to a sequence of tones, the effective integration windows shorten precisely at the tone offsets before returning to their maximum values, &#x003c4;<italic><sub>n</sub></italic>, during the tones (<xref ref-type="fig" rid="pcbi-1000301-g002">Figure 2C</xref>). In response to a click train with alternating inter-click intervals (<xref ref-type="fig" rid="pcbi-1000301-g008">Figure 8B</xref>), the window length settles to a maximum value after a longer period of transient fluctuations. <xref ref-type="fig" rid="pcbi-1000301-g004">Figure 4</xref> illustrates the discrete processing steps of the model in the form of a flowchart. <xref ref-type="table" rid="pcbi-1000301-t001">Table 1</xref> gives the set of parameter values used in the simulations. Further neurobiological justifications for the model are presented in the <xref ref-type="sec" rid="s4">Discussion</xref>. A Matlab-based software implementation of the model is freely available from the first author.</p><fig id="pcbi-1000301-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000301.g004</object-id><label>Figure 4</label><caption><title>Diagrammatic representation of the computations involved in the recurrent processes of <italic>A<sub>n</sub></italic>(<italic>t,l</italic>) in flowchart form.</title></caption><graphic xlink:href="pcbi.1000301.g004"/></fig></sec></sec><sec id="s3"><title>Results</title><p>The model was evaluated using a representative set of psychophysical experiments, which illustrate the different time scales of temporal integration and resolution in pitch perception. A further experiment was conducted specifically for this study. Finally, the last evaluation shows that the proposed model can also replicate neurophysiological data.</p><sec id="s3a"><title>Global Pitch of Non-Simultaneous Tones</title><p>Hall and Peters' experiment highlighted an unsolved problem concerning the balance between synthetic and analytic listening in response to a sequence of pure tones <xref ref-type="bibr" rid="pcbi.1000301-Hall1">&#x0005b;14&#x0005d;</xref>,<xref ref-type="bibr" rid="pcbi.1000301-Grose1">&#x0005b;15&#x0005d;</xref>. The stimuli of the pioneering Hall and Peters' study <xref ref-type="bibr" rid="pcbi.1000301-Hall1">&#x0005b;14&#x0005d;</xref> consisted of three tones played sequentially either in quiet (<xref ref-type="fig" rid="pcbi-1000301-g005">Figure 5A, left panel</xref>) or against a background of white noise (<xref ref-type="fig" rid="pcbi-1000301-g005">Figure 5A, right panel</xref>). Each tone lasted 40 ms and was separated from the following tone by a gap of 10 ms. Tone frequencies were 650, 850 and 1050 Hz (similar results were obtained with a harmonic sequence). The overall level of the noise was about 15 dB above the level of the tones. The individual tones in the sequence were perceived in both conditions.</p><fig id="pcbi-1000301-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000301.g005</object-id><label>Figure 5</label><caption><title>Response of the model to stimuli used in the Hall and Peters' experiment <xref ref-type="bibr" rid="pcbi.1000301-Hall1">&#x0005b;14&#x0005d;</xref>.</title><p>(A) Spectrogram of a rapid sequence of three 40-ms tones presented in quiet (left panel) and after the addition of white noise (right panel). (B) Response of the third stage of the model, <italic>A<sub>3</sub></italic>(<italic>t,l</italic>), for the stimulus in quiet (left panel) and in noise (right panel). In the noise condition, the response represents the average over three different random realizations of the noise background. Different colours represent activation strength as a percentage of the maximum response as in previous figures. Arrows indicate the lowest pitch reported by listeners in each condition. (C) Snapshot of <italic>A<sub>3</sub></italic>(<italic>t,l</italic>) at the end of the stimulus (<italic>t<sub>final</sub></italic>) in quiet (left panel) and in noise (right panel). Vertical dashed lines correspond to the final predicted pitch.</p></caption><graphic xlink:href="pcbi.1000301.g005"/></fig><p>In the experiment, listeners were instructed to match the <italic>lowest</italic> pitch that they perceived, and in the quiet condition, this was the first of the tones (650 Hz). However, in the noise condition, the non-simultaneous tones combine to create a lower global pitch of about 213 Hz, which is not perceived in the quiet condition. Recently, it was shown that the cascade autocorrelation model, which used two fixed integration stages, could account for the perception of the global pitch in the noise condition when the time constant of the second stage was long enough <xref ref-type="bibr" rid="pcbi.1000301-BalaguerBallester3">&#x0005b;13&#x0005d;</xref>. However, the same, long, integration stage could not be used to simultaneously predict the perception of the individual tones in quiet.</p><p><xref ref-type="fig" rid="pcbi-1000301-g005">Figure 5B</xref> shows the responses <italic>A<sub>3</sub></italic>(<italic>t,l</italic>) over time. As in <xref ref-type="fig" rid="pcbi-1000301-g002">Figure 2</xref>, the responses after each time step have been normalized for visualization purposes (however, it should be noted that their real magnitudes, which are close to zero during the silent gaps, are not evident in the figure). The maximum of <italic>A<sub>3</sub></italic>(<italic>t,l</italic>) correctly predicts the pitches perceived in quiet, which correspond approximately to the frequencies of the individual tones at each moment in time (left plot). Thus, the peak in the profile of the final response at the end of the stimulus correctly reflects the period of the last tone of the sequence at 0.95 ms, and the lowest reported pitch corresponds to the first tone in the sequence (horizontal arrow in <xref ref-type="fig" rid="pcbi-1000301-g005">Figure 5B</xref>).</p><p>However, when background noise is present (<xref ref-type="fig" rid="pcbi-1000301-g005">Figure 5B, right plot</xref>), a global pitch gradually emerges (horizontal arrow in the right plot), and the peak in the final response occurs at the reciprocal of the perceived pitch of 213 Hz (4.7 ms, right panel of <xref ref-type="fig" rid="pcbi-1000301-g005">Figure 5C</xref>). The above results match precisely the listeners' responses in this study <xref ref-type="bibr" rid="pcbi.1000301-Hall1">&#x0005b;14&#x0005d;</xref>.</p><p>Many other studies have explored more explicitly the characteristics of temporal integration in pitch perception. Earlier findings showed that the accuracy of pitch discrimination increases with stimulus duration <xref ref-type="bibr" rid="pcbi.1000301-Moore1">&#x0005b;1&#x0005d;</xref>,<xref ref-type="bibr" rid="pcbi.1000301-Moore2">&#x0005b;19&#x0005d;</xref>, depends on the resolvability of the harmonics <xref ref-type="bibr" rid="pcbi.1000301-Plack2">&#x0005b;20&#x0005d;</xref>, and on the sudden onsets and offsets of overlapping tones <xref ref-type="bibr" rid="pcbi.1000301-Bregman1">&#x0005b;21&#x0005d;</xref>,<xref ref-type="bibr" rid="pcbi.1000301-Bregman2">&#x0005b;22&#x0005d;</xref>. In <xref ref-type="fig" rid="pcbi-1000301-g006">Figure 6</xref>, another example of the model's ability to simulate the integration of pitch information across noise-filled gaps is presented <xref ref-type="bibr" rid="pcbi.1000301-Plack1">&#x0005b;17&#x0005d;</xref>,<xref ref-type="bibr" rid="pcbi.1000301-White1">&#x0005b;18&#x0005d;</xref>. <xref ref-type="fig" rid="pcbi-1000301-g006">Figure 6A</xref> shows a sequence of two unresolved complex tones of 20-ms duration, containing 100 harmonics of a 250-Hz base frequency, high-pass filtered from 5500 to 7500 Hz. After the first of the tones, there was either a short silent gap (silent-gap condition) or a noise-filled gap, having a similar mean level to the harmonic complex (noise-burst condition). Background noise was added to mask distortion products. In their study, Plack and White reported that subjects perceived pitch continuity through the gap in the noise-burst condition, but not in the silent-gap condition <xref ref-type="bibr" rid="pcbi.1000301-Plack1">&#x0005b;17&#x0005d;</xref>. The normalized model output <italic>A<sub>3</sub></italic>(<italic>t,l</italic>) (<xref ref-type="fig" rid="pcbi-1000301-g006">Figure 6C</xref>) is qualitatively consistent with a continuous pitch sensation in the noise-burst condition (right panel), which does not occur in the silent-gap condition (left panel).</p><fig id="pcbi-1000301-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000301.g006</object-id><label>Figure 6</label><caption><title>Response of the model to stimuli used in the Plack and White experiment <xref ref-type="bibr" rid="pcbi.1000301-Plack1">&#x0005b;17&#x0005d;</xref>.</title><p>(A) Stimulus waveform of a rapid sequence of two 20-ms complex tones (harmonics of 250 Hz) separated by a 8-ms silent gap (left panel) or a noise of similar root mean square level as the complex tones (right panel); after band pass filtering (5500&#x02013;7500 Hz) and the addition of a white noise background. (B) Effective integration times, <italic>E<sub>2</sub></italic>(<italic>t</italic>) (green solid line) and <italic>E<sub>3</sub></italic>(<italic>t</italic>) (red dotted line) at the second and third stages of the model. (C) Response of the third stage of the model, <italic>A<sub>3</sub></italic>(<italic>t,l</italic>), for the silent-gap condition (left panel) and noise-burst condition (right panel). Different colours represent activation strength as a percentage of the maximum response as in previous figures.</p></caption><graphic xlink:href="pcbi.1000301.g006"/></fig><p>Conditions under which pitch encoding is affected by the presence of other sounds have been also studied using non-simultaneous stimuli such as temporal &#x0201c;fringes&#x0201d; (consisting of complex tones played immediately before and after a &#x0201c;target&#x0201d; tone) <xref ref-type="bibr" rid="pcbi.1000301-Carlyon1">&#x0005b;16&#x0005d;</xref>,<xref ref-type="bibr" rid="pcbi.1000301-Micheyl1">&#x0005b;53&#x0005d;</xref>,<xref ref-type="bibr" rid="pcbi.1000301-Gockel1">&#x0005b;54&#x0005d;</xref>; and by mistuning delayed harmonics of the complex <xref ref-type="bibr" rid="pcbi.1000301-BalaguerBallester2">&#x0005b;12&#x0005d;</xref>, <xref ref-type="bibr" rid="pcbi.1000301-Darwin1">&#x0005b;55&#x0005d;</xref>&#x02013;<xref ref-type="bibr" rid="pcbi.1000301-Gockel2">&#x0005b;57&#x0005d;</xref>. The model described here also accounts for the &#x0201c;reset&#x0201d; of pitch information occurring for large frequency differences between fringe and target tones <xref ref-type="bibr" rid="pcbi.1000301-Micheyl1">&#x0005b;53&#x0005d;</xref> (data not shown).</p></sec><sec id="s3b"><title>Temporal Resolution for Pitch Information</title><p>The previous section shows the model's ability to generate stimulus-dependent changes in the effective time scale of temporal integration for extracting pitch information. This raises the question of whether the ability of the model to adjust the effective integration windows could also account for the temporal resolution of the auditory system. While there is substantial evidence for temporal integration in pitch perception, temporal resolution in pitch perception is perhaps still poorly understood. Therefore, we conducted a psychoacoustic experiment specifically to investigate the temporal resolution of pitch information. It should be stressed that this experiment was conducted independently of the model development and was subsequently used to test the model's <italic>predictions</italic>.</p><sec id="s3b1"><title>Psychoacoustic study</title><p>Thresholds were measured in two experimental conditions, designed to assess the temporal resolution of the auditory system to changes in pitch strength. In both conditions, a stimulus referred to as rippled noise (RN) was used. RN is generated by delaying a random noise by a delay, <italic>d</italic>, and adding the delayed copy back to the original noise <xref ref-type="bibr" rid="pcbi.1000301-Yost1">&#x0005b;58&#x0005d;</xref>. This delay-and-add process creates a degree of serial correlation in the noise stimulus. When the delay is between about 1 and 30 ms, this correlation gives rise to the perception of a buzzy tone with a pitch corresponding to the reciprocal of the delay, 1/<italic>d</italic>. The serial correlation, and thus the pitch, of RN can be switched on and off by replacing portions of the delayed noise by an uncorrelated noise of the same intensity. In the first condition, referred to as the gap condition, serial correlation was switched off for a single, brief period around the temporal centre of the stimulus, and the shortest detectable gap in correlation, referred to as the pitch-gap detection threshold, was measured.</p><p>In the second condition, referred to as the modulation condition, correlation was switched on and off periodically according to a square-wave function with a 50&#x00025; duty cycle (i.e., the proportion of time for which correlation was high). In this case, the pitch-modulation detection threshold was measured. This threshold is the fastest rate at which the modulation in correlation was just detectable. Both the pitch-gap and pitch-modulation detection thresholds were measured for four different values of the RN delay, <italic>d</italic> (1, 2, 4, 8, 12 and 16 ms). <xref ref-type="fig" rid="pcbi-1000301-g007">Figure 7A</xref> shows an example of a RN stimulus for <italic>d</italic>&#x0200a;&#x0003d;&#x0200a;4 ms in which the gap in correlation is 25 ms. Note that the gap is not visible in the spectrogram. <xref ref-type="fig" rid="pcbi-1000301-g007">Figure 7B</xref> shows the first peak height of the average running autocorrelation as a function of time (Rh1&#x0005b;t&#x0005d;) for both the modulated (red) and gap (blue) RN stimuli of the same delay and gap sizes. Note that panels A and C in <xref ref-type="fig" rid="pcbi-1000301-g007">Figure 7</xref> refer to the gap stimulus alone.</p><fig id="pcbi-1000301-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000301.g007</object-id><label>Figure 7</label><caption><title>Comparison between human and model pitch-gap and pitch-modulation thresholds in a task specifically designed for assessing temporal resolution in pitch perception (see text for details).</title><p>(A) Spectrogram for a rippled noise (RN) with a 4-ms delay, which contains a 25-ms gap in serial correlation around the centre of the stimulus, not visible in the figure. (B) First peak height of the running autocorrelation as a function of time (Rh1&#x0005b;t&#x0005d;) for both the modulated (red) and gap (blue) RN stimuli; averaged over 10<sup>5</sup> stimulus realizations. (C) <italic>A<sub>3</sub></italic>(<italic>t,l</italic>), for the stimulus shown in panel A, normalized and displayed as in previous figures. (D) Average detection thresholds and standard errors for the pitch-gap (blue circles) and pitch-modulation conditions (red triangles). The corresponding model predictions are shown in the same colours (dots and stars).</p></caption><graphic xlink:href="pcbi.1000301.g007"/></fig><p>Thresholds were obtained using a two-interval, two-alternative forced-choice (2I2AFC) adaptive procedure using a 3-down 1-up rule <xref ref-type="bibr" rid="pcbi.1000301-Levitt1">&#x0005b;59&#x0005d;</xref>. Stimuli had a duration of 1 s; they were low pass filtered at 5 kHz (24 dB/oct.) and presented at a level of 65 dB SPL (decibel sound pressure level). A minimum of three threshold estimates were obtained for each condition for each of five participants. <xref ref-type="fig" rid="pcbi-1000301-g007">Figure 7D</xref> shows the average gap (blue circles) and modulation detection thresholds (red triangles) with standard errors as a function of the RN delay, <italic>d</italic>, (for computational costs in the model simulations, we only show the results up to <italic>d&#x0200a;&#x0003d;&#x0200a;</italic>8 ms). Stimuli were generated digitally and converted into analogue signals with a 24-bit amplitude resolution and a sampling rate of 25 kHz using TDT System 3 (Tucker-Davies Technology, Alachua, FL, USA) and Matlab (The Mathworks, Natick, MA, USA). They were amplified (TDT HB7) and presented over headphones (K240 DF, AKG, Vienna, Austria) to the participant, who was seated in a double walled sound attenuating room.</p></sec><sec id="s3b2"><title>Model predictions</title><p><xref ref-type="fig" rid="pcbi-1000301-g007">Figure 7C</xref> illustrates <italic>A<sub>3</sub></italic>(<italic>t,l</italic>) (normalized at each time step as in previous figures) in response to the stimulus shown in <xref ref-type="fig" rid="pcbi-1000301-g007">Figure 7A</xref> as a function of autocorrelation lag. While the 25-ms uncorrelated noise portion is not visually appreciable in the stimulus spectrogram (<xref ref-type="fig" rid="pcbi-1000301-g007">Figure 7A</xref>), the gap (<xref ref-type="fig" rid="pcbi-1000301-g007">Figure 7B, blue line</xref>) is audible. Consistent with perception, the predicted pitch (red highlight in <xref ref-type="fig" rid="pcbi-1000301-g007">Figure 7C</xref>) shows a discontinuity around the position of the gap in the stimulus.</p><p>The blue dots and red stars in <xref ref-type="fig" rid="pcbi-1000301-g007">Figure 7D</xref> show the model predictions, averaged over 100 stimulus realizations for each condition. When the gap or modulation led to discontinuities in the pitch predicted by the model (as shown in <xref ref-type="fig" rid="pcbi-1000301-g007">Figure 7C</xref>), the gap or modulation was considered to be &#x0201c;detectable&#x0201d; by the model. The criteria for detecting a discontinuity were as follows: the predicted pitch around the midpoint of the stimulus duration changed by at least a semitone, and the duration of the detected discontinuity was greater than 4 ms.</p><p>Using the above criteria, the predicted thresholds qualitatively match the listeners' mean detection thresholds in both tasks (gap and modulation detection; the modelled and measured thresholds were statistically indistinguishable for all but two of the delays tested). Importantly, it can be seen that, for each RN delay, the model predicted the thresholds for the modulation detection task to be significantly greater than that for the gap detection task (solid lines), as was indeed the case in the data (dotted lines); i.e., the perception of the discontinuity is more difficult when modulations occur periodically rather than only once. This result is somewhat counterintuitive, because the modulation condition contains similar information to the gap condition (see <xref ref-type="fig" rid="pcbi-1000301-g007">Figure 7B</xref>), but repeated over time. It would be difficult to explain this using a conventional autocorrelation model with a single integration time constant. In such a model, the presence of a short discontinuity could only be detected by using a short time constant. Therefore, <italic>A<sub>3</sub></italic>(<italic>t,l</italic>) would only reflect the recent stimulus history and not the influence of previous modulation cycles. However, in the model reported here, the stimulus-dependency of the effective time constants allows the model to capture both the short term disruptions and the longer term contextual influence and thereby the perceptual differences in pitch-gap and pitch-modulation conditions (<xref ref-type="fig" rid="pcbi-1000301-g007">Figure 7D</xref>).</p></sec></sec><sec id="s3c"><title>Pitch of Click Train Stimuli</title><p><xref ref-type="fig" rid="pcbi-1000301-g002">Figure 2B</xref> showed that the model uses very short integration times for pitch information when a change in pitch occurs. However, it is possible to construct a class of stimuli, in which the periodicities change continually over very short time scales but which nevertheless elicit a single pitch <xref ref-type="bibr" rid="pcbi.1000301-Carlyon4">&#x0005b;49&#x0005d;</xref>,<xref ref-type="bibr" rid="pcbi.1000301-Carlyon5">&#x0005b;50&#x0005d;</xref>, suggesting that pitch information is integrated across these rapid changes in periodicity. The stimuli in question are high-pass-filtered click trains where the interval between successive clicks varies. Previously we showed that the cascade autocorrelation model with fixed integration times <xref ref-type="bibr" rid="pcbi.1000301-BalaguerBallester3">&#x0005b;13&#x0005d;</xref> predicted the pitch percept elicited by a range of click train stimuli, which had proved problematic for conventional autocorrelation models <xref ref-type="bibr" rid="pcbi.1000301-Carlyon4">&#x0005b;49&#x0005d;</xref>, <xref ref-type="bibr" rid="pcbi.1000301-Carlyon5">&#x0005b;50&#x0005d;</xref>, <xref ref-type="bibr" rid="pcbi.1000301-Kaernbach1">&#x0005b;60&#x0005d;</xref>&#x02013;<xref ref-type="bibr" rid="pcbi.1000301-Pressnitzer2">&#x0005b;63&#x0005d;</xref>. Here, we test whether the current model (which generalizes the model reported in <xref ref-type="bibr" rid="pcbi.1000301-BalaguerBallester3">&#x0005b;13&#x0005d;</xref> by including variable integration times) retains this ability. This is an important question, because a rapid reset of pitch information is apparently in contradiction with the long-term integration used in <xref ref-type="bibr" rid="pcbi.1000301-BalaguerBallester3">&#x0005b;13&#x0005d;</xref>, as was illustrated in the <xref ref-type="sec" rid="s2">Methods</xref> section (<xref ref-type="fig" rid="pcbi-1000301-g003">Figure 3</xref>).</p><p>As an example, <xref ref-type="fig" rid="pcbi-1000301-g008">Figure 8</xref> shows the response of the model to one of these stimuli. In this case, the inter-click intervals alternate between 4 and 6 ms, but listeners usually report a single pitch somewhere in between these extremes and closer to the longer interval. Carlyon et al. <xref ref-type="bibr" rid="pcbi.1000301-Carlyon4">&#x0005b;49&#x0005d;</xref>,<xref ref-type="bibr" rid="pcbi.1000301-Carlyon5">&#x0005b;50&#x0005d;</xref> presented the click trains with a duration of 400 ms. Stimuli were band-pass-filtered with cut-off frequencies of 3900 and 5300 Hz in order to avoid the harmonic spectral components being resolved by the cochlear filters. They also added a pink noise to avoid audible distortion products. Carlyon et al. <xref ref-type="bibr" rid="pcbi.1000301-Carlyon5">&#x0005b;50&#x0005d;</xref> demonstrated that the combined auditory nerve responses, measured as compound action potentials (CAPs), were stronger for the largest inter-click interval (6 ms) than for the shorter interval (4 ms). Therefore, they suggested that a population of more central neurons, which respond only when their inputs exceed a fixed threshold value, would respond preferentially to the longer intervals, thereby explaining listeners' preference for matching a pitch close to 6 ms.</p><fig id="pcbi-1000301-g008" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000301.g008</object-id><label>Figure 8</label><caption><title>Model response to a high-pass-filtered click train with alternating inter-click intervals <xref ref-type="bibr" rid="pcbi.1000301-Carlyon4">&#x0005b;49&#x0005d;</xref>,<xref ref-type="bibr" rid="pcbi.1000301-Carlyon5">&#x0005b;50&#x0005d;</xref>.</title><p>(A) Central portion of the stimulus waveform (the total duration is 400 ms) for a click train with inter-click intervals alternating between 4 and 6 ms after high-pass filtering and the addition of a pink noise background. (B) Effective integration time, <italic>E<sub>2</sub></italic>(<italic>t</italic>) (green solid line) and <italic>E<sub>3</sub></italic>(<italic>t</italic>) (red dotted line) at the second and third stages of the model. (C) Model response at the third stage, <italic>A<sub>3</sub></italic>(<italic>t,l</italic>), normalized and displayed as in previous figures. The arrow marks the lag corresponding to the pitch reported by listeners. (D) Final snapshot of <italic>A<sub>3</sub></italic>(<italic>t,l</italic>) at <italic>t<sub>final</sub></italic>. The vertical dashed line corresponds to the average pitch reported by listeners.</p></caption><graphic xlink:href="pcbi.1000301.g008"/></fig><p><xref ref-type="fig" rid="pcbi-1000301-g008">Figure 8C</xref> shows that the predicted pitch of the model (red highlight) varies almost randomly for approximately 80 ms and then progressively stabilizes at a lag in the region of 5.5&#x02013;6 ms (see horizontal arrow in <xref ref-type="fig" rid="pcbi-1000301-g008">Figure 8C</xref>). Thus, the model prediction is in good agreement with the geometric average of the reported pitch values (shown by vertical dashed line in <xref ref-type="fig" rid="pcbi-1000301-g008">Figure 8D</xref>). While the final snapshot of <italic>A<sub>3</sub></italic>(<italic>t<sub>final</sub>,l</italic>) (<xref ref-type="fig" rid="pcbi-1000301-g008">Figure 8D</xref>) peaks close to the geometric mean of the reported pitches (vertical dashed line), there are other prominent peaks in <italic>A<sub>3</sub></italic>(<italic>t<sub>final</sub>,l</italic>) close to this maximum; this is consistent with the large variability in reported pitches for these alternating click trains. A prediction of the model yet to be tested is that no reliable pitch estimate would be possible for stimuli shorter than 100 ms. To conclude, it is worth remarking that this model can similarly account for the pitches of the other click train stimuli considered in <xref ref-type="bibr" rid="pcbi.1000301-BalaguerBallester3">&#x0005b;13&#x0005d;</xref>.</p></sec><sec id="s3d"><title>Cortical Latency of the Pitch Onset Response</title><p>The model proposed here is not a formal model of neural populations; nevertheless, it is neurophysiologically based (see <xref ref-type="sec" rid="s2">Methods</xref> and <xref ref-type="sec" rid="s4">Discussion</xref> sections). This raises the question as to whether the model can explain aspects of the responses of neural ensembles in a pitch perception task. Krumbholz et al. <xref ref-type="bibr" rid="pcbi.1000301-Krumbholz2">&#x0005b;37&#x0005d;</xref> identified a transient neuromagnetic response in Heschl's Gyrus, which they termed the &#x0201c;pitch onset response&#x0201d; (POR). In their experiment, they used iterated rippled noise (IRN) stimuli with delays of 4, 8, 12 and 16 ms. IRN differs from the RN stimulus described previously in that the delay-and-add process is iterated <italic>N</italic> times. Increasing the number of iterations, <italic>N</italic>, increases the degree of serial correlation and therefore the pitch strength. <xref ref-type="fig" rid="pcbi-1000301-g009">Figure 9A</xref> shows the spectrogram of an IRN stimulus with a 12 ms delay and 16 iterations. Neuromagnetic responses were recorded to the onset of an IRN, which was directly preceded by an uncorrelated noise with the same energy and spectral composition. Recordings showed that the transition from noise to IRN produced a reliable POR with a mean latency of approximately four times the delay, <italic>d</italic>, plus a constant offset of about 120 ms (left panel in <xref ref-type="fig" rid="pcbi-1000301-g009">Figure 9D, solid blue line</xref>). The authors concluded that the POR reflects pitch-related processing within Heschl's Gyrus in the human auditory cortex. This has been supported by other more recent studies <xref ref-type="bibr" rid="pcbi.1000301-Gutschalk1">&#x0005b;36&#x0005d;</xref>.</p><fig id="pcbi-1000301-g009" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000301.g009</object-id><label>Figure 9</label><caption><title>Model evaluation of the Pitch Onset Response (POR).</title><p>(A) Spectrogram of the final portion of the stimulus waveform; consisting of 500 ms of iterated rippled noise (delay 12 ms, 16 iterations); preceded by uncorrelated noise (not shown). (B) <italic>A<sub>3</sub></italic>(<italic>t,l</italic>) (without any normalization); colours show activation strength as a percentage of the maximum response. The horizontal arrow indicates the delay corresponding to the reported pitch of this stimulus. (C) Smoothed derivative of <italic>A<sub>3</sub></italic>(<italic>t,l</italic>); obtained by convolving the model output with the first derivative of a Gaussian function of 60 ms width and 6 ms of standard deviation (dotted red line). Solid green line shows the variance of <italic>A<sub>3</sub></italic>(<italic>t,l</italic>). <italic>C</italic> is the Pearson correlation coefficient between the smoothed derivative and the variance. (D) Comparison between the model and neuromagnetic results. The solid blue line illustrates the latency of the experimentally measured POR. The dotted red line shows the time at which the maximum of the smoothed derivative is first achieved (within a 2&#x00025; of tolerance in this value). The left panel shows the POR latencies as a function of delay when the number of iterations is fixed (16). The right panel shows POR latencies when the delay is fixed to 16 ms and the number of iterations varies.</p></caption><graphic xlink:href="pcbi.1000301.g009"/></fig><p><xref ref-type="fig" rid="pcbi-1000301-g009">Figure 9B</xref> shows the output of the model, (<italic>A<sub>3</sub></italic>(<italic>t,l</italic>) without any normalization, in contrast to previous plots), for the example shown in <xref ref-type="fig" rid="pcbi-1000301-g009">Figure 9A</xref>. After some time the maximum of <italic>A<sub>3</sub></italic>(<italic>t,l</italic>) (red colour) stabilises and becomes prominent. The predicted pitch is the reciprocal of <italic>L<sub>3</sub></italic>&#x0200a;&#x0003d;&#x0200a;12 ms, which corresponds to the delay of the IRN stimulus. However, the maximum value of <italic>A<sub>3</sub></italic>(<italic>t,L<sub>3</sub></italic>) in <xref ref-type="fig" rid="pcbi-1000301-g009">Figure 9B</xref> emerges gradually. Therefore, there seems to be no obvious correlate of the latency at around 150 ms of the measured cortical response in the model.</p><p>A number of previous studies have suggested that the temporal derivative of the neural population responses at lower levels of processing might correlate with the measured activity in higher (i.e., cortical) levels <xref ref-type="bibr" rid="pcbi.1000301-Fishbach1">&#x0005b;44&#x0005d;</xref>,<xref ref-type="bibr" rid="pcbi.1000301-Fishbach2">&#x0005b;45&#x0005d;</xref>,<xref ref-type="bibr" rid="pcbi.1000301-Coath1">&#x0005b;64&#x0005d;</xref>. Therefore we investigated whether the latency of the pitch onset response might correspond to the latency of the peak in the derivative of <italic>A<sub>3</sub></italic>(<italic>t,L<sub>3</sub></italic>).</p><p>Here, we calculated a smoothed version of the temporal derivative of <italic>A<sub>3</sub></italic>(<italic>t,L<sub>3</sub></italic>) by convolving <italic>A<sub>3</sub></italic>(<italic>t,L<sub>3</sub></italic>) with the first differential of a Gaussian function (representing connection efficacies to higher areas <xref ref-type="bibr" rid="pcbi.1000301-Fishbach1">&#x0005b;44&#x0005d;</xref>,<xref ref-type="bibr" rid="pcbi.1000301-Fishbach2">&#x0005b;45&#x0005d;</xref>). We then used the first maximum of this smoothed derivative to predict the latencies of the POR for different pitch values. <xref ref-type="fig" rid="pcbi-1000301-g009">Figure 9C</xref> illustrates the smoothed derivative of <italic>A<sub>3</sub></italic>(<italic>t,L<sub>3</sub></italic>) for the example shown in <xref ref-type="fig" rid="pcbi-1000301-g009">Figure 9A</xref> (red dotted line). The derivative has a maximum at approximately 168 ms, which is consistent with the POR latency for this condition. The green solid line shows the variance of <italic>A<sub>3</sub></italic>(<italic>t,l</italic>) (calculated at each fixed <italic>t</italic>) for the same stimulus. It appears that the variance of <italic>A<sub>3</sub></italic>(<italic>t,l</italic>), which might be taken to represent the uncertainty of the pitch estimate, reaches a minimum at a similar time as the derivative of <italic>A<sub>3</sub></italic>(<italic>t,L<sub>3</sub></italic>) reaches a maximum (in general, however, the smoothed derivative is a more accurate predictor of the experimental latencies). The red dotted line in <xref ref-type="fig" rid="pcbi-1000301-g009">Figure 9D</xref> (left plot) shows the time at which the smoothed derivative of <italic>A<sub>3</sub></italic>(<italic>t,L<sub>3</sub></italic>) reaches its first maximum as a function of pitch value, which appears to correlate remarkably well with the POR latencies (solid line).</p><p>Krumbholz et al. <xref ref-type="bibr" rid="pcbi.1000301-Krumbholz2">&#x0005b;37&#x0005d;</xref> also found that the POR latency mainly depended on the delay of the IRN stimulus and was influenced little by the number of iterations. The right panel in <xref ref-type="fig" rid="pcbi-1000301-g009">Figure 9D</xref> shows the latencies when the delay is fixed at 16 ms and the number of iterations varies (solid line). Consistent with experimental results, the number of iterations of the stimulus do not significantly affect the smoothed derivative of <italic>A<sub>3</sub></italic>(<italic>t,L<sub>3</sub></italic>(<italic>t</italic>)) (dotted line).</p><p>To conclude, it is worth mentioning that the model also accounts for the minimum duration of IRN stimuli for reliable perceptual discrimination of the pitch, also reported in <xref ref-type="bibr" rid="pcbi.1000301-Krumbholz2">&#x0005b;37&#x0005d;</xref>. The solid line in <xref ref-type="fig" rid="pcbi-1000301-g010">Figure 10</xref> indicates the average perceptual results. The dashed line shows the duration of the transient period in <italic>A<sub>3</sub></italic>(<italic>t,L<sub>3</sub></italic>), i.e., the time window during which the pitch prediction is not stable (e.g. around 100 ms in the stimulus shown in <xref ref-type="fig" rid="pcbi-1000301-g008">Figure 8C</xref>). Clearly, the model simulations match the data extremely well (dashed line in <xref ref-type="fig" rid="pcbi-1000301-g010">Figure 10</xref>). Therefore, the initial period in which the model output varies rapidly seems to correlate with unstable pitch perception. This model prediction might be valid not only for IRN stimuli but also for other pitched sounds.</p><fig id="pcbi-1000301-g010" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000301.g010</object-id><label>Figure 10</label><caption><title>Minimum stimulus duration required to perceive a stable pitch sensation.</title><p>The solid blue line shows the perceptual results averaged over listeners; and the dotted red line, the mean model predictions.</p></caption><graphic xlink:href="pcbi.1000301.g010"/></fig></sec></sec><sec id="s4"><title>Discussion</title><p>We propose a neurocomputational model to explain the observed paradox between temporal integration and temporal resolution in the auditory processing of pitch information. Our goal was to capture essential elements in the temporal dynamics of pitch perception within a unified framework. This model is an extension of the autocorrelation theory of pitch perception formulated in terms of equations describing the activity of neural ensembles <xref ref-type="bibr" rid="pcbi.1000301-Gerstner1">&#x0005b;51&#x0005d;</xref>,<xref ref-type="bibr" rid="pcbi.1000301-Amari1">&#x0005b;65&#x0005d;</xref>, and extended to include feedback processing.</p><p>The principal novelty of the model is the suggestion that top-down connections to sub-cortical areas determine the temporal dynamics of auditory perception, and that this influence is mediated through feedback modulation of recurrent inhibitory circuits. As a result, the responses at each stage adapt to recent and relevant changes in the input stimulus; i.e., feedback in the model essentially determines the dynamics of the &#x0201c;effective&#x0201d; integration window used at each stage. This approach is consistent with the available neuroimaging data: a sustained pitch response (SPR) in lateral Heschl's Gyrus has been shown to adapt to the recent temporal context of a pitch sequence, enhancing the response to rare and brief events <xref ref-type="bibr" rid="pcbi.1000301-Gutschalk1">&#x0005b;36&#x0005d;</xref>. The successful explanation of the latency of the Pitch Onset Response (<xref ref-type="fig" rid="pcbi-1000301-g009">Figure 9D, left plot</xref>) further supports the neurobiological validity of this model. Therefore, we hypothesize that the model captures some fundamental processing aspects of pitch processing, occurring up to Heschl's Gyrus <xref ref-type="bibr" rid="pcbi.1000301-Krumbholz2">&#x0005b;37&#x0005d;</xref>. Consistent with this, a recent study also suggests that the auditory sensory thalamus processes fast changes in speech, which appears to be modulated by slower contextual states <xref ref-type="bibr" rid="pcbi.1000301-vonKriegstein1">&#x0005b;66&#x0005d;</xref>.</p><p>It should be noted that efferent connections to the auditory peripheral model have not yet been implemented, although there is evidence for those connections too <xref ref-type="bibr" rid="pcbi.1000301-Guinan1">&#x0005b;67&#x0005d;</xref>. The addition of this connection could provide a method for controlling the cochlear model, a current focus of our investigations.</p><p>Although highly idealized, the model uses a minimal set of biologically plausible parameters. The values shown in <xref ref-type="table" rid="pcbi-1000301-t001">Table 1</xref> were optimized for generating the correct temporal dynamics of the effective integration windows in the global pitch of non-simultaneous tones, and the pitches of click trains, described in the <xref ref-type="sec" rid="s3">Results</xref> section. Neither the gap detection threshold nor the POR latency experiments were used for parameter optimization; they therefore stand as tests of the generalization of the model.</p><p>The current model might thus serve as a basis for more realistic neurophysiological models in the future. In fact, the model responses during the offsets of tones are similar to responses of neurons to amplitude modulated pure tones measured in the superior paraolivary nucleus (SPON) of rats <xref ref-type="bibr" rid="pcbi.1000301-Kadner1">&#x0005b;68&#x0005d;</xref>. Remarkably, a short gap between tones was found to produce a significant burst of spikes; i.e., a change in neural activity of several orders of magnitude in less than a millisecond during discontinuities between the tones. Consistent with this data, the model responses <italic>A<sub>n</sub></italic>(<italic>t,l</italic>) vary very quickly at tone offsets, because the effective integration windows become very short at these discontinuities (<xref ref-type="fig" rid="pcbi-1000301-g002">Figure 2C</xref>). Interestingly, this very fast offset response in SPON neurons is not a feed-forward process, but is modulated by feedback from neurons in the medial nucleus of the trapezoid body, which inhibit the SPON <xref ref-type="bibr" rid="pcbi.1000301-Kadner1">&#x0005b;68&#x0005d;</xref>. The model architecture shown in <xref ref-type="fig" rid="pcbi-1000301-g001">Figure 1</xref> is similar to this type of feedback inhibitory circuit.</p><p>In some ways (see <xref ref-type="supplementary-material" rid="pcbi.1000301.s001">Text S1</xref>) the model can be understood as a special case of a more general class of models: the <italic>hierarchical generative models</italic> (HGMs) of sensory processing <xref ref-type="bibr" rid="pcbi.1000301-Friston1">&#x0005b;38&#x0005d;</xref>,<xref ref-type="bibr" rid="pcbi.1000301-Friston2">&#x0005b;39&#x0005d;</xref>,<xref ref-type="bibr" rid="pcbi.1000301-Friston3">&#x0005b;69&#x0005d;</xref>. In the HGM approach, it is assumed that higher areas have access to more abstract and contextualized information, and therefore produce a more refined expectation of the next sensory input. Lower areas deal with more detailed information and generate intermediate predictions <xref ref-type="bibr" rid="pcbi.1000301-Friston1">&#x0005b;38&#x0005d;</xref>. A mismatch between these two predictions generates an error, which propagates from the upper level to the level immediately below and minimizes the <italic>free energy</italic> of the model <xref ref-type="bibr" rid="pcbi.1000301-Friston1">&#x0005b;38&#x0005d;</xref>,<xref ref-type="bibr" rid="pcbi.1000301-Friston3">&#x0005b;69&#x0005d;</xref>. This is shown in <xref ref-type="supplementary-material" rid="pcbi.1000301.s001">Text S1</xref>, where a comparison between the proposed model and HGMs is presented. Very recently, Kiebel and colleagues also showed that the minimisation of the free energy can be used to invert temporal hierarchies in the processing of bird songs <xref ref-type="bibr" rid="pcbi.1000301-Kiebel1">&#x0005b;70&#x0005d;</xref>.</p><p>In summary, we propose a unified model to explain the stimulus-dependency of the time constants of temporal processing in auditory perception. We suggest that one possible role for efferent connections in the auditory system is to detect perceptually relevant changes in the temporal patterns of afferent activity and to adapt the effective processing time constants to the stimulus characteristics. Currently, we are not aware of any studies that have explicitly tested the role of efferent signals in pitch perception, thus, this hypothesis has yet to be tested. Nevertheless, a prediction of the model is that blocking the feedback circuits would impair the ability to separate sounds over time. Recent experimental studies in cortical cooling <xref ref-type="bibr" rid="pcbi.1000301-Palmer1">&#x0005b;71&#x0005d;</xref> may provide a methodology for further testing this proposal.</p></sec><sec sec-type="supplementary-material" id="s5"><title>Supporting Information</title><supplementary-material content-type="local-data" id="pcbi.1000301.s001"><label>Text S1</label><caption><p>This section explores the similarities between this study, which does not use a Bayesian inference approach, and the Hierarchical Generative Models (HGMs) of sensory processing.</p><p>(0.10 MB DOC)</p></caption><media xlink:href="pcbi.1000301.s001.doc" mimetype="application" mime-subtype="msword"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></sec></body><back><ack><p>EB-B wants to thank Ray Meddis for his very generous support, which was critical to the completion of this study. The authors also thank the anonymous reviewers for their constructive comments and painstaking work.</p></ack><ref-list><title>References</title><ref id="pcbi.1000301-Moore1"><label>1</label><citation citation-type="book"><person-group person-group-type="author"><name><surname>Moore</surname><given-names>BCJ</given-names></name></person-group><year>2004</year><source>An Introduction to the Psychology of Hearing. 5th edition</source><publisher-loc>London</publisher-loc><publisher-name>Elsevier</publisher-name></citation></ref><ref id="pcbi.1000301-Licklider1"><label>2</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Licklider</surname><given-names>JCR</given-names></name></person-group><year>1951</year><article-title>A duplex theory of pitch perception.</article-title><source>Experientia</source><volume>7</volume><fpage>128</fpage><lpage>134</lpage><pub-id pub-id-type="pmid">14831572</pub-id></citation></ref><ref id="pcbi.1000301-Slaney1"><label>3</label><citation citation-type="book"><person-group person-group-type="author"><name><surname>Slaney</surname><given-names>M</given-names></name><name><surname>Lyon</surname><given-names>RF</given-names></name></person-group><year>1990</year><article-title>A perceptual pitch detector.</article-title><source>Acoustics, Speech, and Signal Processing, ICASSP-90</source><publisher-loc>New York</publisher-loc><publisher-name>IEEE Press</publisher-name><fpage>357</fpage><lpage>360</lpage></citation></ref><ref id="pcbi.1000301-Cariani1"><label>4</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Cariani</surname><given-names>PA</given-names></name><name><surname>Delgutte</surname><given-names>B</given-names></name></person-group><year>1996</year><article-title>Neural correlates of the pitch of complex tones. I. Pitch and pitch salience.</article-title><source>J Neurophysiol</source><volume>76</volume><fpage>1698</fpage><lpage>1716</lpage><pub-id pub-id-type="pmid">8890286</pub-id></citation></ref><ref id="pcbi.1000301-Cariani2"><label>5</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Cariani</surname><given-names>PA</given-names></name><name><surname>Delgutte</surname><given-names>B</given-names></name></person-group><year>1996</year><article-title>Neural correlates of the pitch of complex tones. II. Pitch shift, pitch ambiguity, phase-invariance, pitch circularity, rate-pitch, and the dominance region of pitch.</article-title><source>J Neurophysiol</source><volume>76</volume><fpage>1717</fpage><lpage>1734</lpage><pub-id pub-id-type="pmid">8890287</pub-id></citation></ref><ref id="pcbi.1000301-Meddis1"><label>6</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Meddis</surname><given-names>R</given-names></name><name><surname>Hewitt</surname><given-names>MJ</given-names></name></person-group><year>1991</year><article-title>Virtual pitch and phase sensitivity of a computer model of the auditory periphery: I. Pitch identification.</article-title><source>J Acoust Soc Am</source><volume>89</volume><fpage>2866</fpage><lpage>2882</lpage></citation></ref><ref id="pcbi.1000301-Meddis2"><label>7</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Meddis</surname><given-names>R</given-names></name><name><surname>O'Mard</surname><given-names>L</given-names></name></person-group><year>1997</year><article-title>A unitary model of pitch perception.</article-title><source>J Acoust Soc Am</source><volume>102</volume><fpage>1811</fpage><lpage>1820</lpage><pub-id pub-id-type="pmid">9301058</pub-id></citation></ref><ref id="pcbi.1000301-deCheveign1"><label>8</label><citation citation-type="book"><person-group person-group-type="author"><name><surname>de Cheveign&#x000e9;</surname><given-names>A</given-names></name></person-group><year>2005</year><article-title>Pitch perception models.</article-title><person-group person-group-type="editor"><name><surname>Plack</surname><given-names>CJ</given-names></name><name><surname>Oxenham</surname><given-names>AJ</given-names></name><name><surname>Fay</surname><given-names>RR</given-names></name><name><surname>Popper</surname><given-names>AN</given-names></name></person-group><source>Pitch: Neural Coding and Perception.</source><publisher-loc>New York</publisher-loc><publisher-name>Springer</publisher-name><fpage>169</fpage><lpage>233</lpage></citation></ref><ref id="pcbi.1000301-Bernstein1"><label>9</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Bernstein</surname><given-names>JGW</given-names></name><name><surname>Oxenham</surname><given-names>AJ</given-names></name></person-group><year>2005</year><article-title>An autocorrelation model with place dependence to account for the effect of harmonic number on fundamental frequency discrimination.</article-title><source>J Acoust Soc Am</source><volume>117</volume><fpage>3816</fpage><lpage>3831</lpage><pub-id pub-id-type="pmid">16018484</pub-id></citation></ref><ref id="pcbi.1000301-deCheveign2"><label>10</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>de Cheveign&#x000e9;</surname><given-names>A</given-names></name><name><surname>Pressnitzer</surname><given-names>D</given-names></name></person-group><year>2006</year><article-title>The case of the missing delay lines: synthetic delays obtained by cross-channel phase interaction.</article-title><source>J Acoust Soc Am</source><volume>119</volume><fpage>3908</fpage><lpage>3918</lpage><pub-id pub-id-type="pmid">16838534</pub-id></citation></ref><ref id="pcbi.1000301-BalaguerBallester1"><label>11</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Balaguer-Ballester</surname><given-names>E</given-names></name><name><surname>Denham</surname><given-names>SL</given-names></name><name><surname>Meddis</surname><given-names>R</given-names></name></person-group><year>2006</year><article-title>A synchronized autocorrelation model accounts for pure temporal pitches.</article-title><source>Int J Audiol</source><volume>46</volume><fpage>619</fpage><lpage>658</lpage></citation></ref><ref id="pcbi.1000301-BalaguerBallester2"><label>12</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Balaguer-Ballester</surname><given-names>E</given-names></name><name><surname>Coath</surname><given-names>M</given-names></name><name><surname>Denham</surname><given-names>SL</given-names></name></person-group><year>2007</year><article-title>A model of perceptual segregation based on clustering the time series of the simulated auditory nerve firing probability.</article-title><source>Biol Cybern</source><volume>97</volume><fpage>479</fpage><lpage>491</lpage><pub-id pub-id-type="pmid">17994247</pub-id></citation></ref><ref id="pcbi.1000301-BalaguerBallester3"><label>13</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Balaguer-Ballester</surname><given-names>E</given-names></name><name><surname>Denham</surname><given-names>SL</given-names></name><name><surname>Meddis</surname><given-names>R</given-names></name></person-group><year>2008</year><article-title>A cascade autocorrelation model of pitch perception.</article-title><source>J Acoust Soc Am</source><volume>124</volume><fpage>2186</fpage><lpage>2195</lpage><pub-id pub-id-type="pmid">19062858</pub-id></citation></ref><ref id="pcbi.1000301-Hall1"><label>14</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Hall</surname><given-names>JW</given-names><suffix>III</suffix></name><name><surname>Peters</surname><given-names>RW</given-names></name></person-group><year>1981</year><article-title>Pitch for nonsimultaneous successive harmonics in quiet and noise.</article-title><source>J Acoust Soc Am</source><volume>69</volume><fpage>509</fpage><lpage>513</lpage><pub-id pub-id-type="pmid">7462473</pub-id></citation></ref><ref id="pcbi.1000301-Grose1"><label>15</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Grose</surname><given-names>JH</given-names></name><name><surname>Hall</surname><given-names>JW</given-names><suffix>III</suffix></name><name><surname>Buss</surname><given-names>E</given-names></name></person-group><year>2002</year><article-title>Virtual pitch integration for asynchronous harmonics.</article-title><source>J Acoust Soc Am</source><volume>104</volume><fpage>3006</fpage><lpage>3018</lpage></citation></ref><ref id="pcbi.1000301-Carlyon1"><label>16</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Carlyon</surname><given-names>RP</given-names></name></person-group><year>1996</year><article-title>Encoding the fundamental frequency of a complex tone in presence of spectrally overlapping masker.</article-title><source>J Acoust Soc Am</source><volume>99</volume><fpage>517</fpage><lpage>524</lpage><pub-id pub-id-type="pmid">8568039</pub-id></citation></ref><ref id="pcbi.1000301-Plack1"><label>17</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Plack</surname><given-names>CJ</given-names></name><name><surname>White</surname><given-names>LJ</given-names></name></person-group><year>2000</year><article-title>Perceived continuity and pitch perception.</article-title><source>J Acoust Soc Am</source><volume>108</volume><fpage>1162</fpage><lpage>1169</lpage><pub-id pub-id-type="pmid">11008817</pub-id></citation></ref><ref id="pcbi.1000301-White1"><label>18</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>White</surname><given-names>LJ</given-names></name><name><surname>Plack</surname><given-names>CJ</given-names></name></person-group><year>1998</year><article-title>Temporal processing of the pitch of complex tones.</article-title><source>J Acoust Soc Am</source><volume>103</volume><fpage>2051</fpage><lpage>2063</lpage><pub-id pub-id-type="pmid">9566327</pub-id></citation></ref><ref id="pcbi.1000301-Moore2"><label>19</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Moore</surname><given-names>BCJ</given-names></name></person-group><year>1973</year><article-title>Frequency difference limens for short-duration tones.</article-title><source>J Acoust Soc Am</source><volume>54</volume><fpage>610</fpage><lpage>619</lpage><pub-id pub-id-type="pmid">4754385</pub-id></citation></ref><ref id="pcbi.1000301-Plack2"><label>20</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Plack</surname><given-names>CJ</given-names></name><name><surname>Carlyon</surname><given-names>RP</given-names></name></person-group><year>1995</year><article-title>Differences in fundamental frequency discrimination and frequency modulation detection between complex tones consisting of resolved and unresolved harmonics.</article-title><source>J Acoust Soc Am</source><volume>98</volume><fpage>1355</fpage><lpage>1364</lpage></citation></ref><ref id="pcbi.1000301-Bregman1"><label>21</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Bregman</surname><given-names>AS</given-names></name><name><surname>Ahad</surname><given-names>PA</given-names></name><name><surname>Kim</surname><given-names>J</given-names></name><name><surname>Melnerich</surname><given-names>L</given-names></name></person-group><year>1994</year><article-title>Resetting the pitch-analysis system: 1. Effects of rise times of tones in noise backgrounds or of harmonics in a complex tone.</article-title><source>Percept Psychophys</source><volume>56</volume><fpage>155</fpage><lpage>162</lpage><pub-id pub-id-type="pmid">7971116</pub-id></citation></ref><ref id="pcbi.1000301-Bregman2"><label>22</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Bregman</surname><given-names>AS</given-names></name><name><surname>Ahad</surname><given-names>PA</given-names></name><name><surname>Kim</surname><given-names>J</given-names></name></person-group><year>1994</year><article-title>Resetting the pitch-analysis system. 2. Role of sudden onsets and offsets in the perception of individual components in a cluster of overlapping tones.</article-title><source>J Acoust Soc Am</source><volume>96</volume><fpage>2694</fpage><lpage>2703</lpage><pub-id pub-id-type="pmid">7983275</pub-id></citation></ref><ref id="pcbi.1000301-Wiegrebe1"><label>23</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Wiegrebe</surname><given-names>L</given-names></name></person-group><year>2001</year><article-title>Searching for the time constant in of neural pitch extraction.</article-title><source>J Acoust Soc Am</source><volume>107</volume><fpage>1082</fpage><lpage>1091</lpage><pub-id pub-id-type="pmid">11303922</pub-id></citation></ref><ref id="pcbi.1000301-Denham1"><label>24</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Denham</surname><given-names>SL</given-names></name></person-group><year>2005</year><article-title>Dynamic Iterated Rippled Noise: further evidence for the importance of temporal processing in auditory perception.</article-title><source>Biosystems</source><volume>79</volume><fpage>199</fpage><lpage>206</lpage><pub-id pub-id-type="pmid">15649605</pub-id></citation></ref><ref id="pcbi.1000301-Moore3"><label>25</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Moore</surname><given-names>BCJ</given-names></name><name><surname>Sek</surname><given-names>A</given-names></name></person-group><year>1996</year><article-title>Detection of frequency modulation at low modulation rates: Evidence for a mechanism based on phase locking.</article-title><source>J Acoust Soc Am</source><volume>100</volume><fpage>2320</fpage><lpage>2331</lpage><pub-id pub-id-type="pmid">8865639</pub-id></citation></ref><ref id="pcbi.1000301-Carlyon2"><label>26</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Carlyon</surname><given-names>RP</given-names></name></person-group><year>2000</year><article-title>Detecting coherent and incoherent frequency modulation.</article-title><source>Hear Res</source><volume>140</volume><fpage>173</fpage><lpage>188</lpage><pub-id pub-id-type="pmid">10675645</pub-id></citation></ref><ref id="pcbi.1000301-Carlyon3"><label>27</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Carlyon</surname><given-names>RP</given-names></name><name><surname>Micheyl</surname><given-names>C</given-names></name><name><surname>Deeks</surname><given-names>JM</given-names></name><name><surname>Moore</surname><given-names>BCJ</given-names></name></person-group><year>2004</year><article-title>Auditory processing of real and illusory changes in frequency modulation (FM) phase.</article-title><source>J Acoust Soc Am</source><volume>116</volume><fpage>3629</fpage><lpage>3639</lpage><pub-id pub-id-type="pmid">15658713</pub-id></citation></ref><ref id="pcbi.1000301-deBoer1"><label>28</label><citation citation-type="book"><person-group person-group-type="author"><name><surname>de Boer</surname><given-names>E</given-names></name></person-group><year>1985</year><article-title>Auditory Time Constants: A Paradox?.</article-title><person-group person-group-type="editor"><name><surname>Michelsen</surname><given-names>A</given-names></name></person-group><source>Time Resolution in Auditory Systems.</source><publisher-loc>Berlin</publisher-loc><publisher-name>Springer-Verlag</publisher-name><fpage>141</fpage><lpage>158</lpage></citation></ref><ref id="pcbi.1000301-Krumbholz1"><label>29</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Krumbholz</surname><given-names>K</given-names></name><name><surname>Wiegrebe</surname><given-names>L</given-names></name></person-group><year>1998</year><article-title>Detection thresholds for brief sounds&#x02014;are they a measure of auditory intensity integration?</article-title><source>Hear Res</source><volume>124</volume><fpage>155</fpage><lpage>169</lpage><pub-id pub-id-type="pmid">9822913</pub-id></citation></ref><ref id="pcbi.1000301-Shailer1"><label>30</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Shailer</surname><given-names>MJ</given-names></name><name><surname>Moore</surname><given-names>BCJ</given-names></name></person-group><year>1983</year><article-title>Gap detection as a function of frequency, bandwidth and level.</article-title><source>J Acoust Soc Am</source><volume>74</volume><fpage>467</fpage><lpage>473</lpage><pub-id pub-id-type="pmid">6619424</pub-id></citation></ref><ref id="pcbi.1000301-Viemeister1"><label>31</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Viemeister</surname><given-names>NF</given-names></name><name><surname>Wakefield</surname><given-names>GH</given-names></name></person-group><year>1991</year><article-title>Temporal integration and multiple looks.</article-title><source>J Acoust Soc Am</source><volume>90</volume><fpage>858</fpage><lpage>865</lpage><pub-id pub-id-type="pmid">1939890</pub-id></citation></ref><ref id="pcbi.1000301-Kumar1"><label>32</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kumar</surname><given-names>S</given-names></name><name><surname>Stephan</surname><given-names>KE</given-names></name><name><surname>Warren</surname><given-names>JD</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name><name><surname>Griffiths</surname><given-names>TD</given-names></name></person-group><year>2007</year><article-title>Hierarchical processing of auditory objects in humans.</article-title><source>PLoS Comput Biol</source><volume>3</volume><fpage>e100</fpage><comment>doi:10.1371/journal.pcbi.0030100</comment><pub-id pub-id-type="pmid">17542641</pub-id></citation></ref><ref id="pcbi.1000301-Griffiths1"><label>33</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Griffiths</surname><given-names>TD</given-names></name><name><surname>Uppenkamp</surname><given-names>S</given-names></name><name><surname>Johnsrude</surname><given-names>I</given-names></name><name><surname>Josephs</surname><given-names>O</given-names></name><name><surname>Patterson</surname><given-names>RD</given-names></name></person-group><year>2001</year><article-title>Encoding of the temporal regularity of sound in the human brainstem.</article-title><source>Nat Neurosci</source><volume>4</volume><fpage>633</fpage><lpage>637</lpage><pub-id pub-id-type="pmid">11369945</pub-id></citation></ref><ref id="pcbi.1000301-Griffiths2"><label>34</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Griffiths</surname><given-names>TD</given-names></name><name><surname>Buchel</surname><given-names>C</given-names></name><name><surname>Frackowiak</surname><given-names>RSJ</given-names></name><name><surname>Patterson</surname><given-names>RD</given-names></name></person-group><year>1998</year><article-title>Analysis of temporal structure in sound by the brain.</article-title><source>Nat Neurosci</source><volume>1</volume><fpage>422</fpage><lpage>427</lpage><pub-id pub-id-type="pmid">10196534</pub-id></citation></ref><ref id="pcbi.1000301-Patterson1"><label>35</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Patterson</surname><given-names>RD</given-names></name><name><surname>Uppenkamp</surname><given-names>S</given-names></name><name><surname>Johnsrude</surname><given-names>S</given-names></name><name><surname>Griffiths</surname><given-names>TD</given-names></name></person-group><year>2002</year><article-title>The processing of temporal pitch and melody information in auditory cortex.</article-title><source>Neuron</source><volume>36</volume><fpage>767</fpage><lpage>776</lpage><pub-id pub-id-type="pmid">12441063</pub-id></citation></ref><ref id="pcbi.1000301-Gutschalk1"><label>36</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Gutschalk</surname><given-names>A</given-names></name><name><surname>Patterson</surname><given-names>RD</given-names></name><name><surname>Scherg</surname><given-names>M</given-names></name><name><surname>Uppenkamp</surname><given-names>S</given-names></name><name><surname>Rupp</surname><given-names>A</given-names></name></person-group><year>2007</year><article-title>The effect of temporal context on the sustained pitch response in human auditory cortex.</article-title><source>Cereb Cortex</source><volume>17</volume><fpage>552</fpage><lpage>561</lpage><pub-id pub-id-type="pmid">16603711</pub-id></citation></ref><ref id="pcbi.1000301-Krumbholz2"><label>37</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Krumbholz</surname><given-names>K</given-names></name><name><surname>Patterson</surname><given-names>RD</given-names></name><name><surname>Seither-Preisler</surname><given-names>A</given-names></name><name><surname>Lammertmann</surname><given-names>C</given-names></name><name><surname>Lutkenhoner</surname><given-names>B</given-names></name></person-group><year>2003</year><article-title>Neuromagnetic evidence for a pitch processing center in Heschl's gyrus.</article-title><source>Cereb Cortex</source><volume>13</volume><fpage>765</fpage><lpage>772</lpage><pub-id pub-id-type="pmid">12816892</pub-id></citation></ref><ref id="pcbi.1000301-Friston1"><label>38</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K</given-names></name></person-group><year>2003</year><article-title>Learning and inference in the brain.</article-title><source>Neural Netw</source><volume>16</volume><fpage>1325</fpage><lpage>1352</lpage><pub-id pub-id-type="pmid">14622888</pub-id></citation></ref><ref id="pcbi.1000301-Friston2"><label>39</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K</given-names></name></person-group><year>2005</year><article-title>A theory of cortical responses.</article-title><source>Philos Trans R Soc Lond B Biol Sci</source><volume>360</volume><fpage>815</fpage><lpage>836</lpage><pub-id pub-id-type="pmid">15937014</pub-id></citation></ref><ref id="pcbi.1000301-LopezPoveda1"><label>40</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Lopez-Poveda</surname><given-names>EA</given-names></name><name><surname>Meddis</surname><given-names>R</given-names></name></person-group><year>2001</year><article-title>A human nonlinear cochlear filter bank.</article-title><source>J Acoust Soc Am</source><volume>110</volume><fpage>3170</fpage><lpage>3118</lpage></citation></ref><ref id="pcbi.1000301-Sumner1"><label>41</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Sumner</surname><given-names>CJ</given-names></name><name><surname>O'Mard</surname><given-names>LP</given-names></name><name><surname>Lopez-Poveda</surname><given-names>EA</given-names></name><name><surname>Meddis</surname><given-names>R</given-names></name></person-group><year>2002</year><article-title>A revised model of the inner-hair cell and auditory nerve complex.</article-title><source>J Acoust Soc Am</source><volume>111</volume><fpage>2178</fpage><lpage>2189</lpage><pub-id pub-id-type="pmid">12051437</pub-id></citation></ref><ref id="pcbi.1000301-Dayan1"><label>42</label><citation citation-type="book"><person-group person-group-type="author"><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Abbot</surname><given-names>LF</given-names></name></person-group><year>2001</year><source>Theoretical Neuroscience</source><publisher-loc>Cambridge, Massachusetts</publisher-loc><publisher-name>MIT Press</publisher-name><fpage>231</fpage><lpage>239</lpage></citation></ref><ref id="pcbi.1000301-Meddis3"><label>43</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Meddis</surname><given-names>R</given-names></name><name><surname>O'Mard</surname><given-names>L</given-names></name></person-group><year>2006</year><article-title>Virtual pitch in a computational physiological model.</article-title><source>J Acoust Soc Am</source><volume>120</volume><fpage>3861</fpage><lpage>3868</lpage><pub-id pub-id-type="pmid">17225413</pub-id></citation></ref><ref id="pcbi.1000301-Fishbach1"><label>44</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Fishbach</surname><given-names>A</given-names></name><name><surname>Nelken</surname><given-names>I</given-names></name><name><surname>Yeshurun</surname><given-names>Y</given-names></name></person-group><year>2001</year><article-title>Auditory edge detection: a neural model for physiological and psychoacoustical responses to amplitude transients.</article-title><source>J Neurophysiol</source><volume>85</volume><fpage>2303</fpage><lpage>2323</lpage><pub-id pub-id-type="pmid">11387378</pub-id></citation></ref><ref id="pcbi.1000301-Fishbach2"><label>45</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Fishbach</surname><given-names>A</given-names></name><name><surname>Yeshurun</surname><given-names>Y</given-names></name><name><surname>Nelken</surname><given-names>I</given-names></name></person-group><year>2003</year><article-title>Neural model for physiological responses to frequency and amplitude transitions uncovers topographical order in the auditory cortex.</article-title><source>J Neurophysiol</source><volume>90</volume><fpage>3663</fpage><lpage>3678</lpage><pub-id pub-id-type="pmid">12944531</pub-id></citation></ref><ref id="pcbi.1000301-Winter1"><label>46</label><citation citation-type="book"><person-group person-group-type="author"><name><surname>Winter</surname><given-names>IM</given-names></name></person-group><year>2005</year><article-title>The neurophysiology of pitch.</article-title><person-group person-group-type="editor"><name><surname>Plack</surname><given-names>CJ</given-names></name><name><surname>Oxenham</surname><given-names>AJ</given-names></name><name><surname>Fay</surname><given-names>RR</given-names></name><name><surname>Popper</surname><given-names>AN</given-names></name></person-group><source>Pitch: Neural Coding and perception.</source><publisher-loc>New York</publisher-loc><publisher-name>Springer</publisher-name><fpage>99</fpage><lpage>146</lpage></citation></ref><ref id="pcbi.1000301-Winkler1"><label>47</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Winkler</surname><given-names>I</given-names></name><name><surname>Naatanen</surname><given-names>R</given-names></name></person-group><year>1997</year><article-title>Two separate codes for missing-fundamental pitch in the human auditory cortex.</article-title><source>J Acoust Soc Am</source><volume>102</volume><fpage>1072</fpage><lpage>1082</lpage><pub-id pub-id-type="pmid">9265755</pub-id></citation></ref><ref id="pcbi.1000301-Moore4"><label>48</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Moore</surname><given-names>BCJ</given-names></name><name><surname>Glasberg</surname><given-names>BR</given-names></name></person-group><year>1983</year><article-title>Suggested formulae for calculating auditory-filter bandwidths and excitation patterns.</article-title><source>J Acoust Soc Am</source><volume>74</volume><fpage>750</fpage><lpage>753</lpage><pub-id pub-id-type="pmid">6630731</pub-id></citation></ref><ref id="pcbi.1000301-Carlyon4"><label>49</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Carlyon</surname><given-names>RP</given-names></name><name><surname>Wieringen</surname><given-names>A</given-names></name><name><surname>Long</surname><given-names>CJ</given-names></name><name><surname>Deeks</surname><given-names>JM</given-names></name><name><surname>Wouters</surname><given-names>J</given-names></name></person-group><year>2002</year><article-title>Temporal pitch mechanisms in acoustic and electric hearing.</article-title><source>J Acoust Soc Am</source><volume>112</volume><fpage>621</fpage><lpage>633</lpage><pub-id pub-id-type="pmid">12186042</pub-id></citation></ref><ref id="pcbi.1000301-Carlyon5"><label>50</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Carlyon</surname><given-names>RP</given-names></name><name><surname>Mahendran</surname><given-names>S</given-names></name><name><surname>Deeks</surname><given-names>JM</given-names></name><name><surname>Long</surname><given-names>CJ</given-names></name><name><surname>Axon</surname><given-names>P</given-names></name><name><surname>Baguley</surname><given-names>D</given-names></name><name><surname>Bleeck</surname><given-names>S</given-names></name><name><surname>Winter</surname><given-names>IM</given-names></name></person-group><year>2008</year><article-title>Behavioural and physiological correlates of temporal pitch perception in electric and acoustic hearing.</article-title><source>J Acoust Soc Am</source><volume>123</volume><fpage>973</fpage><lpage>985</lpage><pub-id pub-id-type="pmid">18247900</pub-id></citation></ref><ref id="pcbi.1000301-Gerstner1"><label>51</label><citation citation-type="book"><person-group person-group-type="author"><name><surname>Gerstner</surname><given-names>W</given-names></name><name><surname>Kistler</surname><given-names>WM</given-names></name></person-group><year>2002</year><source>Spiking Neuron Models: Single Neurons, Populations, Plasticity</source><publisher-loc>New York</publisher-loc><publisher-name>Cambridge University Press</publisher-name><fpage>211</fpage><lpage>276</lpage></citation></ref><ref id="pcbi.1000301-vanRossum1"><label>52</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>van Rossum</surname><given-names>MCW</given-names></name><name><surname>van der Meer</surname><given-names>MAA</given-names></name><name><surname>Xiao</surname><given-names>D</given-names></name><name><surname>Oram</surname><given-names>MW</given-names></name></person-group><year>2008</year><article-title>Adaptative integration in the visual cortex by depressing recurrent cortical circuits.</article-title><source>Neural Comput</source><volume>20</volume><fpage>1847</fpage><lpage>1872</lpage><pub-id pub-id-type="pmid">18336081</pub-id></citation></ref><ref id="pcbi.1000301-Micheyl1"><label>53</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Micheyl</surname><given-names>C</given-names></name><name><surname>Carlyon</surname><given-names>RP</given-names></name></person-group><year>1998</year><article-title>Effects of temporal fringes on fundamental-frequency discrimination.</article-title><source>J Acoust Soc Am</source><volume>104</volume><fpage>3006</fpage><lpage>3018</lpage><pub-id pub-id-type="pmid">9821345</pub-id></citation></ref><ref id="pcbi.1000301-Gockel1"><label>54</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Gockel</surname><given-names>H</given-names></name><name><surname>Carlyon</surname><given-names>RP</given-names></name><name><surname>Micheyl</surname><given-names>C</given-names></name></person-group><year>1999</year><article-title>Context dependence of fundamental-frequency discrimination: lateralized temporal fringes.</article-title><source>J Acoust Soc Am</source><volume>106</volume><fpage>3553</fpage><lpage>3561</lpage><pub-id pub-id-type="pmid">10615695</pub-id></citation></ref><ref id="pcbi.1000301-Darwin1"><label>55</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Darwin</surname><given-names>CJ</given-names></name><name><surname>Ciocca</surname><given-names>V</given-names></name></person-group><year>1992</year><article-title>Grouping in pitch perception: effects of onset asynchrony and ear of presentation of a mistuned component.</article-title><source>J Acoust Soc Am</source><volume>91</volume><fpage>3381</fpage><lpage>3390</lpage><pub-id pub-id-type="pmid">1619115</pub-id></citation></ref><ref id="pcbi.1000301-Ciocca1"><label>56</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ciocca</surname><given-names>V</given-names></name><name><surname>Darwin</surname><given-names>CJ</given-names></name></person-group><year>1999</year><article-title>The integration of nonsimultaneous frequency components into a single virtual pitch.</article-title><source>J Acoust Soc Am</source><volume>105</volume><fpage>2421</fpage><lpage>2430</lpage><pub-id pub-id-type="pmid">10212423</pub-id></citation></ref><ref id="pcbi.1000301-Gockel2"><label>57</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Gockel</surname><given-names>H</given-names></name><name><surname>Plack</surname><given-names>CJ</given-names></name><name><surname>Carlyon</surname><given-names>RP</given-names></name></person-group><year>2005</year><article-title>Reduced contribution of a nonsimultaneous mistuned harmonic to residue pitch.</article-title><source>J Acoust Soc Am</source><volume>118</volume><fpage>3783</fpage><lpage>3793</lpage><pub-id pub-id-type="pmid">16419823</pub-id></citation></ref><ref id="pcbi.1000301-Yost1"><label>58</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Yost</surname><given-names>WA</given-names></name></person-group><year>1996</year><article-title>Pitch and pitch strength of iterated rippled noise: is it the envelope or fine structure?.</article-title><source>J Acoust Soc Am</source><volume>100</volume><fpage>2720</fpage><lpage>2730</lpage></citation></ref><ref id="pcbi.1000301-Levitt1"><label>59</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Levitt</surname><given-names>H</given-names></name></person-group><year>1971</year><article-title>Transformed up-down methods in psychoacoustics.</article-title><source>J Acoust Soc Am</source><volume>49</volume><fpage>467</fpage><lpage>477</lpage><pub-id pub-id-type="pmid">5541744</pub-id></citation></ref><ref id="pcbi.1000301-Kaernbach1"><label>60</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kaernbach</surname><given-names>C</given-names></name><name><surname>Demany</surname><given-names>L</given-names></name></person-group><year>1998</year><article-title>Psychophysical evidence against the autocorrelation theory of auditory temporal processing.</article-title><source>J Acoust Soc Am</source><volume>104</volume><fpage>2298</fpage><lpage>2306</lpage><pub-id pub-id-type="pmid">10491694</pub-id></citation></ref><ref id="pcbi.1000301-Kaernbach2"><label>61</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kaernbach</surname><given-names>C</given-names></name><name><surname>Bering</surname><given-names>C</given-names></name></person-group><year>2001</year><article-title>Exploring the temporal mechanisms involved in the pitch of unresolved harmonics.</article-title><source>J Acoust Soc Am</source><volume>110</volume><fpage>1039</fpage><lpage>1048</lpage><pub-id pub-id-type="pmid">11519572</pub-id></citation></ref><ref id="pcbi.1000301-Pressnitzer1"><label>62</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Pressnitzer</surname><given-names>D</given-names></name><name><surname>de Cheveign&#x000e9;</surname><given-names>A</given-names></name><name><surname>Winter</surname><given-names>IM</given-names></name></person-group><year>2002</year><article-title>Perceptual pitch shift for sounds with similar waveform autocorrelation.</article-title><source>Acoust Res Lett Online</source><volume>3</volume><fpage>1</fpage><lpage>6</lpage></citation></ref><ref id="pcbi.1000301-Pressnitzer2"><label>63</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Pressnitzer</surname><given-names>D</given-names></name><name><surname>de Cheveign&#x000e9;</surname><given-names>A</given-names></name><name><surname>Winter</surname><given-names>IM</given-names></name></person-group><year>2004</year><article-title>Physiological correlates of the perceptual pitch shift for sounds with similar waveform autocorrelation.</article-title><source>Acoust Res Lett Online</source><volume>5</volume><fpage>1</fpage><lpage>6</lpage></citation></ref><ref id="pcbi.1000301-Coath1"><label>64</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Coath</surname><given-names>M</given-names></name><name><surname>Brader</surname><given-names>JM</given-names></name><name><surname>Fusi</surname><given-names>S</given-names></name><name><surname>Denham</surname><given-names>SL</given-names></name></person-group><year>2005</year><article-title>Multiple views of the response of an ensemble of spectro-temporal features support concurrence classification of utterance, prosody, sex and speaker identity.</article-title><source>Network</source><volume>16</volume><fpage>285</fpage><lpage>300</lpage><pub-id pub-id-type="pmid">16411500</pub-id></citation></ref><ref id="pcbi.1000301-Amari1"><label>65</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Amari</surname><given-names>S</given-names></name></person-group><year>1997</year><article-title>Dynamics of pattern formation in lateral-inhibition type neural fields.</article-title><source>Biol Cybern</source><volume>27</volume><fpage>77</fpage><lpage>87</lpage><pub-id pub-id-type="pmid">911931</pub-id></citation></ref><ref id="pcbi.1000301-vonKriegstein1"><label>66</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>von Kriegstein</surname><given-names>K</given-names></name><name><surname>Patterson</surname><given-names>RD</given-names></name><name><surname>Griffiths</surname><given-names>TD</given-names></name></person-group><year>2008</year><article-title>Task-dependent modulation of medial geniculate body is behaviourally relevant for speech recognition.</article-title><source>Curr Biol</source><volume>18</volume><fpage>1855</fpage><lpage>1859</lpage><pub-id pub-id-type="pmid">19062286</pub-id></citation></ref><ref id="pcbi.1000301-Guinan1"><label>67</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Guinan</surname><given-names>JJ</given-names><suffix>Jr</suffix></name></person-group><year>2006</year><article-title>Olivocochlear efferents: anatomy, physiology, function, and the measurement of efferent effects in humans.</article-title><source>Ear Hear</source><volume>27</volume><fpage>589</fpage><lpage>607</lpage><pub-id pub-id-type="pmid">17086072</pub-id></citation></ref><ref id="pcbi.1000301-Kadner1"><label>68</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kadner</surname><given-names>A</given-names></name><name><surname>Berrebi</surname><given-names>S</given-names></name></person-group><year>2008</year><article-title>Encoding of the temporal features of auditory stimuli in the medial nucleous of the trapezoid body and superior paraolivary nucleous of the rat.</article-title><source>Neuroscience</source><volume>151</volume><fpage>868</fpage><lpage>887</lpage><pub-id pub-id-type="pmid">18155850</pub-id></citation></ref><ref id="pcbi.1000301-Friston3"><label>69</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>HJ</given-names></name><name><surname>Stephan</surname><given-names>KE</given-names></name></person-group><year>2007</year><article-title>Free-energy and the brain.</article-title><source>Synthese</source><volume>159</volume><fpage>417</fpage><lpage>458</lpage></citation></ref><ref id="pcbi.1000301-Kiebel1"><label>70</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kiebel</surname><given-names>SJ</given-names></name><name><surname>Daunizeau</surname><given-names>J</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name></person-group><year>2008</year><article-title>A hierarchy of time-scales and the brain.</article-title><source>PLoS Comput Biol</source><volume>4</volume><fpage>e1000209</fpage><comment>doi:10.1371/journal.pcbi.1000209</comment><pub-id pub-id-type="pmid">19008936</pub-id></citation></ref><ref id="pcbi.1000301-Palmer1"><label>71</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Palmer</surname><given-names>AR</given-names></name><name><surname>Hall</surname><given-names>DA</given-names></name><name><surname>Sumner</surname><given-names>C</given-names></name><name><surname>Barrett</surname><given-names>DJK</given-names></name><name><surname>Jones</surname><given-names>S</given-names></name><etal/></person-group><year>2007</year><article-title>Some investigations into non-passive listening.</article-title><source>Hear Res</source><volume>229</volume><fpage>148</fpage><lpage>157</lpage><pub-id pub-id-type="pmid">17275232</pub-id></citation></ref></ref-list><fn-group><fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn><fn fn-type="financial-disclosure"><p>This work was supported by EmCAP (Emergent Cognition through Active Perception, 2005&#x02013;2008), a research project in the field of Music Cognition funded by the European Commission (FP6-IST, contract 013123), and EPSRC grant EP/C010841/1 (COLAMN). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</p></fn></fn-group></back></article>