<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN" "archivearticle.dtd"><article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article" xml:lang="EN"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Cereb Cortex</journal-id><journal-id journal-id-type="hwp">cercor</journal-id><journal-id journal-id-type="publisher-id">cercor</journal-id><journal-title>Cerebral Cortex (New York, NY)</journal-title><issn pub-type="ppub">1047-3211</issn><issn pub-type="epub">1460-2199</issn><publisher><publisher-name>Oxford University Press</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">18448453</article-id><article-id pub-id-type="pmc">2638742</article-id><article-id pub-id-type="doi">10.1093/cercor/bhn062</article-id><article-categories><subj-group subj-group-type="heading"><subject>Articles</subject></subj-group></article-categories><title-group><article-title>Enhanced Processing of Threat Stimuli under Limited Attentional Resources</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>De Martino</surname><given-names>Benedetto</given-names></name><xref ref-type="aff" rid="aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Kalisch</surname><given-names>Raffael</given-names></name><xref ref-type="aff" rid="aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Rees</surname><given-names>Geraint</given-names></name><xref ref-type="aff" rid="aff3">3</xref></contrib><contrib contrib-type="author"><name><surname>Dolan</surname><given-names>Raymond J.</given-names></name><xref ref-type="aff" rid="aff1">1</xref></contrib></contrib-group><aff id="aff1"><label>1</label>Wellcome Trust Centre for Neuroimaging UCL, WC1N3BG London, UK</aff><aff id="aff2"><label>2</label>Institut f&#x000fc;r Systemische Neurowissenschaften, Universit&#x000e4;tsklinikum 20246 Hamburg-Eppendorf, Germany</aff><aff id="aff3"><label>3</label>Institute of Cognitive Neuroscience UCL, WC1 3AR London, UK</aff><author-notes><corresp>Address correspondence to Wellcome Trust Centre for Neuroimaging, 12 Queen Square, WaC 1N 3BG London, UK. Email: <email>b.martino@fil.ion.ucl.ac.uk</email>.</corresp></author-notes><!--Fake ppub date generated  by PMC from publisher pub-date/@pub-type='epub-ppub' --><pub-date pub-type="ppub"><month>1</month><year>2009</year></pub-date><pub-date pub-type="epub"><day>29</day><month>4</month><year>2008</year></pub-date><pub-date pub-type="pmc-release"><day>29</day><month>4</month><year>2008</year></pub-date><volume>19</volume><issue>1</issue><fpage>127</fpage><lpage>133</lpage><permissions><copyright-statement>&#x000a9; 2008 The Authors</copyright-statement><copyright-year>2009</copyright-year><license license-type="open-access"><p><!--CREATIVE COMMONS-->This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/2.0/uk/">http://creativecommons.org/licenses/by-nc/2.0/uk/</ext-link>) which permits unrestricted non-commercial use, distribution, and reproduction in any medium, provided the original work is properly cited.</p></license></permissions><abstract><p>The ability to process stimuli that convey potential threat, under conditions of limited attentional resources, confers adaptive advantages. This study examined the neurobiology underpinnings of this capacity. Employing an attentional blink paradigm, in conjunction with functional magnetic resonance imaging, we manipulated the salience of the second of 2 face target stimuli (T2), by varying emotionality. Behaviorally, fearful T2 faces were identified significantly more than neutral faces. Activity in fusiform face area increased with correct identification of T2 faces. Enhanced activity in rostral anterior cingulate cortex (rACC) accounted for the benefit in detection of fearful stimuli reflected in a significant interaction between target valence and correct identification. Thus, under conditions of limited attention resources activation in rACC correlated with enhanced processing of emotional stimuli. We suggest that these data support a model in which a prefrontal &#x0201c;gate&#x0201d; mechanism controls conscious access of emotional information under conditions of limited attentional resources.</p></abstract><kwd-group><kwd>attention</kwd><kwd>attentional blink</kwd><kwd>emotion</kwd><kwd>fMRI</kwd><kwd>fusiform face area</kwd><kwd>rACC</kwd></kwd-group></article-meta></front><body><sec sec-type="intro"><title>Introduction</title><p>Humans share with other animals a striking ability to detect a threatening stimulus. This capacity confers an adaptive advantage allowing organisms to commit attentional resources during goal-directed behavior, whilst retaining an ability to quickly respond to potential harm. Several researchers have proposed that the emotional significance of stimuli is evaluated preattentively (<xref ref-type="bibr" rid="bib9">Dolan 2002</xref>; <xref ref-type="bibr" rid="bib41">Vuilleumier 2005</xref>; <xref ref-type="bibr" rid="bib31">Palermo and Rhodes 2007</xref>; <xref ref-type="bibr" rid="bib43">Vuilleumier and Pourtois 2007</xref>). The central idea here is that stimuli tagged with emotional significance are prioritized for access to selective attentional mechanisms that operate within a limited-capacity system.</p><p>There is compelling behavioral data (<xref ref-type="bibr" rid="bib1">Anderson and Phelps 2001</xref>) demonstrating an emotional modulation of attention using an attentional blink (AB) paradigm, which involves rapid serial presentation of visual stimuli (RVSP). A common finding in this paradigm is increased difficulty detecting a second target if it follows closely in time a first target (<xref ref-type="bibr" rid="bib33">Raymond et al. 1992</xref>). The aforementioned study showed that normal subjects were more likely to detect a second target if it was emotional, whereas patients with amygdala lesions do not show this effect (<xref ref-type="bibr" rid="bib1">Anderson and Phelps 2001</xref>). Clinical neuropsychological studies on patients with unilateral neglect, who typically have right-hemispheric damage, and who fail to attend to stimuli in the left half of space, have reported a dramatic reduction in this behavioral deficit when presented with a left hemifield stimulus that is emotionally salient (<xref ref-type="bibr" rid="bib44">Vuilleumier and Schwartz 2001a</xref>, <xref ref-type="bibr" rid="bib45">2001b</xref>). Finally, anxious individuals are more likely than controls to display attentional biases toward threatening stimuli (<xref ref-type="bibr" rid="bib3">Bishop, Duncan, Brett, et al. 2004</xref>; <xref ref-type="bibr" rid="bib4">Bishop, Duncan, Lawrence 2004</xref>).</p><p>In principle, the emotional significance of a stimulus can influence attentional processing through 2 distinct mechanisms: either by boosting activity in cortical regions that code for the stimulus itself, or via influences from other cortical areas that impose priorities on attentional processing. In support of the first mechanism, numerous studies have found increased activity in cortical visual processing areas when participants view emotionally provocative images, compared with when they view neutral images (<xref ref-type="bibr" rid="bib25">Lane, Reiman, et al. 1997</xref>; <xref ref-type="bibr" rid="bib26">Lang et al. 1998</xref>; <xref ref-type="bibr" rid="bib32">Paradiso et al. 1999</xref>; <xref ref-type="bibr" rid="bib44">Vuilleumier and Schwartz 2001a</xref>, <xref ref-type="bibr" rid="bib45">2001b</xref>). Likewise, activity in the fusiform face area (FFA) shows an increase when participants view emotionally expressive compared with neutral faces (<xref ref-type="bibr" rid="bib5">Breiter et al. 1996</xref>; <xref ref-type="bibr" rid="bib42">Vuilleumier et al. 2001</xref>). Other studies have found increased fusiform activity in response to fear-conditioned faces (<xref ref-type="bibr" rid="bib29">Morris et al. 2001</xref>; <xref ref-type="bibr" rid="bib2">Armony and Dolan 2002</xref>).</p><p>Nevertheless emotional information processing may benefit from a control mechanism that acts as a &#x0201c;gate&#x0201d; in modulating allocation of attentional resources. In the case of control on access to emotional processing, potential influences are likely to involve prefrontal cortex, in particular the ventromedial regions and rostral cingulate cortex. These areas show close reciprocal connections with subcortical limbic regions such as the amygdala and ventral striatum (<xref ref-type="bibr" rid="bib15">Groenewegen and Uylings 2000</xref>; <xref ref-type="bibr" rid="bib47">Wise 2004</xref>), regions strongly implicated in early stages of processing emotional material. For example, focusing attention on the spatial location of an emotionally relevant stimulus is associated with increased activity in bilateral VMPFC (<xref ref-type="bibr" rid="bib2">Armony and Dolan 2002</xref>). One interpretation of the latter finding is that VMPFC is associated with directing spatial attention toward emotionally significant targets. Several other studies have found increased activity in the rostral anterior cingulate cortex (rACC) during selective attention to emotional information (Lane, Fink, et al. 1997; <xref ref-type="bibr" rid="bib10">Elliott et al. 2000</xref>). In addition, rACC activity increases when participants are required to ignore emotional information, compared with when they have to ignore neutral information (<xref ref-type="bibr" rid="bib46">Whalen et al. 1998</xref>). In the present study, we employed functional magnetic resonance imaging (fMRI) in conjunction with an AB paradigm, to investigate how these 2 distinct mechanisms control increased detection of threatening targets under conditions of limited attentional resources.</p></sec><sec sec-type="methods"><title>Methods</title><sec><title>Experimental Design</title><p>In an AB task subjects searched for 2 targets within an RSVP of 15 distracter items. Each stimulus was presented centrally for 70 ms with no interstimulus interval. The first stimulus (T1) comprised a scene (either indoor or outdoor) and the second target (T2) comprised a face (either neutral or fearful. The distracter items were scrambled images of the scene and face together, with each gray scale stimulus subtending 8.5&#x000b0; &#x000d7; 8.5&#x000b0;. All face stimuli were selected from the KDEF database (D. Lundqvist and J.-E. Litton, personal communication; photographic face set available from the Department of Neurosciences, Karolinska Hospital, Stockholm, Sweden). The scrambled images originated from a pool of scene and face images (mixed in 50% proportion) and were created by dividing each quadrant of images into 25 squares randomly scrambling their position. Thin black grids were drawn over the scrambled and intact images to occlude the boundaries of blocks.</p><p>A trial began with presentation of a fixation cross for a variable time between (2000&#x02013;4000 ms) before the onset of the RSVP, which consisted of 15 images each displayed on a screen for 70 ms. All images were scrambled pictures of scenes and faces (distracters) but 2 of the distracters were replaced by 2 intact target images: a T1 scene and a T2 face. At the end of RVSP, subjects reported the identity of both targets by a key press in 2 response period of 4000 ms each. During the T1 response period a display was shown with 3 options: NoScene, Indoor or Outdoor. Subjects indicated by a key press whether no scene, an outdoor scene or an indoor scene was presented. For the T2 response subjects were shown the face that had been presented during the current trial together with 2 other faces of the same gender (male or female) and expression (neutral or fearful) and were asked to indicate by a key press the face shown at T2. A scene target (T1) and face target (T2) was presented in every trial. T1 was presented randomly between the second to seventh position during the RVSP, where T2 was always presented after 5 distractors (350 ms) from T1. A total of 144 trials were presented in 3 sessions of 48 trials each.</p></sec><sec><title>fMRI Scanning Parameters</title><p>We acquired gradient-echo <italic>T</italic><sub>2</sub>*-weighted images (echo planar imaging [EPI]) on a 1.5 Tesla magnetic resonance scanner using a 30&#x000b0; titled acquisition sequence designed to reduce signal dropout in orbitofrontal cortices. Image parameters were as follows: TE 50 ms; TR 3.96 s; slice thickness 2 mm; interslice gap 1 mm. We collected 810 volumes (across 3 sessions) per subject. <italic>T</italic><sub>1</sub>-weighted structural images coregistered with mean EPI images and averaged across subjects to allow group level anatomical localization. Images were analyzed using the statistical parametric software SMP2 (Wellcome Department of Imaging Neuroscience London <ext-link ext-link-type="uri" xlink:href="http://www.fil.ion.ucl.ac.uk/spm">http://www.fil.ion.ucl.ac.uk/spm</ext-link>). Preprocessing consisted of spatial realignment and normalization to a standard EPI template, and spatial smoothing (8-mm kernel).</p></sec><sec><title>Behavioral Data Analysis</title><p>Following the standard procedure, used in AB data analysis, trials in which subjects reported that a T1 scene was not present (missed T1) were discarded. The experiment constituted a 2 &#x000d7; 2 factorial design with the first factor representing the task condition (emotional T2 and neutral T2) and the second representing the behavioral performance of each subject on a trial by trial basis (during the AB task in the scanner correctly reported T2 (Correct-T2) and incorrectly reported T2 (Incorrect-T2).</p><p>Because Correct-T2 includes 33% of correct responses purely by chance (forced response between 3 faces), the number of trials allocated to Correct-T2 on a chance base meant that reaction time (RT) was taken as index of confidence. This was based on the evidence that subjects showed a significant reduction in RT in Correct-T2 compared with Incorrect-T2. The normal RT's distributions for the 2 conditions (Correct-T2 and Incorrect-T2) overlapped for half of the areas (see <xref ref-type="fig" rid="fig1">Fig. 1<italic>b</italic></xref>). We used a median split to divide the Correct-T2 into confident (fastest response) and unconfident correct hits (<xref ref-type="bibr" rid="bib39">Strange and Dolan, 2004</xref>). Only the confident Correct-T2 was included in the fMRI data analysis. A few trials in which the subjects did not press any key at T2 response period were also included in the IT2.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><p>Task. Subjects were asked to search for 2 targets (T1 and T2) embedded in between 13 distractors items at fixation for 70 ms each with no interstimulus interval. The first stimulus (T1) was a scene (either indoor or outdoor) and the second target (T2) was a face (either neutral or fearful). The distractors were scrambled images of the scene and face together. The 2 targets were always separated by 5 distractors (350 ms). At the end of the rapid visual stimuli presentation (RVSP) subjects were asked to report by a key press whether no scene, an outdoor scene or an indoor scene was presented (T1 response 4 s). Subsequently, they were asked to identify the identity of the face T2 by key press in a forced choice between 3 faces: one of these was the one presented in the trial (T2 response 4 s). Note that the red frame is shown here only for the purpose of display and was not part of the original stimuli.</p></caption><graphic xlink:href="cercorbhn062f01_4c"/></fig></sec><sec><title>Imaging Data Analysis</title><p>We analyzed the fMRI data in an event-related design using the general linear model (GLM) within SPM2 (<ext-link ext-link-type="uri" xlink:href="http://www.fil.ion.ucl.ac.uk/spm">http://www.fil.ion.ucl.ac.uk/spm</ext-link>). After discarding the first 6 image volumes from each run to allow for <italic>T</italic><sub>1</sub> equilibration effects, image volumes were realigned and coregistered to each subject's structural scan. Subject-specific regressors of interest were assembled by convolving &#x003b4; functions (corresponding to the time of onset of the beginning of the RVSP) with a canonical hemodynamic response function. We removed low frequency fluctuations by a high-pass filter with a cut-off at 128 s. A correction for temporal autocorrelation in the data (AR 1 + white noise) was applied. Four regressors of interest were built according to the trial type and the subjects&#x02019; responses and were include in the GLM. The onset was locked to the beginning of the RVSP. Two nuisance regressors (T1 incorrect trials and T2 response period) were included in the GLM. Parameter estimates were used to calculate the appropriate linear contrast. These contrast images were then entered into a 1-sample <italic>t</italic>-test across all subjects (random effects analysis). The resulting <italic>Z</italic> statistic images were thresholded at <italic>Z</italic> &#x0003e; 3.1, corresponding to <italic>P</italic> &#x0003c; 0.001 uncorrected. We report results in a priori regions of interest (ROI) (FFA, amygdala, striatum, ACC) previously identified in neuroimaging studies on emotional regulation of attention (<xref ref-type="bibr" rid="bib35">Salamone 1994</xref>; <xref ref-type="bibr" rid="bib23">Lane, Fink, et al. 1997</xref>; <xref ref-type="bibr" rid="bib6">Bush et al. 2000</xref>; Bishop, Duncan, Lawrence 2004; <xref ref-type="bibr" rid="bib37">Seymour et al. 2005</xref>; <xref ref-type="bibr" rid="bib43">Vuilleumier and Pourtois 2007</xref>) at <italic>P</italic> &#x0003c; 0.001 uncorrected for multiple comparisons. We also performed a small volume correction (SVC) using a sphere of 10 mm radius centered on coordinates of a priori ROI (rACC: [<italic>x</italic> = &#x02212;38, <italic>y</italic> = &#x02212;50, <italic>z</italic> = &#x02212;22], <xref ref-type="bibr" rid="bib6">Bush et al. 2000</xref>; and ventral striatum: [<italic>x</italic> = &#x000b1;22, <italic>y</italic> = 10, <italic>z</italic> = &#x02212;10], <xref ref-type="bibr" rid="bib37">Seymour et al. 2005</xref>). The SVC procedure, as implemented in SPM2 using the family-wise error (FWE) correction (<italic>P</italic> &#x0003c; 0.05), allows results to be corrected for multiple nonindependent comparisons with a defined region of interest (ROI). Activations in other regions are only reported and discussed if they survive whole-brain correction for multiple comparisons at <italic>P</italic> &#x0003c; 0.05 (FWE).</p><p>We performed a ROI analysis in the bilateral FFA using the MarsBaR SPM toolbox: (<ext-link ext-link-type="uri" xlink:href="http://marsbar.sourceforge.net/">http://marsbar.sourceforge.net/</ext-link>). The ROIs for the FFA area were defined by the SPM cluster (<italic>P</italic> &#x0003c; 0.05 whole-brain corrected for multiple comparisons) contrasting the activity during the entire task contrasted against the baseline. Definition of this ROI is thus orthogonal and unbiased with respect to all our contrasts of interests. Using the MarsBaR SPM toolbox, we obtained parameter estimates for all voxels within this region, for the group as a whole. These parameter estimates were averaged across the ROI, and specific effects tested using planned 1-sample <italic>t</italic>-tests.</p></sec></sec><sec sec-type="results"><title>Results</title><p>We recruited fifteen healthy subjects who underwent functional magnetic resonance imaging (fMRI) while performing a modified AB task (<xref ref-type="bibr" rid="bib1">Anderson and Phelps 2001</xref>; <xref ref-type="bibr" rid="bib33">Raymond et al. 1992</xref>). We presented subjects with 15 images each displayed on a screen for 70 ms. All images were scrambled picture of scenes and faces (distractors) but 2 of the distractors were replaced by 2 intact target images (<xref ref-type="bibr" rid="bib28">Marois et al. 2004</xref>). The participants&#x02019; task was to identify both targets identity at the end of each trial. The first target (T1) was always a scene (either indoor or outdoor) followed, after 5 intervening distractors (350-ms lag), by another target (T2) which was always a face (either neutral or fearful). This experimental design allowed us to identify the neurobiological underpinnings supporting an increased capacity to process emotional stimuli, under conditions of high attentional load</p><p>Our experimental paradigm elicited a robust AB effect. For the entire scanning period participants were able to detect the T1 scene on 91.7% of the trials. After correct T1 detection subjects could correctly report the T2 face stimuli significantly more often when the face was fearful (Fearful-T2) compared with when it was neutral (Neutral-T2) 58.8% versus 46.8% (<italic>t</italic> (14) = 5.2, <italic>P</italic> &#x0003c; 0.001 2-tailed paired <italic>t</italic>-test) (<xref ref-type="fig" rid="fig2">Fig. 2<italic>a</italic></xref>).</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><p>Behavioral results. (<italic>a</italic>) Behavioral results (main). The graph shows the <italic>&#x000d7;</italic> percentage (%) increase of trials in which the subject correctly reported the T2 face identity (Correct-T2) for a T2 fearful face condition (Fearful-T2 58.8%; SE 1.85) respect to a T2 neutral face condition (Neutral-T2 46.8%; SE 1.95) (Fearful-T2 vs. Neutral-T2 [<italic>t</italic>(14) = 5.2, <italic>P</italic> &#x0003c; 0.001 2-tailed paired <italic>t</italic>-test]). In both the T2 detection was significantly above chance level of 33% (forced choice between tree faces) represented in the graph with a dashed line (neutral-T2: <italic>t</italic>(14) = 7.05, <italic>P</italic> &#x0003c; 0.001, Fearful-T2: <italic>t</italic>(14) = 13.9, <italic>P</italic> &#x0003c; 0.001 2 tailed 1-sample <italic>t</italic>-test). (<italic>b</italic>) Behavioral results (RT). The histograms represent the RT distributions for number of trials. In black is shown the condition in which the T2 face was correctly reported (Correct-T2) and in brown the condition in which the T2 face was incorrectly reported (Incorrect-T2). The 2 distributions partially overlap with the RT mean value significantly shorter in the Correct-T2 versus the Incorrect-T2 (<italic>F</italic><sub>1,14</sub> = 22.6, <italic>P</italic> &#x0003c; 0.001). The dashed line represent the median split for the Correct-T2 condition (see experimental procedure).</p></caption><graphic xlink:href="cercorbhn062f02_ht"/></fig><p>The 2 &#x000d7; 2 fully factorial design employed in our experiment allowed us to study how the emotional valence of the T2 face, that was either fearful or neutral (Fearful-T2 vs. Neutral-T2), impacted upon correct or incorrect T2 face detection (Correct-T2 vs. Incorrect-T2). RTs for T2 targets were analyzed by repeated measures ANOVA. We detected a shortening in RTs for correct T2 (mean value 2.76 &#x000b1; 0.20 s) relative to incorrect T2 detection (mean value 2.95 &#x000b1; 0.28 s), a reduction that was statistically significant (<italic>F</italic><sub>1,14</sub> = 22.6, <italic>P</italic> &#x0003c; 0.001) (<xref ref-type="fig" rid="fig2">Fig. 2<italic>b</italic></xref>). By contrast the emotional valence of the T2 face stimulus (fearful vs. neutral) did not produce significant changes in RTs (<italic>F</italic><sub>1,14</sub> = 2.8, <italic>P</italic> = 0.11).</p><p>Our experimental design included a forced choice decision task for 3 faces at the time of T2 response. Accordingly, one third of trials, classified as Correct-T2, can be attributable to chance alone. In order to address this issue, we used a median split based on RTs in the fMRI analysis as measure of confidence for correct T2 identification. This procedure was motivated by evidence that subjects showed a significant reduction RTs for Correct-T2 compared with Incorrect-T2 detection and that the normal RTs distribution for the 2 conditions (Correct-T2 and Incorrect-T2) overlapped for half of the areas (see <xref ref-type="fig" rid="fig1">Fig. 1<italic>b</italic></xref> and Methods section). Such a procedure has been previously used (<xref ref-type="bibr" rid="bib39">Strange and Dolan 2004</xref>) to deal with similar confounds in event-related fMRI design, where the accurate trials categorization is critical to achieve a robust estimation of the GLM.</p><p>For the imaging data we first contrasted BOLD activity during the period in which subjects were engaged in the task versus the resting period, a contrast that enabled us to identify stimulus responsive regions. This contrast revealed significant activation within both right and left fusiform face regions (FFA) (R-FFA ([<italic>x</italic> = 30, <italic>y</italic> = &#x02212;48, <italic>z</italic> = &#x02212;24] <italic>Z</italic> = 5.88, 25-voxels) and L-FFA ([<italic>x</italic> = &#x02212;38, <italic>y</italic> = &#x02212;50, <italic>z</italic> = &#x02212;22] <italic>Z</italic> = 5.28, 97-voxels) <italic>P</italic> &#x0003c; 0.05 whole-brain corrected for multiple comparisons [FWE]). The location of these 2 clusters of activity is consistent in location with FFA activity previously reported (<xref ref-type="bibr" rid="bib20">Kanwisher et al. 1997</xref>, <xref ref-type="bibr" rid="bib21">1999</xref>) (<xref ref-type="fig" rid="fig3">Fig. 3<italic>a</italic></xref>). These clusters were then used to define ROIs in which we performed a statistical analysis between the different conditions during the AB task.</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><p>FFA. (<italic>a</italic>) Coronal section of SPMs showing both FFA contrasting activity during the entire task against the baseline (R-FFA ([<italic>x</italic> = 30, <italic>y</italic> = &#x02212;48, <italic>z</italic> = &#x02212;24] <italic>Z</italic> = 5.88, 25-voxels L-FFA ([<italic>x</italic> = &#x02212;38, <italic>y</italic> = &#x02212;50, <italic>z</italic> = &#x02212;22] <italic>Z</italic> = 5.28, 97-voxels <italic>P</italic> &#x0003c; 0.05 whole-brain corrected for multiple comparison FWE). Both clusters were used to identify respective ROIs used in a ROIs analysis that revealed a significant increased activation in the Correct-T2 versus Incorrect-T2 (R-FFA <italic>Z</italic> = 3.27 <italic>P</italic> &#x0003c; 0.05, L-FFA <italic>Z</italic> = 5.32, <italic>P</italic> &#x0003c; 0.05). L-FFA showed a nonsignificant trend for Fearful-T2 versus Neutral-T2 (<italic>Z</italic> = 2.01, <italic>P</italic> = 0.11) with a significant simple effect in the Incorrect-T2 condition Fearful-T2_Incorrect-T2 versus Neutral-T2_Incorrect-T2 (<italic>Z</italic> = 2.56, <italic>P</italic> &#x0003c; 0.05). (<italic>b</italic>) Plot of signal percentage changes for the L-FFA cluster.</p></caption><graphic xlink:href="cercorbhn062f03_4c"/></fig><p>Activity in both FFAs significantly predicted subjects&#x02019; ability to report correct face identity in the response period (R-FFA <italic>Z</italic> = 3.27, <italic>P</italic> &#x0003c; 0.05, L-FFA <italic>Z</italic> = 5.32, <italic>P</italic> &#x0003c; 0.05) (<xref ref-type="fig" rid="fig3">Fig. 3<italic>b</italic></xref>). Neither the left or right FFA showed increased activity for fearful face T2 compared with neutral (Fearful-T2 vs. Neutral-T2), although we observed trend level effect in the L-FFA (<italic>Z</italic> = 2.01, <italic>P</italic> = 0.11). Nevertheless, in trials where the T2 were incorrectly reported L-FFA showed a significant increase in activity (<italic>Z</italic> = 2.56, <italic>P</italic> &#x0003c; 0.05) for fearful T2, targets versus neutral T2 (Fearful-T2_Incorrect-T2 vs. Neutral-T2_Incorrect-T2). No significant interaction between valence of the target T2 (Fearful-T2 vs. Neutral-T2) and increased performance in T2 detection was observed suggesting that the FFA activity cannot fully account for the behavioral increase in T2 fearful face detection.</p><p>Using a voxel based analysis we then identified regions showing an increase in activity for fearful T2 faces versus neutral T2 faces (Fearful-T2 vs. Neutral-T2). Bilateral ventral striatum showed a significant increase in BOLD activity: R-striatum ([<italic>x</italic> = 20, <italic>y</italic> = 16, <italic>z</italic> = 0] <italic>Z</italic> = 4.08, 68-voxels, <italic>P</italic> &#x0003c; 0.001 uncorrected and <italic>P</italic> &#x0003c; 0.05 SVC), L-striatum ([<italic>x</italic> = &#x02212;26, <italic>y</italic> = 14, <italic>z</italic> = &#x02212;4) <italic>Z</italic> = 3.63, 8-voxels, <italic>P</italic> &#x0003c; 0.001 uncorrected and <italic>P</italic> &#x0003c; 0.05 SVC). Both simple contrasts: Fearful-T2_Correct-T2 versus Neutral-T2_Correct-T2 and Fearful-T2_Incorrect-T2 versus Neutral-T2_Incorrect-T2 also showed statistically significant striatal activation (<xref ref-type="fig" rid="fig4">Fig. 4</xref>).</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><p>Striatum. (<italic>a</italic>) SPM showing response in both ventral striatum nuclei for the Fearful-T2 versus Neutral-T2 statistical contrast R-striatum ([<italic>x</italic> = 20, <italic>y</italic> = 16, <italic>z</italic> = 0] <italic>Z</italic> = 4.08, 68-voxels, <italic>P</italic> &#x0003c; 0.001 uncorrected), L-striatum ([<italic>x</italic> = &#x02212;26, <italic>y</italic> = 14, <italic>z</italic> = &#x02212;4) <italic>Z</italic> = 3.63, 8-voxels, <italic>P</italic> &#x0003c; 0.001 uncorrected and <italic>P</italic> &#x0003c; 0.05 SVC). (<italic>b</italic>) Plot of signal percentage changes for the both ventral striatum nuclei clusters.</p></caption><graphic xlink:href="cercorbhn062f04_4c"/></fig><p>The fully factorial design of our experiment allowed us to examine how the emotional valence of T2 (Fearful-T2 vs. Neutral-T2) (<xref ref-type="table" rid="tbl2">Table 2</xref>) modulated accuracy in T2 detection (Correct-T2 vs. Incorrect-T2) (<xref ref-type="table" rid="tbl3">Table 3</xref>), the principal experimental goal of the study. The most direct way to determine at a neural level an effect of T2 valence on T2 response accuracy is to identify brain areas showing a significant interaction between the 2 factors across all trial conditions ([Fearful-T2_Correct-T2 &#x02212; Fearful-T2_Incorrect-T2] &#x0003e; [Neutral-T2_Correct-T2 &#x02212; Neutral-T2_Incorrect-T2]) (<xref ref-type="table" rid="tbl1">Table 1</xref>). This interaction contrast identifies brain areas specifically activated when emotional T2 stimuli are correctly reported, rather than responding to the valence of T2 stimuli alone. The rACC showed significantly enhanced activity within this interaction ([<italic>x</italic> = 14, <italic>y</italic> = 40, <italic>z</italic> = 22] <italic>Z</italic> = 3.59, 25-voxels <italic>P</italic> &#x0003c; 0.001 uncorrected and <italic>P</italic> &#x0003c; 0.05 SVC) (see <xref ref-type="fig" rid="fig5">Fig. 5</xref>). rACC was significantly more active when subjects correctly reported the T2 identity in the fearful face condition as showed by the simple effect (Fearful-T2_Correct-T2 vs. Fearful-T2_Incorrect-T2) ([<italic>x</italic> = 10, <italic>y</italic> = 38, <italic>z</italic> = 18] <italic>Z</italic> = 4.25, 32-voxels <italic>P</italic> &#x0003c; 0.001 uncorrected and <italic>P</italic> &#x0003c; 0.05 SVC).</p><table-wrap id="tbl1" position="float"><label>Table 1</label><caption><p>Brain areas significantly more active during interaction contrast ([Fearful-T2_Correct-T2 &#x02212; Fearful-T2_Incorrect-T2] &#x0003e; [Neutral-T2_Correct-T2 &#x02212; Neutral-T2_Incorrect-T2])</p></caption><table frame="hsides" rules="groups"><thead><tr><td rowspan="1" colspan="1">Region</td><td rowspan="1" colspan="1">Laterality</td><td rowspan="1" colspan="1"><italic>x</italic></td><td rowspan="1" colspan="1"><italic>y</italic></td><td rowspan="1" colspan="1"><italic>z</italic></td><td rowspan="1" colspan="1"><italic>Z</italic>-score</td></tr></thead><tbody><tr><td rowspan="1" colspan="1">rACC*</td><td rowspan="1" colspan="1">R</td><td align="char" char="." rowspan="1" colspan="1">14</td><td align="char" char="." rowspan="1" colspan="1">40</td><td align="char" char="." rowspan="1" colspan="1">22</td><td align="char" char="." rowspan="1" colspan="1">3.59</td></tr><tr><td rowspan="1" colspan="1">Cerebellum</td><td rowspan="1" colspan="1">L</td><td align="char" char="." rowspan="1" colspan="1">32</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;76</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;30</td><td align="char" char="." rowspan="1" colspan="1">4.04</td></tr><tr><td rowspan="1" colspan="1">Inferior postcentral sulcus</td><td rowspan="1" colspan="1">R</td><td align="char" char="." rowspan="1" colspan="1">56</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;10</td><td align="char" char="." rowspan="1" colspan="1">26</td><td align="char" char="." rowspan="1" colspan="1">3.89</td></tr><tr><td rowspan="1" colspan="1">Lingual gyrus</td><td rowspan="1" colspan="1">R</td><td align="char" char="." rowspan="1" colspan="1">14</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;78</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;8</td><td align="char" char="." rowspan="1" colspan="1">3.69</td></tr></tbody></table><table-wrap-foot><fn><p>Note: Abbreviations: Fearful-T2, fearful face target T2; Neutral-T2, neutral face target T2; Correct-T2, correctly identified face target T2; Incorrect-T2, incorrectly identified face target T2. All values <italic>P</italic> &#x0003c; 0.001 uncorrected with all clusters exciding an extent threshold of 5 voxels. *Statistically significant activations&#x02014;regions that survive to the SVC for multiple comparisons FWE <italic>P</italic> &#x0003c; 0.05 (see Methods for more details).</p></fn></table-wrap-foot></table-wrap><table-wrap id="tbl2" position="float"><label>Table 2</label><caption><p>Brain areas significantly more active during interaction contrast (Fearful-T2 &#x0003e; Neutral-T2)</p></caption><table frame="hsides" rules="groups"><thead><tr><td rowspan="1" colspan="1">Region</td><td rowspan="1" colspan="1">Laterality</td><td rowspan="1" colspan="1"><italic>x</italic></td><td rowspan="1" colspan="1"><italic>y</italic></td><td rowspan="1" colspan="1"><italic>z</italic></td><td rowspan="1" colspan="1"><italic>Z</italic>-score</td></tr></thead><tbody><tr><td rowspan="1" colspan="1">Ventral striatum*</td><td rowspan="1" colspan="1">R</td><td align="char" char="." rowspan="1" colspan="1">20</td><td align="char" char="." rowspan="1" colspan="1">16</td><td align="char" char="." rowspan="1" colspan="1">0</td><td align="char" char="." rowspan="1" colspan="1">4.08</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">L</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;28</td><td align="char" char="." rowspan="1" colspan="1">14</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;4</td><td align="char" char="." rowspan="1" colspan="1">3.63</td></tr><tr><td rowspan="1" colspan="1">Lingual gyrus</td><td rowspan="1" colspan="1">R</td><td align="char" char="." rowspan="1" colspan="1">8</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;78</td><td align="char" char="." rowspan="1" colspan="1">4</td><td align="char" char="." rowspan="1" colspan="1">3.59</td></tr></tbody></table><table-wrap-foot><fn><p>Note: All values <italic>P</italic> &#x0003c; 0.001 uncorrected with all clusters exciding an extent threshold of 5 voxels. *Statistically significant activations&#x02014;regions that survive to the SVC for multiple comparisons FWE <italic>P</italic> &#x0003c; 0.05 (see Methods for more details).</p></fn></table-wrap-foot></table-wrap><table-wrap id="tbl3" position="float"><label>Table 3</label><caption><p>Brain areas significantly more active during interaction contrast (Correct-T2 &#x0003e; Incorrect-T2)</p></caption><table frame="hsides" rules="groups"><thead><tr><td rowspan="1" colspan="1">Region</td><td rowspan="1" colspan="1">Laterality</td><td rowspan="1" colspan="1"><italic>x</italic></td><td rowspan="1" colspan="1"><italic>y</italic></td><td rowspan="1" colspan="1"><italic>z</italic></td><td rowspan="1" colspan="1"><italic>Z</italic>-score</td></tr></thead><tbody><tr><td rowspan="1" colspan="1">Posterior insula</td><td rowspan="1" colspan="1">L</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;42</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;8</td><td align="char" char="." rowspan="1" colspan="1">16</td><td align="char" char="." rowspan="1" colspan="1">4.64</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">L</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;32</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;2</td><td align="char" char="." rowspan="1" colspan="1">2</td><td align="char" char="." rowspan="1" colspan="1">4.05</td></tr><tr><td rowspan="1" colspan="1">Inferior frontal sulcus</td><td rowspan="1" colspan="1">R</td><td align="char" char="." rowspan="1" colspan="1">30</td><td align="char" char="." rowspan="1" colspan="1">54</td><td align="char" char="." rowspan="1" colspan="1">10</td><td align="char" char="." rowspan="1" colspan="1">4.98</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">R</td><td align="char" char="." rowspan="1" colspan="1">44</td><td align="char" char="." rowspan="1" colspan="1">48</td><td align="char" char="." rowspan="1" colspan="1">2</td><td align="char" char="." rowspan="1" colspan="1">3.91</td></tr><tr><td rowspan="1" colspan="1">Superior frontal sulcus</td><td rowspan="1" colspan="1">L</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;26</td><td align="char" char="." rowspan="1" colspan="1">46</td><td align="char" char="." rowspan="1" colspan="1">38</td><td align="char" char="." rowspan="1" colspan="1">4.14</td></tr><tr><td rowspan="1" colspan="1">Orbitofrontal cortex</td><td rowspan="1" colspan="1">R</td><td align="char" char="." rowspan="1" colspan="1">32</td><td align="char" char="." rowspan="1" colspan="1">42</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;16</td><td align="char" char="." rowspan="1" colspan="1">3.51</td></tr><tr><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">L</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;34</td><td align="char" char="." rowspan="1" colspan="1">22</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;20</td><td align="char" char="." rowspan="1" colspan="1">4.21</td></tr><tr><td rowspan="1" colspan="1">ACC</td><td rowspan="1" colspan="1">R</td><td align="char" char="." rowspan="1" colspan="1">2</td><td align="char" char="." rowspan="1" colspan="1">32</td><td align="char" char="." rowspan="1" colspan="1">28</td><td align="char" char="." rowspan="1" colspan="1">3.67</td></tr><tr><td rowspan="1" colspan="1">Pre-Supplementary Motor Area</td><td rowspan="1" colspan="1">L</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;4</td><td align="char" char="." rowspan="1" colspan="1">10</td><td align="char" char="." rowspan="1" colspan="1">46</td><td align="char" char="." rowspan="1" colspan="1">3.67</td></tr><tr><td rowspan="1" colspan="1">Cerebellum</td><td rowspan="1" colspan="1">L</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;36</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;68</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;46</td><td align="char" char="." rowspan="1" colspan="1">3.50</td></tr><tr><td rowspan="1" colspan="1">Inferior parietal gyrus</td><td rowspan="1" colspan="1">R</td><td align="char" char="." rowspan="1" colspan="1">66</td><td align="char" char="." rowspan="1" colspan="1">&#x02212;42</td><td align="char" char="." rowspan="1" colspan="1">22</td><td align="char" char="." rowspan="1" colspan="1">4.98</td></tr></tbody></table><table-wrap-foot><fn><p>Note: All values <italic>P</italic> &#x0003c; 0.001 uncorrected with all clusters exciding an extent threshold of 5 voxels.</p></fn></table-wrap-foot></table-wrap><fig id="fig5" position="float"><label>Figure 5.</label><caption><p>rACC. (<italic>a</italic>) Plot of signal percentage changes for the rACC cluster. (<italic>b</italic>) Sagittal SPM image during the interaction contrast ([Fearful-T2_Correct-T2 &#x02212; Fearful-T2_Incorrect-T2] &#x0003e; [Neutral-T2_Correct-T2 &#x02212; Neutral-T2_Incorrect-T2]) showing the activity of the rACC ([<italic>x</italic> = 14, <italic>y</italic> = 40, <italic>z</italic> = 22] <italic>Z</italic> = 3.59, 25-voxels <italic>P</italic> &#x0003c; 0.001 uncorrected and <italic>P</italic> &#x0003c; 0.05 SVC) is modulated by the T2 identification (Correct-T2 vs. Incorrect-T2) selectively in the when the T2 stimulus was a fearful face (Fearful-T2). rACC is significantly more active simple effect (Fearful-T2_Correct-T2 vs. Fearful-T2_Incorrect-T2) ([<italic>x</italic> = 10, <italic>y</italic> = 38, <italic>z</italic> = 18] <italic>Z</italic> = 4.25, 32-voxels <italic>P</italic> &#x0003c; 0.001 uncorrected and <italic>P</italic> &#x0003c; 0.05 SVC).</p></caption><graphic xlink:href="cercorbhn062f05_4c"/></fig></sec><sec sec-type="discussion"><title>Discussion</title><p>Our behavioral results replicate previous findings (<xref ref-type="bibr" rid="bib1">Anderson and Phelps 2001</xref>) in showing an increase in detection of arousing, compared with neutral, words in the AB, but extends these findings to a more ecological context of face processing. Moreover, the findings support a model that suggests an overlap in face identity and face expression recognition processes, in contrast with a view that propose 2 distinct parallel mechanisms (<xref ref-type="bibr" rid="bib7">Calder and Young 2005</xref>). RT for the correctly reported target was significantly shorter, supporting a more complete and accurate processing of these targets.</p><p>Although previous fMRI studies have examined the neurobiology of the AB effect using neutral stimuli (<xref ref-type="bibr" rid="bib27">Marois et al. 2000</xref>, <xref ref-type="bibr" rid="bib28">2004</xref>) the present study is the first to investigate the mechanisms underlying a reduced blink effect for emotional T2 items. The fMRI data show a significant increase in FFA activity for faces that subsequently would have been correctly reported. These results support claims that detection and identification of faces, critically depends on FFA activity (<xref ref-type="bibr" rid="bib20">Kanwisher et al. 1997</xref>, <xref ref-type="bibr" rid="bib21">1999</xref>; <xref ref-type="bibr" rid="bib14">Grill-Spector et al. 2004</xref>). Moreover in trials where a fearful face was incorrectly reported L-FFA showed increased activity for fearful faces compared with the neutral ones. This finding is in keeping with previous findings of a reported increase in FFA activity for fearful unattended faces versus neutral unattended faces (<xref ref-type="bibr" rid="bib42">Vuilleumier et al. 2001</xref>; <xref ref-type="bibr" rid="bib41">Vuilleumier 2005</xref>) in a spatial divided attention task. Our results extend these findings to the domain of nonspatial attention, and support a model that proposes enhanced processing of emotional stimuli even under conditions where they do not reach full awareness (<xref ref-type="bibr" rid="bib43">Vuilleumier and Pourtois 2007</xref>). The data also show that FFA activity is critically associated with the correct face identification. An important caveat is that because FFA activity did not show an interaction between valence of the target T2 and increased performance in T2 detection these observations cannot fully explain our behavioral increase in T2 fearful face detection.</p><p>Comparing brain activity in trials where the T2 target was a fearful face with trials where T2 was a neutral face was associated with activity increase in bilateral ventral striatum. These region is implicated in anticipation of reward (<xref ref-type="bibr" rid="bib30">O'Doherty 2004</xref>; <xref ref-type="bibr" rid="bib36">Schultz 2006</xref>) and anticipation of both aversive stimuli as well as painful stimulation (<xref ref-type="bibr" rid="bib35">Salamone 1994</xref>; <xref ref-type="bibr" rid="bib18">Jensen et al. 2003</xref>; <xref ref-type="bibr" rid="bib37">Seymour et al. 2005</xref>). Previous neuroimaging studies have also shown that ventral striatum is more active when subjects are exposed to unpleasant visual stimuli (<xref ref-type="bibr" rid="bib32">Paradiso et al. 1999</xref>). It has been suggested that striatum is implicated in responding to arousing stimuli (<xref ref-type="bibr" rid="bib17">Horvitz 2002</xref>). Furthermore, evidence from animals and humans literature, show that ventral striatum plays a key role in instrumental learning and goal-directed behavior (<xref ref-type="bibr" rid="bib16">Hollerman et al. 2000</xref>). Thus, our data are in keep with a role for the striatum in motivation and adaptation of behavior related to affective situations (<xref ref-type="bibr" rid="bib34">Robbins and Everitt 1996</xref>; <xref ref-type="bibr" rid="bib11">Everitt et al. 1999</xref>; <xref ref-type="bibr" rid="bib36">Schultz 2006</xref>).</p><p>The rACC showed an increase in activity in the critical interaction contrast that sought to identify brain areas underpinning an increase in detection for fearful T2 targets seen in our behavioral findings. The rACC (Brodman areas 24a-c and 32) is considered to have distinct anatomical and functional characteristics compared with the more caudal anterior cingulate cortex (<xref ref-type="bibr" rid="bib6">Bush et al. 2000</xref>). At neuroanatomical level this area shares reciprocal connections with amygdala, nucleus accumbens, anterior insula, and orbitofrontal cortex. At a functional level convergent evidence shows that rACC has a primary role in processing emotional information and regulating emotional responses (<xref ref-type="bibr" rid="bib6">Bush et al. 2000</xref>). In particular rACC activity is implicated in awareness for emotional material (Lane, Fink, et al. 1997; Lane et al. <xref ref-type="bibr" rid="bib24">1998</xref>; <xref ref-type="bibr" rid="bib8">Carretie et al. 2001</xref>; <xref ref-type="bibr" rid="bib38">Simpson et al. 2001</xref>), attention to emotional stimuli (<xref ref-type="bibr" rid="bib42">Vuilleumier et al. 2001</xref>; <xref ref-type="bibr" rid="bib12">Fichtenholtz et al. 2004</xref>) and rating of affect intensity (<xref ref-type="bibr" rid="bib40">Taylor et al. 2003</xref>). During anxiety, altered response of rACC has been associated with an impaired processing of treat-related attentional competitors (<xref ref-type="bibr" rid="bib3">Bishop et al. 2004</xref>) and with appraisal of emotional material (<xref ref-type="bibr" rid="bib19">Kalisch et al. 2006</xref>). More generally, rACC has been shown playing a key role in selective attention to emotional information (<xref ref-type="bibr" rid="bib23">Lane, Fink, et al. 1997</xref>; <xref ref-type="bibr" rid="bib10">Elliott et al. 2000</xref>). Our behavioral manipulation highlights a role for rACC in early stages of emotional processing (<xref ref-type="bibr" rid="bib19">Kalisch et al. 2006</xref>). In this regard the results extend the functional role of rACC to include mediating selective detection of potential threat under conditions of limited attentional capacity, as elicited by the AB paradigm.</p><p>A previous study (<xref ref-type="bibr" rid="bib1">Anderson and Phelps 2001</xref>) using a word RVSP with either a neutral or an arousing T2 demonstrated that patients with left amygdala damage did not have a significant behavioral advantage in emotional T2 detection. A theoretical model of emotional modulation of AB predicts that amygdala may play a key role in mediating this effect (<xref ref-type="bibr" rid="bib13">Fragopanagos et al. 2005</xref>; <xref ref-type="bibr" rid="bib31">Palermo and Rhodes 2007</xref>). In our study we did not find a statistically significant amygdala activation either in the critical interaction ([Fearful-T2_Correct-T2 &#x02212; Fearful-T2_Incorrect-T2] &#x0003e; [Neutral-T2_Correct-T2 &#x02212; Neutral-T2_Incorrect-T2]) or in the main effect of fearful versus neutral T2, even at a more liberal threshold of <italic>P</italic> &#x0003c; 0.05 uncorrected. This negative finding does not exclude a possible involvement of amygdala in our task. In fact the statistical power of the analysis was limited by the number of events and brief presentation of the target. This may have rendered it more difficult to detect rapid changes in amygdala, particularly when considering the low signal to noise ratio in this subcortical area (<xref ref-type="bibr" rid="bib22">LaBar et al. 2001</xref>). Additionally, all faces, even neutral ones especially when presented briefly may have potential emotional significance and can activate amygdala (<xref ref-type="bibr" rid="bib48">Wright and Liu 2006</xref>).</p><p>Finally, our data suggests a model in which early control exerted by rACC is required for enhanced processing of threat targets. In fact the stimulus driven activity in visual areas, although necessary for the correct T2 process, does not appear sufficient to explain enhanced behavioral processing of the fearful T2 targets. One possibility is that enhanced activity in rACC, triggered by subcortical areas (e.g., striatum) sensitive to stimulus valence, mediates correct target identification by gating the access of the potentially threatening stimulus to full awareness.</p><p>In conclusion, using a modification of an attentional blink task in which we manipulated the emotional valence of a face T2 target, we observed a significant increase in correct detection of fearful compared with neutral targets. These data replicate previous findings using words as arousing stimuli (<xref ref-type="bibr" rid="bib1">Anderson and Phelps 2001</xref>). Our behavioral results demonstrate that even when humans are unable to detect nonthreatening stimuli due to attentional overload, they retain the ability to detect emotional items. Our imaging data indicates that although activity in visual areas like FFA is necessary for the correct stimulus detection, it does not account for the increased detection of threatening targets. Instead frontal rACC activity mediates a control on attention and awareness for emotional items even in conditions in which normal attentional capacity is limited.</p></sec><sec><title>Funding</title><p>This work was supported by a <grant-sponsor>Wellcome Trust Programme Grant to RJD</grant-sponsor> and a <grant-sponsor>Wellcome Trust PhD Scholarship to BDM.</grant-sponsor></p></sec></body><back><ack><p>The authors would like to thank Dharshan Kumaran, Hugo Spiers, James Kilner for the helpful discussions during the analysis. <italic>Conflict of Interest</italic>: None declared.</p></ack><ref-list><ref id="bib1"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>AK</given-names></name><name><surname>Phelps</surname><given-names>EA</given-names></name></person-group><article-title>Lesions of the human amygdala impair enhanced perception of emotionally salient events</article-title><source>Nature.</source><year>2001</year><volume>411</volume><fpage>305</fpage><lpage>309</lpage><pub-id pub-id-type="pmid">11357132</pub-id></citation></ref><ref id="bib2"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Armony</surname><given-names>JL</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><article-title>Modulation of spatial attention by fear-conditioned stimuli: an event-related fMRI study</article-title><source>Neuropsychologia.</source><year>2002</year><volume>40</volume><fpage>817</fpage><lpage>826</lpage><pub-id pub-id-type="pmid">11900732</pub-id></citation></ref><ref id="bib3"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Bishop</surname><given-names>S</given-names></name><name><surname>Duncan</surname><given-names>J</given-names></name><name><surname>Brett</surname><given-names>M</given-names></name><name><surname>Lawrence</surname><given-names>AD</given-names></name></person-group><article-title>Prefrontal cortical function and anxiety: controlling attention to threat-related stimuli</article-title><source>Nat Neurosci.</source><year>2004</year><volume>7</volume><fpage>184</fpage><lpage>188</lpage><pub-id pub-id-type="pmid">14703573</pub-id></citation></ref><ref id="bib4"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Bishop</surname><given-names>SJ</given-names></name><name><surname>Duncan</surname><given-names>J</given-names></name><name><surname>Lawrence</surname><given-names>AD</given-names></name></person-group><article-title>State anxiety modulation of the amygdala response to unattended threat-related stimuli</article-title><source>J Neurosci.</source><year>2004</year><volume>24</volume><fpage>10364</fpage><lpage>10368</lpage><pub-id pub-id-type="pmid">15548650</pub-id></citation></ref><ref id="bib5"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Breiter</surname><given-names>HC</given-names></name><name><surname>Etcoff</surname><given-names>NL</given-names></name><name><surname>Whalen</surname><given-names>PJ</given-names></name><name><surname>Kennedy</surname><given-names>WA</given-names></name><name><surname>Rauch</surname><given-names>SL</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name><name><surname>Strauss</surname><given-names>MM</given-names></name><name><surname>Hyman</surname><given-names>SE</given-names></name><name><surname>Rosen</surname><given-names>BR</given-names></name></person-group><article-title>Response and habituation of the human amygdala during visual processing of facial expression</article-title><source>Neuron.</source><year>1996</year><volume>17</volume><fpage>875</fpage><lpage>887</lpage><pub-id pub-id-type="pmid">8938120</pub-id></citation></ref><ref id="bib6"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Bush</surname><given-names>G</given-names></name><name><surname>Luu</surname><given-names>P</given-names></name><name><surname>Posner</surname><given-names>MI</given-names></name></person-group><article-title>Cognitive and emotional influences in anterior cingulate cortex</article-title><source>Trends Cogn Sci.</source><year>2000</year><volume>4</volume><fpage>215</fpage><lpage>222</lpage><pub-id pub-id-type="pmid">10827444</pub-id></citation></ref><ref id="bib7"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Calder</surname><given-names>AJ</given-names></name><name><surname>Young</surname><given-names>AW</given-names></name></person-group><article-title>Understanding the recognition of facial identity and facial expression</article-title><source>Nat Rev Neurosci.</source><year>2005</year><volume>6</volume><fpage>641</fpage><lpage>651</lpage><pub-id pub-id-type="pmid">16062171</pub-id></citation></ref><ref id="bib8"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Carretie</surname><given-names>L</given-names></name><name><surname>Martin-Loeches</surname><given-names>M</given-names></name><name><surname>Hinojosa</surname><given-names>JA</given-names></name><name><surname>Mercado</surname><given-names>F</given-names></name></person-group><article-title>Emotion and attention interaction studied through event-related potentials</article-title><source>J Cogn Neurosci.</source><year>2001</year><volume>13</volume><fpage>1109</fpage><lpage>1128</lpage><pub-id pub-id-type="pmid">11784449</pub-id></citation></ref><ref id="bib9"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><article-title>Emotion, cognition, and behavior</article-title><source>Science.</source><year>2002</year><volume>298</volume><fpage>1191</fpage><lpage>1194</lpage><pub-id pub-id-type="pmid">12424363</pub-id></citation></ref><ref id="bib10"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Elliott</surname><given-names>R</given-names></name><name><surname>Rubinsztein</surname><given-names>JS</given-names></name><name><surname>Sahakian</surname><given-names>BJ</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><article-title>Selective attention to emotional stimuli in a verbal go/no-go task: an fMRI study</article-title><source>Neuroreport.</source><year>2000</year><volume>11</volume><fpage>1739</fpage><lpage>1744</lpage><pub-id pub-id-type="pmid">10852235</pub-id></citation></ref><ref id="bib11"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Everitt</surname><given-names>BJ</given-names></name><name><surname>Parkinson</surname><given-names>JA</given-names></name><name><surname>Olmstead</surname><given-names>MC</given-names></name><name><surname>Arroyo</surname><given-names>M</given-names></name><name><surname>Robledo</surname><given-names>P</given-names></name><name><surname>Robbins</surname><given-names>TW</given-names></name></person-group><article-title>Associative processes in addiction and reward. The role of amygdala-ventral striatal subsystems</article-title><source>Ann N Y Acad Sci.</source><year>1999</year><volume>877</volume><fpage>412</fpage><lpage>438</lpage><pub-id pub-id-type="pmid">10415662</pub-id></citation></ref><ref id="bib12"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Fichtenholtz</surname><given-names>HM</given-names></name><name><surname>Dean</surname><given-names>HL</given-names></name><name><surname>Dillon</surname><given-names>DG</given-names></name><name><surname>Yamasaki</surname><given-names>H</given-names></name><name><surname>McCarthy</surname><given-names>G</given-names></name><name><surname>LaBar</surname><given-names>KS</given-names></name></person-group><article-title>Emotion-attention network interactions during a visual oddball task</article-title><source>Brain Res Cogn Brain Res.</source><year>2004</year><volume>20</volume><fpage>67</fpage><lpage>80</lpage><pub-id pub-id-type="pmid">15130591</pub-id></citation></ref><ref id="bib13"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Fragopanagos</surname><given-names>N</given-names></name><name><surname>Kockelkoren</surname><given-names>S</given-names></name><name><surname>Taylor</surname><given-names>JG</given-names></name></person-group><article-title>A neurodynamic model of the attentional blink</article-title><source>Brain Res Cogn Brain Res.</source><year>2005</year><volume>24</volume><fpage>568</fpage><lpage>586</lpage><pub-id pub-id-type="pmid">16099367</pub-id></citation></ref><ref id="bib14"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Grill-Spector</surname><given-names>K</given-names></name><name><surname>Knouf</surname><given-names>N</given-names></name><name><surname>Kanwisher</surname><given-names>N</given-names></name></person-group><article-title>The fusiform face area subserves face perception, not generic within-category identification</article-title><source>Nat Neurosci.</source><year>2004</year><volume>7</volume><fpage>555</fpage><lpage>562</lpage><pub-id pub-id-type="pmid">15077112</pub-id></citation></ref><ref id="bib15"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Groenewegen</surname><given-names>HJ</given-names></name><name><surname>Uylings</surname><given-names>HB</given-names></name></person-group><article-title>The prefrontal cortex and the integration of sensory, limbic and autonomic information</article-title><source>Prog Brain Res.</source><year>2000</year><volume>126</volume><fpage>3</fpage><lpage>28</lpage><pub-id pub-id-type="pmid">11105636</pub-id></citation></ref><ref id="bib16"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Hollerman</surname><given-names>JR</given-names></name><name><surname>Tremblay</surname><given-names>L</given-names></name><name><surname>Schultz</surname><given-names>W</given-names></name></person-group><article-title>Involvement of basal ganglia and orbitofrontal cortex in goal-directed behavior</article-title><source>Prog Brain Res.</source><year>2000</year><volume>126</volume><fpage>193</fpage><lpage>215</lpage><pub-id pub-id-type="pmid">11105648</pub-id></citation></ref><ref id="bib17"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Horvitz</surname><given-names>JC</given-names></name></person-group><article-title>Dopamine gating of glutamatergic sensorimotor and incentive motivational input signals to the striatum</article-title><source>Behav Brain Res.</source><year>2002</year><volume>137</volume><fpage>65</fpage><lpage>74</lpage><pub-id pub-id-type="pmid">12445716</pub-id></citation></ref><ref id="bib18"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Jensen</surname><given-names>J</given-names></name><name><surname>McIntosh</surname><given-names>AR</given-names></name><name><surname>Crawley</surname><given-names>AP</given-names></name><name><surname>Mikulis</surname><given-names>DJ</given-names></name><name><surname>Remington</surname><given-names>G</given-names></name><name><surname>Kapur</surname><given-names>S</given-names></name></person-group><article-title>Direct activation of the ventral striatum in anticipation of aversive stimuli</article-title><source>Neuron.</source><year>2003</year><volume>40</volume><fpage>1251</fpage><lpage>1257</lpage><pub-id pub-id-type="pmid">14687557</pub-id></citation></ref><ref id="bib19"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kalisch</surname><given-names>R</given-names></name><name><surname>Wiech</surname><given-names>K</given-names></name><name><surname>Critchley</surname><given-names>HD</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><article-title>Levels of appraisal: a medial prefrontal role in high-level appraisal of emotional material</article-title><source>Neuroimage.</source><year>2006</year><volume>30</volume><fpage>1458</fpage><lpage>1466</lpage><pub-id pub-id-type="pmid">16388969</pub-id></citation></ref><ref id="bib20"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kanwisher</surname><given-names>N</given-names></name><name><surname>McDermott</surname><given-names>J</given-names></name><name><surname>Chun</surname><given-names>MM</given-names></name></person-group><article-title>The fusiform face area: a module in human extrastriate cortex specialized for face perception</article-title><source>J Neurosci.</source><year>1997</year><volume>17</volume><fpage>4302</fpage><lpage>4311</lpage><pub-id pub-id-type="pmid">9151747</pub-id></citation></ref><ref id="bib21"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kanwisher</surname><given-names>N</given-names></name><name><surname>Stanley</surname><given-names>D</given-names></name><name><surname>Harris</surname><given-names>A</given-names></name></person-group><article-title>The fusiform face area is selective for faces not animals</article-title><source>Neuroreport.</source><year>1999</year><volume>10</volume><fpage>183</fpage><lpage>187</lpage><pub-id pub-id-type="pmid">10094159</pub-id></citation></ref><ref id="bib22"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>LaBar</surname><given-names>KS</given-names></name><name><surname>Gitelman</surname><given-names>DR</given-names></name><name><surname>Mesulam</surname><given-names>MM</given-names></name><name><surname>Parrish</surname><given-names>TB</given-names></name></person-group><article-title>Impact of signal-to-noise on functional MRI of the human amygdala</article-title><source>Neuroreport.</source><year>2001</year><volume>12</volume><fpage>3461</fpage><lpage>3464</lpage><pub-id pub-id-type="pmid">11733691</pub-id></citation></ref><ref id="bib23"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Lane</surname><given-names>RD</given-names></name><name><surname>Fink</surname><given-names>GR</given-names></name><name><surname>Chau</surname><given-names>PM</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><article-title>Neural activation during selective attention to subjective emotional responses</article-title><source>Neuroreport.</source><year>1997</year><volume>8</volume><fpage>3969</fpage><lpage>3972</lpage><pub-id pub-id-type="pmid">9462476</pub-id></citation></ref><ref id="bib24"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Lane</surname><given-names>RD</given-names></name><name><surname>Reiman</surname><given-names>EM</given-names></name><name><surname>Axelrod</surname><given-names>B</given-names></name><name><surname>Yun</surname><given-names>LS</given-names></name><name><surname>Holmes</surname><given-names>A</given-names></name><name><surname>Schwartz</surname><given-names>GE</given-names></name></person-group><article-title>Neural correlates of levels of emotional awareness. Evidence of an interaction between emotion and attention in the anterior cingulate cortex</article-title><source>J Cogn Neurosci.</source><year>1998</year><volume>10</volume><fpage>525</fpage><lpage>535</lpage><pub-id pub-id-type="pmid">9712681</pub-id></citation></ref><ref id="bib25"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Lane</surname><given-names>RD</given-names></name><name><surname>Reiman</surname><given-names>EM</given-names></name><name><surname>Bradley</surname><given-names>MM</given-names></name><name><surname>Lang</surname><given-names>PJ</given-names></name><name><surname>Ahern</surname><given-names>GL</given-names></name><name><surname>Davidson</surname><given-names>RJ</given-names></name><name><surname>Schwartz</surname><given-names>GE</given-names></name></person-group><article-title>Neuroanatomical correlates of pleasant and unpleasant emotion</article-title><source>Neuropsychologia.</source><year>1997</year><volume>35</volume><fpage>1437</fpage><lpage>1444</lpage><pub-id pub-id-type="pmid">9352521</pub-id></citation></ref><ref id="bib26"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Lang</surname><given-names>PJ</given-names></name><name><surname>Bradley</surname><given-names>MM</given-names></name><name><surname>Fitzsimmons</surname><given-names>JR</given-names></name><name><surname>Cuthbert</surname><given-names>BN</given-names></name><name><surname>Scott</surname><given-names>JD</given-names></name><name><surname>Moulder</surname><given-names>B</given-names></name><name><surname>Nangia</surname><given-names>V</given-names></name></person-group><article-title>Emotional arousal and activation of the visual cortex: an fMRI analysis</article-title><source>Psychophysiology.</source><year>1998</year><volume>35</volume><fpage>199</fpage><lpage>210</lpage><pub-id pub-id-type="pmid">9529946</pub-id></citation></ref><ref id="bib27"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Marois</surname><given-names>R</given-names></name><name><surname>Chun</surname><given-names>MM</given-names></name><name><surname>Gore</surname><given-names>JC</given-names></name></person-group><article-title>Neural correlates of the attentional blink</article-title><source>Neuron.</source><year>2000</year><volume>28</volume><fpage>299</fpage><lpage>308</lpage><pub-id pub-id-type="pmid">11087002</pub-id></citation></ref><ref id="bib28"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Marois</surname><given-names>R</given-names></name><name><surname>Yi</surname><given-names>DJ</given-names></name><name><surname>Chun</surname><given-names>MM</given-names></name></person-group><article-title>The neural fate of consciously perceived and missed events in the attentional blink</article-title><source>Neuron.</source><year>2004</year><volume>41</volume><fpage>465</fpage><lpage>472</lpage><pub-id pub-id-type="pmid">14766184</pub-id></citation></ref><ref id="bib29"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Morris</surname><given-names>JS</given-names></name><name><surname>Buchel</surname><given-names>C</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><article-title>Parallel neural responses in amygdala subregions and sensory cortex during implicit fear conditioning</article-title><source>Neuroimage.</source><year>2001</year><volume>13</volume><fpage>1044</fpage><lpage>1052</lpage><pub-id pub-id-type="pmid">11352610</pub-id></citation></ref><ref id="bib30"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>O'Doherty</surname><given-names>JP</given-names></name></person-group><article-title>Reward representations and reward-related learning in the human brain: insights from neuroimaging</article-title><source>Curr Opin Neurobiol.</source><year>2004</year><volume>14</volume><fpage>769</fpage><lpage>776</lpage><pub-id pub-id-type="pmid">15582382</pub-id></citation></ref><ref id="bib31"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Palermo</surname><given-names>R</given-names></name><name><surname>Rhodes</surname><given-names>G</given-names></name></person-group><article-title>Are you always on my mind? A review of how face perception and attention interact</article-title><source>Neuropsychologia.</source><year>2007</year><volume>45</volume><fpage>75</fpage><lpage>92</lpage><pub-id pub-id-type="pmid">16797607</pub-id></citation></ref><ref id="bib32"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Paradiso</surname><given-names>S</given-names></name><name><surname>Johnson</surname><given-names>DL</given-names></name><name><surname>Andreasen</surname><given-names>NC</given-names></name><name><surname>O'Leary</surname><given-names>DS</given-names></name><name><surname>Watkins</surname><given-names>GL</given-names></name><name><surname>Ponto</surname><given-names>LL</given-names></name><name><surname>Hichwa</surname><given-names>RD</given-names></name></person-group><article-title>Cerebral blood flow changes associated with attribution of emotional valence to pleasant, unpleasant, and neutral visual stimuli in a PET study of normal subjects</article-title><source>Am J Psychiatry.</source><year>1999</year><volume>156</volume><fpage>1618</fpage><lpage>1629</lpage><pub-id pub-id-type="pmid">10518175</pub-id></citation></ref><ref id="bib33"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Raymond</surname><given-names>JE</given-names></name><name><surname>Shapiro</surname><given-names>KL</given-names></name><name><surname>Arnell</surname><given-names>KM</given-names></name></person-group><article-title>Temporary suppression of visual processing in an RSVP task: an attentional blink?</article-title><source>J Exp Psychol Hum Percept Perform.</source><year>1992</year><volume>18</volume><fpage>849</fpage><lpage>860</lpage><pub-id pub-id-type="pmid">1500880</pub-id></citation></ref><ref id="bib34"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Robbins</surname><given-names>TW</given-names></name><name><surname>Everitt</surname><given-names>BJ</given-names></name></person-group><article-title>Neurobehavioural mechanisms of reward and motivation</article-title><source>Curr Opin Neurobiol.</source><year>1996</year><volume>6</volume><fpage>228</fpage><lpage>236</lpage><pub-id pub-id-type="pmid">8725965</pub-id></citation></ref><ref id="bib35"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Salamone</surname><given-names>JD</given-names></name></person-group><article-title>The involvement of nucleus accumbens dopamine in appetitive and aversive motivation</article-title><source>Behav Brain Res.</source><year>1994</year><volume>61</volume><fpage>117</fpage><lpage>133</lpage><pub-id pub-id-type="pmid">8037860</pub-id></citation></ref><ref id="bib36"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Schultz</surname><given-names>W</given-names></name></person-group><article-title>Behavioral theories and the neurophysiology of reward</article-title><source>Annu Rev Psychol.</source><year>2006</year><volume>57</volume><fpage>87</fpage><lpage>115</lpage><pub-id pub-id-type="pmid">16318590</pub-id></citation></ref><ref id="bib37"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Seymour</surname><given-names>B</given-names></name><name><surname>O'Doherty</surname><given-names>JP</given-names></name><name><surname>Koltzenburg</surname><given-names>M</given-names></name><name><surname>Wiech</surname><given-names>K</given-names></name><name><surname>Frackowiak</surname><given-names>R</given-names></name><name><surname>Friston</surname><given-names>K</given-names></name><name><surname>Dolan</surname><given-names>R</given-names></name></person-group><article-title>Opponent appetitive-aversive neural processes underlie predictive learning of pain relief</article-title><source>Nat Neurosci.</source><year>2005</year><volume>8</volume><fpage>1234</fpage><lpage>1240</lpage><pub-id pub-id-type="pmid">16116445</pub-id></citation></ref><ref id="bib38"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Simpson</surname><given-names>JR</given-names><suffix>Jr</suffix></name><name><surname>Drevets</surname><given-names>WC</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Gusnard</surname><given-names>DA</given-names></name><name><surname>Raichle</surname><given-names>ME</given-names></name></person-group><article-title>Emotion-induced changes in human medial prefrontal cortex: II. During anticipatory anxiety</article-title><source>Proc Natl Acad Sci USA.</source><year>2001</year><volume>98</volume><fpage>688</fpage><lpage>693</lpage><pub-id pub-id-type="pmid">11209066</pub-id></citation></ref><ref id="bib39"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Strange</surname><given-names>BA</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><article-title>Beta-adrenergic modulation of emotional memory-evoked human amygdala and hippocampal responses</article-title><source>Proc Natl Acad Sci USA.</source><year>2004</year><volume>101</volume><fpage>11454</fpage><lpage>11458</lpage><pub-id pub-id-type="pmid">15269349</pub-id></citation></ref><ref id="bib40"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Taylor</surname><given-names>SF</given-names></name><name><surname>Phan</surname><given-names>KL</given-names></name><name><surname>Decker</surname><given-names>LR</given-names></name><name><surname>Liberzon</surname><given-names>I</given-names></name></person-group><article-title>Subjective rating of emotionally salient stimuli modulates neural activity</article-title><source>Neuroimage.</source><year>2003</year><volume>18</volume><fpage>650</fpage><lpage>659</lpage><pub-id pub-id-type="pmid">12667842</pub-id></citation></ref><ref id="bib41"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Vuilleumier</surname><given-names>P</given-names></name></person-group><article-title>How brains beware: neural mechanisms of emotional attention</article-title><source>Trends Cogn Sci.</source><year>2005</year><volume>9</volume><fpage>585</fpage><lpage>594</lpage><pub-id pub-id-type="pmid">16289871</pub-id></citation></ref><ref id="bib42"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Vuilleumier</surname><given-names>P</given-names></name><name><surname>Armony</surname><given-names>JL</given-names></name><name><surname>Driver</surname><given-names>J</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><article-title>Effects of attention and emotion on face processing in the human brain: an event-related fMRI study</article-title><source>Neuron.</source><year>2001</year><volume>30</volume><fpage>829</fpage><lpage>841</lpage><pub-id pub-id-type="pmid">11430815</pub-id></citation></ref><ref id="bib43"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Vuilleumier</surname><given-names>P</given-names></name><name><surname>Pourtois</surname><given-names>G</given-names></name></person-group><article-title>Distributed and interactive brain mechanisms during emotion face perception: evidence from functional neuroimaging</article-title><source>Neuropsychologia.</source><year>2007</year><volume>45</volume><fpage>174</fpage><lpage>194</lpage><pub-id pub-id-type="pmid">16854439</pub-id></citation></ref><ref id="bib44"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Vuilleumier</surname><given-names>P</given-names></name><name><surname>Schwartz</surname><given-names>S</given-names></name></person-group><article-title>Beware and be aware: capture of spatial attention by fear-related stimuli in neglect</article-title><source>Neuroreport.</source><year>2001a</year><volume>12</volume><fpage>1119</fpage><lpage>1122</lpage><pub-id pub-id-type="pmid">11338176</pub-id></citation></ref><ref id="bib45"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Vuilleumier</surname><given-names>P</given-names></name><name><surname>Schwartz</surname><given-names>S</given-names></name></person-group><article-title>Emotional facial expressions capture attention</article-title><source>Neurology.</source><year>2001b</year><volume>56</volume><fpage>153</fpage><lpage>158</lpage><pub-id pub-id-type="pmid">11160948</pub-id></citation></ref><ref id="bib46"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Whalen</surname><given-names>PJ</given-names></name><name><surname>Bush</surname><given-names>G</given-names></name><name><surname>McNally</surname><given-names>RJ</given-names></name><name><surname>Wilhelm</surname><given-names>S</given-names></name><name><surname>McInerney</surname><given-names>SC</given-names></name><name><surname>Jenike</surname><given-names>MA</given-names></name><name><surname>Rauch</surname><given-names>SL</given-names></name></person-group><article-title>The emotional counting Stroop paradigm: a functional magnetic resonance imaging probe of the anterior cingulate affective division</article-title><source>Biol Psychiatry.</source><year>1998</year><volume>44</volume><fpage>1219</fpage><lpage>1228</lpage><pub-id pub-id-type="pmid">9861465</pub-id></citation></ref><ref id="bib47"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Wise</surname><given-names>RA</given-names></name></person-group><article-title>Dopamine, learning and motivation</article-title><source>Nat Rev Neurosci.</source><year>2004</year><volume>5</volume><fpage>483</fpage><lpage>494</lpage><pub-id pub-id-type="pmid">15152198</pub-id></citation></ref><ref id="bib48"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Wright</surname><given-names>P</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name></person-group><article-title>Neutral faces activate the amygdala during identity matching</article-title><source>Neuroimage.</source><year>2006</year><volume>29</volume><fpage>628</fpage><lpage>636</lpage><pub-id pub-id-type="pmid">16143545</pub-id></citation></ref></ref-list></back></article>