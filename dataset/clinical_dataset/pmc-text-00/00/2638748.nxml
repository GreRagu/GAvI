<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN" "archivearticle.dtd"><article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article" xml:lang="EN"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Cereb Cortex</journal-id><journal-id journal-id-type="hwp">cercor</journal-id><journal-id journal-id-type="publisher-id">cercor</journal-id><journal-title>Cerebral Cortex (New York, NY)</journal-title><issn pub-type="ppub">1047-3211</issn><issn pub-type="epub">1460-2199</issn><publisher><publisher-name>Oxford University Press</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">18460449</article-id><article-id pub-id-type="pmc">2638748</article-id><article-id pub-id-type="doi">10.1093/cercor/bhn060</article-id><article-categories><subj-group subj-group-type="heading"><subject>Articles</subject></subj-group></article-categories><title-group><article-title>Spatiotemporal Signatures of Large-Scale Synfire Chains for Speech Processing as Revealed by MEG</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Pulverm&#x000fc;ller</surname><given-names>Friedemann</given-names></name><xref ref-type="aff" rid="aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Shtyrov</surname><given-names>Yury</given-names></name><xref ref-type="aff" rid="aff1">1</xref></contrib></contrib-group><aff id="aff1"><label>1</label>Medical Research Council Cognition and Brain Sciences Unit, Cambridge CB2 2EF, UK</aff><author-notes><corresp>Address correspondence to Friedemann Pulverm&#x000fc;ller, PhD, Medical Research Council Cognition and Brain Sciences Unit, 15 Chaucer Road, Cambridge CB2 2EF, UK. Email: <email>friedemann.pulvermuller@mrc-cbu.cam.ac.uk</email>.</corresp></author-notes><!--Fake ppub date generated  by PMC from publisher pub-date/@pub-type='epub-ppub' --><pub-date pub-type="ppub"><month>1</month><year>2009</year></pub-date><pub-date pub-type="epub"><day>5</day><month>5</month><year>2008</year></pub-date><pub-date pub-type="pmc-release"><day>5</day><month>5</month><year>2008</year></pub-date><volume>19</volume><issue>1</issue><fpage>79</fpage><lpage>88</lpage><permissions><copyright-statement>&#x000a9; 2008 The Authors</copyright-statement><copyright-year>2009</copyright-year><license license-type="open-access"><p><!--CREATIVE COMMONS-->This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/2.0/uk/">http://creativecommons.org/licenses/by-nc/2.0/uk/</ext-link>) which permits unrestricted non-commercial use, distribution, and reproduction in any medium, provided the original work is properly cited.</p></license></permissions><abstract><p>We report a new brain signature of memory trace activation in the human brain revealed by magnetoencephalography and distributed source localization. Spatiotemporal patterns of cortical activation can be picked up in the time course of source images underlying magnetic brain responses to speech and noise stimuli, especially the generators of the magnetic mismatch negativity. We found that acoustic signals perceived as speech elicited a well-defined spatiotemporal pattern of sequential activation of superior&#x02013;temporal and inferior&#x02013;frontal cortex, whereas the same identical stimuli, when perceived as noise, did not elicit temporally structured activation. Strength of local sources constituting large-scale spatiotemporal patterns reflected additional lexical and syntactic features of speech. Morphological processing of the critical sound as verb inflection led to particularly pronounced early left inferior&#x02013;frontal activation, whereas the same sound functioning as inflectional affix of a noun activated superior&#x02013;temporal cortex more strongly. We conclude that precisely timed spatiotemporal patterns involving specific cortical areas may represent a brain code of memory circuit activation. These spatiotemporal patterns are best explained in terms of synfire mechanisms linking neuronal populations in different cortical areas. The large-scale synfire chains appear to reflect the processing of stimuli together with the context-dependent perceptual and cognitive information bound to them.</p></abstract><kwd-group><kwd>inflectional affix</kwd><kwd>language</kwd><kwd>MEG</kwd><kwd>noise</kwd><kwd>spatiotemporal pattern</kwd><kwd>speech</kwd></kwd-group></article-meta></front><body><p>An important question in cognitive neuroscience addresses the nature of memory traces that store experiences, familiar objects, and spoken words in the human brain. Neurophysiological studies in monkeys have demonstrated local cortical circuits generating precisely timed sequences of nerve cell activation, so-called synfire chains, that may contribute to specific perceptual, cognitive, and behavioral processes (<xref ref-type="bibr" rid="bib2">Abeles 1991</xref>; <xref ref-type="bibr" rid="bib3">Abeles et al. 1993</xref>; <xref ref-type="bibr" rid="bib51">Prut et al. 1998</xref>; <xref ref-type="bibr" rid="bib30">Ikegaya et al. 2004</xref>). However, memory circuits are not necessarily local. Cognitive processing implies binding of information across modalities (auditory and motor in the case of spoken words <xref ref-type="bibr" rid="bib61">Rizzolatti et al. 2001</xref>), and the circuits storing such cross-modality information span wide cortical areas (<xref ref-type="bibr" rid="bib21">Fuster et al. 2000</xref>; <xref ref-type="bibr" rid="bib20">Fuster 2003</xref>). Therefore, neuronal populations in different areas of cortex may become active in a defined spatiotemporal order indexing specific stimulus information (<xref ref-type="bibr" rid="bib52">Pulverm&#x000fc;ller 1999</xref>; <xref ref-type="bibr" rid="bib20">Fuster 2003</xref>; <xref ref-type="bibr" rid="bib16">Feldman 2006</xref>; <xref ref-type="bibr" rid="bib50">Plenz and Thiagarajan 2007</xref>). To capture the activation of interarea circuits, it is necessary to investigate the dynamic spatiotemporal patterns with which excitation emerges in different cortical areas and, especially, their stimulus specificity. Functional imaging studies measuring metabolic change suffer from the slowness of such change, which does not allow the tracking of the exact timing of neuronal activation spreading in the millisecond range. However, such interarea spatiotemporal mapping of memory circuits is possible using whole-brain neurophysiological imaging with magnetoencephalography (MEG).</p><p>At the large-scale level of whole-brain recordings with MEG, 1 early brain response, which peaks already between 100 and 200 ms after critical stimulus onset, has proven fruitful in revealing the existence of memory traces in the human brain. This brain response, the mismatch negativity (MMN) and its magnetic equivalent, has been found to be larger to familiar language sounds than to sounds of a foreign language (<xref ref-type="bibr" rid="bib43">N&#x000e4;&#x000e4;t&#x000e4;nen et al. 1997</xref>, <xref ref-type="bibr" rid="bib44">2001</xref>) and is even enhanced to meaningful words and sounds as compared with meaningless sound sequences (<xref ref-type="bibr" rid="bib34">Korpilahti et al. 2001</xref>; <xref ref-type="bibr" rid="bib54">Pulverm&#x000fc;ller et al. 2001</xref>; <xref ref-type="bibr" rid="bib49">Pettigrew et al. 2004</xref>; <xref ref-type="bibr" rid="bib18">Frangos et al. 2005</xref>; <xref ref-type="bibr" rid="bib68">Shtyrov et al. 2005</xref>; <xref ref-type="bibr" rid="bib26">Hauk et al. 2006</xref>; <xref ref-type="bibr" rid="bib56">Pulverm&#x000fc;ller and Shtyrov 2006</xref>). The MMN may therefore be a useful tool for investigating the brain dynamics of speech and sound processing.</p><p>Large-scale neurophysiological imaging methods, including MEG, measure neuronal mass activity and are capable of mapping its time course with greatest precision. They do not, however, provide direct information about the locus of the sources that contribute to these dynamics. Inherent to the method is the problem of determining sources in a 3-dimensional space from a 2-dimensional surface topography. This so-called inverse problem does not have a unique solution (<xref ref-type="bibr" rid="bib76">von Helmholtz 1853</xref>), and it is for this very reason that source estimation procedures require assumptions restricting the space of possible solutions (<xref ref-type="bibr" rid="bib22">H&#x000e4;m&#x000e4;l&#x000e4;inen et al. 1993</xref>; <xref ref-type="bibr" rid="bib31">Ilmoniemi 1993</xref>). Methods calculating equivalent current dipoles, ECDs, build upon the assumption that surface topographies are produced by single dipoles or sets of point sources. Difficulties of single or multiple dipole approaches emerge from the distributed character of most cortical activations, which is misrepresented by dipoles, inaccuracies in the estimation of source depth, and difficulties in a priori determining the number of sources (see, e.g., <xref ref-type="bibr" rid="bib24">Hauk 2004</xref>; <xref ref-type="bibr" rid="bib29">Huang et al. 2006</xref>).</p><p>Distributed source estimation techniques are not subject to these problems, as a large number of concurrently active sources is allowed, and a number of source constellations are determined, which all explain the surface topography equally well. One of these solutions is then selected because it is most parsimonious according to mathematically defined criteria. The most established approach, the so-called L2 norm or classical minimum norm solution, minimizes the sum of squares of strength for all coactive sources, and the L1 norm is based on the sum of rectified source strengths (<xref ref-type="bibr" rid="bib31">Ilmoniemi 1993</xref>; <xref ref-type="bibr" rid="bib23">H&#x000e4;m&#x000e4;l&#x000e4;inen and Ilmoniemi 1994</xref>; <xref ref-type="bibr" rid="bib19">Fuchs et al. 1999</xref>). These methods also do have their own specific limitations and disadvantages. The L2 norm is known to make focal sources appear more distributed, resulting in limited spatial resolution, and making it difficult to separate overlapping source time courses, especially if the sources are close together. L1 norm solutions can, in principle, localize focal sources and are therefore less likely to lead to interference between source time courses. However, limitations of this method include its high computational demands, temporal discontinuities (spiking character of source time courses), and spatial instability of the solution (great activation differences between adjacent sources). There are ways to overcome these limitations, for example, by collapsing source data over regions of interest (ROIs) (to compensate for spatial instability) and by sacrificing some of the excellent temporal resolution of MEG (to compensate for temporal discontinuity). In essence, L1 methods have a great potential of tracking the specific time courses of distant cortical sources, while still outperforming L2 in spatial resolution and fMRI in the temporal domain (<xref ref-type="bibr" rid="bib74">Uutela et al. 1999</xref>; <xref ref-type="bibr" rid="bib71">Stenbacka et al. 2002</xref>; <xref ref-type="bibr" rid="bib57">Pulverm&#x000fc;ller et al. 2003</xref>; <xref ref-type="bibr" rid="bib5">Auranen et al. 2005</xref>; <xref ref-type="bibr" rid="bib46">Osipova et al. 2006</xref>).</p><p>Neuroimaging studies applied different strategies to pin down cortical dynamics of memory circuits. Metabolic imaging showed, and it is generally agreed, that language elements, for example, meaningful words and sounds distinguishing between them, are cortically stored as distributed neuronal ensembles binding perception, articulation, and semantic information (<xref ref-type="bibr" rid="bib7">Barsalou 1999</xref>; <xref ref-type="bibr" rid="bib52">Pulverm&#x000fc;ller 1999</xref>, <xref ref-type="bibr" rid="bib53">2005</xref>; <xref ref-type="bibr" rid="bib20">Fuster 2003</xref>; <xref ref-type="bibr" rid="bib60">Rizzolatti and Craighero 2004</xref>; <xref ref-type="bibr" rid="bib16">Feldman 2006</xref>; <xref ref-type="bibr" rid="bib33">Kiefer et al. 2007</xref>). One approach to tackling the dynamics of memory circuit activation in the brain therefore compares meaningful spoken language with nonlinguistic sounds with similar acoustic spectrotemporal characteristics, for example, speech and signal-correlated noise, SCN (<xref ref-type="bibr" rid="bib62">Scott and Johnsrude 2003</xref>). However, in this case, the spectrotemporal match is usually not perfect and differences in brain activation may therefore be driven by the remaining acoustic differences between speech and noise stimuli. A different approach uses familiar meaningful stimuli, for which a memory trace is present in the brain, and meaningless items of a very similar type as controls, as in the comparison of spoken words and meaningless pseudowords (<xref ref-type="bibr" rid="bib28">Holcomb and Neville 1990</xref>; <xref ref-type="bibr" rid="bib10">Compton et al. 1991</xref>; <xref ref-type="bibr" rid="bib8">Bentin et al. 1999</xref>). If averages over large numbers of words and pseudowords are taken, it may appear unlikely that acoustic, phonetic, and phonological features of the stimulus groups differ. However, as a large number of features may differ between different speech and speech-like stimuli, excluding all possibly relevant confounds by stimulus matching appears impossible.</p><p>A solution to the multiple confounds problem in speech research is possible adopting a strategy well established in psychoacoustics, namely investigating brain responses to <italic>identical stimuli</italic>, whose perceptual and cognitive processing is being changed by different contexts (cf. <xref ref-type="bibr" rid="bib40">Micheyl et al. 2003</xref>; <xref ref-type="bibr" rid="bib9">Carlyon 2004</xref>). A research strategy for neuroscience experiments of this type is offered by the MMN paradigm (<xref ref-type="bibr" rid="bib44">N&#x000e4;&#x000e4;t&#x000e4;nen et al. 2001</xref>). Brain responses to frequently presented context stimuli are recorded along with responses to rare deviant stimuli, each of which consists of the context stimulus cross-spliced with the <italic>critical stimulus</italic> attached to its end. As frequent standard stimulus and rare deviant stimulus are, in this case, identical up to the starting point of the critical stimulus, it becomes possible, by calculating the MMN brain response, to subtract out the contribution of the context, just leaving the brain response to the critical part of the deviant stimulus as perceived in the respective context (<xref ref-type="bibr" rid="bib56">Pulverm&#x000fc;ller and Shtyrov 2006</xref>). By changing contexts and subtracting out its contribution to the brain response, specific perceptual and linguistic processes triggered by the critical stimulus in these contexts can thus be monitored.</p><p>Here, we chose contexts that made the critical stimulus item either part of a meaningful word, thus activating a memory network in the brain, or part of a noise stimulus, therefore also changing its perceptual characteristics. Interestingly, there are language sounds that only sound like speech when presented in the context of speech but are, however, perceived as unfamiliar noise if presented in isolation or embedded into sounds other than speech (<xref ref-type="bibr" rid="bib35">Liberman 1996</xref>). The word-final phonemic sound [t] in Finnish, for example, can signal a meaningful grammatical word ending when placed after the stem of a noun or verb. If the brief noise constituting the plosion of the [t] terminates a meaningless spoken syllable, it does not have a clear role as part of a meaningful item, even though it is still perceived as the spoken sound [t]. However, in the context of noise, the very same critical stimulus is perceived as a meaningless unfamiliar chirp-like sound. As a function of context, the same noise burst can therefore generate different percepts thereby creating the opportunity to study acoustic and linguistic processing.</p><p>In the present study, we investigated MEG brain activity elicited by brief noise bursts placed in 4 different contexts (noise, pseudoword, noun, verb context). Previous research indicated that the magnitude and location of cortical activation can distinguish between speech and noise (<xref ref-type="bibr" rid="bib47">Palva et al. 2002</xref>; <xref ref-type="bibr" rid="bib62">Scott and Johnsrude 2003</xref>; <xref ref-type="bibr" rid="bib72">Uppenkamp et al. 2006</xref>). Furthermore, there is much discussion about whether even fine-grained morphological and syntactic information linked to nouns and verbs may be reflected by specific local cortical processes (<xref ref-type="bibr" rid="bib27">Hillis and Caramazza 1995</xref>; <xref ref-type="bibr" rid="bib63">Shapiro and Caramazza 2003b</xref>; <xref ref-type="bibr" rid="bib6">Bak et al. 2006</xref>). Here we ask whether the timing of cortical source activation is speech specific and possibly reflects word and morpheme type.</p><sec sec-type="materials|methods"><title>Materials and Methods</title><sec><title>Subjects</title><p>Participants were 16 healthy right-handed (<xref ref-type="bibr" rid="bib45">Oldfield 1971</xref>) monolingual native speakers of Finnish aged 21&#x02013;39 (6 males) without left-handed family members. They had normal hearing and did not report any history of neurological illness or drug abuse. They were paid for their participation after signing an informed consent form. Ethical permission for the study was granted by the Helsinki University Central Hospital Ethics Board.</p></sec><sec><title>Stimuli</title><p>The standard stimuli were the syllables <italic>vy&#x000f6;, ly&#x000f6;</italic>, and <italic>ry&#x000f6;</italic> and a spectrally similar SCN. The same 4 sounds with the addition of the consonant [t] in the end&#x02014;which, in noise context, sounded like a chirp noise&#x02014;were used as deviant stimuli in their respective recording sessions. Whereas the first and the second word are stems of a Finnish noun and verb, respectively, meaning &#x0201c;belt&#x0201d; and &#x0201c;hit&#x0201d;, the third item is a meaningless pseudoword in Finnish. For stimulus production, the CVV syllables <italic>vy&#x000f6;, ly&#x000f6;,</italic> and <italic>ry&#x000f6;</italic> were spoken repeatedly by a female native speaker of Finnish and recorded digitally (sampling rate 44.1 Hz). As acoustic events following each other within a window of approximately 200 ms may, depending on their spectrotemporal similarity, perceptually interact with each other, possibly giving rise to phenomena such as differential auditory masking, illusions, or streaming (<xref ref-type="bibr" rid="bib41">N&#x000e4;&#x000e4;t&#x000e4;nen 1995</xref>; <xref ref-type="bibr" rid="bib17">Fishman et al. 2001</xref>; <xref ref-type="bibr" rid="bib40">Micheyl et al. 2003</xref>; <xref ref-type="bibr" rid="bib9">Carlyon 2004</xref>), great effort was spent to match the stimuli for a range of acoustic features. To this end, tokens of each syllable type with the same duration and F0 frequency and matched with regard to the envelope of the acoustic wave form were selected and adjusted to have the same sound energy (root mean square of the signal). For producing SCN, we used the spectral characteristics obtained from the speech stimuli using the Fast Fourier Transform. To further approximate the spoken stimulus properties, the amplitude of the noise stimulus was modulated using the temporal envelope of the speech signals. This meticulous stimulus generation was done to ensure, as carefully as possible, that stimuli were matched for acoustic and spectrotemporal characteristics, including length, acoustic energy, spectral composition, and temporal envelope. The resulting 4 &#x0201c;standard&#x0201d; stimuli were all 310 ms long. The final [t] sound in the 4 &#x0201c;deviant&#x0201d; counterparts of these stimuli was obtained from the recording of a similarly matched syllable <italic>ty&#x000f6;t</italic> (to avoid a coarticulation bias, which would have resulted in case the [t] had been spoken directly after one of the actual standards) and was then cross-spliced onto each original CVV syllable after a silent closure time of 55 ms. Stimulus length for these slightly longer &#x0201c;deviant&#x0201d; stimuli was 400 ms, and the onset of the final noise constituting the [t] was always at 365 ms. The word final [t] sound always indicates nominative plural on nouns and second-person singular on verbs. The affixed pseudoword was meaningless.</p><p>To examine the influence of context on the perception of the critical stimulus, the cross-spliced [t]/noise, 7 subjects different from the MEG participants were presented with the 4 deviant stimuli and, in a separate condition, the critical stimulus out of context. Stimulus order was randomized separately for each participant. Ratings of speech likeness of the critical sound on a 10-point scale (1&#x02014;not speech like, 10&#x02014;like natural speech) differed between noise and speech contexts (context <italic>ly&#x000f6;</italic>: mean&#x02009;=&#x02009;6.86 [SE&#x02009;=&#x02009;0.63], <italic>vy&#x000f6;</italic>: 7.71 [0.64], <italic>ry&#x000f6;</italic>: 6.29 [0.99], noise: 3.00 [1.09], out-of-context: 3.29 [0.94], <italic>F</italic><sub>4,24</sub>&#x02009;=&#x02009;8.39, <italic>P</italic> &#x0003c; 0.00022). These psychoacoustic data confirm that the contexts biased the auditory system toward noise or speech perception of the critical stimulus, that is, toward a chirp or [t] sound.</p></sec><sec><title>Design</title><p>In 4 separate blocks, each pair of standard and deviant stimuli, which only differed in the presence or absence of the final chirp noise, was presented in a passive oddball task. In each experimental block, standard and deviant stimuli occurred with a probability of 0.86 and 0.14, respectively. The sequence was pseudorandomized and block order counterbalanced. Presentation was binaural at 50 dB above the individual hearing threshold and the stimulus-onset asynchrony was 900 ms. Crucially, the same critical stimulus and the same acoustic contrast were present in all 4 contexts, that of noun, verb, pseudoword, and noise. As the MMN reflects acoustic stimulus features and especially acoustic contrasts between standard and deviant stimulus (<xref ref-type="bibr" rid="bib42">N&#x000e4;&#x000e4;t&#x000e4;nen and Alho 1997</xref>), the present paradigm controls for acoustic effects on the brain response. A minimum of 150 artifact-free deviant trials were recorded in each block, thus resulting in slightly over 60&#x02032; experimental time. To further control for any possible acoustic effects of the final plosion sound on the MMN, we also obtained brain responses (300 artifact-free trials minimum) to the 4 longer stimuli, each presented repetitively as frequent standard stimulus in a separate recording block. Subjects were instructed to ignore the auditory stimuli but focus their attention on a self-selected video film presented throughout the recording. Video films were silent and did not contain written language.</p></sec><sec><title>MEG Recording and Data Analysis</title><p>Subjects were comfortably seated under the MEG helmet after head coordinates and head shapes had been recorded using a 3D-Space Fasttrack Digitisation system to allow for anatomical colocalization. Nasion and preauricular points were used as anatomical anchor points. The evoked magnetic fields were recorded (passband 0.03&#x02013;200 Hz, sampling rate 600 Hz) with a whole-head 306-channel MEG setup (Elekta Neuromag, Helsinki, Finland) during the auditory stimulation (<xref ref-type="bibr" rid="bib4">Ahonen et al. 1993</xref>). The recordings started 100 ms before stimulus onset and ended 900 ms thereafter. The responses were on line averaged separately for all types of stimuli in each condition. Epochs with voltage variation exceeding 150 &#x003bc;V at either of 2 bipolar eye movement electrodes or with field intensity variation exceeding 3000 femtotesla per centimeter (fT/cm) at any MEG channel were excluded from averaging. The averaged responses were filtered off-line (passband 1&#x02013;20 Hz), and linear detrending was applied on the entire epoch. A silent period of 50 ms before the critical stimulus (chirp/[t] sound) onset was used as the baseline.</p><p>The so-called &#x0201c;identity MMN&#x0201d; (see <xref ref-type="bibr" rid="bib56">Pulverm&#x000fc;ller and Shtyrov 2006</xref>) was obtained for each context condition, noun, verb, pseudoword, and noise, by subtracting the averaged neurophysiological response to the deviant stimulus by the response to the same identical stimulus presented as a frequently repeated item (&#x0201c;control deviant stimulus&#x0201d;, see also <xref ref-type="fig" rid="fig1">Fig. 1</xref>). Estimation of distributed cortical sources was performed using the L1-Minimum Current Estimation module of the Elekta Neuromag MEG analysis software (<xref ref-type="bibr" rid="bib74">Uutela et al. 1999</xref>). Singular value decomposition (SVD) was applied to reduce the influence of noise (<xref ref-type="bibr" rid="bib73">Uusitalo and Ilmoniemi 1997</xref>). To reduce the temporal instability of L1 solutions, source estimations were performed over time intervals of 5 ms. Source solutions were calculated independently for each subject, condition, and time step. To standardize the individual solutions, the current estimates of each subject and the grand average source constellations were projected on the 1231 possible source loci of a triangularized gray matter surface of an averaged brain (<xref ref-type="bibr" rid="bib74">Uutela et al. 1999</xref>). For statistical evaluation, maximum activation values and activation latencies were computed for relatively large (radii ranging between 1 and 2 cm) ellipsoid ROIs, capturing the majority of the inferior&#x02013;frontal, inferior&#x02013;central, and superior&#x02013;temporal areas. These areas were selected because they are most significant for acoustic and speech processes (<xref ref-type="bibr" rid="bib57">Pulverm&#x000fc;ller et al. 2003</xref>; <xref ref-type="bibr" rid="bib72">Uppenkamp et al. 2006</xref>). Large ROIs were chosen to minimize the likelihood of spatial errors and to overcome the spatial instability of local L1 solutions. <xref ref-type="fig" rid="fig2">Figure 2</xref> indicates the left hemispheric inferior&#x02013;frontal, inferior&#x02013;central, and superior&#x02013;temporal ROIs on the triangularized gray matter surface. Homotopic regions were used for the right hemisphere. Maximal source strengths in a time window of 50&#x02013;250 ms after critical stimulus onset were extracted for each subject and condition in the 3 ROIs in both hemispheres. Significance of activation was tested by comparing activation with baseline activity in the same ROIs. ROI-specific activation latencies were determined by measuring the point in time where 50% of the local maximal activation was reached for the first time (latency of half maximum). Local source strengths and latencies were then compared between ROIs and context conditions using repeated-measures analyses of variance and planned comparison <italic>F</italic>-tests.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><p>Stimuli, event-related fields and MMN topographies. (<italic>a</italic>) Critical stimuli presented as frequently repeated items (blue curves) and rare deviant stimuli (red curves) of an oddball paradigm elicited event-related fields that did not differ between each other up to the final [t] sound (vertical lines in the middle). 100&#x02013;150 ms after this critical sound, there was a small N100m response when stimuli were repeatedly presented (see blue curves), with a MMN overlaid on top of it when the critical [t] sound was the rare deviant stimulus (see red curves). The critical difference, the MMN, is shaded in gray. (<italic>b</italic>) The diagrams on the right show the topographies of the MMN recorded above the left and right hemispheres.</p></caption><graphic xlink:href="cercorbhn060f01_4c"/></fig><fig id="fig2" position="float"><label>Figure 2.</label><caption><p>Top diagram: Left hemispheric activation landscape obtained in the present experiment, including foci in superior&#x02013;temporal, central, and inferior&#x02013;frontal cortex. Yellow ellipses indicate the ROIs that formed the basis of statistical source analysis. The time course of activation in the 3 ROIs is shown for the grand average of source estimates for all stimuli taken together.</p></caption><graphic xlink:href="cercorbhn060f02_4c"/></fig></sec></sec><sec><title>Results</title><sec><title>General Pattern of Activation</title><p>Standard stimuli including the context stimuli (noise and CVV stimuli without the critical stimulus, the final [t] sound) and frequently repeated &#x0201c;control deviant&#x0201d; stimuli (which also included the critical stimulus) elicited relatively flat responses reflecting the acoustic dynamics in the input. Critically, event-related fields did not distinguish between the 4 &#x0201c;control deviants,&#x0201d; which were used in the calculation of MMNs. A reliable N100m complex followed the [t] sound in all conditions but did not significantly differentiate between them (blue lines in <xref ref-type="fig" rid="fig1">Fig. 1a</xref>). In contrast, the same items (CVV/noise plus critical stimulus) presented as rare deviant stimuli produced pronounced differences in brain activation between the 4 conditions (red curves in <xref ref-type="fig" rid="fig1">Fig. 1a</xref>). These were equally manifest in the magnetic MMN.</p><p>The subtraction of &#x0201c;control deviant&#x0201d; from deviant responses yielded identity MMNs peaking at 100&#x02013;150 ms after onset of the [t] sound (shaded areas in <xref ref-type="fig" rid="fig1">Fig. 1a</xref>). The percentage of activity underlying the MMN peak that was explained by ROIs (MMN sources in all ROIs divided by the sum of all sources in the entire brain volume) was 92.7%. This implies that the a priori choice of ROIs was appropriate for capturing most of the variance in MMN activation. ROI analysis revealed significant left hemispheric sources of the MMN for each of the 4 deviant stimuli in superior&#x02013;temporal, inferior&#x02013;central, and inferior&#x02013;frontal ROIs (<italic>F</italic> values &#x0003e; 4, <italic>P</italic> values &#x0003c; 0.05). A typical left hemispheric activation pattern is shown in <xref ref-type="fig" rid="fig2">Figure 2</xref>, with ROIs and their dynamics indicated. Whereas superior&#x02013;temporal and inferior&#x02013;central activation were also present in the right hemisphere for all deviants, reliable right inferior&#x02013;frontal activation significantly above the level of the baseline was only seen in the noise and pseudoword conditions. Left hemispheric and superior&#x02013;temporal sources underlying the MMN revealed differences between conditions in the timing of their activation and in their activation strength.</p></sec><sec><title>Activation Time Course Reflects Speech&#x02013;Nonspeech Distinction</title><p>Analysis of MMN activation times in different ROIs indicated simultaneous superior&#x02013;temporal activation in both hemispheres (95 ms on both sides, difference nonsignificant [ns]). Within the left hemisphere, activation times differed between ROIs, <italic>F</italic><sub>2,30</sub>&#x02009;=&#x02009;4.57, <italic>P</italic> &#x0003c; 0.02. Inferior&#x02013;frontal activation tended to follow upon superior&#x02013;temporal activation; the inferior&#x02013;central focus was sparked near simultaneously with the latter. <xref ref-type="fig" rid="fig3">Figures 3</xref> and <xref ref-type="fig" rid="fig4">4</xref> indicate and statistical analysis confirmed that the activation time difference between superior&#x02013;temporal and inferior&#x02013;frontal areas depended on stimulus context. Interestingly, the delay of inferior&#x02013;frontal relative to superior&#x02013;temporal activation was significant for linguistic contexts constituted by nouns, verbs, and pseudowords, <italic>F</italic><sub>1,15</sub> = 11.81, <italic>P</italic> &#x0003c; 0.004, but there was no such difference in ROI activation times for the same critical stimulus presented in noise context (<italic>F</italic> &#x0003c; 1, <xref ref-type="fig" rid="fig3">Fig. 3</xref>).</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><p>Timing of inferior&#x02013;frontal (IF), inferior&#x02013;central (IC), and superior&#x02013;temporal (ST) source activations. Averages over all subjects (bars) and standard errors (lines) of the latencies of half maxima are shown relative to critical stimulus onset. Note the significant differences between ST and IF activation times in the speech conditions but not in the noise condition.</p></caption><graphic xlink:href="cercorbhn060f03_ht"/></fig><fig id="fig4" position="float"><label>Figure 4.</label><caption><p>Illustration of spatiotemporal patterns of MMN brain activity elicited when the critical stimulus was presented in the noun, verb, pseudowords, and noise contexts. Stimulus-specific grand averages of activation landscapes are illustrated for 2 time steps, 100 and 120 ms after critical stimulus onset. Source estimates for the left and right hemisphere are shown side by side for each time segment. Note yellow arrows indicating that superior&#x02013;temporal and inferior&#x02013;frontal sources in the left hemisphere emerged in sequence for words (100 vs 120 ms; see set of diagrams at the top) and simultaneously for noise (100 ms in both areas; diagrams on the lower right).</p></caption><graphic xlink:href="cercorbhn060f04_4c"/></fig><p>Critically, the difference in spatiotemporal patterns between speech and noise became manifest in a statistically significant interaction between the factors stimulus context (speech vs noise) and ROI (inferior&#x02013;frontal vs superior&#x02013;temporal), <italic>F</italic><sub>1,15</sub>&#x02009;=&#x02009;5.37, <italic>P</italic> &#x0003c; 0.04. Half-maxima of superior&#x02013;temporal cortex activation were measured at 97 ms for word and at 91 ms for pseudoword contexts (difference ns); those in inferior&#x02013;frontal cortex followed after a 12 ms delay at 109 and 103 ms, respectively. The comparison of inferior&#x02013;central to inferior&#x02013;frontal activation tended to show the same differences, but in this case statistical tests did not reach significance (<xref ref-type="fig" rid="fig3">Fig. 3</xref>).</p></sec><sec><title>Local Source Strengths Reflect Linguistic Differences</title><p>The strength of early local cortical source activation distinguished between noun, verb, pseudoword, and noise contexts. An analysis of variance compared maximal source strengths in ROIs with significant activation across all stimulus context conditions (left inferior&#x02013;frontal, inferior&#x02013;central, and superior&#x02013;temporal and right superior&#x02013;temporal). There was a main effect of ROI, <italic>F</italic><sub>3,45</sub>&#x02009;=&#x02009;9.14, <italic>P</italic> &#x0003c; 0.0001, and, critically, an interaction of the stimulus context and ROI factors, <italic>F<sub>9,135</sub></italic> = 4.27, <italic>P</italic> &#x0003c; 0.0001 (<xref ref-type="fig" rid="fig5">Figs 5</xref> and <xref ref-type="fig" rid="fig6">6</xref>).</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><p>Differential laterality of superior&#x02013;temporal source strengths. Averages over all participants (bars) and standard errors (lines) of ROI-specific activation are given. Significant superior&#x02013;temporal laterality emerged for speech but not for noise contexts. LH - left hemisphere, RH - right hemisphere, ST - superior-temporal ROI.</p></caption><graphic xlink:href="cercorbhn060f05_ht"/></fig><fig id="fig6" position="float"><label>Figure 6.</label><caption><p>Maximal source strengths elicited in the superior&#x02013;temporal, inferior&#x02013;central and inferior&#x02013;frontal ROIs in the left hemisphere. Averages over all participants (bars) and standard errors (lines) of ROI-specific activation are shown. ST - superior-temporal, IC - inferior-central, IF - inferior-frontal.</p></caption><graphic xlink:href="cercorbhn060f06_ht"/></fig><p>Superior&#x02013;temporal sources in the left and right hemispheres were compared between the 4 conditions, yielding main effects of <italic>laterality</italic> (stronger sources in the left hemisphere; <italic>F</italic><sub>1,15</sub>&#x02009;=&#x02009;4.25, <italic>P</italic> &#x0003c; 0.05) and stimulus context (activation strong for noise and words but weak for pseudowords; <italic>F</italic><sub>3,45</sub> = 3.08, <italic>P</italic> &#x0003c; 0.04). The interaction of both factors was also significant, <italic>F</italic><sub>3,45</sub> = 4.56, <italic>P</italic> &#x0003c; 0.007, demonstrating that laterality changed with stimulus context (<xref ref-type="fig" rid="fig5">Fig. 5</xref>). Planned comparison tests documented significant laterality of superior&#x02013;temporal ROI activation for linguistic contexts (noun, <italic>F</italic><sub>1,15</sub> = 4.40, <italic>P</italic> &#x0003c; 0.03; verb, <italic>F</italic><sub>1,15</sub> = 10.37, <italic>P</italic> &#x0003c; 0.003; pseudoword, <italic>F</italic><sub>1,15</sub> = 5.56, <italic>P</italic> &#x0003c; 0.02) but not for noise context.</p><p>The right hemispheric superior&#x02013;temporal source was largest for noise context and significantly reduced relative to noise for all speech conditions (<italic>F</italic> values &#x0003e;8, <italic>P</italic> values &#x0003c;0.01). Noun contexts yielded stronger right superior&#x02013;temporal activation than verb, <italic>F</italic><sub>1,15</sub> = 9.59, <italic>P</italic> &#x0003c; 0.004, and pseudoword contexts, <italic>F</italic><sub>1,15</sub> = 3.59, <italic>P</italic> &#x0003c; 0.04.</p><p>The left hemispheric superior&#x02013;temporal source was significantly stronger for word than for pseudoword contexts, <italic>F</italic><sub>1,15</sub>&#x02009;=&#x02009;3.23, <italic>P</italic> &#x0003c; 0.05 (cf. <xref ref-type="bibr" rid="bib54">Pulverm&#x000fc;ller et al. 2001</xref>), without a general significant difference between noise and speech stimuli. Left hemispheric inferior&#x02013;central activation, which occurred near simultaneously with the left superior&#x02013;temporal activation, showed a tendency toward the same effects, but comparisons did not reach significance.</p><p>Source dynamics in inferior&#x02013;frontal cortex also showed differences between stimulus contexts, <italic>F</italic><sub>3,45</sub>&#x02009;=&#x02009;2.66, <italic>P</italic> &#x0003c; 0.05. <xref ref-type="fig" rid="fig6">Figure 6</xref> plots source strengths obtained in the 3 left hemispheric ROIs in all 4 conditions. Verb context led to strongest activation (6.1 nAm), followed by noun (4.9 nAm) and pseudoword (4.8 nAm) contexts; noise contexts elicited the smallest activation (4.2 nAm). As the critical stimulus in verb contexts elicited stronger activation than in noun context, <italic>F</italic><sub>1,16</sub> = 4.40, <italic>P</italic> &#x0003c; 0.03, it appears that particularly strong inferior&#x02013;frontal activation observed in this study reflected the processing of grammatical features of inflectional affixes of verbs.</p></sec></sec><sec><title>Discussion</title><p>This study investigated spatiotemporal dynamics of local cortical sources elicited by identical stimuli presented in different contexts, where they were perceived as noise, meaningless sound, and grammatical suffix of noun and verb, respectively. Main findings were the following.</p><list list-type="order"><list-item><p>Timing of local cortical source activations distinguished speech from noise: a significant delay between superior&#x02013;temporal and inferior&#x02013;frontal activation was found to be associated with speech processing (<xref ref-type="fig" rid="fig3">Fig. 3</xref>).</p></list-item><list-item><p>Superior-temporal activation indicated lexical context: magnitude of left superior&#x02013;temporal sources reflected memory trace activation for spoken words. Meaningful noun and verb contexts led to stronger superior&#x02013;temporal source activation than the meaningless pseudoword context (<xref ref-type="fig" rid="fig5">Fig. 5</xref>).</p></list-item><list-item><p>Local cortical activation reflected processing of specific inflectional affixes: left inferior&#x02013;frontal source activation was stronger when verb affixes were processed compared with noun affix processing, and the reverse was found for right superior&#x02013;temporal activation (<xref ref-type="fig" rid="fig5">Figs 5</xref> and <xref ref-type="fig" rid="fig6">6</xref>).</p></list-item></list><p>As the contribution of stimulus contexts to the brain response was removed by using control conditions, this study could reveal brain responses to identical critical stimuli placed in different contexts. Because physically identical stimuli elicited different patterns of magnetic brain activation, we conclude that it was the contextual bias of the cortical processes elicited by these critical stimuli, which led to the differential cortical activation documented. We argue here that the contextual influences on brain activation are related to phonological and semantic levels. One may still argue that differential spectrotemporal similarity between context and critical stimuli could, in theory, lead to differential nonlinguistic early perceptual interactions, as known from streaming or masking (<xref ref-type="bibr" rid="bib17">Fishman et al. 2001</xref>; <xref ref-type="bibr" rid="bib40">Micheyl et al. 2003</xref>, <xref ref-type="bibr" rid="bib39">2007</xref>). However, we would like to draw attention to the meticulous matching of spectrotemporal features of standard stimuli, which, together with the fact that identical critical parts of deviant stimuli were used, would make it unlikely that the spectral differences between stimuli <italic>per se</italic> explain the present results. Such differences may predict an activation difference in superior&#x02013;temporal cortex (possibly even lower structures), where early nonlinguistic perceptual processes are typically manifest but can, in our view, not easily explain the critical observations of the present study about differential laterality and well-timed activation of widespread cortical sources.</p><p>Limitations originating from the impossibility to guarantee exact acoustic and psycholinguistic matching of speech and noise stimuli can be overcome by 1) using identical stimuli perceived and processed differently in different contexts and 2) removing additive contributions of these contexts. As the investigation targeted identical stimuli, the present results allow for conclusions on critical perceptual and cognitive processes, independent of the physical features of the critical stimuli. On the other hand, the use of a small stimulus set may appear as a disadvantage of the present research strategy. Using few well-controlled stimuli to address general questions is, however, an established strategy in a range of research fields, especially in psychophysics and psychoacoustics (<xref ref-type="bibr" rid="bib9">Carlyon 2004</xref>), from where the strategy had been imported to brain science. There are further arguments in favor of a single-item approach. To reveal the earliest brain responses reflecting higher cognitive processes, it is essential to minimize stimulus variance. Averaging over the brain correlates of variable speech stimuli, for example, will blur and possibly remove early focal and short-lived brain activity, therefore making it impossible to study precise early activation time courses (<xref ref-type="bibr" rid="bib56">Pulverm&#x000fc;ller and Shtyrov 2006</xref>). Furthermore, the inflectional system of most languages includes only a small number of inflectional affixes (English has 4 for verbs and 1 for nouns), and, as we demonstrate here, even items as similar as the final &#x0201c;s&#x0201d; in &#x0201c;sees&#x0201d; and &#x0201c;seas&#x0201d; may have different brain correlates. Therefore, some areas of the neuroscience of language require a single-item approach.</p><sec><title>Timing of Local Cortical Sources Tells Speech from Noise</title><p>A significant interaction demonstrated that source activation latencies, and therefore spatiotemporal patterns, differed between noise, pseudoword, and word contexts. There was no significant between-area difference in activation latencies for noise contexts. In contrast, all speech stimuli elicited a significantly earlier superior&#x02013;temporal activation compared with their inferior&#x02013;frontal activation, the relevant delay being 12 ms.</p><p>Earlier MEG work had reported activation spreading from temporal to frontal cortex in response to tone and word stimuli (<xref ref-type="bibr" rid="bib11">Dale et al. 2000</xref>; <xref ref-type="bibr" rid="bib58">Rinne et al. 2000</xref>; <xref ref-type="bibr" rid="bib36">Marinkovic et al. 2003</xref>; <xref ref-type="bibr" rid="bib57">Pulverm&#x000fc;ller et al. 2003</xref>; <xref ref-type="bibr" rid="bib25">Hauk and Pulverm&#x000fc;ller 2004</xref>; <xref ref-type="bibr" rid="bib14">Dhond et al. 2007</xref>). As we show here, the minimal but well-defined delay between superior&#x02013;temporal and inferior&#x02013;frontal sources in the left hemisphere may index the signature of distributed memory circuits for speech. In line with the spatial aspect of the present findings, earlier work has suggested that frontotemporal circuits are involved in speech processing in humans (eg, <xref ref-type="bibr" rid="bib62">Scott and Johnsrude 2003</xref>; <xref ref-type="bibr" rid="bib53">Pulverm&#x000fc;ller 2005</xref>; <xref ref-type="bibr" rid="bib72">Uppenkamp et al. 2006</xref>) and that similar circuits can play a role in animal communication (<xref ref-type="bibr" rid="bib60">Rizzolatti and Craighero 2004</xref>; <xref ref-type="bibr" rid="bib32">Kanwal and Rauschecker 2007</xref>). Our spatiotemporal results suggest that these frontotemporal circuits can be conceptualized as neuronal assemblies whose neuronal elements are held together by long-distance links ensuring precisely timed functional interaction.</p><p>Precisely timed activation patterns, or &#x0201c;neuronal avalanches&#x0201d; (<xref ref-type="bibr" rid="bib50">Plenz and Thiagarajan 2007</xref>), are known from multiple-unit recordings in animals and are commonly attributed to neuronal circuits called synfire chains (<xref ref-type="bibr" rid="bib1">Abeles 1982</xref>). Synfire chains consist of component neuron sets linked to each other in a stepwise manner, thus generating a specific spatiotemporal pattern of neuronal activity when the chain ignites. Neurophysiological evidence from the animal literature supports the existence of synfire chains in local cortical areas and also demonstrated that their activation correlates with specific behaviors (<xref ref-type="bibr" rid="bib3">Abeles et al. 1993</xref>; <xref ref-type="bibr" rid="bib75">Vaadia et al. 1995</xref>; <xref ref-type="bibr" rid="bib50">Plenz and Thiagarajan 2007</xref>). The specific spatiotemporal patterns of activity revealed here by MEG source analysis are best explained by the existence of inter-area synfire chains spread out over superior&#x02013;temporal and inferior&#x02013;frontal cortex and specifically processing speech stimuli. We therefore suggest that the stimulus-elicited activation of long-term memory circuits for spoken words and morphemes contributes to the emergence of the precisely timed pattern of cortical activation spreading between cortical areas.</p><p>Whereas pseudowords may partly activate memory circuits for words and morphemes (<xref ref-type="bibr" rid="bib77">Wennekers et al. 2006</xref>)&#x02014;as reflected by a reduced activation but a still measurable superior&#x02013;temporal inferior&#x02013;frontal time delay&#x02014;unfamiliar noise sounds may not activate corresponding memory traces. Their processing is best described in terms of acoustic processes followed by attention switching (<xref ref-type="bibr" rid="bib58">Rinne et al. 2000</xref>; <xref ref-type="bibr" rid="bib59">Rinne et al. 2005</xref>). The brain signatures for such acoustic processing and attention switching include a symmetric bilateral response in superior&#x02013;temporal cortex (<xref ref-type="bibr" rid="bib44">N&#x000e4;&#x000e4;t&#x000e4;nen et al. 2001</xref>; <xref ref-type="bibr" rid="bib48">Patterson et al. 2002</xref>). The bilateral nature of the frontal brain response to the brief spectrally rich critical stimuli may reflect aspects of their spectrotemporal characteristics (<xref ref-type="bibr" rid="bib78">Zatorre et al. 2002</xref>).</p></sec><sec><title>Left Superior&#x02013;Temporal Activation Indicates Lexical Context</title><p>Memory circuit activation became manifest both in the fine-grained timing of local sources and in their strength. Whereas symmetric strong superior&#x02013;temporal activation was elicited by critical stimuli in noise contexts, speech contexts led to left lateralized superior&#x02013;temporal activity. Therefore, it appears that, similar to the timing of local cortical sources, the laterality of superior&#x02013;temporal activation reflects the speech/noise contrast. However, right frontal activation tended to indicate a different distinction, as it was still significant to noise and pseudoword contexts but insignificant for word contexts (cf. <xref ref-type="bibr" rid="bib68">Shtyrov et al. 2005</xref>).</p><p>Local source strengths distinguished between speech stimuli. Left hemispheric superior&#x02013;temporal activation in word contexts was stronger than that in pseudoword contexts. This lexical enhancement replicates earlier results (<xref ref-type="bibr" rid="bib34">Korpilahti et al. 2001</xref>; <xref ref-type="bibr" rid="bib54">Pulverm&#x000fc;ller et al. 2001</xref>; <xref ref-type="bibr" rid="bib69">Shtyrov and Pulverm&#x000fc;ller 2002</xref>; <xref ref-type="bibr" rid="bib15">Endrass et al. 2004</xref>; <xref ref-type="bibr" rid="bib49">Pettigrew et al. 2004</xref>; <xref ref-type="bibr" rid="bib70">Sittiprapaporn et al. 2004</xref>; <xref ref-type="bibr" rid="bib67">Shtyrov et al. 2007</xref>). The right superior&#x02013;temporal sources reflected the speech&#x02013;noise distinction, as it was stronger for noise than for all speech contexts examined.</p></sec><sec><title>Local Signatures of Inflectional Processing: Noun vs Verb Affixes</title><p>An extensive debate in cognitive neuroscience addresses the question whether nouns and verbs have different brain correlates. In spite of positive results, earlier work addressing this question is still under discussion (<xref ref-type="bibr" rid="bib38">Miceli et al. 1984</xref>; <xref ref-type="bibr" rid="bib12">Damasio and Tranel 1993</xref>; <xref ref-type="bibr" rid="bib13">Daniele et al. 1994</xref>; <xref ref-type="bibr" rid="bib55">Pulverm&#x000fc;ller et al. 1999</xref>; <xref ref-type="bibr" rid="bib66">Shapiro et al. 2005</xref>). Any sets of nouns and verbs are characterized, apart from their membership in different lexical and syntactic categories, by semantic features possibly underlying differences in brain activity these items may elicit. Even if pseudowords are placed in verb and noun contexts, such as &#x0201c;to wug&#x0201d; and &#x0201c;the wug&#x0201d; (<xref ref-type="bibr" rid="bib63">Shapiro and Caramazza 2003</xref>), these contexts constitute a bias toward action or object reading, thus implying semantic differences. A potentially fruitful strategy is offered by the study of inflectional affixes of nouns and verbs, as these items would be linked to noun- and verb-related grammatical information without referring to objects or actions. Also, the inflectional system appears to be a rich target of neuroscience research (<xref ref-type="bibr" rid="bib37">Marslen-Wilson and Tyler 2007</xref>). The present paradigm, where the contribution of processes elicited by noun and verb stems are removed from the brain response, offers a unique opportunity to investigate the brain correlates of grammatical information linked to noun and verb affixes. Surprisingly, we found reliable differences in brain activation between noun and verb affixes. The noun affix led to stronger excitation in right superior&#x02013;temporal cortex than the verb suffix (cf. <xref ref-type="bibr" rid="bib66">Shapiro et al. 2005</xref>), whereas the latter activated left inferior&#x02013;frontal cortex more strongly than the former (cf. <xref ref-type="bibr" rid="bib66">Shapiro et al. 2005</xref>; <xref ref-type="bibr" rid="bib65">Shapiro et al. 2006</xref>). This is consistent with psycholinguistic theories postulating distinct brain mechanisms for grammatical information related to nouns and verbs (cf. <xref ref-type="bibr" rid="bib63">Shapiro and Caramazza 2003</xref>a, 2003b). Critically, our present results suggest highly specific cortical activation patterns and possibly underlying neural circuits for inflectional affixes of nouns and verbs. It appears that these affixes, respectively, spark synfire chains with similar temporal structure but differential interactions between local neuronal assemblies in inferior&#x02013;frontal and superior&#x02013;temporal areas.</p></sec><sec><title>Summary</title><p>Spatiotemporal patterns and local sources extracted from MEG recordings can identify cortical memory circuits of different types. The present results indicate that the speech&#x02013;noise contrast and a range of fine-grained psycholinguistic differences between speech&#x02013;language materials are reflected by spatiotemporal patterns of cortical activity, especially the timing of local cortical sources and by their magnitude. We also report differences in local source strengths in inferior&#x02013;frontal and superior&#x02013;temporal lobe that may index specific morphological processes elicited by noun and verb inflection. Mechanistically, the cortical circuits underlying these specific rapid spatiotemporal patterns revealed by MEG appear as variants of the synfire chains documented by intracortical recordings. As spatiotemporal patterns and local sources differed already 100 ms after stimulation, we note that functional specificity of perceptual and cognitive brain processes arises surprisingly early.</p></sec></sec><sec><title>Funding</title><p>Medical Research Council (U1055.04.003.00001.01, U1055.04.003.00003.01); European Community under the &#x0201c;Information Society Technologies&#x0201d; and the &#x0201c;New and Emerging Science and Technology&#x0201d; Programmes (IST-2001-35282, NESTCOM).</p></sec></body><back><ack><p>We are grateful to Risto Ilmoniemi, Risto N&#x000e4;&#x000e4;t&#x000e4;nen, Ian Nimmo-Smith, Juha Montonen, Elina Pihko, and Johanna Salonen for their contributions to this work at different stages. <italic>Conflict of Interest</italic>: None declared.</p></ack><ref-list><ref id="bib1"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Abeles</surname><given-names>M</given-names></name></person-group><article-title>Local cortical circuits. An electrophysiological study</article-title><year>1982</year><comment>Berlin (Germany): Springer</comment></citation></ref><ref id="bib2"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Abeles</surname><given-names>M</given-names></name></person-group><article-title>Corticonics&#x02014;neural circuits of the cerebral cortex</article-title><year>1991</year><comment>Cambridge (MA): Cambridge University Press</comment></citation></ref><ref id="bib3"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Abeles</surname><given-names>M</given-names></name><name><surname>Bergman</surname><given-names>H</given-names></name><name><surname>Margalit</surname><given-names>E</given-names></name><name><surname>Vaadia</surname><given-names>E</given-names></name></person-group><article-title>Spatiotemporal firing patterns in the frontal cortex of behaving monkeys</article-title><source>J Neurophysiol</source><year>1993</year><volume>70</volume><fpage>1629</fpage><lpage>1638</lpage><pub-id pub-id-type="pmid">8283219</pub-id></citation></ref><ref id="bib4"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ahonen</surname><given-names>AI</given-names></name><name><surname>H&#x000e4;m&#x000e4;l&#x000e4;inen</surname><given-names>MS</given-names></name><name><surname>Ilmoniemi</surname><given-names>RJ</given-names></name><name><surname>Kajola</surname><given-names>MJ</given-names></name><name><surname>Knuutila</surname><given-names>JE</given-names></name><name><surname>Simola</surname><given-names>JT</given-names></name><name><surname>Vilkman</surname><given-names>VA</given-names></name></person-group><article-title>Sampling theory for neuromagnetic detector arrays</article-title><source>IEEE Trans Biomed Eng</source><year>1993</year><volume>40</volume><fpage>859</fpage><lpage>869</lpage><pub-id pub-id-type="pmid">8288276</pub-id></citation></ref><ref id="bib5"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Auranen</surname><given-names>T</given-names></name><name><surname>Nummenmaa</surname><given-names>A</given-names></name><name><surname>Hamalainen</surname><given-names>MS</given-names></name><name><surname>Jaaskelainen</surname><given-names>IP</given-names></name><name><surname>Lampinen</surname><given-names>J</given-names></name><name><surname>Vehtari</surname><given-names>A</given-names></name><name><surname>Sams</surname><given-names>M</given-names></name></person-group><article-title>Bayesian analysis of the neuromagnetic inverse problem with l(p)-norm priors</article-title><source>Neuroimage</source><year>2005</year><volume>26</volume><fpage>870</fpage><lpage>884</lpage><pub-id pub-id-type="pmid">15955497</pub-id></citation></ref><ref id="bib6"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Bak</surname><given-names>TH</given-names></name><name><surname>Yancopoulou</surname><given-names>D</given-names></name><name><surname>Nestor</surname><given-names>PJ</given-names></name><name><surname>Xuereb</surname><given-names>JH</given-names></name><name><surname>Spillantini</surname><given-names>MG</given-names></name><name><surname>Pulverm&#x000fc;ller</surname><given-names>F</given-names></name><name><surname>Hodges</surname><given-names>JR</given-names></name></person-group><article-title>Clinical, imaging and pathological correlates of a hereditary deficit in verb and action processing</article-title><source>Brain</source><year>2006</year><volume>129</volume><fpage>321</fpage><lpage>332</lpage><pub-id pub-id-type="pmid">16330501</pub-id></citation></ref><ref id="bib7"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Barsalou</surname><given-names>LW</given-names></name></person-group><article-title>Perceptual symbol systems</article-title><source>Behav Brain Sci</source><year>1999</year><volume>22</volume><fpage>577</fpage><lpage>609</lpage><comment>discussion 610&#x02013;560</comment><pub-id pub-id-type="pmid">11301525</pub-id></citation></ref><ref id="bib8"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Bentin</surname><given-names>S</given-names></name><name><surname>Mouchetant-Rostaing</surname><given-names>Y</given-names></name><name><surname>Giard</surname><given-names>MH</given-names></name><name><surname>Echallier</surname><given-names>JF</given-names></name><name><surname>Pernier</surname><given-names>J</given-names></name></person-group><article-title>ERP manifestations of processing printed words at different psycholinguistic levels: time course and scalp distribution</article-title><source>J Cogn Neurosci</source><year>1999</year><volume>11</volume><fpage>235</fpage><lpage>260</lpage><pub-id pub-id-type="pmid">10402254</pub-id></citation></ref><ref id="bib9"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Carlyon</surname><given-names>RP</given-names></name></person-group><article-title>How the brain separates sounds</article-title><source>Trends Cogn Sci</source><year>2004</year><volume>8</volume><fpage>465</fpage><lpage>471</lpage><pub-id pub-id-type="pmid">15450511</pub-id></citation></ref><ref id="bib10"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Compton</surname><given-names>PE</given-names></name><name><surname>Grossenbacher</surname><given-names>P</given-names></name><name><surname>Posner</surname><given-names>MI</given-names></name><name><surname>Tucker</surname><given-names>DM</given-names></name></person-group><article-title>A cognitive-anatomical approach to attention in lexical access</article-title><source>J Cogn Neurosci</source><year>1991</year><volume>3</volume><fpage>304</fpage><lpage>312</lpage></citation></ref><ref id="bib11"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Dale</surname><given-names>AM</given-names></name><name><surname>Liu</surname><given-names>AK</given-names></name><name><surname>Fischl</surname><given-names>BR</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name><name><surname>Belliveau</surname><given-names>JW</given-names></name><name><surname>Lewine</surname><given-names>JD</given-names></name><name><surname>Halgren</surname><given-names>E</given-names></name></person-group><article-title>Dynamic statistical parametric mapping: combining fMRI and MEG for high-resolution imaging of cortical activity</article-title><source>Neuron</source><year>2000</year><volume>26</volume><fpage>55</fpage><lpage>67</lpage><pub-id pub-id-type="pmid">10798392</pub-id></citation></ref><ref id="bib12"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Damasio</surname><given-names>AR</given-names></name><name><surname>Tranel</surname><given-names>D</given-names></name></person-group><article-title>Nouns and verbs are retrieved with differently distributed neural systems</article-title><source>Proc Natl Acad Sci U S A</source><year>1993</year><volume>90</volume><fpage>4957</fpage><lpage>4960</lpage><pub-id pub-id-type="pmid">8506341</pub-id></citation></ref><ref id="bib13"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Daniele</surname><given-names>A</given-names></name><name><surname>Giustolisi</surname><given-names>L</given-names></name><name><surname>Silveri</surname><given-names>MC</given-names></name><name><surname>Colosimo</surname><given-names>C</given-names></name><name><surname>Gainotti</surname><given-names>G</given-names></name></person-group><article-title>Evidence for a possible neuroanatomical basis for lexical processing of nouns and verbs</article-title><source>Neuropsychologia</source><year>1994</year><volume>32</volume><fpage>1325</fpage><lpage>1341</lpage><pub-id pub-id-type="pmid">7533275</pub-id></citation></ref><ref id="bib14"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Dhond</surname><given-names>RP</given-names></name><name><surname>Witzel</surname><given-names>T</given-names></name><name><surname>Dale</surname><given-names>AM</given-names></name><name><surname>Halgren</surname><given-names>E</given-names></name></person-group><article-title>Spatiotemporal cortical dynamics underlying abstract and concrete word reading</article-title><source>Hum Brain Mapp</source><year>2007</year><volume>28</volume><fpage>355</fpage><lpage>362</lpage><pub-id pub-id-type="pmid">16944493</pub-id></citation></ref><ref id="bib15"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Endrass</surname><given-names>T</given-names></name><name><surname>Mohr</surname><given-names>B</given-names></name><name><surname>Pulverm&#x000fc;ller</surname><given-names>F</given-names></name></person-group><article-title>Enhanced mismatch negativity brain response after binaural word presentation</article-title><source>Eur J Neurosci</source><year>2004</year><volume>19</volume><fpage>1653</fpage><lpage>1660</lpage><pub-id pub-id-type="pmid">15066161</pub-id></citation></ref><ref id="bib16"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Feldman</surname><given-names>J</given-names></name></person-group><source>From molecule to metaphor: a neural theory of language</source><year>2006</year><publisher-loc>Cambridge (MA)</publisher-loc><publisher-name>MIT Press</publisher-name></citation></ref><ref id="bib17"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Fishman</surname><given-names>YI</given-names></name><name><surname>Reser</surname><given-names>DH</given-names></name><name><surname>Arezzo</surname><given-names>JC</given-names></name><name><surname>Steinschneider</surname><given-names>M</given-names></name></person-group><article-title>Neural correlates of auditory stream segregation in primary auditory cortex of the awake monkey</article-title><source>Hear Res</source><year>2001</year><volume>151</volume><fpage>167</fpage><lpage>187</lpage><pub-id pub-id-type="pmid">11124464</pub-id></citation></ref><ref id="bib18"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Frangos</surname><given-names>J</given-names></name><name><surname>Ritter</surname><given-names>W</given-names></name><name><surname>Friedman</surname><given-names>D</given-names></name></person-group><article-title>Brain potentials to sexually suggestive whistles show meaning modulates the mismatch negativity</article-title><source>Neuroreport</source><year>2005</year><volume>16</volume><fpage>1313</fpage><lpage>1317</lpage><pub-id pub-id-type="pmid">16056131</pub-id></citation></ref><ref id="bib19"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Fuchs</surname><given-names>M</given-names></name><name><surname>Wagner</surname><given-names>M</given-names></name><name><surname>Kohler</surname><given-names>T</given-names></name><name><surname>Wischmann</surname><given-names>HA</given-names></name></person-group><article-title>Linear and nonlinear current density reconstructions</article-title><source>J Clin Neurophysiol</source><year>1999</year><volume>16</volume><fpage>267</fpage><lpage>295</lpage><pub-id pub-id-type="pmid">10426408</pub-id></citation></ref><ref id="bib20"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Fuster</surname><given-names>JM</given-names></name></person-group><article-title>Cortex and mind: unifying cognition</article-title><year>2003</year><comment>New York: Oxford University Press</comment></citation></ref><ref id="bib21"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Fuster</surname><given-names>JM</given-names></name><name><surname>Bodner</surname><given-names>M</given-names></name><name><surname>Kroger</surname><given-names>JK</given-names></name></person-group><article-title>Cross-modal and cross-temporal association in neurons of frontal cortex</article-title><source>Nature</source><year>2000</year><volume>405</volume><fpage>347</fpage><lpage>351</lpage><pub-id pub-id-type="pmid">10830963</pub-id></citation></ref><ref id="bib22"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>H&#x000e4;m&#x000e4;l&#x000e4;inen</surname><given-names>MS</given-names></name><name><surname>Hari</surname><given-names>R</given-names></name><name><surname>Ilmoniemi</surname><given-names>RJ</given-names></name><name><surname>Knuutila</surname><given-names>J</given-names></name><name><surname>Lounasmaa</surname><given-names>OV</given-names></name></person-group><article-title>Magnetoencephalography&#x02014;theory, instrumentation, and applications to noninvasive studies of the working human brain</article-title><source>Rev Mod Phys</source><year>1993</year><volume>65</volume><fpage>413</fpage><lpage>497</lpage></citation></ref><ref id="bib23"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>H&#x000e4;m&#x000e4;l&#x000e4;inen</surname><given-names>MS</given-names></name><name><surname>Ilmoniemi</surname><given-names>RJ</given-names></name></person-group><article-title>Interpreting magnetic fields of the brain: minimum norm estimates</article-title><source>Med Biol Eng Comput</source><year>1994</year><volume>32</volume><fpage>35</fpage><lpage>42</lpage><pub-id pub-id-type="pmid">8182960</pub-id></citation></ref><ref id="bib24"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Hauk</surname><given-names>O</given-names></name></person-group><article-title>Keep it simple: a case for using classical minimum norm estimation in the analysis of EEG and MEG data</article-title><source>Neuroimage</source><year>2004</year><volume>21</volume><fpage>1612</fpage><lpage>1621</lpage><pub-id pub-id-type="pmid">15050585</pub-id></citation></ref><ref id="bib25"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Hauk</surname><given-names>O</given-names></name><name><surname>Pulverm&#x000fc;ller</surname><given-names>F</given-names></name></person-group><article-title>Neurophysiological distinction of action words in the fronto-central cortex</article-title><source>Hum Brain Mapp</source><year>2004</year><volume>21</volume><fpage>191</fpage><lpage>201</lpage><pub-id pub-id-type="pmid">14755838</pub-id></citation></ref><ref id="bib26"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Hauk</surname><given-names>O</given-names></name><name><surname>Shtyrov</surname><given-names>Y</given-names></name><name><surname>Pulverm&#x000fc;ller</surname><given-names>F</given-names></name></person-group><article-title>The sound of actions as reflected by mismatch negativity: rapid activation of cortical sensory-motor networks by sounds associated with finger and tongue movements</article-title><source>Eur J Neurosci</source><year>2006</year><volume>23</volume><fpage>811</fpage><lpage>821</lpage><pub-id pub-id-type="pmid">16487161</pub-id></citation></ref><ref id="bib27"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Hillis</surname><given-names>AE</given-names></name><name><surname>Caramazza</surname><given-names>A</given-names></name></person-group><article-title>Representation of grammatical categories of words in the brain</article-title><source>J Cogn Neurosci</source><year>1995</year><volume>7</volume><fpage>396</fpage><lpage>407</lpage></citation></ref><ref id="bib28"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Holcomb</surname><given-names>PJ</given-names></name><name><surname>Neville</surname><given-names>HJ</given-names></name></person-group><article-title>Auditory and visual semantic priming in lexical decision: a comparison using event-related brain potentials</article-title><source>Lang Cogn Process</source><year>1990</year><volume>5</volume><fpage>281</fpage><lpage>312</lpage></citation></ref><ref id="bib29"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>MX</given-names></name><name><surname>Dale</surname><given-names>AM</given-names></name><name><surname>Song</surname><given-names>T</given-names></name><name><surname>Halgren</surname><given-names>E</given-names></name><name><surname>Harrington</surname><given-names>DL</given-names></name><name><surname>Podgorny</surname><given-names>I</given-names></name><name><surname>Canive</surname><given-names>JM</given-names></name><name><surname>Lewis</surname><given-names>S</given-names></name><name><surname>Lee</surname><given-names>RR</given-names></name></person-group><article-title>Vector-based spatial-temporal minimum L1-norm solution for MEG</article-title><source>Neuroimage</source><year>2006</year><volume>31</volume><fpage>1025</fpage><lpage>1037</lpage><pub-id pub-id-type="pmid">16542857</pub-id></citation></ref><ref id="bib30"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ikegaya</surname><given-names>Y</given-names></name><name><surname>Aaron</surname><given-names>G</given-names></name><name><surname>Cossart</surname><given-names>R</given-names></name><name><surname>Aronov</surname><given-names>D</given-names></name><name><surname>Lampl</surname><given-names>I</given-names></name><name><surname>Ferster</surname><given-names>D</given-names></name><name><surname>Yuste</surname><given-names>R</given-names></name></person-group><article-title>Synfire chains and cortical songs: temporal modules of cortical activity</article-title><source>Science</source><year>2004</year><volume>304</volume><fpage>559</fpage><lpage>564</lpage><pub-id pub-id-type="pmid">15105494</pub-id></citation></ref><ref id="bib31"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ilmoniemi</surname><given-names>RJ</given-names></name></person-group><article-title>Models of source currents in the brain</article-title><source>Brain Topogr</source><year>1993</year><volume>5</volume><fpage>331</fpage><lpage>336</lpage><pub-id pub-id-type="pmid">8357703</pub-id></citation></ref><ref id="bib32"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kanwal</surname><given-names>JS</given-names></name><name><surname>Rauschecker</surname><given-names>JP</given-names></name></person-group><article-title>Auditory cortex of bats and primates: managing species-specific calls for social communication</article-title><source>Front Biosci</source><year>2007</year><volume>12</volume><fpage>4621</fpage><lpage>4640</lpage><pub-id pub-id-type="pmid">17485400</pub-id></citation></ref><ref id="bib33"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kiefer</surname><given-names>M</given-names></name><name><surname>Sim</surname><given-names>EJ</given-names></name><name><surname>Liebich</surname><given-names>S</given-names></name><name><surname>Hauk</surname><given-names>O</given-names></name><name><surname>Tanaka</surname><given-names>J</given-names></name></person-group><article-title>Experience-dependent plasticity of conceptual representations in human sensory-motor areas</article-title><source>J Cogn Neurosci</source><year>2007</year><volume>19</volume><fpage>525</fpage><lpage>542</lpage><pub-id pub-id-type="pmid">17335399</pub-id></citation></ref><ref id="bib34"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Korpilahti</surname><given-names>P</given-names></name><name><surname>Krause</surname><given-names>CM</given-names></name><name><surname>Holopainen</surname><given-names>I</given-names></name><name><surname>Lang</surname><given-names>AH</given-names></name></person-group><article-title>Early and late mismatch negativity elicited by words and speech-like stimuli in children</article-title><source>Brain Lang</source><year>2001</year><volume>76</volume><fpage>332</fpage><lpage>339</lpage><pub-id pub-id-type="pmid">11247648</pub-id></citation></ref><ref id="bib35"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Liberman</surname><given-names>AM</given-names></name></person-group><article-title>Speech: a special code</article-title><year>1996</year></citation></ref><ref id="bib36"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Marinkovic</surname><given-names>K</given-names></name><name><surname>Dhond</surname><given-names>RP</given-names></name><name><surname>Dale</surname><given-names>AM</given-names></name><name><surname>Glessner</surname><given-names>M</given-names></name><name><surname>Carr</surname><given-names>V</given-names></name><name><surname>Halgren</surname><given-names>E</given-names></name></person-group><article-title>Spatiotemporal dynamics of modality-specific and supramodal word processing</article-title><source>Neuron</source><year>2003</year><volume>38</volume><fpage>487</fpage><lpage>497</lpage><pub-id pub-id-type="pmid">12741994</pub-id></citation></ref><ref id="bib37"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Marslen-Wilson</surname><given-names>WD</given-names></name><name><surname>Tyler</surname><given-names>LK</given-names></name></person-group><article-title>Morphology, language and the brain: the decompositional substrate for language comprehension</article-title><source>Philos Trans R Soc Lond B Biol Sci</source><year>2007</year><volume>362</volume><fpage>823</fpage><lpage>836</lpage><pub-id pub-id-type="pmid">17395577</pub-id></citation></ref><ref id="bib38"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Miceli</surname><given-names>G</given-names></name><name><surname>Silveri</surname><given-names>M</given-names></name><name><surname>Villa</surname><given-names>G</given-names></name><name><surname>Caramazza</surname><given-names>A</given-names></name></person-group><article-title>On the basis of agrammatics' difficulty in producing main verbs</article-title><source>Cortex</source><year>1984</year><volume>20</volume><fpage>207</fpage><lpage>220</lpage><pub-id pub-id-type="pmid">6204813</pub-id></citation></ref><ref id="bib39"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Micheyl</surname><given-names>C</given-names></name><name><surname>Carlyon</surname><given-names>RP</given-names></name><name><surname>Gutschalk</surname><given-names>A</given-names></name><name><surname>Melcher</surname><given-names>JR</given-names></name><name><surname>Oxenham</surname><given-names>AJ</given-names></name><name><surname>Rauschecker</surname><given-names>JP</given-names></name><name><surname>Tian</surname><given-names>B</given-names></name><name><surname>Courtenay Wilson</surname><given-names>E</given-names></name></person-group><article-title>The role of auditory cortex in the formation of auditory streams</article-title><source>Hear Res</source><year>2007</year><volume>229</volume><fpage>116</fpage><lpage>131</lpage><pub-id pub-id-type="pmid">17307315</pub-id></citation></ref><ref id="bib40"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Micheyl</surname><given-names>C</given-names></name><name><surname>Carlyon</surname><given-names>RP</given-names></name><name><surname>Shtyrov</surname><given-names>Y</given-names></name><name><surname>Hauk</surname><given-names>O</given-names></name><name><surname>Dodson</surname><given-names>T</given-names></name><name><surname>Pulverm&#x000fc;ller</surname><given-names>F</given-names></name></person-group><article-title>The neurophysiological basis of the auditory continuity illusion: a mismatch negativity study</article-title><source>J Cogn Neurosci</source><year>2003</year><volume>15</volume><fpage>747</fpage><lpage>758</lpage><pub-id pub-id-type="pmid">12965047</pub-id></citation></ref><ref id="bib41"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>N&#x000e4;&#x000e4;t&#x000e4;nen</surname><given-names>R</given-names></name></person-group><article-title>The mismatch negativity: a powerful tool for cognitive neuroscience</article-title><source>Ear Hear</source><year>1995</year><volume>16</volume><fpage>6</fpage><lpage>18</lpage><pub-id pub-id-type="pmid">7774770</pub-id></citation></ref><ref id="bib42"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>N&#x000e4;&#x000e4;t&#x000e4;nen</surname><given-names>R</given-names></name><name><surname>Alho</surname><given-names>K</given-names></name></person-group><article-title>Mismatch negativity&#x02013;the measure for central sound representation accuracy</article-title><source>Audiol Neurootol</source><year>1997</year><volume>2</volume><fpage>341</fpage><lpage>353</lpage><pub-id pub-id-type="pmid">9390839</pub-id></citation></ref><ref id="bib43"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>N&#x000e4;&#x000e4;t&#x000e4;nen</surname><given-names>R</given-names></name><name><surname>Lehtokoski</surname><given-names>A</given-names></name><name><surname>Lennes</surname><given-names>M</given-names></name><name><surname>Cheour</surname><given-names>M</given-names></name><name><surname>Huotilainen</surname><given-names>M</given-names></name><name><surname>Iivonen</surname><given-names>A</given-names></name><name><surname>Valnio</surname><given-names>A</given-names></name><name><surname>Alku</surname><given-names>P</given-names></name><name><surname>Ilmoniemi</surname><given-names>RJ</given-names></name><name><surname>Luuk</surname><given-names>A</given-names></name><etal/></person-group><article-title>Language-specific phoneme representations revealed by electric and magnetic brain responses</article-title><source>Nature</source><year>1997</year><volume>385</volume><fpage>432</fpage><lpage>434</lpage><pub-id pub-id-type="pmid">9009189</pub-id></citation></ref><ref id="bib44"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>N&#x000e4;&#x000e4;t&#x000e4;nen</surname><given-names>R</given-names></name><name><surname>Tervaniemi</surname><given-names>M</given-names></name><name><surname>Sussman</surname><given-names>E</given-names></name><name><surname>Paavilainen</surname><given-names>P</given-names></name><name><surname>Winkler</surname><given-names>I</given-names></name></person-group><article-title>&#x02018;Primitive intelligence&#x02019; in the auditory cortex</article-title><source>Trends Neurosci</source><year>2001</year><volume>24</volume><fpage>283</fpage><lpage>288</lpage><pub-id pub-id-type="pmid">11311381</pub-id></citation></ref><ref id="bib45"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Oldfield</surname><given-names>RC</given-names></name></person-group><article-title>The assessment and analysis of handedness: the Edinburgh Inventory</article-title><source>Neuropsychologia</source><year>1971</year><volume>9</volume><fpage>97</fpage><lpage>113</lpage><pub-id pub-id-type="pmid">5146491</pub-id></citation></ref><ref id="bib46"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Osipova</surname><given-names>D</given-names></name><name><surname>Rantanen</surname><given-names>K</given-names></name><name><surname>Ahveninen</surname><given-names>J</given-names></name><name><surname>Ylikoski</surname><given-names>R</given-names></name><name><surname>Happola</surname><given-names>O</given-names></name><name><surname>Strandberg</surname><given-names>T</given-names></name><name><surname>Pekkonen</surname><given-names>E</given-names></name></person-group><article-title>Source estimation of spontaneous MEG oscillations in mild cognitive impairment</article-title><source>Neurosci Lett</source><year>2006</year><volume>405</volume><fpage>57</fpage><lpage>61</lpage><pub-id pub-id-type="pmid">16854528</pub-id></citation></ref><ref id="bib47"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Palva</surname><given-names>S</given-names></name><name><surname>Palva</surname><given-names>JM</given-names></name><name><surname>Shtyrov</surname><given-names>Y</given-names></name><name><surname>Kujala</surname><given-names>T</given-names></name><name><surname>Ilmoniemi</surname><given-names>RJ</given-names></name><name><surname>Kaila</surname><given-names>K</given-names></name><name><surname>Naatanen</surname><given-names>R</given-names></name></person-group><article-title>Distinct gamma-band evoked responses to speech and non-speech sounds in humans</article-title><source>J Neurosci</source><year>2002</year><volume>22</volume><fpage>RC211</fpage><pub-id pub-id-type="pmid">11844845</pub-id></citation></ref><ref id="bib48"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Patterson</surname><given-names>RD</given-names></name><name><surname>Uppenkamp</surname><given-names>S</given-names></name><name><surname>Johnsrude</surname><given-names>IS</given-names></name><name><surname>Griffiths</surname><given-names>TD</given-names></name></person-group><article-title>The processing of temporal pitch and melody information in auditory cortex</article-title><source>Neuron</source><year>2002</year><volume>36</volume><fpage>767</fpage><lpage>776</lpage><pub-id pub-id-type="pmid">12441063</pub-id></citation></ref><ref id="bib49"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Pettigrew</surname><given-names>CM</given-names></name><name><surname>Murdoch</surname><given-names>BE</given-names></name><name><surname>Ponton</surname><given-names>CW</given-names></name><name><surname>Finnigan</surname><given-names>S</given-names></name><name><surname>Alku</surname><given-names>P</given-names></name><name><surname>Kei</surname><given-names>J</given-names></name><name><surname>Sockalingam</surname><given-names>R</given-names></name><name><surname>Chenery</surname><given-names>HJ</given-names></name></person-group><article-title>Automatic auditory processing of english words as indexed by the mismatch negativity, using a multiple deviant paradigm</article-title><source>Ear Hear</source><year>2004</year><volume>25</volume><fpage>284</fpage><lpage>301</lpage><pub-id pub-id-type="pmid">15179119</pub-id></citation></ref><ref id="bib50"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Plenz</surname><given-names>D</given-names></name><name><surname>Thiagarajan</surname><given-names>TC</given-names></name></person-group><article-title>The organizing principles of neuronal avalanches: cell assemblies in the cortex?</article-title><source>Trends Neurosci</source><year>2007</year><volume>30</volume><fpage>101</fpage><lpage>110</lpage><pub-id pub-id-type="pmid">17275102</pub-id></citation></ref><ref id="bib51"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Prut</surname><given-names>Y</given-names></name><name><surname>Vaadia</surname><given-names>E</given-names></name><name><surname>Bergman</surname><given-names>H</given-names></name><name><surname>Haalman</surname><given-names>I</given-names></name><name><surname>Slovin</surname><given-names>H</given-names></name><name><surname>Abeles</surname><given-names>M</given-names></name></person-group><article-title>Spatiotemporal structure of cortical activity: properties and behavioral relevance</article-title><source>J Neurophysiol</source><year>1998</year><volume>79</volume><fpage>2857</fpage><lpage>2874</lpage><pub-id pub-id-type="pmid">9636092</pub-id></citation></ref><ref id="bib52"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Pulverm&#x000fc;ller</surname><given-names>F</given-names></name></person-group><article-title>Words in the brain's language</article-title><source>Behav Brain Sci</source><year>1999</year><volume>22</volume><fpage>253</fpage><lpage>336</lpage><pub-id pub-id-type="pmid">11301524</pub-id></citation></ref><ref id="bib53"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Pulverm&#x000fc;ller</surname><given-names>F</given-names></name></person-group><article-title>Brain mechanisms linking language and action</article-title><source>Nat Rev Neurosci</source><year>2005</year><volume>6</volume><fpage>576</fpage><lpage>582</lpage><pub-id pub-id-type="pmid">15959465</pub-id></citation></ref><ref id="bib54"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Pulverm&#x000fc;ller</surname><given-names>F</given-names></name><name><surname>Kujala</surname><given-names>T</given-names></name><name><surname>Shtyrov</surname><given-names>Y</given-names></name><name><surname>Simola</surname><given-names>J</given-names></name><name><surname>Tiitinen</surname><given-names>H</given-names></name><name><surname>Alku</surname><given-names>P</given-names></name><name><surname>Alho</surname><given-names>K</given-names></name><name><surname>Martinkauppi</surname><given-names>S</given-names></name><name><surname>Ilmoniemi</surname><given-names>RJ</given-names></name><name><surname>N&#x000e4;&#x000e4;t&#x000e4;nen</surname><given-names>R</given-names></name></person-group><article-title>Memory traces for words as revealed by the mismatch negativity</article-title><source>Neuroimage</source><year>2001</year><volume>14</volume><fpage>607</fpage><lpage>616</lpage><pub-id pub-id-type="pmid">11506534</pub-id></citation></ref><ref id="bib55"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Pulverm&#x000fc;ller</surname><given-names>F</given-names></name><name><surname>Lutzenberger</surname><given-names>W</given-names></name><name><surname>Preissl</surname><given-names>H</given-names></name></person-group><article-title>Nouns and verbs in the intact brain: evidence from event-related potentials and high-frequency cortical responses</article-title><source>Cereb Cortex</source><year>1999</year><volume>9</volume><fpage>498</fpage><lpage>508</lpage></citation></ref><ref id="bib56"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Pulverm&#x000fc;ller</surname><given-names>F</given-names></name><name><surname>Shtyrov</surname><given-names>Y</given-names></name></person-group><article-title>Language outside the focus of attention: the mismatch negativity as a tool for studying higher cognitive processes</article-title><source>Prog Neurobiol.</source><year>2006</year><volume>79</volume><fpage>49</fpage><lpage>71</lpage><pub-id pub-id-type="pmid">16814448</pub-id></citation></ref><ref id="bib57"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Pulverm&#x000fc;ller</surname><given-names>F</given-names></name><name><surname>Shtyrov</surname><given-names>Y</given-names></name><name><surname>Ilmoniemi</surname><given-names>RJ</given-names></name></person-group><article-title>Spatio-temporal patterns of neural language processing: an MEG study using minimum-norm current estimates</article-title><source>Neuroimage</source><year>2003</year><volume>20</volume><fpage>1020</fpage><lpage>1025</lpage><pub-id pub-id-type="pmid">14568471</pub-id></citation></ref><ref id="bib58"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Rinne</surname><given-names>T</given-names></name><name><surname>Alho</surname><given-names>K</given-names></name><name><surname>Ilmoniemi</surname><given-names>RJ</given-names></name><name><surname>Virtanen</surname><given-names>J</given-names></name><name><surname>Naatanen</surname><given-names>R</given-names></name></person-group><article-title>Separate time behaviors of the temporal and frontal mismatch negativity sources</article-title><source>Neuroimage</source><year>2000</year><volume>12</volume><fpage>14</fpage><lpage>19</lpage><pub-id pub-id-type="pmid">10875898</pub-id></citation></ref><ref id="bib59"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Rinne</surname><given-names>T</given-names></name><name><surname>Degerman</surname><given-names>A</given-names></name><name><surname>Alho</surname><given-names>K</given-names></name></person-group><article-title>Superior temporal and inferior frontal cortices are activated by infrequent sound duration decrements: an fMRI study</article-title><source>Neuroimage</source><year>2005</year><volume>26</volume><fpage>66</fpage><lpage>72</lpage><pub-id pub-id-type="pmid">15862206</pub-id></citation></ref><ref id="bib60"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Rizzolatti</surname><given-names>G</given-names></name><name><surname>Craighero</surname><given-names>L</given-names></name></person-group><article-title>The mirror-neuron system</article-title><source>Annu Rev Neurosci</source><year>2004</year><volume>27</volume><fpage>169</fpage><lpage>192</lpage><pub-id pub-id-type="pmid">15217330</pub-id></citation></ref><ref id="bib61"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Rizzolatti</surname><given-names>G</given-names></name><name><surname>Fogassi</surname><given-names>L</given-names></name><name><surname>Gallese</surname><given-names>V</given-names></name></person-group><article-title>Neurophysiological mechanisms underlying the understanding and imitation of action</article-title><source>Nat Rev Neurosci</source><year>2001</year><volume>2</volume><fpage>661</fpage><lpage>670</lpage><pub-id pub-id-type="pmid">11533734</pub-id></citation></ref><ref id="bib62"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Scott</surname><given-names>SK</given-names></name><name><surname>Johnsrude</surname><given-names>IS</given-names></name></person-group><article-title>The neuroanatomical and functional organization of speech perception</article-title><source>Trends Neurosci</source><year>2003</year><volume>26</volume><fpage>100</fpage><lpage>107</lpage><pub-id pub-id-type="pmid">12536133</pub-id></citation></ref><ref id="bib63"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Shapiro</surname><given-names>K</given-names></name><name><surname>Caramazza</surname><given-names>A</given-names></name></person-group><article-title>Grammatical processing of nouns and verbs in left frontal cortex?</article-title><source>Neuropsychologia</source><year>2003a</year><volume>41</volume><fpage>1189</fpage><lpage>1198</lpage><pub-id pub-id-type="pmid">12753958</pub-id></citation></ref><ref id="bib64"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Shapiro</surname><given-names>K</given-names></name><name><surname>Caramazza</surname><given-names>A</given-names></name></person-group><article-title>The representation of grammatical categories in the brain</article-title><source>Trends Cogn Sci</source><year>2003b</year><volume>7</volume><fpage>201</fpage><lpage>206</lpage><pub-id pub-id-type="pmid">12757821</pub-id></citation></ref><ref id="bib65"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Shapiro</surname><given-names>KA</given-names></name><name><surname>Moo</surname><given-names>LR</given-names></name><name><surname>Caramazza</surname><given-names>A</given-names></name></person-group><article-title>Cortical signatures of noun and verb production</article-title><source>Proc Natl Acad Sci U S A</source><year>2006</year><volume>103</volume><fpage>1644</fpage><lpage>1649</lpage><pub-id pub-id-type="pmid">16432232</pub-id></citation></ref><ref id="bib66"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Shapiro</surname><given-names>KA</given-names></name><name><surname>Mottaghy</surname><given-names>FM</given-names></name><name><surname>Schiller</surname><given-names>NO</given-names></name><name><surname>Poeppel</surname><given-names>TD</given-names></name><name><surname>Fluss</surname><given-names>MO</given-names></name><name><surname>Muller</surname><given-names>HW</given-names></name><name><surname>Caramazza</surname><given-names>A</given-names></name><name><surname>Krause</surname><given-names>BJ</given-names></name></person-group><article-title>Dissociating neural correlates for nouns and verbs</article-title><source>Neuroimage</source><year>2005</year><volume>24</volume><fpage>1058</fpage><lpage>1067</lpage><pub-id pub-id-type="pmid">15670683</pub-id></citation></ref><ref id="bib67"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Shtyrov</surname><given-names>Y</given-names></name><name><surname>Osswald</surname><given-names>K</given-names></name><name><surname>Pullverm&#x000fc;ller</surname><given-names>F</given-names></name></person-group><article-title>Memory traces for spoken words in the brain as revealed by the haemodynamic correlate of the mismatch negativity (MMN)</article-title><source>Cereb Cortex</source><year>2008</year><volume>18</volume><issue>1</issue><fpage>29</fpage><lpage>37</lpage><pub-id pub-id-type="pmid">17412721</pub-id></citation></ref><ref id="bib68"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Shtyrov</surname><given-names>Y</given-names></name><name><surname>Pihko</surname><given-names>E</given-names></name><name><surname>Pulverm&#x000fc;ller</surname><given-names>F</given-names></name></person-group><article-title>Determinants of dominance: is language laterality explained by physical or linguistic features of speech?</article-title><source>Neuroimage</source><year>2005</year><volume>27</volume><fpage>37</fpage><lpage>47</lpage><pub-id pub-id-type="pmid">16023039</pub-id></citation></ref><ref id="bib69"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Shtyrov</surname><given-names>Y</given-names></name><name><surname>Pulverm&#x000fc;ller</surname><given-names>F</given-names></name></person-group><article-title>Memory traces for inflectional affixes as shown by the mismatch negativity</article-title><source>Eur J Neurosci</source><year>2002</year><volume>15</volume><fpage>1085</fpage><lpage>1091</lpage><pub-id pub-id-type="pmid">11918667</pub-id></citation></ref><ref id="bib70"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Sittiprapaporn</surname><given-names>W</given-names></name><name><surname>Chindaduangratn</surname><given-names>C</given-names></name><name><surname>Kotchabhakdi</surname><given-names>N</given-names></name></person-group><article-title>Long-term memory traces for familiar spoken words in tonal languages as revealed by the Mismatch Negativity</article-title><source>Songkjla Nakharin J Sci Technol</source><year>2004</year><volume>26</volume><fpage>1</fpage><lpage>8</lpage></citation></ref><ref id="bib71"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Stenbacka</surname><given-names>L</given-names></name><name><surname>Vanni</surname><given-names>S</given-names></name><name><surname>Uutela</surname><given-names>K</given-names></name><name><surname>Hari</surname><given-names>R</given-names></name></person-group><article-title>Comparison of minimum current estimate and dipole modeling in the analysis of simulated activity in the human visual cortices</article-title><source>Neuroimage</source><year>2002</year><volume>16</volume><fpage>936</fpage><lpage>943</lpage><pub-id pub-id-type="pmid">12202081</pub-id></citation></ref><ref id="bib72"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Uppenkamp</surname><given-names>S</given-names></name><name><surname>Johnsrude</surname><given-names>IS</given-names></name><name><surname>Norris</surname><given-names>D</given-names></name><name><surname>Marslen-Wilson</surname><given-names>W</given-names></name><name><surname>Patterson</surname><given-names>RD</given-names></name></person-group><article-title>Locating the initial stages of speech-sound processing in human temporal cortex</article-title><source>Neuroimage</source><year>2006</year><volume>31</volume><fpage>1284</fpage><lpage>1296</lpage><pub-id pub-id-type="pmid">16504540</pub-id></citation></ref><ref id="bib73"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Uusitalo</surname><given-names>MA</given-names></name><name><surname>Ilmoniemi</surname><given-names>RJ</given-names></name></person-group><article-title>Signal-space projection method for separating MEG or EEG into components</article-title><source>Med Biol Eng Comput</source><year>1997</year><volume>35</volume><fpage>135</fpage><lpage>140</lpage><pub-id pub-id-type="pmid">9136207</pub-id></citation></ref><ref id="bib74"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Uutela</surname><given-names>K</given-names></name><name><surname>H&#x000e4;m&#x000e4;l&#x000e4;inen</surname><given-names>M</given-names></name><name><surname>Somersalo</surname><given-names>E</given-names></name></person-group><article-title>Visualization of magnetoencephalographic data using minimum current estimates</article-title><source>Neuroimage</source><year>1999</year><volume>10</volume><fpage>173</fpage><lpage>180</lpage><pub-id pub-id-type="pmid">10417249</pub-id></citation></ref><ref id="bib75"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Vaadia</surname><given-names>E</given-names></name><name><surname>Haalman</surname><given-names>I</given-names></name><name><surname>Abeles</surname><given-names>M</given-names></name><name><surname>Bergman</surname><given-names>H</given-names></name><name><surname>Prut</surname><given-names>Y</given-names></name><name><surname>Slovin</surname><given-names>H</given-names></name><name><surname>Aertsen</surname><given-names>A</given-names></name></person-group><article-title>Dynamics of neuronal interactions in monkey cortex in relation to behavioural events</article-title><source>Nature</source><year>1995</year><volume>373</volume><fpage>515</fpage><lpage>518</lpage><pub-id pub-id-type="pmid">7845462</pub-id></citation></ref><ref id="bib76"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>von Helmholtz</surname><given-names>H</given-names></name></person-group><article-title>&#x000dc;ber einige Gesetze der Vertheilung elektrischer Str&#x000f6;me in k&#x000f6;rperlichen Leitern, mit Anwendung auf die thierisch-elektrischen Versuche</article-title><source>Ann Phys Chem</source><year>1853</year><volume>89</volume><fpage>211</fpage><fpage>353</fpage><lpage>233</lpage><lpage>377</lpage></citation></ref><ref id="bib77"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Wennekers</surname><given-names>T</given-names></name><name><surname>Garagnani</surname><given-names>M</given-names></name><name><surname>Pulverm&#x000fc;ller</surname><given-names>F</given-names></name></person-group><article-title>Language models based on Hebbian cell assemblies</article-title><source>J Physiol Paris</source><year>2006</year><volume>100</volume><fpage>16</fpage><lpage>30</lpage><pub-id pub-id-type="pmid">17081735</pub-id></citation></ref><ref id="bib78"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Zatorre</surname><given-names>RJ</given-names></name><name><surname>Belin</surname><given-names>P</given-names></name><name><surname>Penhune</surname><given-names>VB</given-names></name></person-group><article-title>Structure and function of auditory cortex: music and speech</article-title><source>Trends Cogn Sci</source><year>2002</year><volume>6</volume><fpage>37</fpage><lpage>46</lpage><pub-id pub-id-type="pmid">11849614</pub-id></citation></ref></ref-list></back></article>