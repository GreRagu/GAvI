<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN" "archivearticle.dtd"><article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article" xml:lang="EN"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id><journal-id journal-id-type="publisher-id">bioinformatics</journal-id><journal-id journal-id-type="hwp">bioinfo</journal-id><journal-title>Bioinformatics</journal-title><issn pub-type="ppub">1367-4803</issn><issn pub-type="epub">1460-2059</issn><publisher><publisher-name>Oxford University Press</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">18940828</article-id><article-id pub-id-type="pmc">2639296</article-id><article-id pub-id-type="doi">10.1093/bioinformatics/btn546</article-id><article-id pub-id-type="publisher-id">btn546</article-id><article-categories><subj-group subj-group-type="heading"><subject>Original Papers</subject><subj-group><subject>Sequence Analysis</subject></subj-group></subj-group></article-categories><title-group><article-title>Prediction of kinase-specific phosphorylation sites using conditional random fields</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Dang</surname><given-names>Thanh Hai</given-names></name><xref ref-type="aff" rid="AFF1"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Van Leemput</surname><given-names>Koenraad</given-names></name><xref ref-type="aff" rid="AFF1"><sup>2</sup></xref></contrib><contrib contrib-type="author"><name><surname>Verschoren</surname><given-names>Alain</given-names></name><xref ref-type="aff" rid="AFF1"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Laukens</surname><given-names>Kris</given-names></name><xref ref-type="aff" rid="AFF1"><sup>1</sup></xref><xref ref-type="corresp" rid="COR1">*</xref></contrib></contrib-group><aff id="AFF1"><sup>1</sup>Intelligent Systems Laboratory and <sup>2</sup>Advanced Database Research and Modelling, Department of Mathematics and Computer Science, Middelheimlaan 1, B-2020 Antwerpen, Belgium</aff><author-notes><corresp id="COR1">*To whom correspondence should be addressed.</corresp><fn><p>Associate Editor: Alex Bateman</p></fn></author-notes><pub-date pub-type="ppub"><day>15</day><month>12</month><year>2008</year></pub-date><pub-date pub-type="epub"><day>20</day><month>10</month><year>2008</year></pub-date><pub-date pub-type="pmc-release"><day>20</day><month>10</month><year>2008</year></pub-date><volume>24</volume><issue>24</issue><fpage>2857</fpage><lpage>2864</lpage><history><date date-type="received"><day>14</day><month>7</month><year>2008</year></date><date date-type="rev-recd"><day>12</day><month>9</month><year>2008</year></date><date date-type="accepted"><day>17</day><month>10</month><year>2008</year></date></history><permissions><copyright-statement>&#x000a9; 2008 The Author(s)</copyright-statement><copyright-year>2008</copyright-year><license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by-nc/2.0/uk/"><p><!--CREATIVE COMMONS-->This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/2.0/uk/">http://creativecommons.org/licenses/by-nc/2.0/uk/</ext-link>) which permits unrestricted non-commercial use, distribution, and reproduction in any medium, provided the original work is properly cited.</p></license></permissions><abstract><p><bold>Motivation:</bold> Phosphorylation is a crucial post-translational protein modification mechanism with important regulatory functions in biological systems. It is catalyzed by a group of enzymes called kinases, each of which recognizes certain target sites in its substrate proteins. Several authors have built computational models trained from sets of experimentally validated phosphorylation sites to predict these target sites for each given kinase. All of these models suffer from certain limitations, such as the fact that they do not take into account the dependencies between amino acid motifs within protein sequences in a global fashion.</p><p><bold>Results:</bold> We propose a novel approach to predict phosphorylation sites from the protein sequence. The method uses a positive dataset to train a conditional random field (CRF) model. The negative training dataset is used to specify the decision threshold corresponding to a desired false positive rate. Application of the method on experimentally verified benchmark phosphorylation data (Phospho.ELM) shows that it performs well compared to existing methods for most kinases. This is to our knowledge that the first report of the use of CRFs to predict post-translational modification sites in protein sequences.</p><p><bold>Availability:</bold> The source code of the implementation, called CRPhos, is available from <ext-link ext-link-type="uri" xlink:href="http://www.ptools.ua.ac.be/CRPhos/">http://www.ptools.ua.ac.be/CRPhos/</ext-link></p><p><bold>Contact:</bold> <email>kris.laukens@ua.ac.be</email></p><p><bold>Suplementary Information:</bold> Supplementary data are available at <ext-link ext-link-type="uri" xlink:href="http://www.ptools.ua.ac.be/CRPhos/">http://www.ptools.ua.ac.be/CRPhos/</ext-link></p></abstract></article-meta></front><body><sec sec-type="intro" id="SEC1"><title>1 INTRODUCTION</title><p>Protein phosphorylation is an essential type of post-translational modification that consists of the addition of a phosphate (PO<sub>4</sub>) group to serine (S), threonine (T), tyrosine (Y) and to a lesser extent histidine (H) residues. The process is catalyzed by a group of enzymes called kinases, and can be reverted by phosphatases. Phosphorylation has important implications on the function of a protein. If an enzyme gets phosphorylated its activity may be stimulated or inhibited, for example, leading to altered metabolic fluxes in the case of a metabolic enzyme, or resulting in the modulation of a regulatory effect if the substrate protein plays a regulatory role. The human genome encodes more than 500 different kinases, many of which have been related to cancer and other diseases (Manning <italic>et al.</italic>, <xref ref-type="bibr" rid="B20">2002</xref>). They regulate a diverse range of biochemical pathways and biological functions and are often indispensable signal integrators in a living system. Being one of the most important reversible mechanisms of post-translational modification, phosphorylation is a prevalent subject of research in biochemistry.</p><p>A first step towards elucidating the phosphorylation network consists of the determination of the phosphorylated residues in a substrate protein for a given kinase. Revealing the exact position of a phosphorylation in a sequence is essential to get irrefutable evidence for the assignment of a protein as a kinase substrate. It also provides powerful clues for biomedical drug design or other biotechnological applications. Phosphorylation sites on substrates are usually experimentally determined by mass spectrometry-based techniques (reviewed by Jensen, <xref ref-type="bibr" rid="B16">2004</xref>). This has led to several databases of phosphorylation sites, often tied to specific species, such as &#x02018;The Phosphorylation Site Database&#x02019; (Gnad <italic>et al.</italic>, <xref ref-type="bibr" rid="B9">2007</xref>), &#x02018;Phospho.ELM&#x02019; (Diella <italic>et al.</italic>, <xref ref-type="bibr" rid="B5">2004</xref>, <xref ref-type="bibr" rid="B6">2008</xref>), &#x02018;PhosphoSite&#x02019; (Hornbeck, <xref ref-type="bibr" rid="B11">2004</xref>) and &#x02018;PhosPhAt&#x02019; (Heazlewood <italic>et al.</italic>, <xref ref-type="bibr" rid="B10">2008</xref>). Performing such experiments, however, remains time consuming, labor intensive and expensive. These disadvantages have been anticipated by the bioinformatics community with the development of predictive models that are trained with experimentally annotated and known phosphorylation sites. These models can be used to predict potential target sequences and thus significantly reduce the number of sequences that need to be verified by mass spectrometry.</p><p>Several computational models have been built and applied with varying success to predict phosphorylation sites, including hidden Markov models (HMMs) (Huang <italic>et al.</italic>, <xref ref-type="bibr" rid="B13">2005b</xref>), neural networks (Blom <italic>et al.</italic>, <xref ref-type="bibr" rid="B1">1999</xref>, <xref ref-type="bibr" rid="B2">2004</xref>; Ingrell <italic>et al.</italic>, <xref ref-type="bibr" rid="B15">2007</xref>), group-based scoring method (Xue <italic>et al.</italic>, <xref ref-type="bibr" rid="B32">2005</xref>; Zhou <italic>et al.</italic>, <xref ref-type="bibr" rid="B34">2004</xref>), Bayesian decision theory (Xue <italic>et al.</italic>, <xref ref-type="bibr" rid="B33">2006</xref>), support vector machines (SVMs) (Kim <italic>et al.</italic>, <xref ref-type="bibr" rid="B17">2004</xref>; Plewczynski <italic>et al.</italic>, <xref ref-type="bibr" rid="B27">2005</xref>, <xref ref-type="bibr" rid="B28">2008</xref>; Wong <italic>et al.</italic>, <xref ref-type="bibr" rid="B31">2007</xref>) and algorithms to identify short protein sequence motifs on recognized substrates (Neuberger <italic>et al.</italic>, <xref ref-type="bibr" rid="B24">2007</xref>; Obenauer <italic>et al.</italic>, <xref ref-type="bibr" rid="B25">2003</xref>). Particularly the flanking sequence (typically -4,+4) around the potential sites (S/Y/T) is often used to develop these models. Apart from the protein sequence, some additional information has also been integrated, including disorder information (Iakoucheva <italic>et al.</italic>, <xref ref-type="bibr" rid="B14">2004</xref>), structure information (Blom <italic>et al.</italic>, <xref ref-type="bibr" rid="B1">1999</xref>) and the distribution of the phosphorylated sites (Moses <italic>et al.</italic>, <xref ref-type="bibr" rid="B23">2007</xref>). The majority of the computational models dedicated to predicting phosphorylation sites use the experimentally validated database Phospho.ELM (Diella <italic>et al.</italic>, <xref ref-type="bibr" rid="B5">2004</xref>, <xref ref-type="bibr" rid="B6">2008</xref>) for training and for the evaluation of their performance. Due to the fact that for some particular kinases in Phospho.ELM only a small number of phosphorylated sites is known, the annotated Swiss-Prot database (Boeckmann <italic>et al.</italic>, <xref ref-type="bibr" rid="B3">2003</xref>) is often used in complement to increase the size of the training and testing dataset.</p><p>In this article, we introduce a novel machine learning scheme that overcomes several disadvantages associated with existing methods. The model is based on conditional random fields (CRFs) (Lafferty <italic>et al.</italic>, <xref ref-type="bibr" rid="B19">2001</xref>) and allows prediction of phosphorylated sites for each specific kinase separately. The positive and negative datasets are flanking sequences of amino acids around the potentially phosphorylated residues. Information about the chemical classes that individual amino acids belong to is also incorporated. The CRF model is trained from only the positive training dataset. The key idea of this approach is to generate the probability distribution for the positive data samples. This derived distribution takes the probability values of the positive training dataset, calculated from the corresponding learned CRF model, as its values. Within a set of protein sequences, the number of truly phosphorylated sites is always small compared to the number of non-phosphorylated sites. To overcome this difficulty, we apply Chebyshev's Inequality from statistics theory to find high confidence boundaries of the derived distribution. These boundaries are used to select a part of the negative training data, which is then used to calculate a decision threshold based on a user-provided allowed false positive rate. To evaluate the performance of the method, <italic>k</italic>-fold cross-validations were performed on the experimentally verified phosphorylation dataset. This new method performs well according to commonly used measures.</p></sec><sec sec-type="methods" id="SEC2"><title>2 METHODS</title><p>CRFs were introduced initially for solving the problem of labeling sequence data that arises in scientific fields such as bioinformatics and natural language processing. In sequence labeling problems, each data item <italic>x</italic><sub><italic>i</italic></sub> is a sequence of observations {<italic>x</italic><sub><italic>i</italic>1</sub>,<italic>x</italic><sub><italic>i</italic>2</sub>,&#x02026;,<italic>x</italic><sub><italic>iT</italic></sub>}. The purpose of the technique is to make a prediction of the sequence labels, that is, <italic>y</italic><sub><italic>i</italic></sub>={<italic>y</italic><sub><italic>i</italic>1</sub>,<italic>y</italic><sub><italic>i</italic>2</sub>,&#x02026;,<italic>y</italic><sub><italic>iT</italic></sub>}, corresponding to this sequence of observations.</p><p>So far, in addition to CRFs, some probabilistic models have been introduced to tackle this problem, such as HMMs (Freitag and McCallum <italic>et al.</italic>, <xref ref-type="bibr" rid="B8">2000</xref>) and maximum entropy Markov models (MEMMs) (McCallum, <italic>et al.</italic>, <xref ref-type="bibr" rid="B8">2000</xref>). In this section, we review and compare these models, before motivating and discussing our choice for the CRFs scheme.</p><sec id="SEC2.1"><title>2.1 Review of existing models</title><p>An HMM is one of the most common methods for performing sequence labeling. It is a generative model that maximizes the joint probability distribution <italic>p</italic>(<italic>X</italic>, <italic>Y</italic>), where <italic>X</italic> and <italic>Y</italic> are random variables whose values take on all observation sequences and corresponding label sequences, respectively. To calculate the joint probability, HMMs need to enumerate all possible observation sequences. This is intractable when the number of atomic observations becomes large. Moreover the interacting range between positions in a sequence is often long. First-order HMMs relax these strict constraints by working with two assumptions. The first one is the fact that a prediction of a future observation only depends on the present one (or on the immediate previous one). As a result we have <italic>p</italic>(<italic>X</italic><sub><italic>t</italic>+1</sub>&#x02223;<italic>X</italic><sub><italic>t</italic></sub>,<italic>X</italic><sub><italic>t</italic>&#x02212;1</sub>,&#x02026;,<italic>X</italic><sub>1</sub>)=<italic>p</italic>(<italic>X</italic><sub><italic>t</italic>+1</sub>&#x02223;<italic>X</italic><sub><italic>t</italic></sub>). The second assumption is the time invariant or stationary: <italic>p</italic>(<italic>X</italic><sub><italic>t</italic>+1</sub>&#x02223;<italic>X</italic><sub><italic>t</italic></sub>)=<italic>p</italic>(<italic>X</italic><sub>2</sub>&#x02223;<italic>X</italic><sub>1</sub>).</p><p>These limitations of HMMs in particular and generative models in general are the motivation behind the introduction of conditional models. By maximizing the conditional probability <italic>p</italic>(<italic>Y</italic>&#x02223;<italic>X</italic>) from the training dataset, conditional models do not explicitly model the observation sequences. Furthermore, these models remain valid if dependencies between arbitrary features exist in the observation sequences, and they do not need to account for these arbitrary dependencies. The probability of a transition between labels may not only depend on the current observation but also on past and future observations. MEMMs (McCallum <italic>et al.</italic>, <xref ref-type="bibr" rid="B22">2000</xref>) are a typical group of conditional probabilistic models. Each state in a MEMM has an exponential model that takes the observation features as input, and outputs the distribution over the possible next states. These exponential models are trained by an appropriate iterative scaling method in the maximum entropy framework.</p><p>On the other hand, MEMMs and non-generative finite state models based on next-state classifiers are all victims of a weakness called <italic>label bias</italic> (Lafferty <italic>et al.</italic>, <xref ref-type="bibr" rid="B19">2001</xref>). In these models, the transitions leaving a given state compete only against each other, rather than against all other transitions in the model. The total score mass arriving at a state must be distributed and observed over all next states. An observation may affect which state will be the next, but does not affect the total weight passed on to it. This will result in a bias in the distribution of the total score weight at a state with fewer next states. In particular, if a state has only one out-going transition, the total score weight will be transferred regardless of the observation. A simple example of the label bias problem has been introduced in the work of Lafferty <italic>et al.</italic> (<xref ref-type="bibr" rid="B19">2001</xref>).</p></sec><sec id="SEC2.2"><title>2.2 Conditional random fields</title><p>CRFs are discriminative probabilistic models that not only inherit all advantages of MEMMs but also overcome the label bias weakness. While MEMMs use exponential models of the current state to calculate the conditional probabilities of the next states, CRFs use a single exponential model for the conditional probability of all training labels, given the observation sequence. Therefore, the weight of an arbitrary feature can be learned from its global interactions with all the other features. This means that the weights of all the features within CRFs can be traded-off against each other. CRFs have been applied to some common problems in natural language processing, such as NP (noun phrase)-chunking, POS (part of speech)-tagging and text segmentation (Sha and Pereira, <xref ref-type="bibr" rid="B29">2003</xref>), and the experimental results are significantly better than those from HMMs and MEMMs.</p><p>In CRFs, the dependencies between the label components of a random variable <italic>Y</italic> are represented by an undirected graph <italic>G</italic>=(<italic>E</italic>,<italic>V</italic>). Let <italic>C</italic> be a set of cliques in graph <italic>G</italic>. Suppose that there exists a set of <italic>K</italic> feature functions <italic>f</italic><sub><italic>k</italic></sub> (<italic>c</italic>,<italic>X</italic>) predefined in each clique <italic>c</italic>&#x02208;<italic>C</italic>, where <inline-formula><inline-graphic xlink:href="btn546i1.jpg"/></inline-formula>. According to the Hammersley&#x02013;Clifford theorem, the conditional probability of a label sequence given the observation sequence is calculated as follows (Sha and Pereira, <xref ref-type="bibr" rid="B29">2003</xref>):<disp-formula id="M1"><label>(1)</label><graphic xlink:href="btn546m1.jpg" position="float"/></disp-formula>Here <italic>Z</italic><sub><italic>o</italic></sub> is the normalization function defined over all possible label sequences and &#x003c6;(<italic>c</italic>,<italic>X</italic>) is called the potential function of clique <bold><italic>c</italic></bold>. This is a non-negative real-valued function and is defined as follows:<disp-formula id="M2"><label>(2)</label><graphic xlink:href="btn546m2.jpg" position="float"/></disp-formula>The parameters &#x003b1;<sub><italic>k</italic></sub> are learned globally from a labeled training dataset. Although the graph <italic>G</italic> of <italic>Y</italic> may have a general structure for the problem of modeling the sequence the most simple and important structure is the linear chain structure. Several authors have previously applied CRFs with a linear structure and obtained good performances (Lafferty <italic>et al.</italic>, <xref ref-type="bibr" rid="B19">2001</xref>; Sha and Pereira, <xref ref-type="bibr" rid="B29">2003</xref>). Within a linear structure, each clique is an edge with two end points. The conditional probability formula can then be rewritten as follows:<disp-formula id="M3"><label>(3)</label><graphic xlink:href="btn546m3.jpg" position="float"/></disp-formula>In this formula <italic>Y</italic>&#x02223;<sub><italic>e</italic></sub>, <italic>Y</italic>&#x02223;<sub><italic>v</italic></sub> are components of the random variable <italic>Y</italic> corresponding to the edges and vertices of graph <italic>G</italic>, respectively. The function <italic>g</italic><sub><italic>k</italic></sub> and <italic>h</italic><sub><italic>k</italic></sub> are the respective feature functions for the state&#x02013;observation pair and the state&#x02013;state pair. These are real-valued functions but are often defined as Boolean functions. In the domain of phosphorylation site prediction, these feature functions, <italic>g</italic><sub>1</sub> for example, can be defined as follows:<disp-formula id="M4"><label>(4)</label><graphic xlink:href="btn546m4.jpg" position="float"/></disp-formula>Here <italic>AA</italic><sub>&#x02212;3</sub>=&#x0201c;R&#x0201d; means &#x02018;<italic>The amino acid three positions left from current AA is R&#x02019;</italic> and <italic>L</italic>(<italic>AA</italic><sub>0</sub>)=&#x0201c;Phos&#x0201d; means &#x02018;<italic>The label of the current amino acid is phosphorylated&#x02019;</italic>.</p><p>As explained in the <xref ref-type="sec" rid="SEC3.1">Section 3.1</xref>, the state&#x02013;state pair feature functions (<italic>h</italic><sub><italic>k</italic></sub> in formula 3) are not declared in our implementation. Several authors have proposed methods to efficiently induce such feature functions from datasets (Lafferty <italic>et al.</italic>, <xref ref-type="bibr" rid="B19">2001</xref>; McCallum, <xref ref-type="bibr" rid="B21">2003</xref>; Pietra <italic>et al.</italic>, <xref ref-type="bibr" rid="B26">1997</xref>).</p><p>The weights of the CRFs are learned from the training dataset {<italic>x</italic><sub><italic>i</italic></sub>,<italic>y</italic><sub><italic>i</italic></sub>} to maximize the conditional log likelihood of label sequences {<italic>y</italic><sub><italic>i</italic></sub>} (Sha and Pereira, <xref ref-type="bibr" rid="B29">2003</xref>).<disp-formula id="M5"><label>(5)</label><graphic xlink:href="btn546m5.jpg" position="float"/></disp-formula>This likelihood function in CRFs is convex when the training label sequences (i.e. a series of the labels &#x02018;phosphorylated&#x02019; and &#x02018;non-phosphorylated&#x02019;) make the state sequences (i.e. a series of amino acids) unambiguous (McCallum, <xref ref-type="bibr" rid="B21">2003</xref>). In the case of phosphorylation site prediction this means that the training labels do corroborate the substrate specificity of the kinase. This situation happens often in practice. It guarantees that the global maximum value of the log likelihood of the conditional probability <italic>L</italic> will be found.</p></sec><sec id="SEC2.3"><title>2.3 Proposed algorithm</title><p>In this section, we introduce an algorithm that has all of the advantages of the CRFs discussed in the above section. The algorithm follows a <italic>novelty</italic> detection approach, as previously successfully implemented in gene prioritization by De Bie <italic>et al.</italic> (<xref ref-type="bibr" rid="B4">2007</xref>). It builds a CRF model <italic>M</italic><sup>+</sup> for all training data objects that belong to the positive class. In this application, we designed the features or patterns according to the motifs described in the biochemical literature on phosphorylation site prediction (reviewed by Kobe <italic>et al.</italic>, <xref ref-type="bibr" rid="B18">2005</xref>). All patterns used are listed in the <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/cgi/content/full/btn546/DC1">Supplementary Material</ext-link>. If this set of features and patterns is well designed, the probabilities <italic>p</italic>(+&#x02223;<italic>x</italic>, <italic>M</italic><sup>+</sup>) that a positive training data object <italic>x</italic> is labeled as positive (+) are guaranteed to be the global maximum. This is due to the convex characteristic of the conditional log likelihood function in CRFs. They will distribute mainly near the largest probability value 1. Furthermore, according to Chebyshev's Inequality (Ewens and Grant, <xref ref-type="bibr" rid="B7">2001</xref>), given a random variable <italic>X</italic> and a real number <italic>n</italic>&#x0003e;0, <italic>p</italic>(&#x02223;<italic>X</italic>&#x02212;<italic>E</italic>(<italic>X</italic>)&#x02223;&#x02265;<italic>n</italic>&#x003c3;)&#x02264;1/<italic>n</italic><sup>2</sup>. Here <italic>E</italic>(<italic>X</italic>)and &#x003c3;<sup>2</sup> denote the expected value and the variance of variable <italic>X</italic>, respectively. This means that the confidence degree of a value of <italic>X</italic> belonging to the range [<italic>E</italic>(<italic>X</italic>)&#x02212;<italic>n</italic>*&#x003c3;,<italic>E</italic>(<italic>X</italic>)+<italic>n</italic>*&#x003c3;] is larger than (1&#x02212;1/<italic>n</italic><sup>2</sup>). For example, with <italic>n</italic>=3, the confidence degree is &#x0003e;89%. From now this interval will be referred to as the <italic>n-confidence interval</italic>. When applied to the distribution of the probability values <italic>p</italic>(+&#x02223;<italic>x</italic>, <italic>M</italic><sup>+</sup>), the expected value can be estimated by the average value of all values <italic>p</italic>(+&#x02223;<italic>x</italic>, <italic>M</italic><sup>+</sup>), with <italic>x</italic> being the positive training data objects. The <italic>n-confidence interval</italic> is enlarged by increasing the value <italic>n</italic> until the upper bound equals 1. This interval is used in the proposed algorithm to overcome the difficulty that the number of examples in the positive training dataset is very small. Due to the guarantee of obtaining the global maximum of the CRFs, the <italic>n-confidence interval</italic> is expected to contain all values <italic>p</italic>(+&#x02223;<italic>x</italic>, <italic>M</italic><sup>+</sup>) of all real positive data objects.</p><p>Moreover, the negative training dataset may contain some phosphorylated residues that have not yet been experimentally verified as such. These negative data will then get high probabilities&#x02014;within the <italic>n-confidence interval</italic>&#x02014;of being labeled as positive, and will not be considered during the process of controlling the false positive rate of the obtained classifier.</p><p><inline-formula><inline-graphic xlink:href="btn546i2.jpg"/></inline-formula></p><p>A new data object will be classified as positive if the probability of classifying it as positive given the model <italic>M</italic><sup>+</sup> is greater than or equal to the threshold &#x003b8;.</p><p>In all experiments, we used the open source software tool CRF++<ext-link ext-link-type="uri" xlink:href="http://crfpp.sourceforge.net/">http://crfpp.sourceforge.net/</ext-link> to build the model.</p></sec></sec><sec sec-type="results|discussion" id="SEC3"><title>3 RESULTS AND DISCUSSION</title><sec id="SEC3.1"><title>3.1 Implementation</title><p>We used the Phospho.ELM (Diella <italic>et al.</italic>, <xref ref-type="bibr" rid="B6">2008</xref>) (version 0707) database to experimentally evaluate our approach. This dataset has been used as a benchmark to test the performance of most computational phosphorylation prediction models previously published. Phospho.ELM contains experimentally verified phosphorylation sites in eukaryotic proteins, manually curated from the literature. It stores information about substrate proteins with the exact positions of the residues that are experimentally verified to be phosphorylated by a given kinase. For each potentially phosphorylated residue (S, T or Y), we extracted the nine amino acid sequence, including the central residue, surrounding it (from -4 to +4). All of these sequences of which the central residue was annotated as phosphorylated by a given kinase were considered as the positive set, whereas all remaining 9mer sequences on the same substrate proteins, were considered as negative examples. Following Kim <italic>et al.</italic> (<xref ref-type="bibr" rid="B17">2004</xref>), we discarded highly homologous sequences (over 70% identity) from the positive and negative training dataset to avoid overestimation on accuracy when cross-validating. Such bias appears if the testing data are highly homologous to the training data. The number of positive and negative samples for different kinases, after removing the redundancies, is shown in <xref ref-type="table" rid="T1">Table 1</xref>. There are clearly much more negative samples than positive ones. Apart from the amino acid itself, the chemical/structural group that an amino acid belongs to is used as an additional feature for each residue. Twenty amino acids were grouped into eight different clusters (<xref ref-type="table" rid="T2">Table 2</xref>) according to their common chemical/structural properties (Wong <italic>et al.</italic>, <xref ref-type="bibr" rid="B31">2007</xref>). For each position in the positive sequence data, a set of Boolean value feature functions was declared, including functions for amino acids (e.g. formula 4), for chemical groups (e.g. formula 6) and for combinations of amino acids and chemical groups (e.g. formula 7).<disp-formula id="M6"><label>(6)</label><graphic xlink:href="btn546m6.jpg" position="float"/></disp-formula><disp-formula id="M7"><label>(7)</label><graphic xlink:href="btn546m7.jpg" position="float"/></disp-formula>Here <italic>G</italic><sub>&#x02212;3</sub>=&#x0201c;<italic>Sulfur</italic>&#x0201d;means &#x02018;<italic>The chemical group of the amino acid (AA) three positions left from the current AA belongs to the cluster Sulfur&#x02019;</italic> and <italic>L</italic>(<italic>AA</italic><sub>0</sub>)=&#x0201c;<italic>Phos</italic>&#x0201d; means &#x02018;<italic>The label of the current amino acid is phosphorylated&#x02019;</italic>.<table-wrap id="T1" position="float"><label>Table 1.</label><caption><p>The size of positive and negative datasets for some common protein kinases, obtained from Phospho.ELM version 0707</p></caption><table frame="hsides" rules="groups"><thead align="left"><tr><th rowspan="1" colspan="1">Protein kinase</th><th rowspan="1" colspan="1">Positive size</th><th rowspan="1" colspan="1">Negative size</th></tr></thead><tbody align="left"><tr><td rowspan="1" colspan="1">Abl(Proto-oncogene tyrosine-protein kinase)</td><td rowspan="1" colspan="1">45</td><td rowspan="1" colspan="1">1209</td></tr><tr><td rowspan="1" colspan="1">ATM (Ataxia telangiectasia mutated)</td><td rowspan="1" colspan="1">55</td><td rowspan="1" colspan="1">1882</td></tr><tr><td rowspan="1" colspan="1">CaM-KII (Calcium/calmodulin-dependent protein kinases)</td><td rowspan="1" colspan="1">50</td><td rowspan="1" colspan="1">1829</td></tr><tr><td rowspan="1" colspan="1">CDK (Cyclin-dependent kinases)</td><td rowspan="1" colspan="1">104</td><td rowspan="1" colspan="1">1990</td></tr><tr><td rowspan="1" colspan="1">CK1 (Casein kinases 1)</td><td rowspan="1" colspan="1">42</td><td rowspan="1" colspan="1">1051</td></tr><tr><td rowspan="1" colspan="1">CK2 (Casein kinases 2)</td><td rowspan="1" colspan="1">226</td><td rowspan="1" colspan="1">3875</td></tr><tr><td rowspan="1" colspan="1">DNA-PK (DNA-dependent protein kinase catalytic subunit)</td><td rowspan="1" colspan="1">20</td><td rowspan="1" colspan="1">632</td></tr><tr><td rowspan="1" colspan="1">EGFR (Epidermal growth factor receptor)</td><td rowspan="1" colspan="1">44</td><td rowspan="1" colspan="1">823</td></tr><tr><td rowspan="1" colspan="1">Fyn (Proto-oncogene tyrosine-protein kinase)</td><td rowspan="1" colspan="1">48</td><td rowspan="1" colspan="1">1409</td></tr><tr><td rowspan="1" colspan="1">GSK-3 (Glycogen synthase kinases 3)</td><td rowspan="1" colspan="1">32</td><td rowspan="1" colspan="1">866</td></tr><tr><td rowspan="1" colspan="1">InsR (Insulin receptor)</td><td rowspan="1" colspan="1">44</td><td rowspan="1" colspan="1">724</td></tr><tr><td rowspan="1" colspan="1">Met (Hepatocyte growth factor receptor)</td><td rowspan="1" colspan="1">13</td><td rowspan="1" colspan="1">132</td></tr><tr><td rowspan="1" colspan="1">mTOR (FK506 binding protein 12-rapamycin associated protein 1)</td><td rowspan="1" colspan="1">13</td><td rowspan="1" colspan="1">50</td></tr><tr><td rowspan="1" colspan="1">PKA (cAMP-dependent protein kinase)</td><td rowspan="1" colspan="1">310</td><td rowspan="1" colspan="1">8823</td></tr><tr><td rowspan="1" colspan="1">PKB (Protein kinases B)</td><td rowspan="1" colspan="1">79</td><td rowspan="1" colspan="1">3563</td></tr><tr><td rowspan="1" colspan="1">PKC (Protein kinase)</td><td rowspan="1" colspan="1">227</td><td rowspan="1" colspan="1">4428</td></tr><tr><td rowspan="1" colspan="1">Src (Proto-oncogene tyrosine-protein kinase)</td><td rowspan="1" colspan="1">141</td><td rowspan="1" colspan="1">2681</td></tr><tr><td rowspan="1" colspan="1">Syk (Tyrosine-protein kinase)</td><td rowspan="1" colspan="1">45</td><td rowspan="1" colspan="1">680</td></tr></tbody></table></table-wrap><table-wrap id="T2" position="float"><label>Table 2.</label><caption><p>The chemical classes to which the 20 amino acids belong, based on Wong <italic>et al.</italic> (<xref ref-type="bibr" rid="B31">2007</xref>)</p></caption><table frame="hsides" rules="groups"><thead align="left"><tr><th rowspan="1" colspan="1">Group name</th><th rowspan="1" colspan="1">Amino Acids</th></tr></thead><tbody align="left"><tr><td rowspan="1" colspan="1">Sulfur</td><td rowspan="1" colspan="1">C, M</td></tr><tr><td rowspan="1" colspan="1">Aliphatic 1</td><td rowspan="1" colspan="1">A, G, P</td></tr><tr><td rowspan="1" colspan="1">Aliphatic 2</td><td rowspan="1" colspan="1">I, L, V</td></tr><tr><td rowspan="1" colspan="1">Acid</td><td rowspan="1" colspan="1">D, E</td></tr><tr><td rowspan="1" colspan="1">Base</td><td rowspan="1" colspan="1">H, K, R</td></tr><tr><td rowspan="1" colspan="1">Aromatic</td><td rowspan="1" colspan="1">F, W, Y</td></tr><tr><td rowspan="1" colspan="1">Amide</td><td rowspan="1" colspan="1">N, Q</td></tr><tr><td rowspan="1" colspan="1">Small hydroxy</td><td rowspan="1" colspan="1">S, T</td></tr></tbody></table></table-wrap></p><p>When applying the algorithm (<xref ref-type="sec" rid="SEC2.3">Section 2.3</xref>) to build a predictive model from the positive (i.e. central residue is phosphorylated) and negative (i.e. central residue is not phosphorylated) sequence data, the conditional probabilities in Steps 4 and 7 are probabilities of the central residues in the sequence data having the label &#x02018;Phos&#x02019; (i.e. &#x02018;phosphorylated&#x02019;). These probabilities are equivalent to the total sum of the probabilities of all possible label sequences of which the central labels are &#x02018;Phos&#x02019;, assigned by a CRF given the flanking sequence of amino acids. This increases the computational complexity of the algorithm due to the required enumeration of all possible surrounding labels.</p><p>To tackle this problem, we introduce a transferring method that is applied to the sequence data as follows. Each nine-residue long amino acid sequence is represented in an equivalent form, where the center residue (S, Y or T) is a data object and the surrounding residues themselves and their corresponding features become the new features (<xref ref-type="fig" rid="F1">Fig. 1</xref>). The information about the positions of the residues is conserved, thus the CRF model still has the ability to exploit the meaning of residue positions if suitable feature functions (<italic>g</italic><sub><italic>k</italic></sub>) are used. The state&#x02013;state feature functions (<italic>h</italic><sub><italic>k</italic></sub>, formula 3) are not further declared since the dependencies between labeling information of the surrounding amino acids is omitted in this new representation.<fig id="F1" position="float"><label>Fig. 1.</label><caption><p>Method for transforming an amino acid sequence to a data object of the central amino acid.</p></caption><graphic xlink:href="btn546f1"/></fig></p></sec><sec id="SEC3.2"><title>3.2 Evaluation</title><p>To evaluate the performance of the algorithm, <italic>k</italic>-fold cross-validation was used for the model trained from the large datasets, whereas Jackknife cross-validation was applied when the models were trained with less than 30 positives. Each cross-validation was performed 20 times, and after each round we calculated Sensitivity (Sn)=TP/(TP+FN) and Specificity (Sp)=TN/(TN+FP). Here TP, TN, FP and FN are true positive, true negative, false positive and false negative values, respectively. The average values after 20 runs were used as the final measure of the performance for the model.</p><p>For each kinase-specific phosphorylation predictor, the ROC (receiver operating characteristic) curve, which shows the tradeoff between sensitivity and specificity, was generated from the final average. The ROC curves obtained from different <italic>k</italic>-fold cross-validations (<italic>k</italic>=2, 4, 6, 8, 10) were approximately the same (data not shown). For the sake of clarity, all shown ROC curves are the result from 10-fold cross-validation (<xref ref-type="fig" rid="F3">Fig. 3</xref> and <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/cgi/content/full/btn546/DC1">Supplementary figures</ext-link>, blue lines). All ROC curves, except CDK1 and PKB, reach 100% sensitivity with a specificity of at least 20%. Because the number of positives is much smaller than the number of negatives, this implies a significant reduction in the number of required validations, even if no false negatives are desired.</p><p>We also validated whether the observed specificity value of a classifier generated from the method is close to the expected value. For each value of an expected specificity, a 4-fold cross-validation procedure was implemented 20 times. The average observed specificity was calculated and compared with the expected value (<xref ref-type="fig" rid="F2">Fig. 2</xref>). These values were identical for kinases with a negative training dataset larger than 1500. For kinases with a smaller negative training set, the smallest regression coefficient was 0.97, for the &#x02018;mTOR&#x02019; kinase, of which the number of negative training sequences was only 50. As a consequence, the algorithm can return any desired point (classifier) on the ROC curve based on taking into account an expected specificity value as input.<fig id="F2" position="float"><label>Fig. 2.</label><caption><p>Relation between expected and observed specificity values of obtained predictor. All lines are generated using linear regression.</p></caption><graphic xlink:href="btn546f2"/></fig></p><p>The model proposed in this article uses the positive dataset for training, and uses the negative data to calculate a decision threshold. In order to demonstrate the efficiency of this approach, we also tested a conventional approach, using both the positive and negative data for training a CRF model. For this experiment, the nine amino acid protein sequences from both the positive and the negative dataset were taken as input to the learning algorithm of the CRFs. The derived ROC curves are shown in red in <xref ref-type="fig" rid="F3">Figure 3</xref> and in the <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/cgi/content/full/btn546/DC1">Supplementary Material</ext-link>. For most kinases, this conventional approach results in a slightly worse ROC curve, indicating that our approach outperforms the application of CRFs trained on both positive and negative data.<fig id="F3" position="float"><label>Fig. 3.</label><caption><p>ROC curves of our method for some well-studied kinases, using 10-fold cross-validation (CRPhos). CRF* stands for the equivalent curve for a CRF model learned from both the positive and negative training dataset. For comparison, corresponding performance measures reported in literature are shown: PPSP (Xue <italic>et al.</italic>, <xref ref-type="bibr" rid="B33">2006</xref>), Scansite (Obenauer <italic>et al.</italic>, <xref ref-type="bibr" rid="B25">2003</xref>), NetPhosK (Blom <italic>et al.</italic>, <xref ref-type="bibr" rid="B2">2004</xref>), KinasePhos 1.0 (Huang <italic>et al.</italic>, <xref ref-type="bibr" rid="B12">2005a</xref>), KinasePhos 2.0 (Wong <italic>et al.</italic>, <xref ref-type="bibr" rid="B31">2007</xref>), GPS (Zhou <italic>et al.</italic>, <xref ref-type="bibr" rid="B34">2004</xref>) and PredPhospho (Kim <italic>et al.</italic>, <xref ref-type="bibr" rid="B17">2004</xref>).</p></caption><graphic xlink:href="btn546f3"/></fig></p></sec><sec id="SEC3.3"><title>3.3 Comparison</title><p>The derived ROC curves allow for easy comparison of our method with reported performance measures from other methods. We followed two different approaches.</p><p>The approach applied by most authors of phosphorylation site prediction methods, is the direct comparison of obtained results with previously reported performances (Huang <italic>et al.</italic>, <xref ref-type="bibr" rid="B12">2005a</xref>; Kim <italic>et al.</italic>, <xref ref-type="bibr" rid="B17">2004</xref>; Zhou <italic>et al.</italic>, <xref ref-type="bibr" rid="B34">2004</xref>). If available, performance values, reported in literature as pairs of sensitivities/specificities, were shown as colored dots on the ROC plots for each kinase method (<xref ref-type="fig" rid="F3">Fig. 3</xref> and <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/cgi/content/full/btn546/DC1">Supplementary Fig. 1</ext-link>). These values can be considered worse or better, depending on whether these dots fall below or above the CRPhos ROC curve, respectively. In most cases, CRPhos yielded a performance that is comparable or better than other methods. (SVMs-based approaches applied in Predphospho (Kim <italic>et al.</italic>, <xref ref-type="bibr" rid="B17">2004</xref>) and KinasePhos 2.0 (Wong <italic>et al.</italic>, <xref ref-type="bibr" rid="B31">2007</xref>) do perform better in some instances (e.g. both in CK2, KinasePhos 2.0 in PKC, PredPhospho in CDK), but worse in other cases (both in PKA, PredPhospho in PKC). However, both predictors have been validated on data of which the size of the negative and positive subset has been equalized, in contrast to this article. Compared with PPSP (Xue <italic>et al.</italic>, <xref ref-type="bibr" rid="B33">2006</xref>), CRPhos performs better for the majority of the kinases, but worse or similar for a few. From all kinases, only the prediction for CK2 by CRPhos is generally worse than those by other prediction methods, although even then CRPhos achieves both sensitivity and specificity values above 80%. NetphosK could only be compared for PKA and ATM, yielding worse and better performance, respectively. Except for CK2, CRPhos performs similar or better than the other methods, including GPS (Zhou <italic>et al.</italic>, <xref ref-type="bibr" rid="B34">2004</xref>), Scansite (Obenauer <italic>et al.</italic>, <xref ref-type="bibr" rid="B25">2003</xref>) and KinasePhos 1.0 (Huang <italic>et al.</italic>, <xref ref-type="bibr" rid="B12">2005a</xref>).</p><p>There is a chance that the version of the dataset, which is different for previously published models, affects the above comparison. An ideal solution to perform an unbiased comparison is running new cross-validations on all existing methods using the same dataset that we used. This is practically hard to achieve since trainable versions of most tools are not available. An alternative solution consists of testing and comparing our method and other existing ones on the same testing dataset. There is however a high chance to get a biased comparison if some testing data are already learned by one of the methods.</p><p>To eliminate this problem, a more rigorous approach was recently deployed by Wan <italic>et al.</italic> (<xref ref-type="bibr" rid="B30">2008</xref>). They generated a subset of Phospho.ELM, called MetaPS06, which contains the phosphorylation sites that were only recently added, after publication of existing prediction models. This MetaPS06 set does not overlap with any previously used training data. By testing this dataset against different prediction tools, Wan and Colleagues (<xref ref-type="bibr" rid="B30">2008</xref>) obtained comparable performance measurements that represent the predictive power of each tool. To generate equivalent performance values, we removed from Phosphos.ELM version 07 all phosphorylated sites originated from Phospho.ELM version 06 (with annotation data &#x0003c;12/31/2004), as described (Wan <italic>et al.</italic>, <xref ref-type="bibr" rid="B30">2008</xref>). For this experiment the removed dataset was used to train the CRPhos model, whereas the remaining fraction was used for testing. The results (<xref ref-type="fig" rid="F4">Fig. 4</xref>) demonstrate that the performance of CRPhos remains better than the performance of most other methods. Unlike other methods, CRPhos learns the model only from the &#x02018;golden&#x02019; positive dataset and not from the &#x02018;un-golden&#x02019; negative dataset. This negative dataset could contain some real phosphorylated (positive) data that have not yet been experimentally validated. This may cause a bias in the prediction by models that are trained from both positive and negative data.<fig id="F4" position="float"><label>Fig. 4.</label><caption><p>Performance of CRPhos with the testing dataset that is created according to the scheme in Wan <italic>et al.</italic> (<xref ref-type="bibr" rid="B30">2008</xref>). The remaining dataset after removing this testing data from Phospho.ELM v.07 was used to train CRPhos. The performance measure of other existing methods, reported by Wan <italic>et al.</italic> (<xref ref-type="bibr" rid="B30">2008</xref>), are shown for comparison.</p></caption><graphic xlink:href="btn546f4"/></fig></p><p>Moreover, we also cross-validated our model using the older versions of Phospho.ELM. versions 06 &#x00026; 1206. <ext-link ext-link-type="uri" xlink:href="http://bioinformatics.oxfordjournals.org/cgi/content/full/btn546/DC1">Supplementary Figure 2</ext-link> demonstrates that this has almost no effect on the performance.</p><p>A significant advantage of the method described in this article lies in the fact that it is able to generate predictions for all possible specificity values. Any classifier, defined by a point in the ROC curve, can be readily obtained, whereas other approaches are only able to generate one classifier with a fixed sensitivity/specificity.</p></sec></sec><sec sec-type="conclusions" id="SEC4"><title>4 CONCLUSION</title><p>In this article, we introduced a novel approach based on CRFs to predict kinase-specific phosphorylation sites. Upon validation with a real dataset of phosphorylation sites, the method yielded accurate predictions that were similar or better than predictions obtained with existing methods. This is consistent with the theoretical advantages of CRFs, including the convergence to the global maximum of the log likelihood conditional probability and the capability of capturing all amino acid motifs and their interactions in a global fashion.</p><p>Our approach employs Chebyshev's Inequality to find the confidence interval for the distribution of the real positive data. As a result, it overcomes the difficulty that, in reality, the size of the experimentally verified positive data is very small compared to that of the negative data. Moreover, the use of Chebyshev's Inequality also allows eliminating the noisy negative data, which may contain target sites that have not yet been experimentally assigned as positive.</p><p>Finally, this method allows obtaining an optimal prediction for any given allowed false positive rate. This gives the end-user extra flexibility, especially when applied in situations where either incomplete detection, or false positives are undesired.</p></sec><sec sec-type="supplementary-material"><title>Supplementary Material</title><supplementary-material id="PMC_1" content-type="local-data"><caption><title>[Supplementary Data]</title></caption><media mimetype="text" mime-subtype="html" xlink:href="btn546_index.html"/><media xlink:role="associated-file" mimetype="application" mime-subtype="msword" xlink:href="btn546_bioinf-2008-1096-File002.doc"/></supplementary-material></sec></body><back><ack><title>ACKNOWLEDGEMENTS</title><p>The authors are grateful to Koen Smets for valuable feedback on the article. They also wish to thank Taku Kudo for releasing the CRF++tool under an open source license. Francesca Diella and the Phospho.ELM team are gratefully acknowledged for providing the Phospho.ELM dataset and for offering useful suggestions.</p><p><italic>Funding</italic><bold>:</bold> SBO grant (IWT-600450) of the Flemish Institute supporting Scientific&#x02014;Technological Research in industry (IWT); the EU project &#x02018;Inductive Queries for Mining Patterns and Models&#x02019; (IQ).</p><p><italic>Conflict of Interest:</italic> none declared.</p></ack><ref-list><title>REFERENCES</title><ref id="B1"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Blom</surname><given-names>N</given-names></name><etal/></person-group><article-title>Sequence and structure-based prediction of eukaryotic protein phosphorylation sites</article-title><source>J. Mol. Biol.</source><year>1999</year><volume>294</volume><fpage>1351</fpage><lpage>1362</lpage><pub-id pub-id-type="pmid">10600390</pub-id></citation></ref><ref id="B2"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Blom</surname><given-names>N</given-names></name><etal/></person-group><article-title>Prediction of post-translational glycosylation and phosphorylation of proteins from the amino acid sequence</article-title><source>Proteomics</source><year>2004</year><volume>4</volume><fpage>1633</fpage><lpage>1649</lpage><pub-id pub-id-type="pmid">15174133</pub-id></citation></ref><ref id="B3"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Boeckmann</surname><given-names>B</given-names></name><etal/></person-group><article-title>The Swiss-Prot protein knowledgebase and its supplement TrEMBL in 2003</article-title><source>Nucleic Acids Res</source><year>2003</year><volume>31</volume><fpage>365</fpage><lpage>370</lpage><pub-id pub-id-type="pmid">12520024</pub-id></citation></ref><ref id="B4"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>De Bie</surname><given-names>T</given-names></name><etal/></person-group><article-title>Kernel-based data fusion for gene prioritization</article-title><source>Bioinformatics</source><year>2007</year><volume>23</volume><fpage>i125</fpage><lpage>i132</lpage><pub-id pub-id-type="pmid">17646288</pub-id></citation></ref><ref id="B5"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Diella</surname><given-names>F</given-names></name><etal/></person-group><article-title>Phospho.ELM: a database of experimentally verified phosphorylation sites in eukaryotic proteins</article-title><source>BMC Bioinformatics</source><year>2004</year><volume>5</volume><fpage>79</fpage><pub-id pub-id-type="pmid">15212693</pub-id></citation></ref><ref id="B6"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Diella</surname><given-names>F</given-names></name><etal/></person-group><source>Nucleic Acids Res</source><year>2008</year><volume>36</volume><fpage>D240</fpage><lpage>D244</lpage><pub-id pub-id-type="pmid">17962309</pub-id></citation></ref><ref id="B7"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Ewens</surname><given-names>WJ</given-names></name><name><surname>Grant</surname><given-names>GR</given-names></name></person-group><source>Statistical Methods in Bioinformatics: An Introduction.</source><year>2001</year><publisher-loc>Philadelphia, PA</publisher-loc><publisher-name>Springer</publisher-name></citation></ref><ref id="B8"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Freitag</surname><given-names>D</given-names></name><name><surname>McCallum</surname><given-names>A</given-names></name></person-group><article-title>Information extraction with HMM structures learned by stochastic optimization</article-title><source>Proceedings of the Seventeenth National Conference on Artificial Intelligence and Twelfth Conference on Innovative Applications of Artificial Intelligence.</source><year>2000</year><publisher-name>AAAI Press/The MIT Press</publisher-name><fpage>584</fpage><lpage>589</lpage><comment>Available at <ext-link ext-link-type="uri" xlink:href="http://portal.acm.org/citation.cfm?id=723414&#x00026;dl=GUIDE">http://portal.acm.org/citation.cfm?id=723414&#x00026;dl=GUIDE</ext-link></comment></citation></ref><ref id="B9"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Gnad</surname><given-names>F</given-names></name><etal/></person-group><article-title>PHOSIDA (phosphorylation site database): management, structural and evolutionary investigation, and prediction of phosphosites</article-title><source>Genome Biol</source><year>2007</year><volume>8</volume><fpage>R250</fpage><pub-id pub-id-type="pmid">18039369</pub-id></citation></ref><ref id="B10"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Heazlewood</surname><given-names>JL</given-names></name><etal/></person-group><article-title>PhosPhAt: a database of phosphorylation sites in Arabidopsis thaliana and a plant specific phosphorylation site predictor</article-title><source>Nucleic Acids Res</source><year>2008</year><volume>36</volume><fpage>1015</fpage><lpage>1021</lpage></citation></ref><ref id="B11"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Hornbeck</surname><given-names>PV</given-names></name></person-group><article-title>PhosphoSite: a bioinformatics resource dedicated to physiological protein phosphorylation</article-title><source>Proteomics</source><year>2004</year><volume>4</volume><fpage>1551</fpage><lpage>1561</lpage><pub-id pub-id-type="pmid">15174125</pub-id></citation></ref><ref id="B12"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>HD</given-names></name></person-group><article-title>KinasePhos: a web tool for identifying protein kinase-specific phosphorylation sites</article-title><source>Nucleic Acids Res</source><year>2005a</year><volume>33</volume><fpage>226</fpage><lpage>229</lpage></citation></ref><ref id="B13"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>HD</given-names></name><etal/></person-group><article-title>Incorporating hidden Markov model for identifying protein kinase-specific phosphorylation sites</article-title><source>J. Comput. Chem</source><year>2005b</year><volume>26</volume><fpage>1032</fpage><lpage>1041</lpage><pub-id pub-id-type="pmid">15889432</pub-id></citation></ref><ref id="B14"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Iakoucheva</surname><given-names>LM</given-names></name><etal/></person-group><article-title>The importance of intrinsic disorder for protein phosphorylation</article-title><source>Nucleic Acids Res.</source><year>2004</year><volume>32</volume><fpage>1037</fpage><lpage>1049</lpage><pub-id pub-id-type="pmid">14960716</pub-id></citation></ref><ref id="B15"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ingrell</surname><given-names>CR</given-names></name><etal/></person-group><article-title>NetPhosYeast: prediction of protein phosphorylation sites in yeast</article-title><source>Bioinformatic</source><year>2007</year><volume>7</volume><fpage>895</fpage><lpage>897</lpage></citation></ref><ref id="B16"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Jensen</surname><given-names>ON</given-names></name><etal/></person-group><article-title>Modification-specific proteomics: characterization of post-translational modifications by mass spectrometry</article-title><source>Curr. Opin. Chem. Biol</source><year>2004</year><volume>8</volume><fpage>33</fpage><lpage>41</lpage><pub-id pub-id-type="pmid">15036154</pub-id></citation></ref><ref id="B17"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>JH</given-names></name><etal/></person-group><article-title>Prediction of phosphorylation sites using SVMs</article-title><source>Bioinformatics</source><year>2004</year><volume>20</volume><fpage>3179</fpage><lpage>3184</lpage><pub-id pub-id-type="pmid">15231530</pub-id></citation></ref><ref id="B18"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kobe</surname><given-names>B</given-names></name><etal/></person-group><article-title>Substrate specificity of protein kinases and computational prediction of substrates</article-title><source>Biochim. Biophys. Acta</source><year>2005</year><volume>1754</volume><fpage>200</fpage><lpage>209</lpage><pub-id pub-id-type="pmid">16172032</pub-id></citation></ref><ref id="B19"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Lafferty</surname><given-names>JD</given-names></name><etal/></person-group><article-title>Conditional random fields: probabilistic models for segmenting and labeling sequence data</article-title><source>Proceedings of the Eighteenth International Conference on Machine Learning.</source><year>2001</year><publisher-loc>San Francisco, CA, USA</publisher-loc><publisher-name>Morgan Kaufmann Publishers Inc</publisher-name><fpage>282</fpage><lpage>289</lpage></citation></ref><ref id="B20"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Manning</surname><given-names>G</given-names></name><etal/></person-group><article-title>The protein kinase complement of the human genome</article-title><source>Science</source><year>2002</year><volume>298</volume><fpage>1912</fpage><lpage>1934</lpage><pub-id pub-id-type="pmid">12471243</pub-id></citation></ref><ref id="B21"><citation citation-type="book"><person-group person-group-type="author"><name><surname>McCallum</surname><given-names>A</given-names></name></person-group><article-title>Efficiently inducing features of conditional random fields</article-title><source>Proceedings of the 19th Conference in Uncertainty in Articifical Intelligence.</source><year>2003</year><publisher-loc>Acapulco, Mexico</publisher-loc><publisher-name>Morgan Kaufmann</publisher-name><fpage>403</fpage><lpage>410</lpage></citation></ref><ref id="B22"><citation citation-type="book"><person-group person-group-type="author"><name><surname>McCallum</surname><given-names>A</given-names></name><etal/></person-group><article-title>Maximum entropy Markov models for information extraction and segmentation</article-title><source>Proceedings of ICML 2000.</source><year>2000</year><publisher-loc>California</publisher-loc><publisher-name>Stanford</publisher-name><fpage>591</fpage><lpage>598</lpage></citation></ref><ref id="B23"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Moses</surname><given-names>AM</given-names></name><etal/></person-group><article-title>Spatial clustering of phosphorylation site recognition motifs can be exploited to predict the targets of cyclin-dependent kinase</article-title><year>2007</year><volume>8</volume><fpage>R23</fpage></citation></ref><ref id="B24"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Neuberger</surname><given-names>G</given-names></name><etal/></person-group><article-title>pkaPS: prediction of protein kinase A phosphorylation sites with the simplified kinase-substrate binding model</article-title><source>Biol. Direct</source><year>2007</year><volume>2</volume><fpage>1</fpage><pub-id pub-id-type="pmid">17222345</pub-id></citation></ref><ref id="B25"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Obenauer</surname><given-names>JC</given-names></name><etal/></person-group><article-title>Scansite 2.0: proteome-wide prediction of cell signaling interactions using short sequence motifs</article-title><source>Nucleic Acids Res</source><year>2003</year><volume>31</volume><fpage>3635</fpage><lpage>3641</lpage><pub-id pub-id-type="pmid">12824383</pub-id></citation></ref><ref id="B26"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Pietra</surname><given-names>DS</given-names></name><etal/></person-group><article-title>Inducing features of random fields</article-title><source>IEEE Trans. Pattern Anal. Match. Intell</source><year>1997</year><volume>19</volume><fpage>380</fpage><lpage>393</lpage></citation></ref><ref id="B27"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Plewczynski</surname><given-names>D</given-names></name><etal/></person-group><article-title>A support vector machine approach to the identification of phosphorylation sites</article-title><source>Cell. Mol. Biol. Lett</source><year>2005</year><volume>10</volume><fpage>73</fpage><lpage>89</lpage><pub-id pub-id-type="pmid">15809681</pub-id></citation></ref><ref id="B28"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Plewczynski</surname><given-names>D</given-names></name><etal/></person-group><article-title>Automotif server for prediction of phosphorylation sites in proteins using vector machine</article-title><source>J. Mol. Model</source><year>2008</year><volume>14</volume><fpage>69</fpage><lpage>76</lpage><pub-id pub-id-type="pmid">17994256</pub-id></citation></ref><ref id="B29"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Sha</surname><given-names>F</given-names></name><name><surname>Pereira</surname><given-names>F</given-names></name></person-group><article-title>Shallow parsing with conditional random fields</article-title><source>Proceedings of the 2003 Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics.</source><year>2003</year><publisher-loc>Morristown, NJ, USA</publisher-loc><publisher-name>Association for Computational Linguistics</publisher-name><comment>(HLT/NAACL-03)</comment></citation></ref><ref id="B30"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Wan</surname><given-names>J</given-names></name><etal/></person-group><article-title>Meta-prediction of phosphorylation sites with weighted voting and restricted grid search parameter selection</article-title><source>Nucleic Acids Res</source><year>2008</year><volume>36</volume><fpage>e22</fpage><pub-id pub-id-type="pmid">18234718</pub-id></citation></ref><ref id="B31"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Wong</surname><given-names>YH</given-names></name><etal/></person-group><article-title>KinasePhos 2.0: a web server for identifying protein kinase-specific phosphorylation sites based on sequences and coupling patterns</article-title><source>Nucleic Acids Res</source><year>2007</year><volume>35</volume><fpage>W588</fpage><lpage>W594</lpage><pub-id pub-id-type="pmid">17517770</pub-id></citation></ref><ref id="B32"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Xue</surname><given-names>Y</given-names></name><etal/></person-group><article-title>GPS: a comprehensive www server for phosphorylation sites prediction</article-title><source>Nucleic Acids Res.</source><year>2005</year><volume>33</volume><fpage>W184</fpage><lpage>W187</lpage><pub-id pub-id-type="pmid">15980451</pub-id></citation></ref><ref id="B33"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Xue</surname><given-names>Y</given-names></name><etal/></person-group><article-title>PPSP: prediction of PK-specific phosphorylation site with Bayesian decision theory</article-title><source>BMC Bioinformatics</source><year>2006</year><volume>7</volume><fpage>163</fpage><pub-id pub-id-type="pmid">16549034</pub-id></citation></ref><ref id="B34"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>FF</given-names></name><etal/></person-group><article-title>GPS: a novel group-based phosphorylation predicting and scoring method</article-title><source>Biochem. Biophys. Res. Commun.</source><year>2004</year><volume>325</volume><fpage>443</fpage><lpage>1448</lpage></citation></ref></ref-list></back></article>