<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN" "archivearticle.dtd"><article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article" xml:lang="EN"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><journal-title>PLoS ONE</journal-title><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">19247451</article-id><article-id pub-id-type="pmc">2644787</article-id><article-id pub-id-type="publisher-id">08-PONE-RA-06877R2</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0004645</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline"><subject>Neuroscience</subject><subject>Neuroscience/Cognitive Neuroscience</subject><subject>Neuroscience/Sensory Systems</subject></subj-group></article-categories><title-group><article-title>Auditory Attention Activates Peripheral Visual Cortex</article-title><alt-title alt-title-type="running-head">Auditory Attention in Cortex</alt-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Cate</surname><given-names>Anthony D.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>&#x0002a;</sup></xref></contrib><contrib contrib-type="author"><name><surname>Herron</surname><given-names>Timothy J.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Yund</surname><given-names>E. William</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Stecker</surname><given-names>G. Christopher</given-names></name><xref ref-type="aff" rid="aff5"><sup>5</sup></xref></contrib><contrib contrib-type="author"><name><surname>Rinne</surname><given-names>Teemu</given-names></name><xref ref-type="aff" rid="aff6"><sup>6</sup></xref></contrib><contrib contrib-type="author"><name><surname>Kang</surname><given-names>Xiaojian</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author"><name><surname>Petkov</surname><given-names>Christopher I.</given-names></name><xref ref-type="aff" rid="aff7"><sup>7</sup></xref></contrib><contrib contrib-type="author"><name><surname>Disbrow</surname><given-names>Elizabeth A.</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff8"><sup>8</sup></xref></contrib><contrib contrib-type="author"><name><surname>Woods</surname><given-names>David L.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff4"><sup>4</sup></xref></contrib></contrib-group><aff id="aff1"><label>1</label><addr-line>Human Cognitive Neurophysiology Laboratory, Veterans Administration Northern California Health Care System, Martinez, California, United States of America</addr-line></aff><aff id="aff2"><label>2</label><addr-line>Department of Neurology, University of California Davis, Sacramento, California, United States of America</addr-line></aff><aff id="aff3"><label>3</label><addr-line>Center for Neurosciences, University of California Davis, Davis, California, United States of America</addr-line></aff><aff id="aff4"><label>4</label><addr-line>Center for Mind and Brain, University of California Davis, Davis, California, United States of America</addr-line></aff><aff id="aff5"><label>5</label><addr-line>Department of Speech and Hearing Sciences, University of Washington, Seattle, Washington, United States of America</addr-line></aff><aff id="aff6"><label>6</label><addr-line>Department of Psychology, University of Helsinki, Helsinki, Finland</addr-line></aff><aff id="aff7"><label>7</label><addr-line>Institute of Neuroscience, University of Newcastle, Newcastle upon Tyne, United Kingdom</addr-line></aff><aff id="aff8"><label>8</label><addr-line>Department of Radiology, University of California San Francisco, San Francisco, California, United States of America</addr-line></aff><contrib-group><contrib contrib-type="editor"><name><surname>Gribble</surname><given-names>Paul L.</given-names></name><role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1">The University of Western Ontario, Canada</aff><author-notes><corresp id="cor1">&#x0002a; E-mail: <email>acate@ebire.org</email></corresp><fn fn-type="con"><p>Conceived and designed the experiments: EWY CIP DW. Performed the experiments: ADC EWY GCS TR XK CIP DW. Analyzed the data: ADC TJH XK CIP. Contributed reagents/materials/analysis tools: ADC TJH XK DW. Wrote the paper: ADC TJH EWY XK EAD DW.</p></fn></author-notes><pub-date pub-type="collection"><year>2009</year></pub-date><pub-date pub-type="epub"><day>27</day><month>2</month><year>2009</year></pub-date><volume>4</volume><issue>2</issue><elocation-id>e4645</elocation-id><history><date date-type="received"><day>15</day><month>10</month><year>2008</year></date><date date-type="accepted"><day>19</day><month>1</month><year>2009</year></date></history><copyright-statement>This is an open-access article distributed under the terms of the Creative Commons Public Domain declaration which stipulates that, once placed in the public domain, this work may be freely reproduced, distributed, transmitted, modified, built upon, or otherwise used by anyone for any lawful purpose.</copyright-statement><copyright-year>2009</copyright-year><abstract><sec><title>Background</title><p>Recent neuroimaging studies have revealed that putatively unimodal regions of visual cortex can be activated during auditory tasks in sighted as well as in blind subjects. However, the task determinants and functional significance of auditory occipital activations (AOAs) remains unclear.</p></sec><sec><title>Methodology/Principal Findings</title><p>We examined AOAs in an intermodal selective attention task to distinguish whether they were stimulus-bound or recruited by higher-level cognitive operations associated with auditory attention. Cortical surface mapping showed that auditory occipital activations were localized to retinotopic visual cortex subserving the far peripheral visual field. AOAs depended strictly on the sustained engagement of auditory attention and were enhanced in more difficult listening conditions. In contrast, unattended sounds produced no AOAs regardless of their intensity, spatial location, or frequency.</p></sec><sec><title>Conclusions/Significance</title><p>Auditory attention, but not passive exposure to sounds, routinely activated peripheral regions of visual cortex when subjects attended to sound sources outside the visual field. Functional connections between auditory cortex and visual cortex subserving the peripheral visual field appear to underlie the generation of AOAs, which may reflect the priming of visual regions to process soon-to-appear objects associated with unseen sound sources.</p></sec></abstract><counts><page-count count="12"/></counts></article-meta></front><body><sec id="s1"><title>Introduction</title><p>The assumption that retinotopic visual cortex is activated exclusively by visual inputs has recently been challenged by brain imaging studies that have demonstrated auditory occipital activations (AOAs) in blind <xref ref-type="bibr" rid="pone.0004645-Buchel1">&#x0005b;1&#x0005d;</xref>&#x02013;<xref ref-type="bibr" rid="pone.0004645-Voss1">&#x0005b;8&#x0005d;</xref> as well as sighted subjects <xref ref-type="bibr" rid="pone.0004645-Wu1">&#x0005b;9&#x0005d;</xref>. This study aims to answer two key questions regarding this phenomenon. First, given that AOAs are absent in most neuroimaging studies of audition, what specific aspects of auditory processing are critical for their occurrence? Second, what are the visual response properties of the occipital regions producing AOAs?</p><p>Evidence has emerged for direct anatomical connections between superior temporal and occipital regions that may play an important role in the crossmodal integration of sensory experience <xref ref-type="bibr" rid="pone.0004645-Falchier1">&#x0005b;10&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004645-Cappe1">&#x0005b;11&#x0005d;</xref>. These studies have revealed monosynaptic projections from core and parabelt fields of auditory cortex to V1 in the macaque, with the majority of connections terminating in regions that respond to visual stimuli in the peripheral field <xref ref-type="bibr" rid="pone.0004645-Falchier1">&#x0005b;10&#x0005d;</xref>. Similar connections have been reported in humans <xref ref-type="bibr" rid="pone.0004645-Eckert1">&#x0005b;12&#x0005d;</xref> and may help to explain the enhanced strength of sound-flash illusions in the visual periphery <xref ref-type="bibr" rid="pone.0004645-Zhang1">&#x0005b;13&#x0005d;</xref>&#x02013;<xref ref-type="bibr" rid="pone.0004645-Shams2">&#x0005b;15&#x0005d;</xref>.</p><p>Evidence of AOAs was first reported in with congenitally blind individuals using event-related potentials <xref ref-type="bibr" rid="pone.0004645-Kujala1">&#x0005b;16&#x0005d;</xref>&#x02013;<xref ref-type="bibr" rid="pone.0004645-Kujala2">&#x0005b;18&#x0005d;</xref>. Later, functional magnetic resonance imaging (fMRI) demonstrated AOAs in both early and late-blind subjects <xref ref-type="bibr" rid="pone.0004645-Weeks1">&#x0005b;2&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004645-Garg1">&#x0005b;4&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004645-Voss1">&#x0005b;8&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004645-Stevens1">&#x0005b;19&#x0005d;</xref>&#x02013;<xref ref-type="bibr" rid="pone.0004645-Weaver1">&#x0005b;21&#x0005d;</xref>. Although AOAs have been occasionally reported in blind subjects performing non-spatial auditory discrimination tasks <xref ref-type="bibr" rid="pone.0004645-Weaver1">&#x0005b;21&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004645-Kujala3">&#x0005b;22&#x0005d;</xref>, they are reliably found in blind subjects performing sound localization tasks <xref ref-type="bibr" rid="pone.0004645-Weeks1">&#x0005b;2&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004645-Gougoux1">&#x0005b;6&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004645-Voss1">&#x0005b;8&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004645-Voss2">&#x0005b;20&#x0005d;</xref>. The presence of prominent AOAs in the blind may help to explain their superior performance on sound localization tasks <xref ref-type="bibr" rid="pone.0004645-Muchnik1">&#x0005b;23&#x0005d;</xref>&#x02013;<xref ref-type="bibr" rid="pone.0004645-Voss3">&#x0005b;26&#x0005d;</xref>. Indeed, AOA magnitudes in blind individuals correlate with task performance in auditory localization <xref ref-type="bibr" rid="pone.0004645-Gougoux1">&#x0005b;6&#x0005d;</xref> and non-spatial tasks <xref ref-type="bibr" rid="pone.0004645-Stevens1">&#x0005b;19&#x0005d;</xref>. In contrast to the prominent AOAs found in blind subjects, early studies typically found no AOAs in sighted subjects <xref ref-type="bibr" rid="pone.0004645-Garg1">&#x0005b;4&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004645-Voss2">&#x0005b;20&#x0005d;</xref> suggesting that AOAs may be a consequence of neuroplastic changes resulting from visual deprivation that enhanced auditory processing abilities of the blind <xref ref-type="bibr" rid="pone.0004645-Weeks1">&#x0005b;2&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004645-Kujala1">&#x0005b;16&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004645-Ross1">&#x0005b;27&#x0005d;</xref>&#x02013;<xref ref-type="bibr" rid="pone.0004645-Rauschecker1">&#x0005b;34&#x0005d;</xref>. However, a role for occipital visual cortex in spatial hearing in the normally sighted subjects has also been proposed on the basis of neuropsychological studies <xref ref-type="bibr" rid="pone.0004645-Kerkhoff1">&#x0005b;35&#x0005d;</xref> as well as studies using TMS <xref ref-type="bibr" rid="pone.0004645-Lewald1">&#x0005b;36&#x0005d;</xref> and recent studies using fMRI <xref ref-type="bibr" rid="pone.0004645-Zimmer1">&#x0005b;37&#x0005d;</xref>.</p><p>AOAs have not been reported in the great majority of fMRI studies of auditory processing. Nevertheless, AOAs in normally sighted subjects have been incidentally reported in such diverse tasks as word perception <xref ref-type="bibr" rid="pone.0004645-Specht1">&#x0005b;38&#x0005d;</xref>, speech discrimination <xref ref-type="bibr" rid="pone.0004645-Just1">&#x0005b;39&#x0005d;</xref>, sentence processing <xref ref-type="bibr" rid="pone.0004645-vonKriegstein1">&#x0005b;40&#x0005d;</xref>, detecting a subject's own name <xref ref-type="bibr" rid="pone.0004645-Carmody1">&#x0005b;41&#x0005d;</xref>, intermodal selective attention <xref ref-type="bibr" rid="pone.0004645-Johnson1">&#x0005b;42&#x0005d;</xref>&#x02013;<xref ref-type="bibr" rid="pone.0004645-Sabri1">&#x0005b;44&#x0005d;</xref>, music discrimination <xref ref-type="bibr" rid="pone.0004645-Platel1">&#x0005b;45&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004645-Janata1">&#x0005b;46&#x0005d;</xref>, attention to auditory components in auditory-visual speech <xref ref-type="bibr" rid="pone.0004645-Saito1">&#x0005b;47&#x0005d;</xref>, auditory sound discrimination <xref ref-type="bibr" rid="pone.0004645-Eisenberg1">&#x0005b;48&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004645-Maeder1">&#x0005b;49&#x0005d;</xref> and auditory spatial attention in the absence of visual stimuli <xref ref-type="bibr" rid="pone.0004645-Wu1">&#x0005b;9&#x0005d;</xref>. While these tasks all require active listening to complex sound sources, it is unclear which cognitive or sensory aspects of auditory tasks are critical for the occurrence of AOAs. Do AOAs reflect the sensory analysis of particular sound characteristics in visual cortex, or do they reflect specialized cognitive operations associated with focused auditory attention?</p><p>The regions of visual cortex that generate AOAs also remain obscure. While fMRI studies have broadly localized AOAs to the cuneus <xref ref-type="bibr" rid="pone.0004645-Maeder1">&#x0005b;49&#x0005d;</xref>&#x02013;<xref ref-type="bibr" rid="pone.0004645-Burton2">&#x0005b;52&#x0005d;</xref> and lingual gyrus <xref ref-type="bibr" rid="pone.0004645-Janata1">&#x0005b;46&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004645-Hasegawa1">&#x0005b;53&#x0005d;</xref>&#x02013;<xref ref-type="bibr" rid="pone.0004645-Zimmer2">&#x0005b;55&#x0005d;</xref> in Talairach coordinates, cortical surface mapping techniques are needed to localize AOAs to specific regions of visual cortex. In one recent study, Jack and colleagues examined task-related activations of visual cortex <xref ref-type="bibr" rid="pone.0004645-Jack1">&#x0005b;56&#x0005d;</xref>. Cortical surface maps from individual subjects performing a tone-discrimination task showed widespread AOAs that were centered in peripheral regions of V1 (eccentricities greater than 6&#x000b0;). In the current study, we performed population-based cortical surface mapping to localize AOAs to precise areas of visual cortex with known response properties, in order to elucidate the functional role that AOAs might play during active listening.</p><p>A primary focus of the current study was to compare the role of acoustic and cognitive factors in AOA generation. To this end we applied an intermodal selective attention paradigm originally designed to elucidate the functional properties of auditory cortex <xref ref-type="bibr" rid="pone.0004645-Woods1">&#x0005b;57&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004645-Petkov1">&#x0005b;58&#x0005d;</xref>. To characterize acoustic effects, sounds varied in frequency, location, and intensity in different stimulus blocks. Subjects performed demanding auditory or visual tasks with either unimodal or bimodal stimulus sequences, which were then contrasted to characterize the effects of attention. To ensure that AOAs were not dependent on the idiosyncratic characteristics of the tasks, we used a wide range of stimuli, including different tone patterns and two kinds of visual stimuli (faces and words).</p><p>Reliable AOAs were found in regions of visual cortex subserving the far visual periphery. We analyzed the relationship between AOAs and performance on auditory tasks and also performed event-related analyses to evaluate the possible relationship between AOAs and task-related cognitive operations such as target detection and task switching <xref ref-type="bibr" rid="pone.0004645-Jack1">&#x0005b;56&#x0005d;</xref>. In addition, we used functional connectivity analyses to investigate the relationship between AOAs and modality-specific attentional modulations occurring in visual and auditory cortex. The results suggest that the activation of peripheral visual cortex is an essential component of a cortical network subserving sustained auditory attention.</p></sec><sec sec-type="methods" id="s2"><title>Methods</title><sec id="s2a"><title>Ethics statement</title><p>All subjects provided informed consent in accordance with the VANCHCS Institutional Review Board.</p></sec><sec id="s2b"><title>Subjects</title><p>Nine individuals (aged 18&#x02013;34 years, 8 male, 2 left-handed) each participated in one orientation session that included task training and anatomical imaging and then underwent six separate 1-hr fMRI sessions (three with sparse and three with continuous sampling) over a period of 2&#x02013;6 weeks. All subjects had normal or corrected-to-normal vision and normal hearing.</p></sec><sec id="s2c"><title>Stimuli</title><p>Functional images were acquired while subjects performed attention-demanding one-back matching tasks in the attended modality (<xref ref-type="fig" rid="pone-0004645-g001">Figure 1</xref>) cued by a partially transparent cue letter (&#x0201c;A&#x0201d; or &#x0201c;V&#x0201d;) at fixation indicating the modality to be attended. Stimuli were presented in blocks that used unimodal or bimodal stimulation. In unimodal auditory and visual blocks (UA and UV, respectively), subjects always attended to the presented modality. In bimodal blocks, auditory and visual stimuli were presented concurrently, and subjects were cued to attend to the auditory (BA blocks) or visual (BV) modality. During bimodal sequences auditory and visual stimuli were presented asynchronously with randomized temporal relationships to minimize intermodal integration. The four types of blocks (UA, UV, BA, BV) occurred with equal frequency.</p><fig id="pone-0004645-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0004645.g001</object-id><label>Figure 1</label><caption><title>Stimuli and task.</title><p>Subjects attended to either auditory or visual stimuli in 21 s blocks to detect repeated stimulus events in the modality cued by a letter at fixation (top row). Auditory and visual stimuli occurred asynchronously at mean stimulus onset intervals of 1.5 s within each modality. Auditory targets (asterisk) were repeated tone triplets (250 ms/tone&#x0200a;&#x0003d;&#x0200a;750 ms, red rectangles). Visual stimuli were presented for 700 ms (blue rectangles).</p></caption><graphic xlink:href="pone.0004645.g001"/></fig><p>Auditory stimuli were tone triplets of 750 ms duration generated by selecting pseudorandomly and exhaustively from three 250 ms tones. Target stimuli were triplet repetitions occurring with a probability of 0.1. The tones were separated by 3-semitone steps and centered on frequencies of 225, 900, or 3600 Hz in different blocks. In each block, tones were delivered at either 70 or 90 dB SPL, and to either the left ear, right ear, or both ears according to a randomized design. Tones were presented over continuous broadband 70 dB SPL masking noise through insert earphones. Ambient scanner noise was further attenuated with circumaural ear protectors. Visual stimuli in each block were black and white photographs of faces (visual angle 2&#x000b0;&#x000d7;3&#x000b0;) or words (mean visual angle 2.5&#x000b0;&#x000d7;0.8&#x000b0;). Faces were eight individuals from the Ekman set <xref ref-type="bibr" rid="pone.0004645-Ekman1">&#x0005b;59&#x0005d;</xref>, each with four different facial expressions (disgust, fear, happiness, and neutral). Targets in the face blocks were successive photographs of the same individual with different emotional expressions. Words were selected from ten different semantic categories (e.g., cities, plants, animals, etc.), each with four exemplars. Targets in the word blocks were successive words belonging to the same semantic category. Responses were recorded to measure reaction times (RTs) and to permit the calculation of hit and false alarm rates. Stimulus presentation and response collection were controlled with Presentation software (NBS, Albany, CA.).</p><p>Retinotopic mapping of the visual cortex was performed with two subjects. The horizontal and vertical meridians were mapped using high-contrast checkerboard wedges (extending from 0.2&#x000b0; to 4.79&#x000b0;, 0.05&#x000b0; wide at inner edge, 0.58&#x000b0; wide at outer edge), and two eccentricities were mapped using central (0.96&#x000b0; eccentricity, 0.19&#x000b0; wide) and peripheral (4.79&#x000b0;, 0.38&#x000b0; wide) rings.</p></sec><sec id="s2d"><title>MRI Scanning</title><p>High-resolution T1 anatomical images were acquired from each subject on a 1.5 T Philips Eclipse scanner (matrix size 256&#x000d7;212&#x000d7;256, voxel size 0.94&#x000d7;1.30&#x000d7;0.94 mm, TE 4.47 ms, TR 15 ms, flip angle 35&#x000b0;, field of view 240&#x000d7;240 mm). Six separate functional imaging sessions were performed with each subject using an EPI sequence (matrix size 128&#x000d7;128&#x000d7;29, 29 axial slices 4 mm thick plus 1 mm gap, voxel size 1.88&#x000d7;1.88&#x000d7;5 mm, TE 39.6 ms, flip angle 90&#x000b0;, FOV 240&#x000d7;240 mm). All functional scans used a similar blocked design (16 behavioral trials/block). In three sessions for each subject images were acquired using a sparse imaging sequence (2 functional images acquired per block, TR 10.4 s, 20.8 s/block, sequential slices) to reduce acoustic noise <xref ref-type="bibr" rid="pone.0004645-Hall1">&#x0005b;60&#x0005d;</xref>. The other three sessions employed continuous imaging (8 functional images per block, TR 2.9 s, 23.2 s/block, interleaved slices) to permit the analysis of the time course of activations. Functional data sets from sparse and continuous imaging were analyzed separately for each subject.</p><p>We used cortical surface mapping procedures to analyze the AOA distributions in relation to cortical gyral and sulcal anatomy (<xref ref-type="fig" rid="pone-0004645-g002">Figure 2</xref>). Anatomical image sets were resliced to 1 mm<sup>3</sup>, segmented, inflated and coregistered to a spherical coordinate system using FreeSurfer <xref ref-type="bibr" rid="pone.0004645-Fischl1">&#x0005b;61&#x0005d;</xref>. Each subject's functional images were coregistered and resampled directly into the high-resolution anatomical space <xref ref-type="bibr" rid="pone.0004645-Kang1">&#x0005b;62&#x0005d;</xref> after correcting for head movement using SPM5 <xref ref-type="bibr" rid="pone.0004645-Friston1">&#x0005b;63&#x0005d;</xref>. Functional image data were high-pass filtered with a cutoff of 0.005 Hz using polynomial detrending. Activations in voxels corresponding to the cortical surface were quantified in native 3D space and visualized on the spherical surface using an equal-area Mollweide projection. Functional activations were superimposed on maps of the mean surface curvature of 60 healthy control subjects' whole-head T1 scans and displayed on equal-area Mollweide 2D projections of the spherical mean surface curvature maps.</p><fig id="pone-0004645-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0004645.g002</object-id><label>Figure 2</label><caption><title>Cortical surface analysis display method.</title><p>Schematic diagram showing the transformation of a cortical hemisphere partially inflated using FreeSurfer to the equal-area Mollweide projection flat map used to display the data in this study. Clockwise from top left: Views of the medial and lateral surface of a semi-inflated model of the cortical surface (gray matter/white matter boundary) of the left hemisphere averaged over 60 individual brains. Shading indicates average cortical curvature (light: convex; dark: concave) with an overlaid functional activation map showing the effects of attention (see <xref ref-type="fig" rid="pone-0004645-g004">Figure 4</xref> for more details). Next, the hemisphere is fully inflated to a sphere using FreeSurfer, and rotated to place the posterior occipital lobe at the equator. Finally, the surface of the sphere is visualized using an equal-area Mollweide projection, with the occipital pole at the map's center.</p></caption><graphic xlink:href="pone.0004645.g002"/></fig></sec><sec id="s2e"><title>Behavioral Data Analysis</title><p>Subjects performed a difficult one-back matching task in the auditory or visual modality. Repeated-measures ANOVAs were performed to examine the differences between auditory and visual task performance. Data from auditory and visual tasks were grouped together to form a &#x0201c;modality&#x0201d; factor, which was crossed with imaging protocol (sparse or continuous) in a factorial design. The effects of intermodal attention were analyzed using the two bimodal conditions (BA and BV). Because the stimuli presented in these conditions were identical, every independent factor was included in this analysis: modality of attention; imaging protocol; auditory stimulus intensity, ear of delivery and frequency; and visual stimulus type.</p></sec><sec id="s2f"><title>fMRI Data Analysis</title><sec id="s2f1"><title>Preprocessing</title><p>Percent signal change was calculated relative to the overall mean BOLD response for each voxel. Mean BOLD responses associated with each block were calculated by averaging across both functional images from the sparse imaging sessions and across images 2&#x02013;8 (i.e., beginning 5.8 s after beginning of block) in continuous imaging sessions. Spatial smoothing was applied to the cortical surface data using a 3-mm FWHM Gaussian filter <xref ref-type="bibr" rid="pone.0004645-Chung1">&#x0005b;64&#x0005d;</xref>.</p></sec><sec id="s2f2"><title>Stimulus-Dependent Activations (SDAs) and Attention-Related Modulations (ARMs)</title><p>Statistical contrasts were used to identify stimulus-dependent activations (SDAs; activations related to unattended stimuli; see <xref ref-type="fig" rid="pone-0004645-g003">Figure 3</xref>) and attention-related modulations (ARMs; see <xref ref-type="fig" rid="pone-0004645-g004">Figure 4</xref>). SDAs were obtained by subtracting activations in unimodal conditions from activations in bimodal conditions that differed from the unimodal conditions only by the addition of task-irrelevant stimulation in the unattended modality. Hence visual SDAs were obtained by subtracting signals in UA blocks from signal in BA blocks, while auditory SDAs were obtained by subtracting signals in UV blocks from those in BV blocks. ARMs were identified by contrasting BV and BA blocks. These contained identical stimuli, and differed only in the modality attended.</p><fig id="pone-0004645-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0004645.g003</object-id><label>Figure 3</label><caption><title>Stimulus-dependent activations.</title><p>Stimulus-dependent activations (SDAs) to unattended stimuli projected on a map of mean curvature across both hemispheres (darker gray&#x0200a;&#x0003d;&#x0200a;sulcus). A circled cross indicates the occipital pole. The calcarine sulcus is indicated by the yellow arrow pointing away from the foveal towards the peripheral visual field regions. HG Heschl's gyrus, STG superior temporal gyrus, IPS intraparietal sulcus, CentS central sulcus, TP temporal pole, FG fusiform gyrus, LG lingual gyrus, cun cuneus, POS parietal-occipital sulcus, CC corpus callosum. Data from sessions using sparse image acquisition. All activation maps are triple-thresholded (z&#x0003e;3/p&#x0003c;0.001, signal change &#x0003e;0.1&#x00025;, cluster size &#x0003e;20 voxels).</p></caption><graphic xlink:href="pone.0004645.g003"/></fig><fig id="pone-0004645-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0004645.g004</object-id><label>Figure 4</label><caption><title>Attention-related modulations.</title><p>Visual attention-related modulations (ARMs, blue) were seen in posterior occipitotemporal areas and the IPS. Auditory ARMs (red) were found in auditory cortex along the superior temporal plane with additional foci in the lingual gyrus and cuneus (auditory occipital activations: AOAs). The color scale shows mean percent signal change. Insets (right): mean occipital activations from sparse and continuous image acquisition sessions.</p></caption><graphic xlink:href="pone.0004645.g004"/></fig></sec><sec id="s2f3"><title>Retinotopic Mapping</title><p>To compare the regions of visual cortex showing AOAs with the retinotopic representation of the fovea we mapped the vertical and horizontal meridians and retinal eccentricities up to 5&#x000b0; in two subjects using counterphase flickering (8 Hz) checkerboard patterns <xref ref-type="bibr" rid="pone.0004645-Murray1">&#x0005b;65&#x0005d;</xref>. Since AOAs appeared to fall beyond the maximal eccentricity that could be mapped (5&#x000b0;), we additionally compared AOA distributions with those of activations produced by visual stimuli in the far peripheral field (up to 49&#x000b0; eccentricity) reported by Stenbacka and Vanni <xref ref-type="bibr" rid="pone.0004645-Stenbacka1">&#x0005b;66&#x0005d;</xref>. Due to the variable relationship between gyral structure and stereotaxic coordinates in individual subjects <xref ref-type="bibr" rid="pone.0004645-Amunts1">&#x0005b;67&#x0005d;</xref> we projected the Talairach coordinates from Stenbacka and Vanni to the nearest point on the cortical surface for each individual in the control database of 60 whole-brain T1 scans (white and green dots in <xref ref-type="fig" rid="pone-0004645-g005">Figure 5</xref>). We also measured the 3D Talairach coordinates of AOA maxima in the cuneus and lingual gyrus for both hemispheres.</p><fig id="pone-0004645-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0004645.g005</object-id><label>Figure 5</label><caption><title>Occipital regions activated by auditory attention.</title><p>(A) Left: average cortical surface anatomy showing occipital regions (box). AOAs in all 9 subjects, depicted on maps of their individual occipital cortex surface curvature. Bottom right: the activation map from one subject who underwent retinotopic mapping of the horizontal and vertical meridians (green lines) and two eccentric annuli (white and yellow lines). (B) Cortical surface projections of the Talairach coordinates reported by Stenbacka et al. (2007) for visual checkerboard patterns presented at 12&#x02013;30&#x000b0; and 30&#x02013;49&#x000b0; in the peripheral visual field, superimposed on the mean AOA map averaged across subjects. Dots represent the reported Talairach coordinates (white, 12&#x02013;30&#x000b0;, green, 30&#x02013;49&#x000b0;) projected to the closest corresponding location on the cortical surface for each of 60 brains in the anatomical database.</p></caption><graphic xlink:href="pone.0004645.g005"/></fig></sec><sec id="s2f4"><title>Region of Interest (ROI) Analysis</title><p>We used a region of interest (ROI) analysis to evaluate the reliability of AOA generation and to test whether the AOAs were implicated in perceptual analysis of sensory information or in attention-related cognitive processes. ROIs were defined using the data acquired during sparse fMRI acquisition and their responses were analyzed using the independent data set obtained in sessions using continuous imaging. ROI voxels were required to meet three criteria: percent signal change from baseline (0.1&#x00025;), statistical significance of the ARM contrast (z&#x0003e;2.97, p&#x0003c;0.001, uncorrected, in a fixed-effects analysis) and minimum cluster size (20 contiguous surface voxels). The last two criteria combine to control hemisphere-wide error at p&#x0003c;0.05 (fixed effects analysis) <xref ref-type="bibr" rid="pone.0004645-JinhuXiong1">&#x0005b;68&#x0005d;</xref>. Two ROIs in pericalcarine visual cortex were chosen for analysis: (1) an AOA region, including the clusters in the lingual gyrus and cuneus, and (2) a central vision region in the posterior calcarine sulcus based on the visual ARM cluster in this area.</p><p>Three distinct repeated-measures ANOVAs (treating subjects as a random factor) were performed to test the significance of the ARM and SDA effects using the continuous imaging data. The effects of intermodal attention (i.e. the ARMs) were verified in an ANOVA using the data from the two bimodal conditions (BA and BV). Separate analyses were also performed using data from either the auditory (BA and UA conditions) or visual (BV and UV) attention conditions' data alone, in order to compare activations in the presence and absence of stimuli in the unattended modality.</p></sec><sec id="s2f5"><title>Task-switching Activation Analysis</title><p>We evaluated the hypothesis that AOAs might reflect cognitive operations associated with task switching at block boundaries <xref ref-type="bibr" rid="pone.0004645-Jack1">&#x0005b;56&#x0005d;</xref> by analyzing event-related time course regressors modeling the beginning and end of bimodal stimulus blocks where attention switched from the auditory to the visual modality or vice versa. Event-related time course regressors were created to model the BOLD response produced when subjects switched between performing the auditory and visual tasks. Task-switching events were modeled as square waves beginning at the conclusion of one block and ending 2 seconds later in the following block. Switching events were included for the transitions between all temporally adjacent bimodal blocks with different task modalities. These boxcar time courses were convolved with a standard, bigamma hemodynamic response function <xref ref-type="bibr" rid="pone.0004645-Handwerker1">&#x0005b;69&#x0005d;</xref>. A fixed-effects t-test assessed the fit between the modeled and observed BOLD time courses for each surface voxel. T-maps were double-thresholded using statistical significance (t&#x0003e;3) and cluster size (20 contiguous surface voxels) as criteria.</p></sec><sec id="s2f6"><title>Response-related Activation Analysis</title><p>Event-related time course regressors were also used to determine whether AOAs primarily reflected detection of the unpredictable auditory targets. The measured time course of subjects' button press responses associated with auditory target hits were convolved with a hemodynamic response function (HRF) for both the sparse and continuous imaging sessions. These target-related regressors were contrasted with regressors representing the periods during which subjects made no responses. Within auditory attention blocks, response events were modeled as positive square waves spanning the 750 ms prior to a recorded response, and non-response epochs (of variable length, spanning the intervals between each two response events) were modeled as negative square waves. The resulting two boxcar time courses were normalized to have equal energy, summed together, and were convolved with the standard HRF. A fixed-effects t-test assessed where the time courses for each surface voxel was non-zero. T-maps were double-thresholded using statistical significance (t&#x0003e;3) and cluster size (20 contiguous surface voxels) as criteria.</p></sec><sec id="s2f7"><title>Functional Connectivity Analysis</title><p>The results from the analyses described below revealed that AOAs were positively correlated with sustained auditory attention and negatively correlated with activations in central visual areas during auditory attention conditions. However, because subjects switched attention between auditory and visual stimulus blocks, there was no truly activation-independent baseline. Thus, it is possible that AOAs could reflect relative deactivations of peripheral visual regions due to foveal attention during visual attention blocks <xref ref-type="bibr" rid="pone.0004645-Muller1">&#x0005b;70&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004645-Tootell1">&#x0005b;71&#x0005d;</xref> rather than activations of peripheral visual regions during auditory attention blocks. If AOAs reflected the absence of inhibition during auditory blocks, one would predict a significant negative correlation between BOLD signal in the posterior (foveal) visual cortex and the AOA ROI. Alternatively, if AOAs were part of a cortical network activated during auditory attention, AOAs should be unrelated to activity in central visual field regions of visual cortex but correlated with activations in auditory cortex. We therefore also tested the hypothesis that there was a positive correlation between responses in the AOA ROI and auditory cortex.</p><p>We computed partial correlations <xref ref-type="bibr" rid="pone.0004645-Smith1">&#x0005b;72&#x0005d;</xref> of the AOA ROI time series with time series of both the entire cortical surface and other ROIs <xref ref-type="bibr" rid="pone.0004645-Marrelec1">&#x0005b;73&#x0005d;</xref>. In order to find consistent correlation values across subjects (i.e. a random effects analysis) we computed partial correlations for each subject separately, converted those to normally-distributed z-scores using the standard Pearson product moment distribution, and then performed a t-test that indicated whether mean z-score was significantly different from zero. We first computed the partial correlations of the AOA ROI with every voxel on the cortical surface during unimodal visual blocks while partialling out the global fMRI signal (the mean of the entire cortical surface) and the three main head motion correction components. Second, we calculated the partial correlation under all task conditions between the AOA ROI and an auditory cortex ROI in the same hemisphere defined from sparse data (see Supplemental <xref ref-type="supplementary-material" rid="pone.0004645.s001">Figure S1</xref>) while partialling out (1) the global signal and head motion parameters, (2) an ROI from both hemispheres defined as all visual ARM voxels in the posterior occipital region, and (3) indicator variables for bimodal vs. unimodal blocks and for auditory vs. visual blocks. The first cortical surface partial correlation examined whether there were significant correlations between the AOAs and the posterior occipital region, while the latter ROI-based partial correlation was designed to test the hypothesis that there were correlations between the AOAs and auditory cortex that could not be explained by visual functional activations or by any of the attention block conditions.</p></sec></sec></sec><sec id="s3"><title>Results</title><sec id="s3a"><title>Behavioral tasks</title><p>Hit rates were similar in auditory and visual blocks (62&#x00025; vs. 67&#x00025;, F<sub>(1,8)</sub>&#x0200a;&#x0003d;&#x0200a;2.67, p&#x0003e;0.10). During auditory conditions, subjects were more accurate in blocks with high- than low-intensity sounds (F<sub>(1,8)</sub>&#x0200a;&#x0003d;&#x0200a;16.09, p&#x0003c;0.005). The auditory hit rate was not significantly affected by the presence of visual distractors (F<sub>(1,8)</sub>&#x0200a;&#x0003d;&#x0200a;0.10).</p></sec><sec id="s3b"><title>Activations to unattended auditory and visual stimuli</title><p><xref ref-type="fig" rid="pone-0004645-g003">Figure 3</xref> shows SDAs on the average inflated cortical surface. Visual SDAs (blue, cyan) were localized to the foveal region of retinotopic cortex and surrounding parafoveal zones with additional activations seen in higher visual areas in the temporal and occipital lobes and the intraparietal sulcus. Auditory SDAs were restricted to auditory sensory cortex on Heschl's gyrus and in surrounding regions on the superior temporal plane. There was no evidence of auditory SDAs in occipital cortex.</p></sec><sec id="s3c"><title>Attention-related modulations</title><p><xref ref-type="fig" rid="pone-0004645-g004">Figure 4</xref> shows attention-related modulations (ARMs), isolated by contrasting activations from bimodal visual attention blocks with activations from bimodal auditory attention blocks. Areas showing enhanced activations during visual attention (blue/cyan) included the retinotopic areas in central calcarine cortex as well as higher visual areas in the lateral occipital sulcus, the fusiform gyrus, and the intraparietal sulcus.</p><p>Auditory ARMs were predictably prominent in auditory association cortex along the superior temporal gyrus (STG). In addition, auditory ARMs were evident in the cuneus and lingual gyrus (red/yellow, <xref ref-type="fig" rid="pone-0004645-g004">Figure 4</xref>). These AOAs occurred in peripheral visual cortex anterior to the regions that showed visual ARMs. AOAs had similar amplitudes and distributions in fMRI sessions using continuous and sparse image acquisition (<xref ref-type="fig" rid="pone-0004645-g004">Figure 4</xref>, insert) and were observed in every subject (<xref ref-type="fig" rid="pone-0004645-g005">Figure 5</xref>).</p></sec><sec id="s3d"><title>Occipital regions generating AOAs</title><p>The results from one subject's retinotopic mapping are shown in <xref ref-type="fig" rid="pone-0004645-g005">Figure 5</xref>. AOAs in both subjects occurred in regions that were more peripheral than the maximal 5&#x000b0; eccentricities. AOA peaks occurred at Talairach coordinates of x&#x0200a;&#x0003d;&#x0200a;&#x02212;6, y&#x0200a;&#x0003d;&#x0200a;&#x02212;88 and z&#x0200a;&#x0003d;&#x0200a;16 in the cuneus (lower visual field) and x&#x0200a;&#x0003d;&#x0200a;&#x02212;10, y&#x0200a;&#x0003d;&#x0200a;&#x02212;56 and z&#x0200a;&#x0003d;&#x0200a;&#x02212;3 in the lingual gyrus (upper visual field). AOA foci corresponded to activations in the far peripheral regions of retinotopic cortex between the eccentricities of 12&#x000b0; and 49&#x000b0; as mapped by Stenbacka and Vanni <xref ref-type="bibr" rid="pone.0004645-Stenbacka1">&#x0005b;66&#x0005d;</xref>.</p></sec><sec id="s3e"><title>Region of Interest Analysis</title><p>he mean responses from the two ROIs (AOA and central vision ARM) during the four task conditions (BA bimodal stimulation, auditory attention condition, UA unimodal auditory, BV bimodal visual, UV unimodal visual) are plotted in <xref ref-type="fig" rid="pone-0004645-g006">Figure 6</xref>. <xref ref-type="fig" rid="pone-0004645-g006">Figure 6A</xref> shows the left hemisphere ARM activation map from the sparse imaging data, in which the ROIs are composed of all activated pixels falling within the outlined regions. The corresponding map from the continuous imaging data (used to analyze the ROIs) is shown alongside. The average responses from both ROIs during the four task conditions (UA, BA, UV and BV) are plotted in <xref ref-type="fig" rid="pone-0004645-g006">Figure 6B</xref>. In these plots responses were averaged across corresponding (but independently defined) ROIs from both hemispheres.</p><fig id="pone-0004645-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0004645.g006</object-id><label>Figure 6</label><caption><title>Region of interest (ROI) analyses.</title><p>(A) Left: ARM activation maps from the sparse imaging data, plotted on the mean curvature map of the left hemisphere. The color scale and statistical thresholds are the same as in <xref ref-type="fig" rid="pone-0004645-g003">Figure 3</xref>. All significant voxels circumscribed by the yellow and green lines were designated as the AOA and central vision ROIs, respectively. Right: activation map from the continuous imaging data set used to analyze the ROIs, illustrated using identical thresholds. (B) Mean percent signal change for the four main task conditions in continuous imaging sessions: bimodal auditory (BA), unimodal auditory (UA), bimodal visual (BV) and unimodal visual (UV). A significant BA-BV difference indicates an ARM; a significant BV-UV difference indicates an auditory SDA; a BA-BV difference represents a visual SDA. The AOA ROI response was greatest when subjects attended to sounds in the absence of visual stimuli (UA condition), and showed no auditory SDA. Bars show standard errors of the mean.</p></caption><graphic xlink:href="pone.0004645.g006"/></fig><p>The AOA ROI did not respond to the presence of unattended sounds. Activations in the AOA ROI did not differ in UV and BV conditions, (F<sub>(1,8)</sub>&#x0200a;&#x0003d;&#x0200a;0.42, p&#x0200a;&#x0003d;&#x0200a;0.54) showing that unattended auditory stimuli did not result in significant AOA generation. Moreover, activations in the AOA ROI were not affected by the intensity (F<sub>(1,8)</sub>&#x0200a;&#x0003d;&#x0200a;1.70, p&#x0003e;0.2), spatial location (F<sub>(1,8)</sub>&#x0200a;&#x0003d;&#x0200a;0.05, p&#x0003e;0.9) or frequency (F<sub>(2,16)</sub>&#x0200a;&#x0003d;&#x0200a;3.44, p&#x0003e;0.05) of unattended sounds.</p><p>In contrast, activations in the AOA ROI were significantly enhanced during attention to the auditory modality (BA vs. BV, F<sub>(1,8)</sub>&#x0200a;&#x0003d;&#x0200a;21.34, p&#x0003c;0.003). A comparison of the two auditory task conditions (UA and BA) revealed larger AOAs during the unimodal auditory attention condition when <italic>no</italic> visual stimuli were present (F<sub>(1,8)</sub>&#x0200a;&#x0003d;&#x0200a;8.86, p&#x0003c;0.02) suggesting that unattended visual stimuli inhibited AOA responses. The AOA ROI was not sensitive to the type of visual stimulus: neither the bimodal conditions ANOVA (F<sub>(1,8)</sub>&#x0200a;&#x0003d;&#x0200a;2.30, p&#x0200a;&#x0003d;&#x0200a;0.17) nor the visual task conditions ANOVA (F<sub>(1,8)</sub>&#x0200a;&#x0003d;&#x0200a;2.06, p&#x0200a;&#x0003d;&#x0200a;0.18) showed main effects of visual stimulus type.</p><p>The only stimulus parameter that reliably modulated AOA ROI activity was sound intensity: right hemisphere AOAs were larger during the more difficult auditory tasks with low-intensity sounds (F<sub>(1,8)</sub>&#x0200a;&#x0003d;&#x0200a;14.60, p&#x0003c;0.01). In the two bimodal conditions low-intensity sounds also evoked greater AOAs than high-intensity sounds (F<sub>(1,8)</sub>&#x0200a;&#x0003d;&#x0200a;8.73, p&#x0003c;0.02), with a similar right-hemisphere bias (F<sub>(1,8)</sub>&#x0200a;&#x0003d;&#x0200a;6.73, p&#x0003c;0.05).</p></sec><sec id="s3f"><title>Relationship of AOAs to task switching at the beginning and end of stimulus blocks</title><p><xref ref-type="fig" rid="pone-0004645-g007">Figure 7A</xref> shows the task switching regressor contrast map for the left hemisphere. There was no evidence of AOAs being associated with attentional transitions at the beginning or end of stimulation blocks.</p><fig id="pone-0004645-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0004645.g007</object-id><label>Figure 7</label><caption><title>Task-related processes and auditory occipital activations.</title><p>(A) <italic>Task-switching</italic>. Event-related time course regressors modeled activations associated with block termination and switching between auditory and visual tasks. Shown is the left hemisphere map from the continuous imaging data. Significant AOA regions (white outlines) overlapped very little with regions activated by task switching (red voxels). (B) <italic>Auditory target detection</italic>. Event-related time course regressors modeled button presses to targets during auditory attention blocks (red/yellow) as well as the intervals during which no responses were made (blue/cyan). Left hemisphere map is shown. AOA regions were not activated by target detection. (C) <italic>Inhibition by foveal visual cortex</italic>. Mixed-effects z-scores for the average correlation coefficient between the time course of each surface voxel and the mean time course of the AOA ROI, during unimodal visual conditions. Note the absence of significant correlations with central visual field voxels (region surrounding the circled cross). Left hemisphere map is shown.</p></caption><graphic xlink:href="pone.0004645.g007"/></fig></sec><sec id="s3g"><title>Relationship of AOAs to sustained auditory attention versus target detection responses</title><p><xref ref-type="fig" rid="pone-0004645-g007">Figure 7B</xref> shows that target detection produced little activation within the AOA ROI. Thus, AOAs appeared to primarily reflect tonic attention-related activity rather then activity specifically related to target detection.</p></sec><sec id="s3h"><title>Functional connectivity of AOA ROIs</title><p>The results of a partial correlation analysis using the mean AOA ROI as the seed are shown in <xref ref-type="fig" rid="pone-0004645-g007">Figure 7C</xref>. AOAs showed no significant correlations with activity in foveal visual cortex. However, the second partial correlation analysis showed a significant positive correlation (r&#x0200a;&#x0003d;&#x0200a;0.08; t<sub>8</sub>&#x0200a;&#x0003d;&#x0200a;3.34, p&#x0003c;0.02) between activation in the AOA ROI and auditory cortex. This supports the hypothesis that AOAs are components of a network of brain regions engaged when subjects actively listen to sounds.</p></sec></sec><sec id="s4"><title>Discussion</title><sec id="s4a"><title>Cognitive factors contributing to AOAs</title><p>In this study, AOAs depended critically on the engagement of auditory attention. AOAs were not generated by unattended sounds during visual attention conditions, regardless of sound intensity, location or frequency. In contrast, reliable AOAs were found in all subjects when they actively discriminated sounds. AOA magnitudes were not influenced by sound frequency or location, suggesting that they did not reflect the analysis of acoustic features.</p><p>The only acoustic parameter that modulated AOA magnitudes did so in a manner more consistent with an attentional account of AOA function than with a sensory role. AOAs were larger in blocks with low intensity sounds than in blocks with high intensity sounds. This effect is the opposite of fMRI sound intensity effects that are observed in core auditory sensory regions <xref ref-type="bibr" rid="pone.0004645-Bilecen1">&#x0005b;74&#x0005d;</xref>&#x02013;<xref ref-type="bibr" rid="pone.0004645-Woods2">&#x0005b;79&#x0005d;</xref>. Sound intensity was also the only acoustic parameter that affected behavioral performance. Thus, one explanation of AOA enhancements to low-intensity sounds is that they reflected the increased engagement of sustained auditory attention during the more difficult low-intensity task conditions.</p><p>AOAs were localized to regions of visual cortex with visual receptive fields sensitive to stimuli in the far periphery <xref ref-type="bibr" rid="pone.0004645-Stenbacka1">&#x0005b;66&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004645-Tootell2">&#x0005b;80&#x0005d;</xref>&#x02013;<xref ref-type="bibr" rid="pone.0004645-Sereno1">&#x0005b;82&#x0005d;</xref>. Lesions of these regions impair sound localization performance <xref ref-type="bibr" rid="pone.0004645-Kerkhoff1">&#x0005b;35&#x0005d;</xref>, and transient disruptions in processing in these regions from transcranial magnetic stimulation impairs performance on sound localization tasks <xref ref-type="bibr" rid="pone.0004645-Lewald1">&#x0005b;36&#x0005d;</xref>. The fact that AOA magnitudes were greater during behaviorally difficult blocks with low sound intensity suggests that AOAs are associated with auditory performance in sighted subjects, as has previously been reported in the blind <xref ref-type="bibr" rid="pone.0004645-Garg1">&#x0005b;4&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004645-Gougoux1">&#x0005b;6&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004645-Voss1">&#x0005b;8&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004645-Stevens1">&#x0005b;19&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004645-Voss2">&#x0005b;20&#x0005d;</xref>. The current results show that reliable AOAs can occur during non-spatial auditory discrimination tasks in sighted subjects, consistent with incidental reports of AOAs in previous studies of non-spatial attention tasks <xref ref-type="bibr" rid="pone.0004645-vonKriegstein1">&#x0005b;40&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004645-Degerman1">&#x0005b;43&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004645-Degerman2">&#x0005b;83&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004645-Alain1">&#x0005b;84&#x0005d;</xref>.</p><p>One common feature of experiments in which AOAs are detected in sighted subjects is that sounds were delivered through earphones. In contrast, decreased occipital activations have been reported during auditory attention tasks when sounds were presented through visible loudspeakers located in the frontal spatial plane <xref ref-type="bibr" rid="pone.0004645-Gougoux1">&#x0005b;6&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004645-Voss1">&#x0005b;8&#x0005d;</xref>. These results suggest that when attention is directed to sound sources that are subjectively localized outside the visual field (as when sounds are delivered through headphones) peripheral regions of visual cortex are activated. Thus, AOAs may represent a special case of location-specific activation of visual cortex associated with cross-modal attention to spatial locations outside the visual field <xref ref-type="bibr" rid="pone.0004645-Ress1">&#x0005b;85&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004645-Watkins1">&#x0005b;86&#x0005d;</xref>. As in previous reports, we found no consistent difference in the distribution of AOAs over the two hemispheres when sounds were delivered to one ear or the other <xref ref-type="bibr" rid="pone.0004645-Zimmer1">&#x0005b;37&#x0005d;</xref>. This lack of spatial specificity suggests that invisible sound sources may prime peripheral visual cortex bilaterally, perhaps because stimuli localized outside the visual field can enter the visual field from unpredictable directions.</p></sec><sec id="s4b"><title>AOAs in blind and sighted subjects</title><p>This study adds to growing evidence that AOAs occur in sighted as well as in blind subjects. It is now well-established that blind individuals, especially the congenitally or early blind, often have superior auditory task performance and larger AOAs than those found in sighted subjects <xref ref-type="bibr" rid="pone.0004645-Stevens1">&#x0005b;19&#x0005d;</xref>. The enhanced auditory performance of blind individuals is especially pronounced for sounds presented in the peripheral auditory field <xref ref-type="bibr" rid="pone.0004645-Fieger1">&#x0005b;24&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004645-Roder2">&#x0005b;25&#x0005d;</xref>. Conversely, deaf individuals exhibit enhanced visual target detection, but only in the visual periphery <xref ref-type="bibr" rid="pone.0004645-Bavelier2">&#x0005b;87&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004645-Bavelier3">&#x0005b;88&#x0005d;</xref>.</p><p>Enhanced performance in the blind may reflect cortical reorganization consequent to the disruption of normal visual input to the occipital lobe <xref ref-type="bibr" rid="pone.0004645-Bavelier1">&#x0005b;30&#x0005d;</xref>. Recent studies <xref ref-type="bibr" rid="pone.0004645-Garg1">&#x0005b;4&#x0005d;</xref> have suggested that AOAs in the blind may be mediated by anatomical projections between auditory association cortex and retinotopic visual cortex <xref ref-type="bibr" rid="pone.0004645-Cappe1">&#x0005b;11&#x0005d;</xref>. These projections terminate preferentially in peripheral visual cortex <xref ref-type="bibr" rid="pone.0004645-Falchier1">&#x0005b;10&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004645-Clavagnier1">&#x0005b;89&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004645-Rockland1">&#x0005b;90&#x0005d;</xref> and may play a role in the functional coupling of auditory and visual processing <xref ref-type="bibr" rid="pone.0004645-Eckert1">&#x0005b;12&#x0005d;</xref> seen in the current experiment. Enhanced development or utilization of these pathways may explain why blind individuals outperform sighted subjects in sound-localization tasks, but only when sounds are presented in peripheral locations <xref ref-type="bibr" rid="pone.0004645-Fieger1">&#x0005b;24&#x0005d;</xref>.</p></sec><sec id="s4c"><title>The relationship of AOAs to visual and auditory attention</title><p>Auditory signals can deactivate central regions of visual cortex that are activated by foveally presented visual stimuli <xref ref-type="bibr" rid="pone.0004645-Laurienti1">&#x0005b;91&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004645-Kawashima1">&#x0005b;92&#x0005d;</xref>. These deactivations depend on auditory attention <xref ref-type="bibr" rid="pone.0004645-Lewis1">&#x0005b;93&#x0005d;</xref>&#x02013;<xref ref-type="bibr" rid="pone.0004645-Lewis2">&#x0005b;95&#x0005d;</xref> and are enhanced in conditions with greater auditory attentional load <xref ref-type="bibr" rid="pone.0004645-Hairston1">&#x0005b;96&#x0005d;</xref>. Since we generated AOAs using comparisons of visual versus auditory attention conditions, AOAs may have reflected the release from the inhibition of the peripheral visual cortex that has been hypothesized to occur when subjects attend to foveally presented stimuli <xref ref-type="bibr" rid="pone.0004645-Muller1">&#x0005b;70&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004645-Tootell1">&#x0005b;71&#x0005d;</xref>, <xref ref-type="bibr" rid="pone.0004645-Silver1">&#x0005b;97&#x0005d;</xref>. This explanation is consistent with the observation that unattended visual stimuli reduced AOAs. Unattended visual stimuli would activate central visual cortex and simultaneously inhibit activations in peripheral visual regions.</p><p>However, the inhibition hypothesis predicts that there should be a systematic negative correlation between the magnitude of foveal visual cortex activations and the magnitude of AOAs. We found no significant correlations between AOAs and activations in the central vision ROI, suggesting that AOAs are not a direct consequence of inhibition exerted by foveal visual cortex. Rather, AOAs showed significant functional coupling with attention-related activations in auditory cortex.</p><p>Jack and colleagues <xref ref-type="bibr" rid="pone.0004645-Jack1">&#x0005b;56&#x0005d;</xref> mapped AOAs to the cortical surface during tone discrimination tasks and found activation in retinotopic peripheral visual cortex, as in the current study. They also found that similar AOAs were produced following attended auditory response cues during visual discrimination tasks and when subjects produced self-generated responses in the absence of any auditory stimulation (i.e., after silently counting). It was proposed that these activations reflected top-down modulations of visual cortex associated with task completion at block transitions <xref ref-type="bibr" rid="pone.0004645-Shulman1">&#x0005b;98&#x0005d;</xref>&#x02013;<xref ref-type="bibr" rid="pone.0004645-Dosenbach1">&#x0005b;100&#x0005d;</xref>. However, in the current study, we found no evidence of AOAs at block transitions, nor were AOAs associated with responses to auditory task targets. Thus, an alternative explanation of Jack et al's findings is that the AOAs observed reflected auditory attention to task-relevant auditory cues and the activation of the auditory attention network during silent counting <xref ref-type="bibr" rid="pone.0004645-Kansaku1">&#x0005b;101&#x0005d;</xref>.</p><p>Finally, we should note that the relationship between AOAs and auditory performance does not imply that occipital cortex need always be engaged by auditory attention. The efferent projections from auditory cortex to V1 in the macaque suggest that AOAs reflect the downstream modulation of peripheral visual cortex consequent to attention-related modulations in auditory cortex, of the sort observed in the current experiment (see <xref ref-type="fig" rid="pone-0004645-g004">Fig. 4</xref>) <xref ref-type="bibr" rid="pone.0004645-Woods2">&#x0005b;79&#x0005d;</xref>.</p></sec><sec id="s4d"><title>Conclusions</title><p>Auditory occipital activations (AOAs) were found to depend strictly on auditory attention, and were not elicited by unattended sounds regardless of their acoustic properties. AOAs occurred reliably in auditory attention conditions and were enhanced during attention to unimodal auditory sequences and during the more difficult auditory-attention conditions with low-intensity sounds. AOAs were unrelated to activations in central visual cortex but showed significant functional coupling with attention-related activations in auditory cortex. Our results suggest that visual cortex subserving the far periphery is consistently engaged when subjects attended to sound sources outside the field of view. Crossmodal interactions between sensory cortices may indeed be the rule and not the exception in perception <xref ref-type="bibr" rid="pone.0004645-Shimojo1">&#x0005b;102&#x0005d;</xref>, and focusing on the attentional demands of perceptual tasks in neuroimaging studies may reveal increasing evidence of such effects.</p></sec></sec><sec sec-type="supplementary-material" id="s5"><title>Supporting Information</title><supplementary-material content-type="local-data" id="pone.0004645.s001"><label>Figure S1</label><caption><p>Partial correlation analysis of auditory occipital activations and auditory cortex ROIs. The partial correlation under all task conditions was computed for the AOA ROI (all activated voxels within yellow outline) and an auditory cortex ROI (solid yellow region) located in Heschl's gyrus (HG) and the superior temporal gyrus (STG). The auditory cortex ROI was defined, using the data from sparse image acquisitions sessions, by subtracting responses during unimodal visual (UV) blocks from bimodal visual (BV) blocks. This ROI included all voxels meeting the three criteria of z&#x0003e;5.88 (p&#x0226a;0.001), percent signal change &#x0003e;0.1&#x00025; and cluster size 200 cortical surface voxels, and represented the auditory cortex region responding most strongly to unattended sounds. Data from the continuous image acquisition sessions were used to calculate the correlation while partialling out the global signal (means of both entire hemispheres) and head motion parameters; signal from an ROI defined as all visual ARM voxels in the posterior occipital region (all activated voxels within green outline); and indicator variables for bimodal vs. unimodal blocks and for auditory vs. visual blocks. The activation map shows the auditory (red) and visual (blue) ARM contrast using sparse image acquisition data from the left hemisphere; it is identical to the map in <xref ref-type="fig" rid="pone-0004645-g004">Figure 4</xref>. TP temporal pole, FG fusiform gyrus, IPS intraparietal sulcus, CC corpus callosum, CentS central sulcus. A circled cross indicates the occipital pole.</p><p>(0.92 MB TIF)</p></caption><media xlink:href="pone.0004645.s001.tif" mimetype="image" mime-subtype="tiff"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></sec></body><back><ack><p>We thank Kimmo Alho for helpful comments.</p></ack><ref-list><title>References</title><ref id="pone.0004645-Buchel1"><label>1</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Buchel</surname><given-names>C</given-names></name><name><surname>Price</surname><given-names>C</given-names></name><name><surname>Frackowiak</surname><given-names>RS</given-names></name><name><surname>Friston</surname><given-names>K</given-names></name></person-group><year>1998</year><article-title>Different activation patterns in the visual cortex of late and congenitally blind subjects.</article-title><source>Brain</source><volume>121 (Pt 3)</volume><fpage>409</fpage><lpage>419</lpage><pub-id pub-id-type="pmid">9549517</pub-id></citation></ref><ref id="pone.0004645-Weeks1"><label>2</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Weeks</surname><given-names>R</given-names></name><name><surname>Horwitz</surname><given-names>B</given-names></name><name><surname>Aziz-Sultan</surname><given-names>A</given-names></name><name><surname>Tian</surname><given-names>B</given-names></name><name><surname>Wessinger</surname><given-names>CM</given-names></name><etal/></person-group><year>2000</year><article-title>A positron emission tomographic study of auditory localization in the congenitally blind.</article-title><source>J Neurosci</source><volume>20</volume><fpage>2664</fpage><lpage>2672</lpage><pub-id pub-id-type="pmid">10729347</pub-id></citation></ref><ref id="pone.0004645-Arno1"><label>3</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Arno</surname><given-names>P</given-names></name><name><surname>De Volder</surname><given-names>AG</given-names></name><name><surname>Vanlierde</surname><given-names>A</given-names></name><name><surname>Wanet-Defalque</surname><given-names>MC</given-names></name><name><surname>Streel</surname><given-names>E</given-names></name><etal/></person-group><year>2001</year><article-title>Occipital activation by pattern recognition in the early blind using auditory substitution for vision.</article-title><source>Neuroimage</source><volume>13</volume><fpage>632</fpage><lpage>645</lpage><pub-id pub-id-type="pmid">11305892</pub-id></citation></ref><ref id="pone.0004645-Garg1"><label>4</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Garg</surname><given-names>A</given-names></name><name><surname>Schwartz</surname><given-names>D</given-names></name><name><surname>Stevens</surname><given-names>AA</given-names></name></person-group><year>2007</year><article-title>Orienting auditory spatial attention engages frontal eye fields and medial occipital cortex in congenitally blind humans.</article-title><source>Neuropsychologia</source><volume>45</volume><fpage>2307</fpage><lpage>2321</lpage><pub-id pub-id-type="pmid">17397882</pub-id></citation></ref><ref id="pone.0004645-Roder1"><label>5</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Roder</surname><given-names>B</given-names></name><name><surname>Stock</surname><given-names>O</given-names></name><name><surname>Bien</surname><given-names>S</given-names></name><name><surname>Neville</surname><given-names>H</given-names></name><name><surname>Rosler</surname><given-names>F</given-names></name></person-group><year>2002</year><article-title>Speech processing activates visual cortex in congenitally blind humans.</article-title><source>Eur J Neurosci</source><volume>16</volume><fpage>930</fpage><lpage>936</lpage><pub-id pub-id-type="pmid">12372029</pub-id></citation></ref><ref id="pone.0004645-Gougoux1"><label>6</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Gougoux</surname><given-names>F</given-names></name><name><surname>Zatorre</surname><given-names>RJ</given-names></name><name><surname>Lassonde</surname><given-names>M</given-names></name><name><surname>Voss</surname><given-names>P</given-names></name><name><surname>Lepore</surname><given-names>F</given-names></name></person-group><year>2005</year><article-title>A functional neuroimaging study of sound localization: visual cortex activity predicts performance in early-blind individuals.</article-title><source>PLoS Biol</source><volume>3</volume><fpage>e27</fpage><pub-id pub-id-type="pmid">15678166</pub-id></citation></ref><ref id="pone.0004645-Burton1"><label>7</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Burton</surname><given-names>H</given-names></name><name><surname>McLaren</surname><given-names>DG</given-names></name></person-group><year>2006</year><article-title>Visual cortex activation in late-onset, Braille naive blind individuals: an fMRI study during semantic and phonological tasks with heard words.</article-title><source>Neurosci Lett</source><volume>392</volume><fpage>38</fpage><lpage>42</lpage><pub-id pub-id-type="pmid">16198053</pub-id></citation></ref><ref id="pone.0004645-Voss1"><label>8</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Voss</surname><given-names>P</given-names></name><name><surname>Gougoux</surname><given-names>F</given-names></name><name><surname>Zatorre</surname><given-names>RJ</given-names></name><name><surname>Lassonde</surname><given-names>M</given-names></name><name><surname>Lepore</surname><given-names>F</given-names></name></person-group><year>2008</year><article-title>Differential occipital responses in early- and late-blind individuals during a sound-source discrimination task.</article-title><source>Neuroimage</source><volume>40</volume><fpage>746</fpage><lpage>758</lpage><pub-id pub-id-type="pmid">18234523</pub-id></citation></ref><ref id="pone.0004645-Wu1"><label>9</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>CT</given-names></name><name><surname>Weissman</surname><given-names>DH</given-names></name><name><surname>Roberts</surname><given-names>KC</given-names></name><name><surname>Woldorff</surname><given-names>MG</given-names></name></person-group><year>2007</year><article-title>The neural circuitry underlying the executive control of auditory spatial attention.</article-title><source>Brain Res</source><volume>1134</volume><fpage>187</fpage><lpage>198</lpage><pub-id pub-id-type="pmid">17204249</pub-id></citation></ref><ref id="pone.0004645-Falchier1"><label>10</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Falchier</surname><given-names>A</given-names></name><name><surname>Clavagnier</surname><given-names>S</given-names></name><name><surname>Barone</surname><given-names>P</given-names></name><name><surname>Kennedy</surname><given-names>H</given-names></name></person-group><year>2002</year><article-title>Anatomical evidence of multimodal integration in primate striate cortex.</article-title><source>J Neurosci</source><volume>22</volume><fpage>5749</fpage><lpage>5759</lpage><pub-id pub-id-type="pmid">12097528</pub-id></citation></ref><ref id="pone.0004645-Cappe1"><label>11</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Cappe</surname><given-names>C</given-names></name><name><surname>Barone</surname><given-names>P</given-names></name></person-group><year>2005</year><article-title>Heteromodal connections supporting multisensory integration at low levels of cortical processing in the monkey.</article-title><source>Eur J Neurosci</source><volume>22</volume><fpage>2886</fpage><lpage>2902</lpage><pub-id pub-id-type="pmid">16324124</pub-id></citation></ref><ref id="pone.0004645-Eckert1"><label>12</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Eckert</surname><given-names>MA</given-names></name><name><surname>Kamdar</surname><given-names>NV</given-names></name><name><surname>Chang</surname><given-names>CE</given-names></name><name><surname>Beckmann</surname><given-names>CF</given-names></name><name><surname>Greicius</surname><given-names>MD</given-names></name><etal/></person-group><year>2008</year><article-title>A cross-modal system linking primary auditory and visual cortices: Evidence from intrinsic fMRI connectivity analysis.</article-title><source>Hum Brain Mapp</source><volume>29</volume><fpage>848</fpage><lpage>857</lpage><pub-id pub-id-type="pmid">18412133</pub-id></citation></ref><ref id="pone.0004645-Zhang1"><label>13</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>N</given-names></name><name><surname>Chen</surname><given-names>W</given-names></name></person-group><year>2006</year><article-title>A dynamic fMRI study of illusory double-flash effect on human visual cortex.</article-title><source>Exp Brain Res</source><volume>172</volume><fpage>57</fpage><lpage>66</lpage><pub-id pub-id-type="pmid">16369788</pub-id></citation></ref><ref id="pone.0004645-Shams1"><label>14</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Shams</surname><given-names>L</given-names></name><name><surname>Kamitani</surname><given-names>Y</given-names></name><name><surname>Shimojo</surname><given-names>S</given-names></name></person-group><year>2002</year><article-title>Visual illusion induced by sound.</article-title><source>Brain Res Cogn Brain Res</source><volume>14</volume><fpage>147</fpage><lpage>152</lpage><pub-id pub-id-type="pmid">12063138</pub-id></citation></ref><ref id="pone.0004645-Shams2"><label>15</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Shams</surname><given-names>L</given-names></name><name><surname>Kamitani</surname><given-names>Y</given-names></name><name><surname>Shimojo</surname><given-names>S</given-names></name></person-group><year>2000</year><article-title>Illusions. What you see is what you hear.</article-title><source>Nature</source><volume>408</volume><fpage>788</fpage><pub-id pub-id-type="pmid">11130706</pub-id></citation></ref><ref id="pone.0004645-Kujala1"><label>16</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kujala</surname><given-names>T</given-names></name><name><surname>Alho</surname><given-names>K</given-names></name><name><surname>Paavilainen</surname><given-names>P</given-names></name><name><surname>Summala</surname><given-names>H</given-names></name><name><surname>Naatanen</surname><given-names>R</given-names></name></person-group><year>1992</year><article-title>Neural plasticity in processing of sound location by the early blind: an event-related potential study.</article-title><source>Electroencephalography and Clinical Neurophysiology</source><volume>84</volume><fpage>469</fpage><lpage>472</lpage><pub-id pub-id-type="pmid">1382956</pub-id></citation></ref><ref id="pone.0004645-Alho1"><label>17</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Alho</surname><given-names>K</given-names></name><name><surname>Kujala</surname><given-names>T</given-names></name><name><surname>Paavilainen</surname><given-names>P</given-names></name><name><surname>Summala</surname><given-names>H</given-names></name><name><surname>Naatanen</surname><given-names>R</given-names></name></person-group><year>1993</year><article-title>Auditory processing in visual brain areas of the early blind: evidence from event-related potentials.</article-title><source>Electroencephalography and Clinical Neurophysiology</source><volume>86</volume><fpage>418</fpage><lpage>427</lpage><pub-id pub-id-type="pmid">7686476</pub-id></citation></ref><ref id="pone.0004645-Kujala2"><label>18</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kujala</surname><given-names>T</given-names></name><name><surname>Huotilainen</surname><given-names>M</given-names></name><name><surname>Sinkkonen</surname><given-names>J</given-names></name><name><surname>Ahonen</surname><given-names>AI</given-names></name><etal/></person-group><year>1995</year><article-title>Visual cortex activation in blind humans during sound discrimination.</article-title><source>Neuroscience Letters</source><volume>183</volume><fpage>143</fpage><lpage>146</lpage><pub-id pub-id-type="pmid">7746476</pub-id></citation></ref><ref id="pone.0004645-Stevens1"><label>19</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Stevens</surname><given-names>AA</given-names></name><name><surname>Snodgrass</surname><given-names>M</given-names></name><name><surname>Schwartz</surname><given-names>D</given-names></name><name><surname>Weaver</surname><given-names>K</given-names></name></person-group><year>2007</year><article-title>Preparatory activity in occipital cortex in early blind humans predicts auditory perceptual performance.</article-title><source>J Neurosci</source><volume>27</volume><fpage>10734</fpage><lpage>10741</lpage><pub-id pub-id-type="pmid">17913907</pub-id></citation></ref><ref id="pone.0004645-Voss2"><label>20</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Voss</surname><given-names>P</given-names></name><name><surname>Gougoux</surname><given-names>F</given-names></name><name><surname>Lassonde</surname><given-names>M</given-names></name><name><surname>Zatorre</surname><given-names>RJ</given-names></name><name><surname>Lepore</surname><given-names>F</given-names></name></person-group><year>2006</year><article-title>A positron emission tomography study during auditory localization by late-onset blind individuals.</article-title><source>Neuroreport</source><volume>17</volume><fpage>383</fpage><lpage>388</lpage><pub-id pub-id-type="pmid">16514363</pub-id></citation></ref><ref id="pone.0004645-Weaver1"><label>21</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Weaver</surname><given-names>KE</given-names></name><name><surname>Stevens</surname><given-names>AA</given-names></name></person-group><year>2007</year><article-title>Attention and sensory interactions within the occipital cortex in the early blind: an fMRI study.</article-title><source>J Cogn Neurosci</source><volume>19</volume><fpage>315</fpage><lpage>330</lpage><pub-id pub-id-type="pmid">17280519</pub-id></citation></ref><ref id="pone.0004645-Kujala3"><label>22</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kujala</surname><given-names>T</given-names></name><name><surname>Palva</surname><given-names>MJ</given-names></name><name><surname>Salonen</surname><given-names>O</given-names></name><name><surname>Alku</surname><given-names>P</given-names></name><name><surname>Huotilainen</surname><given-names>M</given-names></name><etal/></person-group><year>2005</year><article-title>The role of blind humans' visual cortex in auditory change detection.</article-title><source>Neurosci Lett</source><volume>379</volume><fpage>127</fpage><lpage>131</lpage><pub-id pub-id-type="pmid">15823429</pub-id></citation></ref><ref id="pone.0004645-Muchnik1"><label>23</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Muchnik</surname><given-names>C</given-names></name><name><surname>Efrati</surname><given-names>M</given-names></name><name><surname>Nemeth</surname><given-names>E</given-names></name><name><surname>Malin</surname><given-names>M</given-names></name><name><surname>Hildesheimer</surname><given-names>M</given-names></name></person-group><year>1991</year><article-title>Central auditory skills in blind and sighted subjects.</article-title><source>Scand Audiol</source><volume>20</volume><fpage>19</fpage><lpage>23</lpage><pub-id pub-id-type="pmid">1842264</pub-id></citation></ref><ref id="pone.0004645-Fieger1"><label>24</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Fieger</surname><given-names>A</given-names></name><name><surname>Roder</surname><given-names>B</given-names></name><name><surname>Teder-Salejarvi</surname><given-names>W</given-names></name><name><surname>Hillyard</surname><given-names>SA</given-names></name><name><surname>Neville</surname><given-names>HJ</given-names></name></person-group><year>2006</year><article-title>Auditory spatial tuning in late-onset blindness in humans.</article-title><source>J Cogn Neurosci</source><volume>18</volume><fpage>149</fpage><lpage>157</lpage><pub-id pub-id-type="pmid">16494677</pub-id></citation></ref><ref id="pone.0004645-Roder2"><label>25</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Roder</surname><given-names>B</given-names></name><name><surname>Teder-Salejarvi</surname><given-names>W</given-names></name><name><surname>Sterr</surname><given-names>A</given-names></name><name><surname>Rosler</surname><given-names>F</given-names></name><name><surname>Hillyard</surname><given-names>SA</given-names></name><etal/></person-group><year>1999</year><article-title>Improved auditory spatial tuning in blind humans.</article-title><source>Nature</source><volume>400</volume><fpage>162</fpage><lpage>166</lpage><pub-id pub-id-type="pmid">10408442</pub-id></citation></ref><ref id="pone.0004645-Voss3"><label>26</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Voss</surname><given-names>P</given-names></name><name><surname>Lassonde</surname><given-names>M</given-names></name><name><surname>Gougoux</surname><given-names>F</given-names></name><name><surname>Fortin</surname><given-names>M</given-names></name><name><surname>Guillemot</surname><given-names>JP</given-names></name><etal/></person-group><year>2004</year><article-title>Early- and late-onset blind individuals show supra-normal auditory abilities in far-space.</article-title><source>Curr Biol</source><volume>14</volume><fpage>1734</fpage><lpage>1738</lpage><pub-id pub-id-type="pmid">15458644</pub-id></citation></ref><ref id="pone.0004645-Ross1"><label>27</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ross</surname><given-names>DA</given-names></name><name><surname>Olson</surname><given-names>IR</given-names></name><name><surname>Gore</surname><given-names>JC</given-names></name></person-group><year>2003</year><article-title>Cortical plasticity in an early blind musician: an fMRl study.</article-title><source>Magn Reson Imaging</source><volume>21</volume><fpage>821</fpage><lpage>828</lpage><pub-id pub-id-type="pmid">14559348</pub-id></citation></ref><ref id="pone.0004645-Neville1"><label>28</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Neville</surname><given-names>H</given-names></name><name><surname>Bavelier</surname><given-names>D</given-names></name></person-group><year>2002</year><article-title>Human brain plasticity: evidence from sensory deprivation and altered language experience.</article-title><source>Prog Brain Res</source><volume>138</volume><fpage>177</fpage><lpage>188</lpage><pub-id pub-id-type="pmid">12432770</pub-id></citation></ref><ref id="pone.0004645-Kahn1"><label>29</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kahn</surname><given-names>DM</given-names></name><name><surname>Krubitzer</surname><given-names>L</given-names></name></person-group><year>2002</year><article-title>Massive cross-modal cortical plasticity and the emergence of a new cortical area in developmentally blind mammals.</article-title><source>Proc Natl Acad Sci U S A</source><volume>99</volume><fpage>11429</fpage><lpage>11434</lpage><pub-id pub-id-type="pmid">12163645</pub-id></citation></ref><ref id="pone.0004645-Bavelier1"><label>30</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Bavelier</surname><given-names>D</given-names></name><name><surname>Neville</surname><given-names>HJ</given-names></name></person-group><year>2002</year><article-title>Cross-modal plasticity: where and how?</article-title><source>Nat Rev Neurosci</source><volume>3</volume><fpage>443</fpage><lpage>452</lpage><pub-id pub-id-type="pmid">12042879</pub-id></citation></ref><ref id="pone.0004645-Liotti1"><label>31</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Liotti</surname><given-names>M</given-names></name><name><surname>Ryder</surname><given-names>K</given-names></name><name><surname>Woldorff</surname><given-names>MG</given-names></name></person-group><year>1998</year><article-title>Auditory attention in the congenitally blind: where, when and what gets reorganized?</article-title><source>Neuroreport</source><volume>9</volume><fpage>1007</fpage><lpage>1012</lpage><pub-id pub-id-type="pmid">9601658</pub-id></citation></ref><ref id="pone.0004645-Kujala4"><label>32</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kujala</surname><given-names>T</given-names></name><name><surname>Alho</surname><given-names>K</given-names></name><name><surname>Huotilainen</surname><given-names>M</given-names></name><name><surname>Ilmoniemi</surname><given-names>RJ</given-names></name><name><surname>Lehtokoski</surname><given-names>A</given-names></name><etal/></person-group><year>1997</year><article-title>Electrophysiological evidence for cross-modal plasticity in humans with early- and late-onset blindness.</article-title><source>Psychophysiology</source><volume>34</volume><fpage>213</fpage><lpage>216</lpage><pub-id pub-id-type="pmid">9090272</pub-id></citation></ref><ref id="pone.0004645-Roder3"><label>33</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Roder</surname><given-names>B</given-names></name><name><surname>Rosler</surname><given-names>F</given-names></name><name><surname>Hennighausen</surname><given-names>E</given-names></name><name><surname>Nacker</surname><given-names>F</given-names></name></person-group><year>1996</year><article-title>Event-related potentials during auditory and somatosensory discrimination in sighted and blind human subjects.</article-title><source>Brain Research Cognitive Brain Research</source><volume>4</volume><fpage>77</fpage><lpage>93</lpage><pub-id pub-id-type="pmid">8883921</pub-id></citation></ref><ref id="pone.0004645-Rauschecker1"><label>34</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Rauschecker</surname><given-names>JP</given-names></name><name><surname>Korte</surname><given-names>M</given-names></name></person-group><year>1993</year><article-title>Auditory compensation for early blindness in cat cerebral cortex.</article-title><source>Journal of Neuroscience</source><volume>13</volume><fpage>4538</fpage><lpage>4548</lpage><pub-id pub-id-type="pmid">8410202</pub-id></citation></ref><ref id="pone.0004645-Kerkhoff1"><label>35</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kerkhoff</surname><given-names>G</given-names></name><name><surname>Artinger</surname><given-names>F</given-names></name><name><surname>Ziegler</surname><given-names>W</given-names></name></person-group><year>1999</year><article-title>Contrasting spatial hearing deficits in hemianopia and spatial neglect.</article-title><source>Neuroreport</source><volume>10</volume><fpage>3555</fpage><lpage>3560</lpage><pub-id pub-id-type="pmid">10619643</pub-id></citation></ref><ref id="pone.0004645-Lewald1"><label>36</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Lewald</surname><given-names>J</given-names></name><name><surname>Meister</surname><given-names>IG</given-names></name><name><surname>Weidemann</surname><given-names>J</given-names></name><name><surname>Topper</surname><given-names>R</given-names></name></person-group><year>2004</year><article-title>Involvement of the superior temporal cortex and the occipital cortex in spatial hearing: evidence from repetitive transcranial magnetic stimulation.</article-title><source>J Cogn Neurosci</source><volume>16</volume><fpage>828</fpage><lpage>838</lpage><pub-id pub-id-type="pmid">15200710</pub-id></citation></ref><ref id="pone.0004645-Zimmer1"><label>37</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Zimmer</surname><given-names>U</given-names></name><name><surname>Lewald</surname><given-names>J</given-names></name><name><surname>Erb</surname><given-names>M</given-names></name><name><surname>Grodd</surname><given-names>W</given-names></name><name><surname>Karnath</surname><given-names>HO</given-names></name></person-group><year>2004</year><article-title>Is there a role of visual cortex in spatial hearing?</article-title><source>Eur J Neurosci</source><volume>20</volume><fpage>3148</fpage><lpage>3156</lpage><pub-id pub-id-type="pmid">15579169</pub-id></citation></ref><ref id="pone.0004645-Specht1"><label>38</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Specht</surname><given-names>K</given-names></name><name><surname>Reul</surname><given-names>J</given-names></name></person-group><year>2003</year><article-title>Functional segregation of the temporal lobes into highly differentiated subsystems for auditory perception: an auditory rapid event-related fMRI-task.</article-title><source>Neuroimage</source><volume>20</volume><fpage>1944</fpage><lpage>1954</lpage><pub-id pub-id-type="pmid">14683700</pub-id></citation></ref><ref id="pone.0004645-Just1"><label>39</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Just</surname><given-names>MA</given-names></name><name><surname>Newman</surname><given-names>SD</given-names></name><name><surname>Keller</surname><given-names>TA</given-names></name><name><surname>McEleney</surname><given-names>A</given-names></name><name><surname>Carpenter</surname><given-names>PA</given-names></name></person-group><year>2004</year><article-title>Imagery in sentence comprehension: an fMRI study.</article-title><source>Neuroimage</source><volume>21</volume><fpage>112</fpage><lpage>124</lpage><pub-id pub-id-type="pmid">14741648</pub-id></citation></ref><ref id="pone.0004645-vonKriegstein1"><label>40</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>von Kriegstein</surname><given-names>K</given-names></name><name><surname>Eger</surname><given-names>E</given-names></name><name><surname>Kleinschmidt</surname><given-names>A</given-names></name><name><surname>Giraud</surname><given-names>AL</given-names></name></person-group><year>2003</year><article-title>Modulation of neural responses to speech by directing attention to voices or verbal content.</article-title><source>Brain Res Cogn Brain Res</source><volume>17</volume><fpage>48</fpage><lpage>55</lpage><pub-id pub-id-type="pmid">12763191</pub-id></citation></ref><ref id="pone.0004645-Carmody1"><label>41</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Carmody</surname><given-names>DP</given-names></name><name><surname>Lewis</surname><given-names>M</given-names></name></person-group><year>2006</year><article-title>Brain activation when hearing one's own and others' names.</article-title><source>Brain Res</source><volume>1116</volume><fpage>153</fpage><lpage>158</lpage><pub-id pub-id-type="pmid">16959226</pub-id></citation></ref><ref id="pone.0004645-Johnson1"><label>42</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>JA</given-names></name><name><surname>Zatorre</surname><given-names>RJ</given-names></name></person-group><year>2005</year><article-title>Attention to simultaneous unrelated auditory and visual events: behavioral and neural correlates.</article-title><source>Cereb Cortex</source><volume>15</volume><fpage>1609</fpage><lpage>1620</lpage><pub-id pub-id-type="pmid">15716469</pub-id></citation></ref><ref id="pone.0004645-Degerman1"><label>43</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Degerman</surname><given-names>A</given-names></name><name><surname>Rinne</surname><given-names>T</given-names></name><name><surname>Salmi</surname><given-names>J</given-names></name><name><surname>Salonen</surname><given-names>O</given-names></name><name><surname>Alho</surname><given-names>K</given-names></name></person-group><year>2006</year><article-title>Selective attention to sound location or pitch studied with fMRI.</article-title><source>Brain Res</source><volume>1077</volume><fpage>123</fpage><lpage>134</lpage><pub-id pub-id-type="pmid">16515772</pub-id></citation></ref><ref id="pone.0004645-Sabri1"><label>44</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Sabri</surname><given-names>M</given-names></name><name><surname>Binder</surname><given-names>JR</given-names></name><name><surname>Desai</surname><given-names>R</given-names></name><name><surname>Medler</surname><given-names>DA</given-names></name><name><surname>Leitl</surname><given-names>MD</given-names></name><etal/></person-group><year>2008</year><article-title>Attentional and linguistic interactions in speech perception.</article-title><source>Neuroimage</source><volume>39</volume><fpage>1444</fpage><lpage>1456</lpage><pub-id pub-id-type="pmid">17996463</pub-id></citation></ref><ref id="pone.0004645-Platel1"><label>45</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Platel</surname><given-names>H</given-names></name><name><surname>Price</surname><given-names>C</given-names></name><name><surname>Baron</surname><given-names>JC</given-names></name><name><surname>Wise</surname><given-names>R</given-names></name><name><surname>Lambert</surname><given-names>J</given-names></name><etal/></person-group><year>1997</year><article-title>The structural components of music perception. A functional anatomical study.</article-title><source>Brain</source><volume>120 (Pt 2)</volume><fpage>229</fpage><lpage>243</lpage><pub-id pub-id-type="pmid">9117371</pub-id></citation></ref><ref id="pone.0004645-Janata1"><label>46</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Janata</surname><given-names>P</given-names></name><name><surname>Tillmann</surname><given-names>B</given-names></name><name><surname>Bharucha</surname><given-names>JJ</given-names></name></person-group><year>2002</year><article-title>Listening to polyphonic music recruits domain-general attention and working memory circuits.</article-title><source>Cogn Affect Behav Neurosci</source><volume>2</volume><fpage>121</fpage><lpage>140</lpage><pub-id pub-id-type="pmid">12455680</pub-id></citation></ref><ref id="pone.0004645-Saito1"><label>47</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Saito</surname><given-names>DN</given-names></name><name><surname>Yoshimura</surname><given-names>K</given-names></name><name><surname>Kochiyama</surname><given-names>T</given-names></name><name><surname>Okada</surname><given-names>T</given-names></name><name><surname>Honda</surname><given-names>M</given-names></name><etal/></person-group><year>2005</year><article-title>Cross-modal binding and activated attentional networks during audio-visual speech integration: a functional MRI study.</article-title><source>Cereb Cortex</source><volume>15</volume><fpage>1750</fpage><lpage>1760</lpage><pub-id pub-id-type="pmid">15716468</pub-id></citation></ref><ref id="pone.0004645-Eisenberg1"><label>48</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Eisenberg</surname><given-names>DP</given-names></name><name><surname>London</surname><given-names>ED</given-names></name><name><surname>Matochik</surname><given-names>JA</given-names></name><name><surname>Derbyshire</surname><given-names>S</given-names></name><name><surname>Cohen</surname><given-names>LJ</given-names></name><etal/></person-group><year>2005</year><article-title>Education-associated cortical glucose metabolism during sustained attention.</article-title><source>Neuroreport</source><volume>16</volume><fpage>1473</fpage><lpage>1476</lpage><pub-id pub-id-type="pmid">16110274</pub-id></citation></ref><ref id="pone.0004645-Maeder1"><label>49</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Maeder</surname><given-names>PP</given-names></name><name><surname>Meuli</surname><given-names>RA</given-names></name><name><surname>Adriani</surname><given-names>M</given-names></name><name><surname>Bellmann</surname><given-names>A</given-names></name><name><surname>Fornari</surname><given-names>E</given-names></name><etal/></person-group><year>2001</year><article-title>Distinct pathways involved in sound recognition and localization: a human fMRI study.</article-title><source>Neuroimage</source><volume>14</volume><fpage>802</fpage><lpage>816</lpage><pub-id pub-id-type="pmid">11554799</pub-id></citation></ref><ref id="pone.0004645-Mayer1"><label>50</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Mayer</surname><given-names>AR</given-names></name><name><surname>Harrington</surname><given-names>D</given-names></name><name><surname>Adair</surname><given-names>JC</given-names></name><name><surname>Lee</surname><given-names>R</given-names></name></person-group><year>2006</year><article-title>The neural networks underlying endogenous auditory covert orienting and reorienting.</article-title><source>Neuroimage</source><volume>30</volume><fpage>938</fpage><lpage>949</lpage><pub-id pub-id-type="pmid">16388970</pub-id></citation></ref><ref id="pone.0004645-Yoo1"><label>51</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Yoo</surname><given-names>SS</given-names></name><name><surname>Lee</surname><given-names>CU</given-names></name><name><surname>Choi</surname><given-names>BG</given-names></name></person-group><year>2001</year><article-title>Human brain mapping of auditory imagery: event-related functional MRI study.</article-title><source>Neuroreport</source><volume>12</volume><fpage>3045</fpage><lpage>3049</lpage><pub-id pub-id-type="pmid">11568634</pub-id></citation></ref><ref id="pone.0004645-Burton2"><label>52</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Burton</surname><given-names>H</given-names></name><name><surname>Diamond</surname><given-names>JB</given-names></name><name><surname>McDermott</surname><given-names>KB</given-names></name></person-group><year>2003</year><article-title>Dissociating cortical regions activated by semantic and phonological tasks: a FMRI study in blind and sighted people.</article-title><source>J Neurophysiol</source><volume>90</volume><fpage>1965</fpage><lpage>1982</lpage><pub-id pub-id-type="pmid">12789013</pub-id></citation></ref><ref id="pone.0004645-Hasegawa1"><label>53</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Hasegawa</surname><given-names>M</given-names></name><name><surname>Carpenter</surname><given-names>PA</given-names></name><name><surname>Just</surname><given-names>MA</given-names></name></person-group><year>2002</year><article-title>An fMRI study of bilingual sentence comprehension and workload.</article-title><source>Neuroimage</source><volume>15</volume><fpage>647</fpage><lpage>660</lpage><pub-id pub-id-type="pmid">11848708</pub-id></citation></ref><ref id="pone.0004645-Burton3"><label>54</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Burton</surname><given-names>MW</given-names></name><name><surname>Locasto</surname><given-names>PC</given-names></name><name><surname>Krebs-Noble</surname><given-names>D</given-names></name><name><surname>Gullapalli</surname><given-names>RP</given-names></name></person-group><year>2005</year><article-title>A systematic investigation of the functional neuroanatomy of auditory and visual phonological processing.</article-title><source>Neuroimage</source><volume>26</volume><fpage>647</fpage><lpage>661</lpage><pub-id pub-id-type="pmid">15955475</pub-id></citation></ref><ref id="pone.0004645-Zimmer2"><label>55</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Zimmer</surname><given-names>U</given-names></name><name><surname>Macaluso</surname><given-names>E</given-names></name></person-group><year>2005</year><article-title>High binaural coherence determines successful sound localization and increased activity in posterior auditory areas.</article-title><source>Neuron</source><volume>47</volume><fpage>893</fpage><lpage>905</lpage><pub-id pub-id-type="pmid">16157283</pub-id></citation></ref><ref id="pone.0004645-Jack1"><label>56</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Jack</surname><given-names>AI</given-names></name><name><surname>Shulman</surname><given-names>GL</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>McAvoy</surname><given-names>M</given-names></name><name><surname>Corbetta</surname><given-names>M</given-names></name></person-group><year>2006</year><article-title>Separate modulations of human V1 associated with spatial attention and task structure.</article-title><source>Neuron</source><volume>51</volume><fpage>135</fpage><lpage>147</lpage><pub-id pub-id-type="pmid">16815338</pub-id></citation></ref><ref id="pone.0004645-Woods1"><label>57</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Woods</surname><given-names>DL</given-names></name><name><surname>Stecker</surname><given-names>GC</given-names></name><name><surname>Rinne</surname><given-names>T</given-names></name><name><surname>Herron</surname><given-names>TJ</given-names></name><name><surname>Cate</surname><given-names>AD</given-names></name><etal/></person-group><year>2008</year><article-title>Functional Maps of Human Auditory Cortex: Effects of Acoustic Features and Attention.</article-title><source>Submitted</source></citation></ref><ref id="pone.0004645-Petkov1"><label>58</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Petkov</surname><given-names>CI</given-names></name><name><surname>Kang</surname><given-names>X</given-names></name><name><surname>Alho</surname><given-names>K</given-names></name><name><surname>Bertrand</surname><given-names>O</given-names></name><name><surname>Yund</surname><given-names>EW</given-names></name><etal/></person-group><year>2004</year><article-title>Attentional modulation of human auditory cortex.</article-title><source>Nat Neurosci</source><volume>7</volume><fpage>658</fpage><lpage>663</lpage><pub-id pub-id-type="pmid">15156150</pub-id></citation></ref><ref id="pone.0004645-Ekman1"><label>59</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ekman</surname><given-names>P</given-names></name></person-group><year>1992</year><article-title>Are there basic emotions?</article-title><source>Psychol Rev</source><volume>99</volume><fpage>550</fpage><lpage>553</lpage><pub-id pub-id-type="pmid">1344638</pub-id></citation></ref><ref id="pone.0004645-Hall1"><label>60</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Hall</surname><given-names>DA</given-names></name><name><surname>Haggard</surname><given-names>MP</given-names></name><name><surname>Akeroyd</surname><given-names>MA</given-names></name><name><surname>Palmer</surname><given-names>AR</given-names></name><name><surname>Summerfield</surname><given-names>AQ</given-names></name><etal/></person-group><year>1999</year><article-title>&#x0201c;Sparse&#x0201d; temporal sampling in auditory fMRI.</article-title><source>Hum Brain Mapp</source><volume>7</volume><fpage>213</fpage><lpage>223</lpage><pub-id pub-id-type="pmid">10194620</pub-id></citation></ref><ref id="pone.0004645-Fischl1"><label>61</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Fischl</surname><given-names>B</given-names></name><name><surname>Sereno</surname><given-names>MI</given-names></name><name><surname>Tootell</surname><given-names>RB</given-names></name><name><surname>Dale</surname><given-names>AM</given-names></name></person-group><year>1999</year><article-title>High-resolution intersubject averaging and a coordinate system for the cortical surface.</article-title><source>Hum Brain Mapp</source><volume>8</volume><fpage>272</fpage><lpage>284</lpage><pub-id pub-id-type="pmid">10619420</pub-id></citation></ref><ref id="pone.0004645-Kang1"><label>62</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kang</surname><given-names>XJ</given-names></name><name><surname>Yund</surname><given-names>EW</given-names></name><name><surname>Herron</surname><given-names>TJ</given-names></name><name><surname>Woods</surname><given-names>DL</given-names></name></person-group><year>2007</year><article-title>Improving the Resolution of Functional Brain Imaging: Analyzing Functional Data in Anatomical Space.</article-title><source>Magn Reson Imaging In press: Pending</source></citation></ref><ref id="pone.0004645-Friston1"><label>63</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>KJ</given-names></name><name><surname>Williams</surname><given-names>S</given-names></name><name><surname>Howard</surname><given-names>R</given-names></name><name><surname>Frackowiak</surname><given-names>RS</given-names></name><name><surname>Turner</surname><given-names>R</given-names></name></person-group><year>1996</year><article-title>Movement-related effects in fMRI time-series.</article-title><source>Magn Reson Med</source><volume>35</volume><fpage>346</fpage><lpage>355</lpage><pub-id pub-id-type="pmid">8699946</pub-id></citation></ref><ref id="pone.0004645-Chung1"><label>64</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Chung</surname><given-names>MK</given-names></name><name><surname>Robbins</surname><given-names>SM</given-names></name><name><surname>Dalton</surname><given-names>KM</given-names></name><name><surname>Davidson</surname><given-names>RJ</given-names></name><name><surname>Alexander</surname><given-names>AL</given-names></name><etal/></person-group><year>2005</year><article-title>Cortical thickness analysis in autism with heat kernel smoothing.</article-title><source>Neuroimage</source><volume>25</volume><fpage>1256</fpage><lpage>1265</lpage><pub-id pub-id-type="pmid">15850743</pub-id></citation></ref><ref id="pone.0004645-Murray1"><label>65</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Murray</surname><given-names>SO</given-names></name><name><surname>Olshausen</surname><given-names>BA</given-names></name><name><surname>Woods</surname><given-names>DL</given-names></name></person-group><year>2003</year><article-title>Processing shape, motion and three-dimensional shape-from-motion in the human cortex.</article-title><source>Cereb Cortex</source><volume>13</volume><fpage>508</fpage><lpage>516</lpage><pub-id pub-id-type="pmid">12679297</pub-id></citation></ref><ref id="pone.0004645-Stenbacka1"><label>66</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Stenbacka</surname><given-names>L</given-names></name><name><surname>Vanni</surname><given-names>S</given-names></name></person-group><year>2007</year><article-title>fMRI of peripheral visual field representation.</article-title><source>Clin Neurophysiol</source><volume>118</volume><fpage>1303</fpage><lpage>1314</lpage><pub-id pub-id-type="pmid">17449320</pub-id></citation></ref><ref id="pone.0004645-Amunts1"><label>67</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Amunts</surname><given-names>K</given-names></name><name><surname>Schleicher</surname><given-names>A</given-names></name><name><surname>Zilles</surname><given-names>K</given-names></name></person-group><year>2007</year><article-title>Cytoarchitecture of the cerebral cortex&#x02013;more than localization.</article-title><source>Neuroimage</source><volume>37</volume><fpage>1061</fpage><lpage>1065; discussion 1066&#x02013;1068</lpage><pub-id pub-id-type="pmid">17870622</pub-id></citation></ref><ref id="pone.0004645-JinhuXiong1"><label>68</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Jinhu Xiong</surname><given-names>J-HG</given-names></name></person-group><year>1995</year><article-title>Clustered pixels analysis for functional MRI activation studies of the human brain.</article-title><source>Human brain mapping</source><volume>3</volume><fpage>287</fpage><lpage>301</lpage></citation></ref><ref id="pone.0004645-Handwerker1"><label>69</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Handwerker</surname><given-names>DA</given-names></name><name><surname>Ollinger</surname><given-names>JM</given-names></name><name><surname>D'Esposito</surname><given-names>M</given-names></name></person-group><year>2004</year><article-title>Variation of BOLD hemodynamic responses across subjects and brain regions and their effects on statistical analyses.</article-title><source>Neuroimage</source><volume>21</volume><fpage>1639</fpage><lpage>1651</lpage><pub-id pub-id-type="pmid">15050587</pub-id></citation></ref><ref id="pone.0004645-Muller1"><label>70</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Muller</surname><given-names>NG</given-names></name><name><surname>Kleinschmidt</surname><given-names>A</given-names></name></person-group><year>2004</year><article-title>The attentional &#x02018;spotlight's&#x02019; penumbra: center-surround modulation in striate cortex.</article-title><source>Neuroreport</source><volume>15</volume><fpage>977</fpage><lpage>980</lpage><pub-id pub-id-type="pmid">15076718</pub-id></citation></ref><ref id="pone.0004645-Tootell1"><label>71</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Tootell</surname><given-names>RB</given-names></name><name><surname>Hadjikhani</surname><given-names>N</given-names></name><name><surname>Hall</surname><given-names>EK</given-names></name><name><surname>Marrett</surname><given-names>S</given-names></name><name><surname>Vanduffel</surname><given-names>W</given-names></name><etal/></person-group><year>1998</year><article-title>The retinotopy of visual spatial attention.</article-title><source>Neuron</source><volume>21</volume><fpage>1409</fpage><lpage>1422</lpage><pub-id pub-id-type="pmid">9883733</pub-id></citation></ref><ref id="pone.0004645-Smith1"><label>72</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>RB</given-names></name></person-group><year>1981</year><article-title>Generalized pairwise semipartial correlation, commonalities analysis and path analysis: Some pre-interpretations and convergencies.</article-title><source>Quality and Quantity</source><volume>15</volume><fpage>279</fpage><lpage>303</lpage></citation></ref><ref id="pone.0004645-Marrelec1"><label>73</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Marrelec</surname><given-names>G</given-names></name><name><surname>Krainik</surname><given-names>A</given-names></name><name><surname>Duffau</surname><given-names>H</given-names></name><name><surname>Pelegrini-Issac</surname><given-names>M</given-names></name><name><surname>Lehericy</surname><given-names>S</given-names></name><etal/></person-group><year>2006</year><article-title>Partial correlation for functional brain interactivity investigation in functional MRI.</article-title><source>Neuroimage</source><volume>32</volume><fpage>228</fpage><lpage>237</lpage><pub-id pub-id-type="pmid">16777436</pub-id></citation></ref><ref id="pone.0004645-Bilecen1"><label>74</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Bilecen</surname><given-names>D</given-names></name><name><surname>Seifritz</surname><given-names>E</given-names></name><name><surname>Scheffler</surname><given-names>K</given-names></name><name><surname>Henning</surname><given-names>J</given-names></name><name><surname>Schulte</surname><given-names>AC</given-names></name></person-group><year>2002</year><article-title>Amplitopicity of the human auditory cortex: an fMRI study.</article-title><source>Neuroimage</source><volume>17</volume><fpage>710</fpage><lpage>718</lpage><pub-id pub-id-type="pmid">12377146</pub-id></citation></ref><ref id="pone.0004645-Jancke1"><label>75</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Jancke</surname><given-names>L</given-names></name><name><surname>Shah</surname><given-names>NJ</given-names></name><name><surname>Posse</surname><given-names>S</given-names></name><name><surname>Grosse-Ryuken</surname><given-names>M</given-names></name><name><surname>Muller-Gartner</surname><given-names>HW</given-names></name></person-group><year>1998</year><article-title>Intensity coding of auditory stimuli: an fMRI study.</article-title><source>Neuropsychologia</source><volume>36</volume><fpage>875</fpage><lpage>883</lpage><pub-id pub-id-type="pmid">9740361</pub-id></citation></ref><ref id="pone.0004645-Langers1"><label>76</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Langers</surname><given-names>DR</given-names></name><name><surname>van Dijk</surname><given-names>P</given-names></name><name><surname>Schoenmaker</surname><given-names>ES</given-names></name><name><surname>Backes</surname><given-names>WH</given-names></name></person-group><year>2007</year><article-title>fMRI activation in relation to sound intensity and loudness.</article-title><source>Neuroimage</source><volume>35</volume><fpage>709</fpage><lpage>718</lpage><pub-id pub-id-type="pmid">17254802</pub-id></citation></ref><ref id="pone.0004645-Lasota1"><label>77</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Lasota</surname><given-names>KJ</given-names></name><name><surname>Ulmer</surname><given-names>JL</given-names></name><name><surname>Firszt</surname><given-names>JB</given-names></name><name><surname>Biswal</surname><given-names>BB</given-names></name><name><surname>Daniels</surname><given-names>DL</given-names></name><etal/></person-group><year>2003</year><article-title>Intensity-dependent activation of the primary auditory cortex in functional magnetic resonance imaging.</article-title><source>J Comput Assist Tomogr</source><volume>27</volume><fpage>213</fpage><lpage>218</lpage><pub-id pub-id-type="pmid">12703014</pub-id></citation></ref><ref id="pone.0004645-Mulert1"><label>78</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Mulert</surname><given-names>C</given-names></name><name><surname>Jager</surname><given-names>L</given-names></name><name><surname>Propp</surname><given-names>S</given-names></name><name><surname>Karch</surname><given-names>S</given-names></name><name><surname>Stormann</surname><given-names>S</given-names></name><etal/></person-group><year>2005</year><article-title>Sound level dependence of the primary auditory cortex: Simultaneous measurement with 61-channel EEG and fMRI.</article-title><source>Neuroimage</source><volume>28</volume><fpage>49</fpage><lpage>58</lpage><pub-id pub-id-type="pmid">16006148</pub-id></citation></ref><ref id="pone.0004645-Woods2"><label>79</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Woods</surname><given-names>DL</given-names></name><name><surname>Stecker</surname><given-names>GC</given-names></name><name><surname>Rinne</surname><given-names>T</given-names></name><name><surname>Herron</surname><given-names>TJ</given-names></name><name><surname>Cate</surname><given-names>AD</given-names></name><etal/></person-group><year>2009</year><article-title>Functional Maps of Human Auditory Cortex: Effects of Acoustic Features and Attention&#x0201d;.</article-title><source>Submitted</source></citation></ref><ref id="pone.0004645-Tootell2"><label>80</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Tootell</surname><given-names>RB</given-names></name><name><surname>Silverman</surname><given-names>MS</given-names></name><name><surname>Switkes</surname><given-names>E</given-names></name><name><surname>De Valois</surname><given-names>RL</given-names></name></person-group><year>1982</year><article-title>Deoxyglucose analysis of retinotopic organization in primate striate cortex.</article-title><source>Science</source><volume>218</volume><fpage>902</fpage><lpage>904</lpage><pub-id pub-id-type="pmid">7134981</pub-id></citation></ref><ref id="pone.0004645-Schneider1"><label>81</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Schneider</surname><given-names>W</given-names></name><name><surname>Noll</surname><given-names>DC</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year>1993</year><article-title>Functional topographic mapping of the cortical ribbon in human vision with conventional MRI scanners.</article-title><source>Nature</source><volume>365</volume><fpage>150</fpage><lpage>153</lpage><pub-id pub-id-type="pmid">8371756</pub-id></citation></ref><ref id="pone.0004645-Sereno1"><label>82</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Sereno</surname><given-names>MI</given-names></name><name><surname>Dale</surname><given-names>AM</given-names></name><name><surname>Reppas</surname><given-names>JB</given-names></name><name><surname>Kwong</surname><given-names>KK</given-names></name><name><surname>Belliveau</surname><given-names>JW</given-names></name><etal/></person-group><year>1995</year><article-title>Borders of multiple visual areas in humans revealed by functional magnetic resonance imaging.</article-title><source>Science</source><volume>268</volume><fpage>889</fpage><lpage>893</lpage><pub-id pub-id-type="pmid">7754376</pub-id></citation></ref><ref id="pone.0004645-Degerman2"><label>83</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Degerman</surname><given-names>A</given-names></name><name><surname>Rinne</surname><given-names>T</given-names></name><name><surname>Pekkola</surname><given-names>J</given-names></name><name><surname>Autti</surname><given-names>T</given-names></name><name><surname>Jaaskelainen</surname><given-names>IP</given-names></name><etal/></person-group><year>2007</year><article-title>Human brain activity associated with audiovisual perception and attention.</article-title><source>Neuroimage</source><volume>34</volume><fpage>1683</fpage><lpage>1691</lpage><pub-id pub-id-type="pmid">17204433</pub-id></citation></ref><ref id="pone.0004645-Alain1"><label>84</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Alain</surname><given-names>C</given-names></name><name><surname>Reinke</surname><given-names>K</given-names></name><name><surname>McDonald</surname><given-names>KL</given-names></name><name><surname>Chau</surname><given-names>W</given-names></name><name><surname>Tam</surname><given-names>F</given-names></name><etal/></person-group><year>2005</year><article-title>Left thalamo-cortical network implicated in successful speech separation and identification.</article-title><source>Neuroimage</source><volume>26</volume><fpage>592</fpage><lpage>599</lpage><pub-id pub-id-type="pmid">15907316</pub-id></citation></ref><ref id="pone.0004645-Ress1"><label>85</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ress</surname><given-names>D</given-names></name><name><surname>Backus</surname><given-names>BT</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name></person-group><year>2000</year><article-title>Activity in primary visual cortex predicts performance in a visual detection task.</article-title><source>Nat Neurosci</source><volume>3</volume><fpage>940</fpage><lpage>945</lpage><pub-id pub-id-type="pmid">10966626</pub-id></citation></ref><ref id="pone.0004645-Watkins1"><label>86</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Watkins</surname><given-names>S</given-names></name><name><surname>Shams</surname><given-names>L</given-names></name><name><surname>Tanaka</surname><given-names>S</given-names></name><name><surname>Haynes</surname><given-names>JD</given-names></name><name><surname>Rees</surname><given-names>G</given-names></name></person-group><year>2006</year><article-title>Sound alters activity in human V1 in association with illusory visual perception.</article-title><source>Neuroimage</source><volume>31</volume><fpage>1247</fpage><lpage>1256</lpage><pub-id pub-id-type="pmid">16556505</pub-id></citation></ref><ref id="pone.0004645-Bavelier2"><label>87</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Bavelier</surname><given-names>D</given-names></name><name><surname>Tomann</surname><given-names>A</given-names></name><name><surname>Hutton</surname><given-names>C</given-names></name><name><surname>Mitchell</surname><given-names>T</given-names></name><name><surname>Corina</surname><given-names>D</given-names></name><etal/></person-group><year>2000</year><article-title>Visual attention to the periphery is enhanced in congenitally deaf individuals.</article-title><source>J Neurosci</source><volume>20</volume><fpage>RC93</fpage><pub-id pub-id-type="pmid">10952732</pub-id></citation></ref><ref id="pone.0004645-Bavelier3"><label>88</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Bavelier</surname><given-names>D</given-names></name><name><surname>Dye</surname><given-names>MW</given-names></name><name><surname>Hauser</surname><given-names>PC</given-names></name></person-group><year>2006</year><article-title>Do deaf individuals see better?</article-title><source>Trends Cogn Sci</source><volume>10</volume><fpage>512</fpage><lpage>518</lpage><pub-id pub-id-type="pmid">17015029</pub-id></citation></ref><ref id="pone.0004645-Clavagnier1"><label>89</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Clavagnier</surname><given-names>S</given-names></name><name><surname>Falchier</surname><given-names>A</given-names></name><name><surname>Kennedy</surname><given-names>H</given-names></name></person-group><year>2004</year><article-title>Long-distance feedback projections to area V1: implications for multisensory integration, spatial awareness, and visual consciousness.</article-title><source>Cogn Affect Behav Neurosci</source><volume>4</volume><fpage>117</fpage><lpage>126</lpage><pub-id pub-id-type="pmid">15460918</pub-id></citation></ref><ref id="pone.0004645-Rockland1"><label>90</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Rockland</surname><given-names>KS</given-names></name><name><surname>Ojima</surname><given-names>H</given-names></name></person-group><year>2003</year><article-title>Multisensory convergence in calcarine visual areas in macaque monkey.</article-title><source>Int J Psychophysiol</source><volume>50</volume><fpage>19</fpage><lpage>26</lpage><pub-id pub-id-type="pmid">14511833</pub-id></citation></ref><ref id="pone.0004645-Laurienti1"><label>91</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Laurienti</surname><given-names>PJ</given-names></name><name><surname>Burdette</surname><given-names>JH</given-names></name><name><surname>Wallace</surname><given-names>MT</given-names></name><name><surname>Yen</surname><given-names>YF</given-names></name><name><surname>Field</surname><given-names>AS</given-names></name><etal/></person-group><year>2002</year><article-title>Deactivation of sensory-specific cortex by cross-modal stimuli.</article-title><source>J Cogn Neurosci</source><volume>14</volume><fpage>420</fpage><lpage>429</lpage><pub-id pub-id-type="pmid">11970801</pub-id></citation></ref><ref id="pone.0004645-Kawashima1"><label>92</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kawashima</surname><given-names>R</given-names></name><name><surname>Imaizumi</surname><given-names>S</given-names></name><name><surname>Mori</surname><given-names>K</given-names></name><name><surname>Okada</surname><given-names>K</given-names></name><name><surname>Goto</surname><given-names>R</given-names></name><etal/></person-group><year>1999</year><article-title>Selective visual and auditory attention toward utterances-a PET study.</article-title><source>Neuroimage</source><volume>10</volume><fpage>209</fpage><lpage>215</lpage><pub-id pub-id-type="pmid">10417253</pub-id></citation></ref><ref id="pone.0004645-Lewis1"><label>93</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Lewis</surname><given-names>JW</given-names></name><name><surname>Beauchamp</surname><given-names>MS</given-names></name><name><surname>Deyoe</surname><given-names>EA</given-names></name></person-group><year>2000</year><article-title>A comparison of visual and auditory motion processing in human cerebral cortex.</article-title><source>Cerebral Cortex</source><volume>10</volume><fpage>873</fpage><lpage>888</lpage><pub-id pub-id-type="pmid">10982748</pub-id></citation></ref><ref id="pone.0004645-McKiernan1"><label>94</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>McKiernan</surname><given-names>KA</given-names></name><name><surname>Kaufman</surname><given-names>JN</given-names></name><name><surname>Kucera-Thompson</surname><given-names>J</given-names></name><name><surname>Binder</surname><given-names>JR</given-names></name></person-group><year>2003</year><article-title>A parametric manipulation of factors affecting task-induced deactivation in functional neuroimaging.</article-title><source>J Cogn Neurosci</source><volume>15</volume><fpage>394</fpage><lpage>408</lpage><pub-id pub-id-type="pmid">12729491</pub-id></citation></ref><ref id="pone.0004645-Lewis2"><label>95</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Lewis</surname><given-names>JW</given-names></name><name><surname>Wightman</surname><given-names>FL</given-names></name><name><surname>Brefczynski</surname><given-names>JA</given-names></name><name><surname>Phinney</surname><given-names>RE</given-names></name><name><surname>Binder</surname><given-names>JR</given-names></name><etal/></person-group><year>2004</year><article-title>Human brain regions involved in recognizing environmental sounds.</article-title><source>Cereb Cortex</source><volume>14</volume><fpage>1008</fpage><lpage>1021</lpage><pub-id pub-id-type="pmid">15166097</pub-id></citation></ref><ref id="pone.0004645-Hairston1"><label>96</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Hairston</surname><given-names>WD</given-names></name><name><surname>Hodges</surname><given-names>DA</given-names></name><name><surname>Casanova</surname><given-names>R</given-names></name><name><surname>Hayasaka</surname><given-names>S</given-names></name><name><surname>Kraft</surname><given-names>R</given-names></name><etal/></person-group><year>2008</year><article-title>Closing the mind's eye: deactivation of visual cortex related to auditory task difficulty.</article-title><source>Neuroreport</source><volume>19</volume><fpage>151</fpage><lpage>154</lpage><pub-id pub-id-type="pmid">18185099</pub-id></citation></ref><ref id="pone.0004645-Silver1"><label>97</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Silver</surname><given-names>MA</given-names></name><name><surname>Ress</surname><given-names>D</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name></person-group><year>2007</year><article-title>Neural correlates of sustained spatial attention in human early visual cortex.</article-title><source>J Neurophysiol</source><volume>97</volume><fpage>229</fpage><lpage>237</lpage><pub-id pub-id-type="pmid">16971677</pub-id></citation></ref><ref id="pone.0004645-Shulman1"><label>98</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Shulman</surname><given-names>GL</given-names></name><name><surname>McAvoy</surname><given-names>MP</given-names></name><name><surname>Cowan</surname><given-names>MC</given-names></name><name><surname>Astafiev</surname><given-names>SV</given-names></name><name><surname>Tansy</surname><given-names>AP</given-names></name><etal/></person-group><year>2003</year><article-title>Quantitative analysis of attention and detection signals during visual search.</article-title><source>J Neurophysiol</source><volume>90</volume><fpage>3384</fpage><lpage>3397</lpage><pub-id pub-id-type="pmid">12917383</pub-id></citation></ref><ref id="pone.0004645-Fox1"><label>99</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Fox</surname><given-names>MD</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Barch</surname><given-names>DM</given-names></name><name><surname>Gusnard</surname><given-names>DA</given-names></name><name><surname>Raichle</surname><given-names>ME</given-names></name></person-group><year>2005</year><article-title>Transient BOLD responses at block transitions.</article-title><source>Neuroimage</source><volume>28</volume><fpage>956</fpage><lpage>966</lpage><pub-id pub-id-type="pmid">16043368</pub-id></citation></ref><ref id="pone.0004645-Dosenbach1"><label>100</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Dosenbach</surname><given-names>NU</given-names></name><name><surname>Visscher</surname><given-names>KM</given-names></name><name><surname>Palmer</surname><given-names>ED</given-names></name><name><surname>Miezin</surname><given-names>FM</given-names></name><name><surname>Wenger</surname><given-names>KK</given-names></name><etal/></person-group><year>2006</year><article-title>A core system for the implementation of task sets.</article-title><source>Neuron</source><volume>50</volume><fpage>799</fpage><lpage>812</lpage><pub-id pub-id-type="pmid">16731517</pub-id></citation></ref><ref id="pone.0004645-Kansaku1"><label>101</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kansaku</surname><given-names>K</given-names></name><name><surname>Johnson</surname><given-names>A</given-names></name><name><surname>Grillon</surname><given-names>ML</given-names></name><name><surname>Garraux</surname><given-names>G</given-names></name><name><surname>Sadato</surname><given-names>N</given-names></name><etal/></person-group><year>2006</year><article-title>Neural correlates of counting of sequential sensory and motor events in the human brain.</article-title><source>Neuroimage</source><volume>31</volume><fpage>649</fpage><lpage>660</lpage><pub-id pub-id-type="pmid">16460961</pub-id></citation></ref><ref id="pone.0004645-Shimojo1"><label>102</label><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Shimojo</surname><given-names>S</given-names></name><name><surname>Shams</surname><given-names>L</given-names></name></person-group><year>2001</year><article-title>Sensory modalities are not separate modalities: plasticity and interactions.</article-title><source>Curr Opin Neurobiol</source><volume>11</volume><fpage>505</fpage><lpage>509</lpage><pub-id pub-id-type="pmid">11502399</pub-id></citation></ref></ref-list><fn-group><fn fn-type="conflict"><p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p></fn><fn fn-type="financial-disclosure"><p><bold>Funding: </bold>Supported by grant DCD5814 to DLW and the VA Research Service.</p></fn></fn-group></back></article>