<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN" "archivearticle.dtd"><article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Hum Resour Health</journal-id><journal-title>Human Resources for Health</journal-title><issn pub-type="epub">1478-4491</issn><publisher><publisher-name>BioMed Central</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">19146690</article-id><article-id pub-id-type="pmc">2647897</article-id><article-id pub-id-type="publisher-id">1478-4491-7-3</article-id><article-id pub-id-type="doi">10.1186/1478-4491-7-3</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research</subject></subj-group></article-categories><title-group><article-title>Programme evaluation training for health professionals in francophone Africa: process, competence acquisition and use</article-title></title-group><contrib-group><contrib id="A1" corresp="yes" contrib-type="author"><name><surname>Ridde</surname><given-names>Val&#x000e9;ry</given-names></name><xref ref-type="aff" rid="I1">1</xref><xref ref-type="aff" rid="I2">2</xref><email>valery.ridde@umontreal.ca</email></contrib><contrib id="A2" contrib-type="author"><name><surname>Fournier</surname><given-names>Pierre</given-names></name><xref ref-type="aff" rid="I1">1</xref><xref ref-type="aff" rid="I2">2</xref><email>pierre.fournier@umontreal.ca</email></contrib><contrib id="A3" contrib-type="author"><name><surname>Banza</surname><given-names>Baya</given-names></name><xref ref-type="aff" rid="I3">3</xref><email>bbaya@issp.bf</email></contrib><contrib id="A4" contrib-type="author"><name><surname>Tourigny</surname><given-names>Caroline</given-names></name><xref ref-type="aff" rid="I2">2</xref><email>caroline.tourigny@umontreal.ca</email></contrib><contrib id="A5" contrib-type="author"><name><surname>Ou&#x000e9;draogo</surname><given-names>Dieudonn&#x000e9;</given-names></name><xref ref-type="aff" rid="I3">3</xref><email>douedraogo@issp.bf</email></contrib></contrib-group><aff id="I1"><label>1</label>Centre de recherche du Centre Hospitalier de l'Universit&#x000e9; de Montr&#x000e9;al, Montr&#x000e9;al, Canada</aff><aff id="I2"><label>2</label>Department of Social and Preventive Medicine, University of Montreal, Montr&#x000e9;al, Canada</aff><aff id="I3"><label>3</label>Institut Sup&#x000e9;rieur des Sciences de la Population, Universit&#x000e9; de Ouagadougou, Ouagadougou, Burkina Faso</aff><pub-date pub-type="collection"><year>2009</year></pub-date><pub-date pub-type="epub"><day>15</day><month>1</month><year>2009</year></pub-date><volume>7</volume><fpage>3</fpage><lpage>3</lpage><ext-link ext-link-type="uri" xlink:href="http://www.human-resources-health.com/content/7/1/3"/><history><date date-type="received"><day>15</day><month>1</month><year>2008</year></date><date date-type="accepted"><day>15</day><month>1</month><year>2009</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2009 Ridde et al; licensee BioMed Central Ltd.</copyright-statement><copyright-year>2009</copyright-year><copyright-holder>Ridde et al; licensee BioMed Central Ltd.</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.0"><p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/2.0"/>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</p><!--<rdf xmlns="http://web.resource.org/cc/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:dc="http://purl.org/dc/elements/1.1" xmlns:dcterms="http://purl.org/dc/terms"><Work xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:dcterms="http://purl.org/dc/terms/" rdf:about=""><license rdf:resource="http://creativecommons.org/licenses/by/2.0"/><dc:type rdf:resource="http://purl.org/dc/dcmitype/Text"/><dc:author>               Ridde               Val&#x000e9;ry                                             valery.ridde@umontreal.ca            </dc:author><dc:title>            Programme evaluation training for health professionals in francophone Africa: process, competence acquisition and use         </dc:title><dc:date>2009</dc:date><dcterms:bibliographicCitation>Human Resources for Health 7(1): 3-. (2009)</dcterms:bibliographicCitation><dc:identifier type="sici">1478-4491(2009)7:1&#x0003c;3&#x0003e;</dc:identifier><dcterms:isPartOf>urn:ISSN:1478-4491</dcterms:isPartOf><License rdf:about="http://creativecommons.org/licenses/by/2.0"><permits rdf:resource="http://web.resource.org/cc/Reproduction" xmlns=""/><permits rdf:resource="http://web.resource.org/cc/Distribution" xmlns=""/><requires rdf:resource="http://web.resource.org/cc/Notice" xmlns=""/><requires rdf:resource="http://web.resource.org/cc/Attribution" xmlns=""/><permits rdf:resource="http://web.resource.org/cc/DerivativeWorks" xmlns=""/></License></Work></rdf>--></license></permissions><abstract><sec><title>Background</title><p>While evaluation is, in theory, a component of training programmes in health planning, training needs in this area remain significant. Improving health systems necessarily calls for having more professionals who are skilled in evaluation. Thus, the Universit&#x000e9; de Ouagadougou (Burkina Faso) and the Universit&#x000e9; de Montr&#x000e9;al (Canada) have partnered to establish, in Burkina Faso, a master's-degree programme in population and health with a course in programme evaluation. This article describes the four-week (150-hour) course taken by two cohorts (2005&#x02013;2006/2006&#x02013;2007) of health professionals from 11 francophone African countries. We discuss how the course came to be, its content, its teaching processes and the master's programme results for students.</p></sec><sec sec-type="methods"><title>Methods</title><p>The conceptual framework was adapted from Kirkpatrick's (1996) four-level evaluation model: reaction, learning, behaviour, results. Reaction was evaluated based on a standardized questionnaire for all the master's courses and lessons. Learning and behaviour competences were assessed by means of a questionnaire (pretest/post-test, one year after) adapted from the work of Stevahn L, King JA, Ghere G, Minnema J: Establishing Essential Competencies for Program Evaluators. <italic>Am J Eval </italic>2005, 26(1):43&#x02013;59. Master's programme effects were tested by comparing the difference in mean scores between times (before, after, one year after) using pretest/post-test designs. Paired sample tests were used to compare mean scores.</p></sec><sec><title>Results</title><p>The teaching is skills-based, interactive and participative. Students of the first cohort gave the evaluation course the highest score (4.4/5) for overall satisfaction among the 16 courses (3.4&#x02013;4.4) in the master's programme. What they most appreciated was that the forms of evaluation were well adapted to the content and format of the learning activities. By the end of the master's programme, both cohorts of students considered that they had greatly improved their mastery of the 60 competences (p &#x0003c; 0.001). This level was maintained one year after completing the master's degree, except for reflective practice (p &#x0003c; 0.05). Those who had carried out an evaluation in the intervening 12 months reported a negative gap between their declared mastery and their actual application. However, this is only statistically significant for reflective practice (p &#x0003c; 0.05).</p></sec><sec><title>Conclusion</title><p>This study shows the importance of integrating summative evaluation into the learning process. Skills-based teaching is much appreciated and well-adapted. Creating a master's programme in population and health in Africa and providing training in evaluation to high-level health professionals from many countries augurs well for scaling up the practice of evaluation in African health systems.</p></sec></abstract></article-meta></front><body><sec><title>Background</title><p>Obtaining international funding in health care is becoming increasingly competitive. For example, to acquire resources needed to fight HIV/AIDS or malaria, African countries must now participate in Global Fund competitions. This situation presents health care managers with two new challenges. First, their requests and action plans increasingly need to be evidence-based. Managers therefore must be able to understand and assess the quality of data and of intervention evaluations. The second challenge is that, when assessing requests, funding agencies look at how well previously-funded programmes met their objectives. These programmes' effectiveness must therefore be demonstrated. Health care managers can no longer be just good planners. They also must be informed evaluators, or have at least the basic knowledge required to interact effectively with the evaluation experts whom they will recruit. Within the current trend of establishing New Public Management in health care in developing countries [<xref ref-type="bibr" rid="B1">1</xref>] and the Paris Declaration on Aid Effectiveness [<xref ref-type="bibr" rid="B2">2</xref>], programme evaluation will become a major sphere of activity for the coming decade. Yet programme evaluation is rarely addressed in training programmes for health planning [<xref ref-type="bibr" rid="B3">3</xref>] and, in Africa, evaluation processes are still too often imposed by external bodies [<xref ref-type="bibr" rid="B4">4</xref>].</p><p>A series of regional seminars on evaluation planned by the Development Assistance Committee of the Organisation for Economic Co-operation and Development (OECD) was started in 1990 in C&#x000f4;te d'Ivoire [<xref ref-type="bibr" rid="B5">5</xref>]. In 1999, the African Evaluation Association (AfrEA) was launched. Despite these efforts, training in programme evaluation remains a relative rarity on the African continent. There are some seminars and workshops, but few training programmes leading to degrees. This is particularly true in francophone Africa [<xref ref-type="bibr" rid="B6">6</xref>,<xref ref-type="bibr" rid="B7">7</xref>]. The strengthening of evaluation capacity building (ECB) has thus become an urgent matter in Africa. Experts in this field are asking for more empirical case studies to document the range of practices in order to improve their knowledge [<xref ref-type="bibr" rid="B8">8</xref>,<xref ref-type="bibr" rid="B9">9</xref>], as ECB is "an emergent field of practice" [<xref ref-type="bibr" rid="B10">10</xref>]. University training is one useful strategy for ECB [<xref ref-type="bibr" rid="B11">11</xref>]. A review of articles published in this field between 1965 and 2003 reveals a lack of literature on practical evaluation training [<xref ref-type="bibr" rid="B12">12</xref>]. This article presents the evaluation of a course on programme evaluation, a four-week (150-hour) course attended by health professionals from 11 francophone African countries.</p><p>The Universit&#x000e9; de Ouagadougou (Burkina Faso) and the Universit&#x000e9; de Montr&#x000e9;al (Canada) have partnered to establish, in Burkina Faso, a master's-degree programme in population and health that includes a course in evaluation. This master's programme is part of a larger programme aimed at reinforcing human and institutional capacities in the analysis and evaluation of public policies and programmes. Its goal is to offer a credible alternative to training programmes offered in North America and Europe. The master's-level training programme includes 12 months of course work and a three-month internship (Table <xref ref-type="table" rid="T1">1</xref>). The training is organized into modules of several consecutive days, to accommodate the teachers who are brought in from a number of African countries and from Canada.</p><table-wrap position="float" id="T1"><label>Table 1</label><caption><p>Structure of the master's programme in 2005&#x02013;2006</p></caption><table frame="hsides" rules="groups"><thead><tr><td align="left"><bold>Blocks and modules</bold></td><td align="left"><bold>Course titles</bold></td><td align="left"><bold>Number of lessons and %</bold></td></tr></thead><tbody><tr><td align="left">BLOCK 1</td><td align="left">Fundamentals and issues in population and health</td><td align="left">31 (16%)</td></tr><tr><td colspan="3"><hr></hr></td></tr><tr><td align="left">Module 1.1</td><td align="left">Fundamentals</td><td align="left">19</td></tr><tr><td colspan="3"><hr></hr></td></tr><tr><td align="left">Module 1.2</td><td align="left">Issues</td><td align="left">12</td></tr><tr><td colspan="3"><hr></hr></td></tr><tr><td align="left">BLOCK 2</td><td align="left">Analysis of population and health issues</td><td align="left">62 (31%)</td></tr><tr><td colspan="3"><hr></hr></td></tr><tr><td align="left">Module 2.1</td><td align="left">Introduction to empirical research methodology</td><td align="left">4</td></tr><tr><td colspan="3"><hr></hr></td></tr><tr><td align="left">Module 2.2</td><td align="left">Quantitative data sources and basic descriptive statistics</td><td align="left">8</td></tr><tr><td colspan="3"><hr></hr></td></tr><tr><td align="left">Module 2.3</td><td align="left">Elements of demography and epidemiology</td><td align="left">20</td></tr><tr><td colspan="3"><hr></hr></td></tr><tr><td align="left">Module 2.4</td><td align="left">Elements of qualitative analysis</td><td align="left">14</td></tr><tr><td colspan="3"><hr></hr></td></tr><tr><td align="left">Module 2.5</td><td align="left">Introduction to multivariate statistical methods</td><td align="left">16</td></tr><tr><td colspan="3"><hr></hr></td></tr><tr><td align="left">BLOCK 3</td><td align="left">Analysis of policies and intervention strategies</td><td align="left">48 (23%)</td></tr><tr><td colspan="3"><hr></hr></td></tr><tr><td align="left">Module 3.1</td><td align="left">Fundamentals of public policy analysis</td><td align="left">16</td></tr><tr><td colspan="3"><hr></hr></td></tr><tr><td align="left">Module 3.2</td><td align="left">Analysis of health systems</td><td align="left">13</td></tr><tr><td colspan="3"><hr></hr></td></tr><tr><td align="left">Module 3.3</td><td align="left">Evaluation</td><td align="left">19</td></tr><tr><td colspan="3"><hr></hr></td></tr><tr><td align="left">BLOCK 4</td><td align="left">Communication</td><td align="left">13 (7%)</td></tr><tr><td colspan="3"><hr></hr></td></tr><tr><td align="left">Module 4.1</td><td align="left">Communication as a tool for influencing individual and collective health and well-being</td><td align="left">7</td></tr><tr><td colspan="3"><hr></hr></td></tr><tr><td align="left">Module 4.2</td><td align="left">Advocacy and information management</td><td align="left">6</td></tr><tr><td colspan="3"><hr></hr></td></tr><tr><td align="left">BLOCK 5</td><td align="left">Planning and implementation of interventions</td><td align="left">47 (23%)</td></tr><tr><td colspan="3"><hr></hr></td></tr><tr><td align="left">Module 5.1</td><td align="left">Principles of planning for interventions</td><td align="left">9</td></tr><tr><td colspan="3"><hr></hr></td></tr><tr><td align="left">Module 5.2</td><td align="left">Operational planning of interventions (programmes, projects)</td><td align="left">17</td></tr><tr><td colspan="3"><hr></hr></td></tr><tr><td align="left">Module 5.3</td><td align="left">Implementation of interventions: resource management</td><td align="left">13</td></tr><tr><td colspan="3"><hr></hr></td></tr><tr><td align="left">Module 5.4</td><td align="left">Monitoring interventions</td><td align="left">8</td></tr><tr><td colspan="3"><hr></hr></td></tr><tr><td align="left">BLOCK 6</td><td align="left">Internship</td><td align="left">(3 months)</td></tr><tr><td colspan="3"><hr></hr></td></tr><tr><td align="left"><bold>TOTAL</bold></td><td></td><td align="left"><bold>201</bold></td></tr></tbody></table></table-wrap><p>The overall objective of the master's programme is to develop students' knowledge and aptitudes in analysis, formulation and implementation management, as well as in the evaluation of population and health programmes, including a specific course in programme evaluation (Table <xref ref-type="table" rid="T1">1</xref>: 3.3). Before presenting the results achieved in the master's programme, we will describe how the course was implemented and its content related to evaluation.</p><sec><title>The programme evaluation course: process and content</title><p>The entire content of the master's programme was planned between 2003 and 2004. The organization into modules and the content of each module were decided using a participative process, after an inventory of training programmes in population and health in several francophone African countries [<xref ref-type="bibr" rid="B13">13</xref>]. Because the evaluation course integrates all the knowledge and competences acquired in the other courses, it was positioned as the last course taken by students at the end of the 12 months (Table <xref ref-type="table" rid="T1">1</xref>). Teaching, when required, would be carried out by African-Canadian pairs, based on the partnership model [<xref ref-type="bibr" rid="B14">14</xref>,<xref ref-type="bibr" rid="B15">15</xref>]. The course content took into account:</p><p>&#x02022; the competences expected of programme evaluators [<xref ref-type="bibr" rid="B16">16</xref>,<xref ref-type="bibr" rid="B17">17</xref>];</p><p>&#x02022; the training needs in evaluation in Africa [<xref ref-type="bibr" rid="B6">6</xref>,<xref ref-type="bibr" rid="B7">7</xref>];</p><p>&#x02022; prior experience of training in evaluation;</p><p>&#x02022; familiarity with training needs of African students.</p><p>After this process, the teaching objectives (Fig. <xref ref-type="fig" rid="F1">1</xref>) and course content (Table <xref ref-type="table" rid="T2">2</xref>) were finalized.</p><fig position="float" id="F1"><label>Figure 1</label><caption><p><bold>Course objectives</bold>.</p></caption><graphic xlink:href="1478-4491-7-3-1"/></fig><table-wrap position="float" id="T2"><label>Table 2</label><caption><p>Lessons of the programme evaluation course for Cohort 1</p></caption><table frame="hsides" rules="groups"><thead><tr><td align="left">Lesson 3.3.1</td><td align="left">Introduction and overall process for evaluation</td></tr></thead><tbody><tr><td align="left">Lesson 3.3.2</td><td align="left">Types and approaches to evaluation</td></tr><tr><td colspan="2"><hr></hr></td></tr><tr><td align="left">Lesson 3.3.3</td><td align="left">Intervention logic</td></tr><tr><td colspan="2"><hr></hr></td></tr><tr><td align="left">Lesson 3.3.4</td><td align="left">Standards and practices in evaluation</td></tr><tr><td colspan="2"><hr></hr></td></tr><tr><td></td><td align="left"><italic>Formative evaluation</italic></td></tr><tr><td colspan="2"><hr></hr></td></tr><tr><td align="left">Lesson 3.3.5</td><td align="left">Implementation analysis 1 (conceptual bases)</td></tr><tr><td colspan="2"><hr></hr></td></tr><tr><td align="left">Lesson 3.3.6</td><td align="left">Implementation analysis 2 (case study: step 1)</td></tr><tr><td colspan="2"><hr></hr></td></tr><tr><td align="left">Lesson 3.3.7</td><td align="left">Implementation analysis 3 (case study: step 2)</td></tr><tr><td colspan="2"><hr></hr></td></tr><tr><td align="left">Lesson 3.3.8</td><td align="left">Analysis of effects/impact 1 (causal attribution)</td></tr><tr><td colspan="2"><hr></hr></td></tr><tr><td align="left">Lesson 3.3.9</td><td align="left">Evaluation design 1: principles and practices</td></tr><tr><td colspan="2"><hr></hr></td></tr><tr><td align="left">Lesson 3.3.10</td><td align="left">Evaluation design 2 (case study: step 3)</td></tr><tr><td colspan="2"><hr></hr></td></tr><tr><td align="left">Lesson 3.3.11</td><td align="left">Efficiency 1</td></tr><tr><td colspan="2"><hr></hr></td></tr><tr><td align="left">Lesson 3.3.12</td><td align="left">Efficiency 2</td></tr><tr><td colspan="2"><hr></hr></td></tr><tr><td align="left">Lesson 3.3.13</td><td align="left">Utilization of evaluation results</td></tr><tr><td colspan="2"><hr></hr></td></tr><tr><td align="left">Lesson 3.3.14</td><td align="left">Group work and consultation sessions</td></tr><tr><td colspan="2"><hr></hr></td></tr><tr><td align="left">Lesson 3.3.15</td><td align="left">Group work</td></tr><tr><td colspan="2"><hr></hr></td></tr><tr><td align="left">Lesson 3.3.16</td><td align="left">Group work and consultation sessions</td></tr><tr><td colspan="2"><hr></hr></td></tr><tr><td align="left">Lesson 3.3.17</td><td align="left">Group work</td></tr><tr><td colspan="2"><hr></hr></td></tr><tr><td></td><td align="left"><italic>Summative evaluation</italic></td></tr></tbody></table></table-wrap><p>The aim is to train professionals who will be able to design, support or carry out a programme evaluation. Students are expected to write an evaluation plan. The course involves 19 lectures or sessions (9.5% of total), corresponding to 147 hours of work:</p><p>&#x02022; 52 hours in class in 13 course sessions;</p><p>&#x02022; 52 hours of individual preparatory work;</p><p>&#x02022; 35 hours of group work in preparing evaluations;</p><p>&#x02022; 8 hours of presence for evaluations.</p><p>This approach represents a departure from classical teaching methods that generally involve lectures and sometimes directed work. In fact, such methods are rarely effective in training programmes for health personnel in low-income countries [<xref ref-type="bibr" rid="B14">14</xref>]. In the case presented here, the entire process is centred on active training in which the student's learning is encouraged, professional experience is validated and course content is more practical than theoretical. Learners actively construct knowledge in collaborative groups [<xref ref-type="bibr" rid="B18">18</xref>]. The course uses a myriad of teaching approaches (Table <xref ref-type="table" rid="T3">3</xref>) based our own experiences as well as well on the literature [<xref ref-type="bibr" rid="B19">19</xref>-<xref ref-type="bibr" rid="B22">22</xref>], from which some exercises were adapted (see additional files <xref ref-type="supplementary-material" rid="S1">1</xref> and <xref ref-type="supplementary-material" rid="S2">2</xref>).</p><table-wrap position="float" id="T3"><label>Table 3</label><caption><p>Examples of pedagogical techniques</p></caption><table frame="hsides" rules="groups"><thead><tr><td align="left"><bold>Technique</bold></td><td align="left"><bold>Content</bold></td><td align="left"><bold>Description</bold></td></tr></thead><tbody><tr><td align="left">Simulation</td><td align="left">Ethical dilemma of negotiation with a client</td><td align="left">A client asks an evaluator to change his evaluation design to please a funding agency. Two groups of students receive the same case description; one is in favor of the request, and the other against.</td></tr><tr><td colspan="3"><hr></hr></td></tr><tr><td align="left">Drawing</td><td align="left">Definition of the evaluation</td><td align="left">Each student must produce a drawing representing his or her perception of the evaluation (see additional file <xref ref-type="supplementary-material" rid="S1">1</xref>)</td></tr><tr><td colspan="3"><hr></hr></td></tr><tr><td></td><td align="left">Logic model</td><td align="left">Each team of students must prepare a graphic representation of the constituent elements of a programme's logic (see additional file <xref ref-type="supplementary-material" rid="S2">2</xref>)</td></tr><tr><td colspan="3"><hr></hr></td></tr><tr><td align="left">Case study</td><td align="left">Theory of intervention</td><td align="left">Each team must determine the theory of the intervention with its various components based upon a real case: the referral system for obstetrical emergencies at Kayes in Mali.</td></tr><tr><td colspan="3"><hr></hr></td></tr><tr><td align="left">Problem-based learning</td><td align="left">Evaluation plan</td><td align="left">Each team must draw up an evaluation plan for a health district in Burkina Faso.</td></tr><tr><td colspan="3"><hr></hr></td></tr><tr><td align="left">Debate</td><td align="left">Evaluation profession</td><td align="left">A senior public health consultant is invited to discuss with the class the profession in Africa. Students must prepare questions in advance.</td></tr></tbody></table></table-wrap><p>Methods for evaluating students provide an opportunity to improve their knowledge and competences in a two-step learning process. First, a formative evaluation (20% of the final course grade) is organized after the first four lessons of the course (Table <xref ref-type="table" rid="T2">2</xref>), which constitute a general introduction to programme evaluation. At the end of this first block, groups of four students are given a day-and-a-half to prepare an oral presentation of a draft evaluation plan. Each team receives the plan for a Burkina Faso health district (a real case), selects a specific theme (AIDS, maternal health, etc.), and then develops and presents the draft of its evaluation plan. This presentation allows the teachers to verify the level of understanding of concepts and whether the evaluation plan is on track. Before the presentation, students also have several occasions to receive feedback on their learning.</p><p>Later, a summative evaluation (80% of the final grade) takes place at the end of the course. Communication skills are also evaluated. Students are expected to write a complete evaluation plan based on the elements presented in Fig. <xref ref-type="fig" rid="F2">2</xref>.</p><fig position="float" id="F2"><label>Figure 2</label><caption><p><bold>Contents of an evaluation plan</bold>.</p></caption><graphic xlink:href="1478-4491-7-3-2"/></fig><p>Knowledge acquired in the course is thus integrated in this final project, which is presented orally. Peers have the opportunity to ask questions and give feedback on their colleagues' work. Students are given four days to carry out this project, during which each group has two one-hour consultation sessions with the teacher.</p><p>We present here the results of the course evaluations, as well as those related to competence acquisition among the two first student cohorts (Cohort 1: 2005&#x02013;2006; Cohort 2: 2006&#x02013;2007) at the end of the master's training.</p></sec></sec><sec sec-type="methods"><title>Methods</title><sec><title>Conceptual framework</title><p>We used a conceptual framework that bases programme evaluation on four levels of outcomes [<xref ref-type="bibr" rid="B23">23</xref>]:</p><p>&#x02022; Level 1: Reaction = participants' satisfaction;</p><p>&#x02022; Level 2: Learning = participants' knowledge acquisition, improved skills or changes in attitude;</p><p>&#x02022; Level 3: Behaviour = changes in participants' on-the-job behaviour;</p><p>&#x02022; Level 4: Results = final change at the organizational and population levels.</p><p>Our discussion here is limited to levels 1 to 3.</p></sec><sec><title>Data collection tools</title><sec><title>Reaction</title><p>At the end of each session and course, every student of Cohort 1 completed a standardized questionnaire containing nine closed questions (Likert-type scale of 1 to 5) and one or two open questions.</p></sec><sec><title>Learning</title><p>We used a standardized questionnaire adapted from the taxonomy of essential competences for programme evaluators [<xref ref-type="bibr" rid="B16">16</xref>,<xref ref-type="bibr" rid="B17">17</xref>,<xref ref-type="bibr" rid="B24">24</xref>]. This taxonomy is a list of 60 competences clustered into six major categories (see Fig. <xref ref-type="fig" rid="F3">3</xref>), translated into French. As is often the case for this type of evaluation [<xref ref-type="bibr" rid="B25">25</xref>], it was impossible to do a pretest before the course because most of the vocabulary was unfamiliar to students. Thus, as has been recommended [<xref ref-type="bibr" rid="B25">25</xref>,<xref ref-type="bibr" rid="B26">26</xref>], we used a retrospective pretest and post-test. The test was administered at the end of the evaluation course, which also corresponds to the end of the master's programme. In addition, for the first cohort of students (n = 17), a second post-test was administered one year later. For each competence, students were asked to assess, on a Likert-type scale of 1 to 4 (easily ... not at all), their degree of mastery before ("I was able to...") and after ("I am able to...") the master's programme.</p></sec><sec><title>Behavior</title><p>By means of the same questionnaire as for competences, we asked students of Cohort 1 whether they had used them (Likert-type scale of 1 to 4 (easily ... not at all)).</p></sec></sec><sec><title>Data analysis</title><p>Programme effects were tested by comparing differences in mean scores between times (before, after, one year after) by pretest-post-test design. Paired sample tests were used to compare mean scores. Data analyses were carried out with SPSS<sup>&#x000a9;</sup>.</p></sec></sec><sec><title>Results</title><sec><title>Participants</title><p>Cohort 1 consisted of 17 students: nine men and eight women, from eight West African countries. Cohort 2 was made up of 19 students: 11 men and eight women, from 11 countries. These students come from a wide variety of disciplines: medicine (13), sociology (10), psychology (2), geography/development (5), pharmacy (3), statistics (1), demographics (1) and nutrition (1).</p></sec><sec><title>Trainees' reaction</title><p>The evaluation by Cohort 1 of the content of each of the 16 modules of the master's programme is presented in the Additional file <xref ref-type="supplementary-material" rid="S3">3</xref>. Additional file <xref ref-type="supplementary-material" rid="S4">4</xref> presents the results of the evaluations of each lesson (Table <xref ref-type="table" rid="T2">2</xref>) of the evaluation course.</p></sec><sec><title>Trainees' learning</title><p>Both cohorts felt they had greatly improved their mastery of the 60 competences by the end of the master's programme. The differences were all positive and all statistically significant for each of the competences (Additional file <xref ref-type="supplementary-material" rid="S5">5</xref>) and for five of the six clusters (Table <xref ref-type="table" rid="T4">4</xref>). For both cohorts, the smallest gain was in interpersonal competences, but the level for this before the course was already among the highest (Fig. <xref ref-type="fig" rid="F3">3</xref>). On the other hand, reflective practice grew substantially in both cohorts.</p><fig position="float" id="F3"><label>Figure 3</label><caption><p><bold>Mean score for competences cluster for Cohort 1 only</bold>.</p></caption><graphic xlink:href="1478-4491-7-3-3"/></fig><table-wrap position="float" id="T4"><label>Table 4</label><caption><p>Differences in mean scores between points in time for competence clusters</p></caption><table frame="hsides" rules="groups"><thead><tr><td align="left"><bold>Cluster of competences</bold></td><td align="center" colspan="2"><bold>Learning</bold></td><td align="center" colspan="2"><bold>Behaviour versus Learning</bold></td></tr><tr><td></td><td colspan="4"><hr></hr></td></tr><tr><td></td><td align="center" colspan="2">After versus Before</td><td align="center">1 year After versus After</td><td align="center">1 year After</td></tr><tr><td></td><td colspan="4"><hr></hr></td></tr><tr><td></td><td align="center">Cohort 1 (N = 17)</td><td align="center">Cohort 2 (N = 19)</td><td align="center">Cohort 1 (N = 17)</td><td align="center">Cohort 1 (N = 8)</td></tr><tr><td></td><td colspan="4"><hr></hr></td></tr><tr><td></td><td align="center">Mean</td><td align="center">Mean</td><td align="center">Mean</td><td align="center">Mean</td></tr></thead><tbody><tr><td align="left">1. Professional practice</td><td align="center">1.61***</td><td align="center">1.67***</td><td align="center">0.05</td><td align="center">-0.25</td></tr><tr><td colspan="5"><hr></hr></td></tr><tr><td align="left">2. Systematic inquiry</td><td align="center">1.00</td><td align="center">1.20***</td><td align="center">-0.35</td><td align="center">-0.11</td></tr><tr><td colspan="5"><hr></hr></td></tr><tr><td align="left">3. Situational analysis</td><td align="center">1.36***</td><td align="center">1.54***</td><td align="center">0.02</td><td align="center">-0.34</td></tr><tr><td colspan="5"><hr></hr></td></tr><tr><td align="left">4. Project management</td><td align="center">1.95**</td><td align="center">1.75***</td><td align="center">-0.51</td><td align="center">-0.33</td></tr><tr><td colspan="5"><hr></hr></td></tr><tr><td align="left">5. Reflective practice</td><td align="center">1.74***</td><td align="center">1.99***</td><td align="center">-0.42*</td><td align="center">-0.41*</td></tr><tr><td colspan="5"><hr></hr></td></tr><tr><td align="left">6. Interpersonal competence</td><td align="center">1.01***</td><td align="center">0.97***</td><td align="center">-0.15</td><td align="center">-0.17</td></tr></tbody></table><table-wrap-foot><p>Note: * p &#x0003c; 0.05; ** p &#x0003c; 0.01; *** p &#x0003c; 0.001</p></table-wrap-foot></table-wrap><p>Among the 10 competences showing the greatest progression, the four that were common to both cohorts were related to the systematic inquiry cluster (2.6: "specifies programme theory"; 2.8: "develops evaluation designs") and reflective practice (5.3: "pursues professional development in evaluation"; 5.5: "builds professional relationships to enhance evaluation practice"). Among the 10 competences remaining at the lowest level, the five common to both cohorts were related to the systematic inquiry cluster (2.11: "assesses validity of data"; 2.20: "conducts meta-evaluations"); situation analysis (3.5: "addresses conflicts") and project management (4.1: "responds to requests for proposals"; 4.3: "writes formal agreements").</p><p>One year after the end of the master's programme, students of Cohort 1 felt that their level of knowledge had been maintained overall, with the exception of reflective practice (Table <xref ref-type="table" rid="T4">4</xref>). Detailed analysis of the 60 competences shows a decrease in mastery of five competences after a year (see additional file <xref ref-type="supplementary-material" rid="S3">3</xref>): 4.2 "presents work in a timely manner"; 5.3 "pursues professional development in evaluation"; 5.4 "pursues professional development in relevant content areas"; 5.5 "builds professional relationships to enhance evaluation practice"; 6.6 "demonstrates cross-cultural competence". Three of these competences are located in cluster 5 (reflective practice).</p></sec><sec><title>Trainees' behaviours</title><p>Among the 15 students of Cohort 1 who responded to the questionnaire a year later, eight (53%) had carried out evaluations, four (26%) had participated in evaluations, and three (20%) had commissioned evaluations. Students who reported having put their knowledge into practice over the intervening 12 months observed a negative gap between their declared mastery and their actual practice (Table <xref ref-type="table" rid="T4">4</xref>, Fig. <xref ref-type="fig" rid="F3">3</xref>). However, this is statistically significant only for reflective practice. A close look at all 60 competences reveals that the situation is the same for 40 of them, where there is a negative gap between declared mastery and actual practice. However, this gap is statistically significant for only two competences: 3.2: "determines programme evaluability", and 5.1: "aware of self as an evaluator" (see additional file <xref ref-type="supplementary-material" rid="S3">3</xref>).</p></sec></sec><sec><title>Discussion</title><p>A number of methodological limitations to the reported results should be mentioned. First, while our assessment was exhaustive, our sample sizes were small, and thus it is quite possible that the difference between behaviour and learning for Cohort 1 is not statistically significant (n = 8 or 7). Second, with respect to the tools, it is possible that a fatigue bias was introduced into the results of the evaluation of all the lessons and courses of Cohort 1. In the African context, where students are rarely asked to evaluate courses and teachers [<xref ref-type="bibr" rid="B27">27</xref>], a social desirability bias could also have been introduced. However, if this was the case, it would be true for all the courses and not only for the one described in this article. In addition, we believe we chose the proper instrument because "more than three decades of research on post + retrospective pretest method has unequivocally supported this approach" [<xref ref-type="bibr" rid="B25">25</xref>].</p><p>Our analysis of the teaching of programme evaluation using the process described above shows that not only was it much appreciated by the students but it also produced positive outcomes. The students gained much knowledge and the degree of mastery of competences was increased and maintained over time. The greatest progress was in competences that were very specific to programme evaluation, as opposed to those in which the students already had attained high levels (systematic inquiry and interpersonal competence). It should nevertheless be noted that the positive effects cannot be attributed solely to the evaluation course, since many other courses in the programme also reinforced certain competences that were on the list of 60. The effect, then, is that of the programme as a whole, which is not a master's degree in evaluation, but rather in population and health. The competences in which the students rated low at the end of the programme were in fact elements that were not addressed in the evaluation course or in the master's programme. That being said, students' low rating of the evaluation of data validity (2.11) should certainly be addressed rapidly by those responsible for the programme.</p><p>This double positive effect is definitely attributable in part to the skills-based teaching approach. The training in programme evaluation remained practical, dynamic and respectful of the students. This was not surprising, since most teachers in evaluation espouse this type of interactive teaching [<xref ref-type="bibr" rid="B3">3</xref>,<xref ref-type="bibr" rid="B12">12</xref>,<xref ref-type="bibr" rid="B18">18</xref>,<xref ref-type="bibr" rid="B21">21</xref>], which was also observed during an experience in Mali [<xref ref-type="bibr" rid="B28">28</xref>]. Rapid integration of the concepts into concrete exercises was an effective strategy, as was the availability of the teaching staff during the lessons. The fact that the difference in knowledge acquisition after the course in the "systematic inquiry" cluster (Table <xref ref-type="table" rid="T4">4</xref>) was not statistically significant for Cohort 1 can be explained by: (1) a very elevated pre-course self-evaluation (2.37); (2) a selection of students who had already acquired competences in their training prior to the master's programme; and (3) competences that were interdisciplinary.</p><p>With respect to level 3 (learning), the data show that it is more difficult to implement evaluation skills than to understand them. In addition, reflective practice remains the only cluster in which the reduction is statistically significant for levels 2 and 3 one year later, while improvements at the end of the master's programme were the highest (Table <xref ref-type="table" rid="T4">4</xref>). Thus, the students learned from this perspective, but it is clear that for them, as for all health professionals [<xref ref-type="bibr" rid="B29">29</xref>], reflecting in action is not the easiest thing to do. Many skills cannot be sustainably acquired in a university programme; if evaluators' skills are to improve, they must be put into practice. Also, our results suggest the importance of organizing the field of practice in evaluation with the help, for example, of the AfrEA, which could propose continuing education programmes and support reflective practice.</p><p>With regard to modalities for evaluating the students' learning, this study shows the importance of integrating summative evaluation into the learning process. From the beginning of the course, students knew the course content, how they would be evaluated at the end, and on what criteria. Transparency was essential. However, the most helpful aspect was that the knowledge and skills considered indispensable for developing an evaluation plan (as an instrument for evaluating learning) were evaluated (through practical exercises) throughout the course.</p><p>The tool for assessing evaluation competences has rarely been used, except by its creator [<xref ref-type="bibr" rid="B24">24</xref>]. In this case, we found it very useful for understanding the strengths and weaknesses of the teaching provided. It allowed us to measure the level of students' knowledge as well as those elements where there was still work to be done. However, this tool was developed in North America, and the question of whether African evaluators might not need other specific competences remains to be examined.</p></sec><sec><title>Conclusion</title><p>This study shows that skills-based teaching is feasible, much appreciated and well-adapted for a university-based evaluation training programme in a West African context. We highlight the importance of integrating summative evaluation into the learning process. Creating a master's-degree programme in population and health in Africa and providing training in evaluation to high-level health professionals from many countries augurs well for scaling up the practice of evaluation in African health systems. However, this cannot occur without significant investment being made across Africa to develop university-based and professional courses in programme evaluation.</p></sec><sec><title>Competing interests</title><p>The authors declare that they have no competing interests.</p></sec><sec><title>Authors' contributions</title><p>VR led the study, data collection and analysis, and wrote the first draft. All authors contributed to the study's conception and design and reviewed the final draft. CT did the statistical analysis. VR is a research fellow with the <italic>Fonds pour la Recherche en Sant&#x000e9; du Qu&#x000e9;bec (FRSQ)</italic>.</p></sec><sec sec-type="supplementary-material"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="S1"><caption><title>Additional file 1</title><p><bold>Drawing the perception of an evaluation (photo).</bold> Each student must produce a drawing representing his or her perception of the evaluation.</p></caption><media xlink:href="1478-4491-7-3-S1.png" mimetype="image" mime-subtype="png"><caption><p>Click here for file</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="S2"><caption><title>Additional file 2</title><p><bold>Graphic representation of the logic of an intervention (photo)</bold>. Each team of students must prepare a graphic representation of the constituent elements of a programme's logic.</p></caption><media xlink:href="1478-4491-7-3-S2.png" mimetype="image" mime-subtype="png"><caption><p>Click here for file</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="S3"><caption><title>Additional file 3</title><p><bold>Evaluation of the content of each module by the students of Cohort 1 (n = 17).</bold> Results of the evaluation by Cohort 1 of the content of each of the 16 modules of the master's programme.</p></caption><media xlink:href="1478-4491-7-3-S3.doc" mimetype="application" mime-subtype="msword"><caption><p>Click here for file</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="S4"><caption><title>Additional file 4</title><p><bold>Evaluation of the content of each lesson of the "Evaluation 3.3" module by the students of Cohort 1 (n = 17). </bold>Results of the evaluation by Cohort 1 of the content of each of each lesson of the evaluation lesson.</p></caption><media xlink:href="1478-4491-7-3-S4.doc" mimetype="application" mime-subtype="msword"><caption><p>Click here for file</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="S5"><caption><title>Additional file 5</title><p><bold>Mean differences among the 60 competences for the two cohorts</bold>. Mastery of the 60 competences by the end of the master's programme and a year later.</p></caption><media xlink:href="1478-4491-7-3-S5.pdf" mimetype="application" mime-subtype="pdf"><caption><p>Click here for file</p></caption></media></supplementary-material></sec></body><back><ack><sec><title>Acknowledgements</title><p>We extend our heartfelt thanks to all the students for their participation in this study and their interest in programme evaluation. The assistance provided by Issa Sombi&#x000e9; and Drissa Sia in data collection was also very much appreciated. The translation and the editing were done by Donna Riley. This programme is funded by the Bill and Melinda Gates Foundation. We also thank the referees for their useful comments to improve this paper.</p></sec></ack><ref-list><ref id="B1"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Mills</surname><given-names>A</given-names></name><name><surname>Bennett</surname><given-names>S</given-names></name><name><surname>Russell</surname><given-names>S</given-names></name><name><surname>Attanayake</surname><given-names>N</given-names></name></person-group><source>The challenge of health sector reform: what must governments do?</source><year>2001</year><publisher-name>Houndmills; New York: Palgrave</publisher-name></citation></ref><ref id="B2"><citation citation-type="book"><person-group person-group-type="author"><collab>OECD</collab></person-group><source>Paris declaration on aid effectiveness. Ownership, Harmonisation, Alignment, Results and Mutual Accountability</source><year>2005</year><publisher-name>Edited by DAC. Paris: DAC, OECD</publisher-name><fpage>12</fpage></citation></ref><ref id="B3"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Davis</surname><given-names>MV</given-names></name></person-group><article-title>Teaching practical public health evaluation methods</article-title><source>Am J Eval</source><year>2006</year><volume>27</volume><fpage>247</fpage><lpage>256</lpage><pub-id pub-id-type="doi">10.1177/0198214006286422</pub-id></citation></ref><ref id="B4"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Varone</surname><given-names>F</given-names></name></person-group><source>D&#x000e9;velopper les capacit&#x000e9;s &#x000e9;valuatives: &#x000e9;tudes pilotes au Congo, Niger et S&#x000e9;n&#x000e9;gal</source><year>2007</year><publisher-name>Paris: Organisation Internationale de la Francophonie</publisher-name><fpage>98</fpage></citation></ref><ref id="B5"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Rouge</surname><given-names>J-C</given-names></name></person-group><article-title>The origin and development of the African evaluation guidelines</article-title><source>New Directions for Evaluation</source><year>2004</year><volume>104</volume><fpage>55</fpage><lpage>66</lpage><pub-id pub-id-type="doi">10.1002/ev.136</pub-id></citation></ref><ref id="B6"><citation citation-type="other"><person-group person-group-type="author"><collab>Banque Africaine de D&#x000e9;veloppement</collab></person-group><article-title>Suivi et Evaluation des Strat&#x000e9;gies de R&#x000e9;duction de la Pauvret&#x000e9; dans les Pays Membres R&#x000e9;gionaux: Evaluation des Besoins en Formation</article-title><source>D&#x000e9;partement de l'Evaluation des Op&#x000e9;rations</source><year>2006</year><fpage>64</fpage></citation></ref><ref id="B7"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Kedowide</surname><given-names>F-C</given-names></name></person-group><source>&#x000c9;tude d'identification des besoins et formulation d'un document de projet de renforcement des capacit&#x000e9;s de formation en mati&#x000e8;re d'&#x000e9;valuation</source><year>2006</year><publisher-name>Ouagadougou: African Evaluation Association</publisher-name><fpage>72</fpage></citation></ref><ref id="B8"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Milstein</surname><given-names>B</given-names></name><name><surname>Chapel</surname><given-names>TJ</given-names></name><name><surname>Wetterhall</surname><given-names>SF</given-names></name><name><surname>Cotton</surname><given-names>DA</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Stockdill SH, Baizerman M, Compton D</surname></name></person-group><article-title>Building capacity for program evaluation at the Centers for Disease Control and Prevention</article-title><source>The Art, Craft, and Science of Evaluation Capacity Building New Directions for Evaluation, n&#x000b0;93, spring 2002</source><year>2002</year><publisher-name>Wiley Periodicals, Inc</publisher-name><fpage>27</fpage><lpage>46</lpage></citation></ref><ref id="B9"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ridde</surname><given-names>V</given-names></name><name><surname>Shakir</surname><given-names>S</given-names></name></person-group><article-title>Evaluation Capacity Building and Humanitarian Organization</article-title><source>Journal of MultiDisciplinary Evaluation</source><year>2005</year><volume>3</volume><fpage>78</fpage><lpage>112</lpage></citation></ref><ref id="B10"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Stockdill</surname><given-names>SH</given-names></name><name><surname>Baizerman</surname><given-names>M</given-names></name><name><surname>Compton</surname><given-names>D</given-names></name><collab>(Eds)</collab></person-group><source>The art, craft and science of evaluation building</source><year>2002</year><publisher-name>Wiley Periodicals, Inc</publisher-name></citation></ref><ref id="B11"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Rogers</surname><given-names>P</given-names></name><name><surname>Gervais</surname><given-names>M</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Ridde V, Dagenais C</surname></name></person-group><article-title>Le renforcement des capacit&#x000e9;s en &#x000e9;valuation</article-title><source>Approches et pratiques de l'&#x000e9;valuation de programme</source><year>2009</year><publisher-name>Montr&#x000e9;al: Presses de l'Universit&#x000e9; de Montr&#x000e9;al</publisher-name><fpage>193</fpage><lpage>212</lpage></citation></ref><ref id="B12"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Trevisan</surname><given-names>MS</given-names></name></person-group><article-title>Practical training in evaluation: a review of the litterature</article-title><source>Americal Journal of Evaluation</source><year>2004</year><volume>25</volume><fpage>255</fpage><lpage>272</lpage></citation></ref><ref id="B13"><citation citation-type="other"><person-group person-group-type="author"><name><surname>Baya</surname><given-names>B</given-names></name><name><surname>Lalibert&#x000e9;</surname><given-names>D</given-names></name><name><surname>Ridde</surname><given-names>V</given-names></name><name><surname>Ouedraogo</surname><given-names>D</given-names></name><name><surname>Piche</surname><given-names>V</given-names></name><name><surname>Fournier</surname><given-names>P</given-names></name><name><surname>Legrand</surname><given-names>T</given-names></name><name><surname>Albert</surname><given-names>L</given-names></name><name><surname>Sondo</surname><given-names>B</given-names></name></person-group><article-title>Le Master Population &#x00026; Sant&#x000e9; de l'universit&#x000e9; de Ouagadougou: le d&#x000e9;fi d'une approche p&#x000e9;dagogique innovante en Afrique sub-saharienne francophone</article-title><source>24e congr&#x000e8;s de l'Association internationale de p&#x000e9;dagogie universitaire Montr&#x000e9;al, Canada</source><year>2007</year></citation></ref><ref id="B14"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Morgan</surname><given-names>CJ</given-names></name><name><surname>Deutschmann</surname><given-names>PW</given-names></name></person-group><article-title>An evolving model for training and education in resource-poor settings: teaching health workers to fish</article-title><source>Med J Aust</source><year>2003</year><volume>178</volume><fpage>21</fpage><lpage>25</lpage><pub-id pub-id-type="pmid">12492385</pub-id></citation></ref><ref id="B15"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Jackson</surname><given-names>SF</given-names></name><name><surname>Ridde</surname><given-names>V</given-names></name><name><surname>Valentini</surname><given-names>H</given-names></name><name><surname>Gierman</surname><given-names>N</given-names></name></person-group><person-group person-group-type="editor"><name><surname>O'Neill M, Pederson A, Rootman I, Dup&#x000e9;r&#x000e9; S</surname></name></person-group><article-title>Canada's role in international health promotion</article-title><source>Health Promotion in Canada: Critical perspectives</source><year>2007</year><edition>2</edition><publisher-name>Toronto: Canadian Scholars Press Inc</publisher-name><fpage>222</fpage><lpage>236</lpage></citation></ref><ref id="B16"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Stevahn</surname><given-names>L</given-names></name><name><surname>King</surname><given-names>JA</given-names></name><name><surname>Ghere</surname><given-names>G</given-names></name><name><surname>Minnema</surname><given-names>J</given-names></name></person-group><article-title>Evaluator competencies in university-based evaluation training programs</article-title><source>Canadian Journal of Program Evaluation</source><year>2005</year><volume>20</volume><fpage>101</fpage><lpage>123</lpage></citation></ref><ref id="B17"><citation citation-type="other"><person-group person-group-type="author"><name><surname>Dor&#x000e9;</surname><given-names>G</given-names></name><name><surname>Marceau</surname><given-names>R</given-names></name></person-group><article-title>L'&#x000e9;valuation de programmes &#x000e0; la fonction publique qu&#x000e9;b&#x000e9;coise un profil de comp&#x000e9;tences requises</article-title><source>T&#x000e9;l&#x000e9;scope</source><year>2006</year><fpage>19</fpage><lpage>30</lpage><comment><bold>printemps &#x02013; &#x000e9;t&#x000e9;</bold></comment></citation></ref><ref id="B18"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>J</given-names></name><name><surname>Wallace</surname><given-names>TL</given-names></name><name><surname>Alkin</surname><given-names>M</given-names></name></person-group><article-title>Using problem-based learning to train evaluators</article-title><source>Americal Journal of Evaluation</source><year>2007</year><volume>28</volume><fpage>536</fpage><lpage>545</lpage><pub-id pub-id-type="doi">10.1177/1098214007305613</pub-id></citation></ref><ref id="B19"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Darabi</surname><given-names>A</given-names></name></person-group><article-title>Teaching Program Evaluation: Using a Systems Approach</article-title><source>Am J Eval</source><year>2002</year><volume>23</volume><fpage>219</fpage><lpage>228</lpage></citation></ref><ref id="B20"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Patton</surname><given-names>MQ</given-names></name></person-group><source>Creative evaluation</source><year>1987</year><edition>2</edition><publisher-name>Newbury Park, Beverly Hills, London, New Delhi: Sage Publications</publisher-name></citation></ref><ref id="B21"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Preskill</surname><given-names>H</given-names></name><name><surname>Russ-Eft</surname><given-names>D</given-names></name></person-group><source>Building evaluation capacity 72 activities for teaching and training</source><year>2005</year><publisher-name>Thousand Oaks. London.: Sage publications</publisher-name></citation></ref><ref id="B22"><citation citation-type="other"><person-group person-group-type="author"><name><surname>Renger</surname><given-names>R</given-names></name><name><surname>Titcomb</surname><given-names>A</given-names></name></person-group><article-title>A Three-Step Approach to Teaching Logic Models</article-title><source>Americal Journal of Evaluation</source><volume>23</volume><fpage>493</fpage><lpage>503</lpage></citation></ref><ref id="B23"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Kirkpatrick</surname><given-names>DL</given-names></name></person-group><source>Evaluating training programs: the four levels</source><year>1994</year><edition>1</edition><publisher-name>San Francisco, Emeryville, CA: Berrett-Koehler; Publishers Group West [distributor]</publisher-name></citation></ref><ref id="B24"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Stevahn</surname><given-names>L</given-names></name><name><surname>King</surname><given-names>JA</given-names></name><name><surname>Ghere</surname><given-names>G</given-names></name><name><surname>Minnema</surname><given-names>J</given-names></name></person-group><article-title>Establishing Essential Competencies for Program Evaluators</article-title><source>Am J Eval</source><year>2005</year><volume>26</volume><fpage>43</fpage><lpage>59</lpage><pub-id pub-id-type="doi">10.1177/1098214004273180</pub-id></citation></ref><ref id="B25"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Lam</surname><given-names>TCM</given-names></name><name><surname>Bengo</surname><given-names>P</given-names></name></person-group><article-title>A comparison of three retrospective self-reporting methods of measuring chage in instructional practice</article-title><source>Am J Eval</source><year>2003</year><volume>24</volume><fpage>65</fpage><lpage>80</lpage></citation></ref><ref id="B26"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Pratt</surname><given-names>CC</given-names></name><name><surname>McGuigan</surname><given-names>WM</given-names></name><name><surname>Katzev</surname><given-names>AR</given-names></name></person-group><article-title>Measuring Program Outcomes: Using Retrospective Pretest Methodology</article-title><source>Am J Eval</source><year>2000</year><volume>21</volume><fpage>341</fpage><lpage>349</lpage></citation></ref><ref id="B27"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Amin</surname><given-names>ME</given-names></name></person-group><article-title>Six factors of course and teaching evaluation in a bilingual university on Central africa</article-title><source>Assessment &#x00026; Evaluation in Higher Education</source><year>2002</year><volume>27</volume><fpage>281</fpage><lpage>291</lpage><pub-id pub-id-type="doi">10.1080/02602930220138633</pub-id></citation></ref><ref id="B28"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Van Dormael</surname><given-names>D</given-names></name><name><surname>Dugas</surname><given-names>S</given-names></name><name><surname>Kone</surname><given-names>Y</given-names></name><name><surname>Coulibaly</surname><given-names>S</given-names></name><name><surname>Sy</surname><given-names>M</given-names></name><name><surname>Marchal</surname><given-names>B</given-names></name><name><surname>Desplats</surname><given-names>D</given-names></name></person-group><article-title>Appropriate training and retention of community doctors in rural areas: a case study from Mali</article-title><source>Human Resources for Health</source><year>2008</year><volume>6</volume><fpage>1478</fpage><lpage>4491</lpage><comment></comment></citation></ref><ref id="B29"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Boutilier</surname><given-names>M</given-names></name><name><surname>Mason</surname><given-names>R</given-names></name></person-group><person-group person-group-type="editor"><name><surname>O'Neill M, Pederson A, Rootman I, Dup&#x000e9;r&#x000e9; S</surname></name></person-group><article-title>The reflexive practionner in health promotion: from reflection to reflexivity</article-title><source>Health Promotion in Canada: Critical perspectives</source><year>2007</year><edition>2</edition><publisher-name>Toronto: Canadian Scholars Press Inc</publisher-name><fpage>301</fpage><lpage>316</lpage></citation></ref></ref-list></back></article>